what is the definition of latent heat of fusion,"['', 'The requested URL was not found on this server.', 'In this article you will get the CBSE Class 9 Science Notes for Chapter 1 - Matter in Our Surroundings: Chapter Notes. The notes are prepared by the subject experts and are completely designed according to the latest syllabus for CBSE Class 9 Science. This article brings you the CBSE Class 9 Science notes for Chapter 1 - Matter in Our Surroundings. These chapter notes are prepared by the subject experts and cover every important topic from the chapter. In between these notes, exercise questions are provided. Students must solve these questions to test their understanding of the learned topics. These questions will help you to track your preparation level and get a hold of the subject. → Anything that occupies space and has mass is called matter. → It exists in the form of five basic elements, the Panch tatva – air, earth, fire , sky and water. → For example: Chair, bed, river, mountain, dog, tree, building, etc. → Matter is made up of small particles called atoms. → These particles are too small to be observed with naked eye. → These particles are constantly moving constantly. → These particles have spaces between them. → Particles of matter attract each other because of the force of attraction. Particles of matter intermix on their own with each other. They do so by getting into the spaces between the particles. This intermixing of particles of two different types of matter on their own is called diffusion. → When a crystal of potassium permanganate is placed in a beaker of water, the water slowly turns purple on its own, even without stirring. → Both potassium permanganate crystal and water are made up of tiny particles. → When the potassium permanganate crystal is put in water, the purple colored particles of potassium permanganate spread throughout water making the whole water look purple. → Actually, on dissolving, the particles of potassium permanganate get into the spaces between the particles of water. → This shows that the particles have spaces between them and are continuously moving on their own. → Fragrance of an incense stick (agarbatti) lightened in one corner of a room, spreads in the whole room quickly. → This also shows that the partices of matter are constantly moving. → The random or zig-zag movement of microscopic particles in a fluid, as a result of continuous bombardment from molecules of the surrounding medium, is known as Brownian motion. → For example, dust moves randomly because the random moving particles of air collide with dust particles. Constituent particles are very closely packed. Constituent particles are less closely packed. Constituent particles are far apart from each other. Force of attraction between particles is very strong. Force of attraction between particles is less strong. Force of attraction between particles is negligible. Force of attraction between particles is very strong. Kinetic energy between particles is more than that in solids. Particles have maximum kinetic energy. Have definite shape and volume. Do not have definite shape but definite volume. Neither have definite shape nor definite volume. Have high density and and can not be diffused. Density is lower than solids and can diffuse. Density is least and can easily diffuse. Incompressible. Almost incompressible. Highly compressible. Q1. What are the conditions for something to be called matter? Q2. Why do gases neither have fixed volume nor fixed shape? Q3. How does the smell of food being cooked in the kitchen reaches us even from a considerable distance? Q4. Explain why does diffusion occurs more quickly in gases than in liquids? 1. By changing the temperature 2. By changing the pressure 1. Effect of Change of Temperature: → On increasing the temperature of solids, the kinetic energy of the particles increases which overcomes the forces of attraction between the particles thereby solid gets converted to a liquid. → Melting: Change of solid state of a substance into liquid is called melting. → Melting point: The temperature at which a solid melts to become a liquid at the atmospheric pressure is called its\xa0melting point. → Melting point of ice is 0oc. → On heating a liquid like water, the kinetic energy of its particles increases as high as in a gas, thus causing the liquid to change to a gas. → Boiling: The change of a liquid substance into gas on heating is called boiling. → Boiling point: The temperature at which a liquid boils and changes rapidly into a gas at the atmospheric pressure is called its\xa0boiling point. → Boiling point if water is 100oC. → On cooling a gas like steam (or water vapour), the kinetic energy of its particles is lowered down, causing them to move slowly and bringing them closer, forming a liquid. → Condensation: The process, in which a gas, on cooling, turns into a liquid at a specific temperature is called\xa0condensation or liquefaction. → When a liquid is cooled down by lowering its temperature, its particles lose the kinetic energy and come to a stationary position, causing the liquid to turn to soilid. Freezing: The change of a liquid substance into soilid by lowering its temperature is called freezing. Freezing point: The temperature at which the state of a substance changes from a liquid to a solid is called the\xa0freezing point\xa0of that substance. Fusion:The process of melting, that is, change of solid state into liquid state is also known as\xa0fusion. Latent heat: The heat energy that is required to change the state of a substance without causing any ruse in the temperature of the substance is called latent heat. Since, the heat energy is hidden in the bulk of the matter, it is called latent heat. Note: Water vapour at 373 K have more energy than water at the same temperature becauseparticles in steam have absorbed extra energy in the form of latent heat of vaporisation. Sublimation: The change of state of a substance directly from a solid to gas or gas to solid, without changing into the liquid state, is called\xa0sublimation. 2. Effect of change of pressure → Gas to liquid: Gases can be liquefied by applying pressure and reducing the temperature. When a high pressure is applied to a gas, it gets compressed and if the temperature is lowered, the gas is liquefied. → Solid CO2\xa0gets converted directly to gaseous state on decrease of pressure to 1 atmosphere without coming into liquid state. This is the reason that solid carbon dioxide is also known as dry ice. Evaporation:The process of conversion of a substance from the liquid state to the gaseous state at any temperature below its boiling point is called\xa0evaporation\xa0or\xa0vaporisation. → Surface area: The rate of evaporation increases on increasing the surface area of the liquid. → Temperature: The rate of evaporation increases with an increase in temperature. → Humidity: Decrease in the humidity increases the rate of evaporation. → Wind speed: An increase in the wind speed increases the rate of evaporation. Evaporation causes cooling:During the process of evaporation, the particles of liquid absorb energy or latent heat of vaporisation from the surrounding to get converted to gaseous state. This absorption of energy from the surroundings make the surroundings cold.For example: The perspiration or sweating in our body keep the body temperature constant by taking away the extra heat from body as the latent heat of vaporisation. Q1. What is the common name of solid carbon dioxide? Q2. What is meant by saying that the latent heat of ice is 3.34 × 105 J/kg? Q3. State two conditions necessary to liquefy a gas. Q4. Why does temperature remain constant during the boiling of water even though heat is being supplied continuously? Q5. Why does desert cooler cool better on a hot, dry day? Q6. Why does the naphthalene balls kept in stored clothes in our home disappear over a period of time? To get more of such useful articles for the preparation of CBSE Class 9 Exam 2021-2022, click here.', 'Unlike re-circulated air, this is the total air required to completely replace the air in a room or building. A rating that measures the amount of heat your equipment delivers for every dollar spent on fuel. A higher rating indicates more efficient equipment. Equipment that simultaneously controls air temperature, relative humidity, purity and motion. An air distribution outlet or grille that directs airflow into desired patterns. The part of the central air conditioning or heat pump system that circulates heated or cooled air throughout ductwork. Some furnaces perform this function. An outdoor temperature, usually between 30° and 45° Fahrenheit, at which a heat pump’s output equals the exact heating needs of the home or business. Below the balance point, supplementary electric resistance heat must maintain indoor comfort. An air-handling device for moving air in a distribution system. The standard of measurement used for the amount of heat required to raise the temperature of one pound of water by one degree (Fahrenheit). BTUH = the number of BTUs per hour. Heat that flows into a space from outdoors and/or indoors. The measure of a unit’s ability to remove heat from an enclosed space. The COP, or Coefficient of Performance, of a heat pump measures the ratio of the rate of useful heat output that the pump delivers (excluding supplementary heating) to the corresponding rate of energy input. Part of a refrigerating mechanism that pumps in vaporized refrigerant from the evaporator, compresses it, liquefies it in the condenser and returns it. A series or network of refrigerant tubes typically placed outside a home or business that removes heat from the hot, gaseous refrigerant and re-liquefies it. Known as “the heart of the system” because it circulates the refrigerant through the loop, the compressor moves the refrigerant from the indoor evaporator to the outdoor condenser, then back to the evaporator. The ability of a heating or cooling system to function in a given amount of space. Heating = BTUs. Cooling = tons. A system that treats air at a central location and carries it to and from rooms by one or more fans and a system of ducts. A heat-pump system that uses a loop of buried plastic pipe as a heat exchanger. Loops can be horizontal or vertical. Building-wide air delivery conducted through pipes or channels. A heating and air conditioning system that usually has a wall-mounted indoor unit and an outside compressor. It does not require ductwork. Used for conducting air to and from an air-handling unit via a pipe or closed conduit made of materials such as sheet metal or fiberglass board. Draws in return air from the top and expels warm air at the bottom. A device for recovering superheat from the compressor discharge gas of a heat pump or central air conditioner for use in heating or preheating water. The reduction of water vapor by cooling the air below the dew point, as well as the removal of water vapor from air by chemical means, refrigeration, etc. The removal of ice or frost buildup from the outdoor coil during the heating season. Found in ductwork, this movable plate opens and closes to control airflow and is used in zoning to regulate airflow to certain rooms. Method of cooling that uses water evaporation to cool warm air. Located inside the home or business, a series or network of tubes filled with refrigerant that removes heat and moisture from indoor air as liquid refrigerant evaporates. Absorbs heat or liquid from the surrounding air and moves it outside the refrigerated area by means of a refrigerant. Also known as a cooling coil, blower coil, chilling unit or indoor coil. The ratio of an air conditioning unit’s cooling capacity in BTUs per hour to the total electrical energy consumed in watts. The backup heat built into a heat pump system. Type of air purifier that uses electrically charged filters to minimize airborne contaminants. A fuel-efficiency rating similar to the miles-per-gallon rating on your car. The part of the system that converts gas, oil, electricity or another fuel into heat for distribution within a structure. R22 refrigerant, also known as Freon, has been the HVAC industry standard refrigerant used in the manufacture of central air conditioning systems. Because R22 refrigerant contributes to depleting the ozone layer, the U.S. government has enacted a policy requiring that air conditioners and heat pumps no longer use R22 refrigerant.  If your existing AC system has R22 refrigerant, it can be serviced and, if necessary, recharged up to January 1, 2020. However, after January 1, 2020, refrigerant manufacturers must cease all production of R22 refrigerant completely.  If you are purchasing a new air conditioning system today, consider one that uses the more environmentally friendly R410A refrigerant. A device that removes dust and other air particles to comfort the respiratory system and protect the heating and cooling equipment. The higher the MERV rating, the better the filter. A heat pump that uses the earth as a heat source in the winter or a heat sink in the summer. Geothermal systems use a series of water loops that move heat to and from the ground. The amount of moisture in the air. Air conditioners remove moisture for added comfort. Regulates humidity input by reacting to moisture content changes in the air. The process of adding moisture to the air within a space. Heating, Ventilation and Air Conditioning. A sideways furnace that draws in return air from one side and expels warm air from the other. The rate at which a specific device can add substantial heat to a substance, expressed in BTUH (British Thermal Units per hour). The total heating output of a heat pump in BTUs during its normal usage period for heating, as divided by the total electrical energy input in watt-hours during the same period. The movement of heat from one place to another, between two substances or within a substance. Airflow into a space usually through walls and leaks around doors and windows. Insulation: Any material that reduces the speed of heat transfer. A refrigerant containing a portion of a fan coil unit similar to a car radiator, typically made of several rows of copper tubing with aluminum fins. Usually located inside the house, it houses the indoor coil, fan, motor and filtering device, sometimes called the air handler. Equal to 1,000 watts of electricity, a kilowatt-hour (kWh) is a common unit of electrical consumption measured by the total energy that one kilowatt creates in an hour. Determines a building’s heat gain and loss to ensure installation of properly sized air conditioning and heating equipment. An air conditioning system’s capability to remove moisture from the air. Latent Heat: The heat energy needed to change the state of a substance (e.g., from a liquid to a gas), but not its temperature. A heating and cooling system consisting of products certified to perform at promised comfort and efficiency levels when used together, in accordance with design and engineering specifications. A furnace with natural airflow around it that supports combustion. It depends on the pressure that heat creates in the flue gases to force them out through the vent system. The portion of a heat pump or central air conditioning system located outside the home. It functions as a heat transfer point for collecting heat from and dispelling heat to the outside air. A heat-pump system that uses groundwater from a well or surface water from a lake, pond or river as a heat source. The water is returned to the environment. The day-to-day cost of running your home comfort equipment, based on daily energy use. A general measure of your home comfort system’s efficiency and value. By combining your purchase price with ongoing operating costs, it determines the number of years required before monthly energy savings offset the purchase price. A device in a heat pump that reverses the flow of refrigerant as the system switches from cooling to heating. Air drawn into a heating unit after having been circulated from the heater’s output supply to a room. Wine cellars that are cooled separately from the rest of the home. The ratio of the amount of vapor contained in the air to the maximum amount the air could hold at that temperature, usually expressed as a percentage. Combination grille and damper assembly covering an air opening or end of an air duct. Set of two copper lines connecting the outdoor unit and the indoor unit. A substance that produces a refrigerating effect while expanding or vaporizing. Type of heating that can be combined with geothermal systems to warm a home’s floors. Auxiliary or emergency heat, usually electrical resistance heat, provided at temperatures below a heat pump’s balance point. The most common type of home central air conditioner, it consists of a compressor (the unit and condenser, installed outside the building) and a non-compressor (the air-handling unit installed within the building). A year-round heating and air conditioning system with all components encased in one unit outside the home. The temperature at which a thermostat is set for desired comfort level. Heat energy that raises or lowers the temperature of a gas, liquid or solid when added or removed from that material. An air conditioning system’s capability to reduce the temperature by removing heat from the air. A rating that denotes the efficiency of air conditioning equipment in terms of the amount of cooling your equipment delivers for every dollar spent on electricity. The higher the SEER, the more efficient the unit and the lower the operating cost. A brand of air conditioning systems used by AGL Services. The unit of measure used in air conditioning to describe the cooling capacity of a system. One ton of cooling is based on the amount of heat needed to melt one ton (2,000 lbs.) of ice in a 24-hour period, and equals 12,000 BTUH. A temperature control device, typically found on an inside wall, that consists of a series of sensors and relays for monitoring and controlling a heating and cooling system. A type of light that can be used to kill mold on the evaporator coil of a cooling system. A furnace that pulls return air in from the bottom and expels warm air from the top. A type of air conditioning system that discharges air into the conditioned space via a top- mounted discharge plenum or through an overhead duct system. The process of supplying or removing air, by natural or mechanical means, to or from any space. Such air may or may not have been conditioned. A barrier essential to prevent moisture from infiltrating into, or migrating from, a data processing center or other “critical space” that contains sensitive electronic instrumentation. Vapor barriers may be created using plastic film, vapor-retardant paint, vinyl wall coverings and vinyl floor systems, in combination with careful sealing of all openings (doors and windows) into the room. A moisture-resistant layer applied to the surfaces of humid spaces that prevents moisture from traveling to a point where it might condense due to lower temperature. A unit of power that equals one joule per second. Named after the Scottish inventor and mechanical engineer James Watt. A brand of geothermal and water source heat pumps used by AGL Services. The practice of providing independent heating and/or cooling to different areas within a structure. A method of dividing a home into zones that makes it possible to control the amount of comfort provided to each. © Copyright 2023 AGL Heating and Air. Web design by\xa0The Design Group', '[ A ]AbatementReduction or removal of a contaminant.Absolute HumidityIt is the ratio of the mass of water vapor to the unit volume of moist air represented in grams per cubic foot (g/ft3).Absolute ZeroTemperature at which all molecular motion ceases (-460 F. and -273 C.).Absorption RefrigeratorRefrigerator which creates low temperature by using the cooling effect formed when a refrigerant is absorbed by chemical substance.ACCAAir Conditioning Contractors of America – a leading HVAC/R Association.Acceptable indoor air qualityIndoor air that does not contain harmful concentrations of contaminants; air with which at least 80% of building occupants do not express dissatisfaction.AccumulatorStorage tank which receives liquid refrigerant from evaporator and prevents it from flowing into suction line before vaporizing. Tank on the suction side of a system that holds excess refrigerant to prevent slugging the compressor with liquid.ACHAir Changes Per Hour. The number of times that air in a house is completely replaced with outdoor air in one hour.Acid Condition In SystemCondition in which refrigerant or oil in system is mixed with fluids that are acid in nature.ACR TubingTubing used in air conditioning and refrigeration. Ends are sealed to keep tubing clean and dry.Activated CarbonSpecially processed carbon used as a filter drier ; commonly used to clean air.ActuatorThat portion of a regulating valve which converts mechanical fluid, thermal energy or electrical energy into mechanical motion to open or close the valve seats.Adiabatic CompressionCompressing refrigerant gas without removing or adding heat.Adjustable GrilleA grille with linear blades which can be adjusted to vary the direction of the discharged air. The linear blades are normally either vertical or horizontal, or both horizontal and vertical.AdsorbentSubstance with the property to hold molecules of fluids without causing a chemical or physical damage.AerationAct of combining substance with air.AFLU (Annual Fuel Utilization Efficiency)A rating that reflects the efficiency of a gas furnace in converting fuel to energy. A rating of 90 means that approximately 90% of the fuel is utilized to provide warmth to your home, while the remaining 10% escapes as exhaust.AFUE (Annual Fuel Utilization Efficiency)This number represents how efficiently a furnace converts fuel to energy. The ratio of annual output of useful energy or heat to the annual energy input to the furnace. The higher the AFUE, the more efficient the furnace — higher efficiency translates to more savings on fuel bills. This will range from 80% to 95%. Percentage of fuel used for heating. A measure of heating efficiency, in consistent units, determined by applying the federal test method for furnaces. This value is intended to represent the ratio of heat transferred to the conditioned space by the fuel energy supplied over one year.Air ConditionerDevice used to control temperature, humidity, cleanliness and movement of air in a confined space.Air ConditioningControl of the temperature, humidity, air movement and cleaning of air in a confined space.Air DiffuserAir distribution outlet or grille designed to direct airflow into desired patterns.Air Exchange RateThe rate at which outside air replaces indoor air in a space. Expressed in one of two ways: the number of changes of outside air per unit of time in air changes per hour (ACH); or the rate at which a volume of outside air enters per unit of time – cubic feet per minute (cfm).Air HandlerThe portion of the central air conditioning or heat pump system that moves heated or cooled air throughout a home’s ductwork. In some systems a furnace handles this function.Allergens and PathogensBiological material, including bacteria, viruses, fungi, mold spores, pollens, skin flakes and insect parts are ubiquitous in indoor environments. These particulates range from less than one to several microns in size. When airborne, they are usually attached to dust particulates of various sizes so that all sizes of airborne particulates may include them.AmbientThe surrounding atmosphere; encompassing on all sides; the environment surrounding a body but undisturbed or unaffected by it.Ambient AirThe air surrounding a building; outside air.Ambient Air TemperatureSurrounding temperature, such as the outdoor air temperature around a building.Ampere (A or Amp)The primary unit of measurement of electrical current. Amps multiplied by Volts determines Watts. Electricity bills are based on watts or kilowatts (a thousand watts) per hour.ARIAir-Conditioning and Refrigeration Institute is a nonprofit, voluntary organization comprised of heating,air conditioning and refrigeration manufacturers. ARI publishes standards for testing and rating heat pumps and air conditioners to provide you with a standardized measure of comparison. So, ARI ensures a level of performance within the industry.ASHRAEA leading HVAC/R Association – American Society of Heating, Refrigerating and Air Conditioning Engineers – http://www.ashrae.org/ The trade association that provides information and sets standards for the industry.ASTMAmerican Society for Testing and Materials. This message is only visible to admins.Problem displaying Facebook posts.Click to show errorError: (#200) Provide valid app IDType: OAuthException Problem displaying Facebook posts.Click to show error Larry S. Brenda R. Luis C. Mukhtar B. The Wells Fargo Home Projects® credit card is issued by Wells Fargo Bank, N.A. with approved credit. Apply for the Wells Fargo Home Projects® credit card by selecting the button below. We are LICENSED, BONDED, AND INSURED and proud members of the Sherman Chamber of Commerce. © copyright 2023 Markl & Sons Cooling & Heating. All Rights Reserved.']","Latent heat can be understood as heat energy in hidden form which is supplied or extracted to change the state of a substance without changing its temperature. Examples are latent heat of fusion and latent heat of vaporization involved in phase changes, i.e. a substance condensing or vaporizing at a specified temperature and pressure."
where did the tradition of an inaugural address come from,"['The page you are looking for might have been removed, had its name changed or is temporarily unavailable. © Copyright  Best Brains. We use cookies to ensure that you got the best experience on our website.  I accept', 'The 4th of July was indeed a major event for it set in motion the rebellion against a corrupt form of government (then known as monarchy) which was dominated by unelected bureaucrats. The American Revolution set off a contagion that manifested in Europe with the French Revolution beginning on the\xa0July 14, 1789. The\xa0first inauguration of\xa0George Washington\xa0took place on\xa0April 30, 1789. So if we take the Cycle of Political Change from 1789, that brings us up to a rather important event of a national hero who was called a traitor and risked being killed or imprisoned for life, exactly as King George III declared. George III declared Thomas Jefferson and everyone else who signed the Declaration of Independence, which Jefferson wrote, a traitor. Snowden could only go to Russia for security for any other country would have turned him over. George III sent an entire army to personally capture Jefferson and hang him. Fortunately, he was warned that an entire army was converging on his home and he had time to flee. That hero reappeared on\xa0May 20, 2013, precisely 224 years on cue from 1789. That hero is\xa0Edward Snowden\xa0for what he revealed was not just that the United States was unconstitutionally violating every right of every American citizen; it was a worldwide cooperation among nations to hunt down their own people because they could feel the reins of power slipping from their grip. They say history produces the heroes we need at critical moments; perhaps this is true. One is hard-pressed to find so many brilliant minds coming together, as was the case in 1776, as we saw with people like Jefferson, Ben Franklin, James Madison, and even Thomas Paine whose words moved a nation along with those of Patrick Henry –\xa0Give Me Liberty or Give Me Death. Hopefully, there will be others who step forward over the next four years to lend a hand once again. We face a very dark new age of totalitarianism where government is crushing all rights to preserve their privileges and power.', 'Looks like something went wrong.', 'Barack Obama will be inaugurated in front of hundreds of thousands of people on Jan. 21, but here\'s a little secret: That\'s just ceremonial. He will actually be sworn in 24 hours beforehand, in what is sure to be a much smaller ceremony. That\'s because the Constitution\'s 20th Amendment specifies that a presidential term begins on Jan. 20 each year. Since that date falls on a Sunday, the big production was pushed back a day. Which means when Obama puts his hand on the Bible in front of a national TV audience and repeats after Chief Justice John Roberts, it will just be a rerun. For an event that\'s essentially etched in stone every four years, the history behind the inauguration date is surprisingly fascinating. It\'s moved up more than three months since\xa0George Washington\'s first in April 1789, but despite mind-blowing advancements in technology, there\'s still nearly a three-month gap between election day and inauguration day. And experts say that gap isn\'t likely to shrink. Our first presidential election began on Dec. 15, 1788, and voting didn’t end until Jan. 10. Though George Washington\'s victory was a forgone conclusion, it wouldn\'t be confirmed for weeks to come. ""The long struggle to ratify the Constitution delayed the selection of the Electoral College until January 1789 and the electors did not meet in their state capitals until March,"" said John Ferling, author of \'The Ascent of George Washington: The Hidden Political Genius of an American Icon.\' ""The Senate then had to count the ballots, and that was not done until early April."" Washington got word of his election on April 14, and arrived in New York on April 23. A week later, on April 30, he was inaugurated. Even though Washington wasn\'t inaugurated until April, his first term technically ended four years after the Constitution was ratified. So for Washington\'s second term -- and every inauguration for the next 144 years -- Inauguration Day was held on March 4, the anniversary of the Constitution\'s ratification (or March 5, if the 4th fell on a Sunday). Though this shaved 47 days off the interregnum (the period between the election and the inauguration), the nation would still find itself saddled with a lame duck president for months on end. When Abraham Lincoln was elected president on Nov. 6, 1860, the nation was teetering on the brink of war, and it would be four months before he could take the reins. During that time, seven states seceded, formed the Confederate States of America, and, two weeks before Lincoln\'s inauguration, selected Jefferson Davis as their own president. It would take another nation-defining crisis before anyone would do anything to address the issue. In 1932, with the Great Depression crushing the economy, Sen. George Norris, an independent from Nebraska, proposed what became known as the ""Lame Duck"" amendment, seeking to move up inauguration day to Jan. 20. ""He was very coy during that interregnum, where Hoover was trying to get him to sign on and start wielding authority before he had authority,"" Clark said. ""And FDR, politically, did not want to be boxed in by being seen to endorse the policies… to avoid the perception that (he) was in any way responsible for what was going on."" Eighty years later, with the advent of the Internet and private jets, the outcome of a presidential election is usually known hours after polls close, and the president-elect can get to D.C. by noon the following day. But presidential inaugurations are still held on Jan. 20 -- exposing America to nearly three months of lame duck presidency. Bruce Ackerman, Sterling Professor of Law and Political Science at Yale University, says this is due to vagaries of the Electoral College, a system he described as ""ridiculous"" and ""antiquated."" Ackerman, who worked for Al Gore during the disputed 2000 election, says the Electoral College requires time to mitigate disputes in close elections. ""You need time to resolve this,"" Ackerman said. ""The statute at the present time requires, if the states want to have the returns unchallenged at subsequent proceedings, they have to hand them in by the middle of December."" Ackerman said we should look to the rest of the world to find a system of Democratic elections that is fast and efficient. ""See how the French do it,"" he said. ""If you look at any modern democracy other than ours, just copy their system. It has all the features you\'re describing."" In France, from election day to inauguration takes about 24 days, and that\'s despite often having a second round of voting in between. Think how nice it\'d be to hold the Inaugural parade on Nov. 30, when the average temperature in DC is a balmy 52. But be prepared to actually watch that parade in chilly January weather.', ""The President of the United States is the elected head of state and head of government of the United States. The president leads the executive branch of the federal government and is the commander-in-chief of the United States Armed Forces. The president is indirectly elected to a four-year term by the people through an Electoral College (or by the House of Representatives, should the Electoral College fail to award an absolute majority of votes to any person). Since the office was established in 1789, 43 people have served as president. The first, George Washington, won a unanimous vote of the Electoral College. Grover Cleveland served two non-consecutive terms in office, and is counted as the nation's 22nd and 24th president. William Henry Harrison spent the shortest time in office, dying 31 days after taking office in 1841. Franklin D. Roosevelt served the longest, over twelve years, before dying early in his fourth term in 1945; he is the only president to have served more than two terms. Since the ratification of the Twenty-second Amendment to the United States Constitution in 1951, no person may be elected president more than twice, and no one who has served more than two years of a term to which someone else was elected may be elected more than once.[1] The current president is Barack Obama, and the president-elect is Donald Trump,[2] whose term of office will commence on January 20, 2017. Of the individuals elected as president, four died in office of natural causes (William Henry Harrison,[3] Zachary Taylor,[4] Warren G. Harding,[5] and Franklin D. Roosevelt), four were assassinated (Abraham Lincoln,[6] James A. Garfield,[6][7] William McKinley,[8] and John F. Kennedy), and one resigned (Richard Nixon).[9] John Tyler was the first vice president to assume the presidency intra-term, and set the precedent that a vice president who does so becomes the fully functioning  president with his own presidency, as opposed to a caretaker president. The Twenty-fifth Amendment to the Constitution put Tyler's precedent into law in 1967. It also established a mechanism by which an intra-term vacancy in the vice presidency could be filled. Richard Nixon was the first president to fill a vacancy under this Provision when he appointed Gerald Ford to the office. Later, Ford became the second to do so when he appointed Nelson Rockefeller to succeed him. Previously, an intra-term vacancy was left unfilled. Presently, there are four living former presidents. The most recent death of a former president was that of Gerald Ford (served 1974 to 1977) on December 26, 2006 (aged 93 years, 165 days). The most recently serving president to die was Ronald Reagan (served 1981 to 1989) on June 5, 2004 (aged 93 years, 120 days). Jimmy Carter currently holds the record for having the longest post-presidency of any president. Four presidents held other high U.S. federal offices after leaving the presidency. Additionally, several presidents campaigned unsuccessfully for other U.S. state or federal elective offices after leaving the presidency."", '', 'Federal Hall National Memorial, currently administered by the National Park Service, has always been a popular landmark with tourists thanks to its position on one of the most photographed intersections in New York. Who can resist that noble statue of George Washington silently meditating on the financial juggernaut of Wall Street? In 2015 Federal Hall was officially named an official American National Treasure, part of the ongoing Saving Places program by\xa0National Trust for Historic Preservation\xa0calling attention to endangered landmarks of national significance. (The following article was originally posted that year in honor.) It joins an impressive hodgepodge of local landmarks such as South Street Seaport, the Lower East Side Tenement Museum and the Whitney Studio. While this sounds like a distinction that might pique the interest of Nicolas Cage — after all, he broke into Trinity Church up the street in the first National Treasure film — the National Treasure program gives a boost to historic places that may be otherwise neglected or under-appreciated. When’s the last time you were there? 1. This isn’t the real Federal Hall\xa0The original structure was built in 1699, built by the British who used materials from\xa0the city’s demolished north defense wall — aka the wall of Wall Street — to construct it.\xa0It was the center of most governmental functions, from city administration to later federal functions. 2. That Federal Hall was remodeled by a controversial architect.\xa0Pierre Charles L’Enfant, a successful city contractor and former Continental Army engineer redesigned the structure in time for its use as the first national capital. According to David McCullough, it was the first building in America designed to exalt the national spirit, in what would come to be known as the Federal style. Lâ’Enfant would later work on the creation of Washington DC from Maryland swampland and be fired from that project by George Washington. 3. George Washington was first inaugurated here on April 30, 1789. The King James bible he was sworn in with — property of a New York Freemason lodge — is still at Federal Hall. 4. The original Federal Hall was torn down in 1812 when city administration moved to the new City Hall.\xa0 Its materials were sold off to make other buildings in the city. 5. The current Federal Hall is actually the original U.S. Custom House which opened in 1842, replacing a structure used for that purpose at 22-24 Wall Street. 6. The offices of the Custom House again moved in 1855, and the building was used as the U.S. Sub-Treasury building. In 1913 it became the first place in New York to buy the original buffalo nickel. Below: Suffrage proponents Mrs. W.L. Prendergast, Mrs. W.L. Colt, Doris Stevens, Alice Paul stop in front of Federal Hall 7. In 1918 Charlie Chaplin and Douglas Fairbanks famously drew thousands to the steps of Federal Hall to promote the sale of war bonds. Later that year doughnuts were auctioned off from its steps as a war fund-raiser. 8. In 1920 a wagon full of dynamite exploded across the street from the Sub-Treasury, killing 38 people in what is today still an unsolved mystery. 9. The Sub-Treasury had moved out by the 1930s, and the building was officially re-opened as the Federal Hall Memorial Museum in January 1940. It was inspired in part by America’s celebration of the 150th anniversary of Washington’s inauguration. The\xa01939-40 World’s Fair presented a replica of the original Federal Hall even after an earlier version of Federal Hall in Bryant Park failed to attract visitors. 10. Federal Hall received a massive renovation in 2006 after the collapse of the World Trade Center in 2001 weakened the foundations of the building. Check out the official announcement at the website for the National Trust for Historic Preservation. Top image by the Wurts Brothers, taken in 1908. Courtesy Museum of the City of New York Hi! Enjoyed the Federal Hall blog post. For #9, if the building reopened as a memorial museum in 1940, wouldn’t that have been to commemorate the 150th anniversary of Washington’s inauguration, not the 225th? I think we would’ve celebrated the 225th last year in 2014. Either way, great blog and podcasts. Keep up the great work! Your email address will not be published. Required fields are marked * Save my name, email, and website in this browser for the next time I comment. Looking for the latest episode of our podcasts? Listen now on iTunes to “The Bowery Boys” and “The First”. Find recent podcast episodes here, and click to read more about listening options here. Find out how you can support the production of the Bowery Boys Podcast.']","The first inauguration, that of George Washington, took place on April 30, 1789. All subsequent (regular) inaugurations from 1793 until 1933, were held on March 4, the day of the year on which the federal government began operations under the U.S. Constitution in 1789. The exception to this pattern being those years in which March 4 fell on a Sunday. When it did, the public inauguration ceremony would take place on Monday, March 5. This happened on four occasions, in 1821, 1849, 1877, and 1917. Inauguration Day moved to January 20, beginning in 1937, following ratification of the Twentieth Amendment to the Constitution, where it has remained since. A similar Sunday exception and move to Monday is made around this date as well (which happened in 1957, 1985, and 2013)."
a primary purpose of the law enforcement assistance administration (leaa) was to,"['Reading of the death of former pro boxer Rubin “Hurricane” Carter today awoke an old memory which reminded me how lucky I was to have, what in retrospect, was a pretty cool father.\xa0 I should add by “cool” I do not mean some kind of “over the hill hipster” who, in a desperate attempt at trying to stay relevant smokes pot or acts in some other immature, out of character way.\xa0 No, I merely mean a father, that despite whatever busy schedule he may have, when he senses that something is of importance, at least to his kid, takes the time to listen and if possible, act on his child’s request or concern. The time was the mid-late70’s (circa 1976-77) and my father had a new job working for the LEAA after years working as chief counsel of a Senate Judiciary subcommittee and later as a staff counsel for the full judiciary committee.\xa0 The Law Enforcement Assistance Administration (LEAA) was a short-lived U.S. federal agency within the Justice Department.\xa0 It administered federal funding to state and local law enforcement agencies, and funded educational programs, research, state planning agencies and local crime initiatives.\xa0 My father really had no qualifications for working for the LEAA other than being one of the principal authors of the Senate’s Amendment to the Omnibus Crime Control Act and needing a job. At the time I was a long haired, anti-establishment teenager with a new favorite lp, Bob Dylan’s “Desire”.\xa0 My motivation for purchasing this album was the wordy but endearing protest song which was the album’s featured single, “Hurricane” written by Bob Dylan and Jacques Levy: The D.A. said he was the one who did the deed Like any teenager with a new record, “Desire” was in heavy rotation and much like the songs off my early Springsteen collection, “Hurricane” was one of those songs you had to memorize the lyrics to. \xa0(My poor parents!) \xa0So after about a month of this constant barrage I honestly can’t remember who approached whom, whether I asked my Dad or Dad came to me and said something like”…if you just stop playing that damn song, I’ll see what I can find out…”. \xa0Which ever it was, in retrospect it was pretty damn cool of the old man and I know it did not win him many friends at his new job poking around this subject with state and federal law enforcement officials. Out of respect to the friends and family of Mr. Carter and in all fairness, I will not repeat the hearsay my father reported back to me other than to confirm the early acknowledgment by those in law enforcement (F.B.I.) of serious problems with the State’s case. \xa0The thing that is important to me today, some 15 years after my father’s passing, is what a cool thing that was for my Dad to do for his son. \xa0RIP Rubin. \xa0I’m so glad you got out of that cell. Help us continue to keep our web content free and accessible to all – without paywalls or invasive pop-up ads. Your support is important because it helps us cover our costs so that we can continue bringing you the independent music journalism you know and trust. Please consider subscribing or donating to No Depression now. Sign up for our twice-weekly email newsletter for roots music reviews, stories, columns, and more from No Depression. We respect your privacy and will never sell our email list to a third party.', '', '', '', 'Teach.com / Online Education / Government Degrees / Online Master of Public Administration Programs (MPA) If you’re interested in contributing to changes in the political, socio-economic or educational landscape by implementing policies and developing programs, then a career in public administration might be for you. A Master of Public Administration (MPA) degree prepares students for public service, nonprofit management and executive roles on the local, state and federal levels. This includes government service, education, community management and more. Known as an MPA degree, this educational qualification is common among mid-career professionals—and it’s possible to obtain one online. Enrolling in an online degree in public administration may allow individuals to continue earning an income while preparing for future professional plans. Some MPA programs may require you to participate in field internships to hone your administrative, policy-making, communication and research skills. Syracuse’s online MPA for Executives program prepares mid-career professionals for leadership and management roles in public service. The program can be completed in as few as 15 months. No GRE required. Syracuse’s online MPA for Executives program prepares mid-career professionals for leadership and management roles in public service. The program can be completed in as few as 15 months. No GRE required. Lead in government, lead for communities. Earn your MPA online from UNC-Chapel Hill’s nationally ranked program in as few as 18 months. Lead in government, lead for communities. Earn your MPA online from UNC-Chapel Hill’s nationally ranked program in as few as 18 months. Before you apply to online MPA programs, make sure you contact the institutions you’re interested in for information about any prerequisites. You’ll also want to start thinking about ways to finance your education, with options like MPA scholarship opportunities. Not all online MPA programs require GRE test scores for admission. In recent years, a number of institutions have dropped the GRE requirement because they don’t see a big enough correlation between test results and a student’s ability to succeed in their program. While several universities don’t require GRE test scores from online MPA program applicants, others make the GRE optional or waive the requirement for students with professional experience or a high GPA. Now you know the answer to the question, “What is an MPA?” But what MPA courses can you expect in a graduate program? The curriculum and number of credits required to earn a master’s degree vary widely depending on the school and specialization. An online MPA program prepares graduates to tackle challenges facing the public and provide policy recommendations that foster change. An online MPA program may include courses in: A master’s degree in public administration doesn’t limit professionals to one sector. Aside from the core courses required at universities, there are several common specializations or concentrations including: Online MPA programs can take different forms, but typically require the same coursework. Core courses typically emphasize policy research, economics and statistical analysis—and programs also offer students the opportunity for specialization. Aspiring public administration professionals have a variety of government degrees to choose from. Other options are executive programs, which are designed for mid-career professionals, and dual degree programs, which may simultaneously focus on public administration and public health. An executive MPA, or EMPA, might be a good option for working professionals who have years of experience in their chosen field and want to take an accelerated path to obtain an MPA. While MPA students might be fresh out of undergraduate school, EMPA students typically have prior leadership experience in public administration. An EMPA requires around 27 to 33 credits and takes up to two years to complete, while an MPA typically requires more than 30 credits and can take up to four years to complete. Both require a bachelor’s degree. One of the main differences between a Master of Public Administration and a Master of Public Policy is that an MPA degree allows you to manage programs that serve the public, while an MPP focuses on creating policies that drive those programs. One of the main differences between a Master of Public Administration and a master’s in urban planning is that an MPA program may provide you with a broad understanding of political systems, while a MUP degree focuses on designing cities and regions. One of the main differences between a master’s in public administration and a master’s in business administration is that an MPA degree holder will use their expertise to drive change in government and nonprofits, while an MBA graduate will usually utilize their business and management skills in the private sector, across industries. Both require knowledge of balancing budgets and managing people. One of the main differences between a JD and MPA is that the JD, or Juris Doctor, is a professional degree in law and an MPA equips graduates with skills to oversee and implement government-funded programs. Those who earn a JD can take the state bar examinations and practice as lawyers in a wide range of industries. The focus of a master’s in public administration and a master’s in international relations (IR) differ in a number of ways. While both programs are designed to prepare professionals for leadership roles in government, an MPA tends to be domestic in focus. In contrast, the IR degree is designed for practice transcending borders, aiming for a greater understanding of how international events are affected by domestic policy decisions. A primary difference between an MPH and MPA is that a master’s in public administration focuses on governance, while a master’s in public health focuses on health, specifically the health of populations. After completing an online MPA program, there are a number of MPA careers you can pursue, some with licensing requirements. If applicable, confirm the licensing requirements for your desired role with your state board. Aspiring MPA professionals can study to work in diverse sectors, like nonprofits, government, education, health care or the private sector. Learn more about some options below: After you’ve chosen the best online MPA program for you, you may still have some unanswered questions. Here are some frequently asked questions about online MPA degrees: You’ve decided to study public administration, but how long does an MPA take to complete? Some students are busy with professional commitments, internship requirements and other responsibilities—so many schools offer flexibility in the amount of time it takes to complete graduate programs in public administration. While MPA programs vary, on average, full-time students can earn their MPA in two years. Some programs may offer accelerated options that allow students to earn their degree at a faster rate. Accreditation status is an important consideration for prospective students, both at the undergraduate and postgraduate levels. Colleges and universities receive accreditation from agencies recognized by the U.S. Department of Education in a process that involves an extensive review of a school’s educational programs and student services. A school’s or program’s accreditation generally ensures high-quality course material and qualified teachers. Apart from what’s included in the curriculum, potential employers may prefer to hire candidates with degrees accredited by a credible agency like the Network of Schools of Public Policy, Affairs, and Administration (NASPAA). If you choose to earn an MPA online, the program will usually cover the same material as the in-person option, no matter the school. However, the platform and method of communication functions differently to accommodate remote learning. Some factors to consider before enrolling in an online MPA program include:\xa0Demand. Individuals studying public administration and management may look forward to joining growing career fields. For example, employment of education administrators is projected to grow 8% from 2020 to 2030, according to the Bureau of Labor Statistics.Work/life balance. Earning an online MPA allows students to balance work, class and other responsibilities.\xa0Learning environment. Many students find the option of taking classes remotely to be favorable, as they may be more comfortable learning in the intimate setting that online classrooms provide. While each online MPA program is different, they all expose students to the laws and regulations that directly and indirectly impact the financing of public programs, the intricacies of government relations and political leadership. It’s up to you to decide what kind of program fits you best based on your educational and financial needs. Teach.com has compiled a comprehensive list of all the online Master of Public Administration programs in the United States along with GRE requirement information, degree type and credit requirements. In searching for the online MPA program that best fits your needs, carefully consider the structure of the coursework and the admissions requirements to make your decision. Find a school that interests you and learn about what it takes to graduate with an online Master of Public Administration. Last updated April 2022. edX.org Teach.com is owned and operated by 2U, Inc., the parent company of edX']","The Law Enforcement Assistance Administration (LEAA) was a U.S. federal agency within the U.S. Dept. of Justice. It administered federal funding to state and local law enforcement agencies and funded educational programs, research, state planning agencies, and local crime initiatives as part of President Lyndon B. Johnson's war on crime."
where did the name machu picchu come from,"['Machu Picchu (Quechua: Machu Pikchu) is a 15th-century Inca citadel situated on a mountain ridge 2,430 metres (7,970 ft) above sea level. It is located in the Cusco Region, Urubamba Province, Machupicchu District in Peru, above the Sacred Valley, which is 80 kilometres (50 mi) northwest of Cuzco and through which the Urubamba River flows. Most archaeologists believe that Machu Picchu was constructed as an estate for the Inca emperor Pachacuti (1438–1472). Often mistakenly referred to as the ""Lost City of the Incas"" (a title more accurately applied to Vilcabamba), it is the most familiar icon of Inca civilization. The Incas built the estate around 1450 but abandoned it a century later at the time of the Spanish Conquest. Although known locally, it was not known to the Spanish during the colonial period and remained unknown to the outside world until American historian Hiram Bingham brought it to international attention in 1911. Machu Picchu was built in the classical Inca style, with polished dry-stone walls. Its three primary structures are the Intihuatana, the Temple of the Sun, and the Room of the Three Windows. Most of the outlying buildings have been reconstructed in order to give tourists a better idea of how they originally appeared. By 1976, thirty percent of Machu Picchu had been restored and restoration continues to this day. Machu Picchu was declared a Peruvian Historic Sanctuary in 1981 and a UNESCO World Heritage Site in 1983. In 2007, Machu Picchu was voted one of the New Seven Wonders of the World in a worldwide Internet poll. In the Quechua language, machu means ""old"" or ""old person"", while pikchu means ""peak; mountain or prominence with a broad base that ends in sharp peaks"", hence the name of the site means ""old peak"". Machu Picchu was built around 1450, at the height of the Inca. Its construction appears to date to the period of the two great Inca rulers, Pachacutec Inca Yupanqui (1438–71) and Túpac Inca Yupanqui (1472–93). It was abandoned just over 100 years later, in 1572, as a belated result of the Spanish Conquest. It is possible that most of its inhabitants died from smallpox introduced by travellers before the Spanish conquistadors arrived in the area. Although it was located only about 80 kilometers (50 mi) from the Inca capital in Cusco, the Spanish never found Machu Picchu and so did not plunder or destroy it, as they did many other sites. The conquistadors had notes of a place called Piccho, although no record of a Spanish visit exists. The types of sacred rocks defaced by the conquistadors in other locations are untouched at Machu Picchu. Over the centuries, the surrounding jungle overgrew the site, and few outside the immediate area knew of its existence. The site may have been discovered and plundered in 1867 by a German businessman, Augusto Berns. Some evidence indicates that German engineer J. M. von Hassel arrived earlier. Maps show references to Machu Picchu as early as 1874. In 1911 American historian and explorer Hiram Bingham travelled the region looking for the old Inca capital and was led to Machu Picchu by a local farmer. Bingham brought Machu Picchu to international attention and organized another expedition in 1912 to undertake major clearing and excavation. He returned in 1914 and 1915 to continue with excavation. In 1981, Peru declared an area of 325.92 square kilometres (125.84 sq mi) surrounding Machu Picchu a ""Historic Sanctuary"". In addition to the ruins, the sanctuary includes a large portion of the adjoining region, rich with the flora and fauna of the Peruvian Yungas and Central Andean wet puna ecoregions. In 1983, UNESCO designated Machu Picchu a World Heritage Site, describing it as ""an absolute masterpiece of architecture and a unique testimony to the Inca civilization"". Bingham was a lecturer at Yale University, although not a trained archaeologist. In 1909, returning from the Pan-American Scientific Congress in Santiago, he traveled through Peru and was invited to explore the Inca ruins at Choqquequirau in the Apurímac Valley. He organized the 1911 Yale Peruvian Expedition in part to search for the Inca capital, which was thought to be the city of Vitcos. He consulted Carlos Romero, a historian in Lima who showed him helpful references and Father Calancha’s Chronicle. Armed with this information the expedition went down the Urubamba River. En route Bingham asked local people to show them Inca ruins. By the time they camped at Mandor Pampa, with Huayna Picchu 2000 feet above them on the opposite bank, they had already examined several ruins, but none fit the descriptions of Vitcos. At Mandor Pampa, Bingham asked farmer and innkeeper Melchor Arteaga if he knew of any nearby ruins. Arteaga said he knew of excellent ruins on the top of Huayna Picchu. The next day, 24 July, Arteaga led Bingham and Sergeant Carrasco across the river on a log bridge and up the Huayna Picchu mountain. At the top of the mountain they came across a small hut occupied by a couple of Quechua, Richarte and Alvarez, who were farming some of the original Machu Picchu agricultural terraces that they had cleared four years earlier. Alvarez\'s 11-year-old son, Pablito, led Bingham along the ridge to the main ruins. The ruins were mostly covered with vegetation except for the cleared agricultural terraces and clearings used by the farmers as vegetable gardens. Because of the vegetation Bingham was not able to observe the full extent of the site. He took preliminary notes, measurements and photographs, noting the fine quality of Inca stonework of several principal buildings. Bingham was unclear about the original purpose of the ruins, but decided that there was no indication that it matched the description of Vitcos. The expedition continued down the Urubamba and up the Vilcabamba Rivers examining all the ruins they could find. Guided by locals Bingham rediscovered and correctly identified the site of the old Inca capital, Vitcos (then called Rosaspata), and the nearby temple of Chuquipalta. He then crossed a pass and into the Pampaconas Valley where he found more ruins heavily buried in the jungle undergrowth at Espíritu Pampa, which he named ""Eromboni Pampa"". As was the case with Machu Picchu, the site was so heavily overgrown that Bingham could only note a few of the buildings. In 1964, Gene Savoy further explored the ruins at Espiritu Pampa and revealed the full extent of the site, identifying it as Vilcabamba Viejo where the Incas fled after the Spanish drove them from Vitcos. On the return of the expedition up the Urubamba River, Bingham sent two men to clear and map the site he referred to as Machu Picchu. As Bingham failed to identify the ruins at Espiritu Pampa as Vilcabamba Viejo, he erroneously theorized that Machu Picchu was Vilcabamba Viejo. Machu Picchu features spectacular workmanship and a dramatic site, while Vilcabamba was built while the short-lived remnant Neo-Inca State was being vanquished by the Spanish; it was built quickly and features crude workmanship. Bingham returned to Machu Picchu in 1912 under the sponsorship of Yale University and National Geographic and with full support of Peruvian President Leguia. The expedition undertook a four-month clearing of the site with local labor, which was expedited with the support of the Prefect of Cuzco. Excavation started in 1912 with further excavation undertaken in 1914 and 1915. Bingham focused on Machu Picchu because of its fine Inca stonework and well-preserved nature, which had lain undisturbed since the site was abandoned. None of Bingham\'s several hypotheses explaining the site held up. During his studies, he carried various artifacts back to Yale. One prominent artifact was a set of 15th-century, ceremonial Incan knives made from bismuth bronze; they are the earliest known artifact containing this alloy. Although local institutions initially welcomed the exploration, they soon accused Bingham of legal and cultural malpractice. Rumors arose that the team was stealing artifacts and smuggling them out of Peru through Bolivia. (In fact, Bingham removed many artifacts, but openly and legally; they were deposited in the Yale University Museum.) Local press perpetuated the accusations, claiming that the excavation harmed the site and deprived local archaeologists of knowledge about their own history. Landowners began to demand rent from the excavators. By the time Bingham and his team left Machu Picchu, locals had formed coalitions to defend their ownership of Machu Picchu and its cultural remains, while Bingham claimed the artifacts ought to be studied by experts in American institutions. Little information describes human sacrifices at Machu Picchu, though many sacrifices were never given a proper burial, and their skeletal remains succumbed to the elements. However, there is evidence that retainers were sacrificed to accompany a deceased noble in the afterlife. Animal, liquid and dirt sacrifices to the gods were much more common, made at the Altar of the Condor. The tradition is upheld by members of the New Age Andean religion. Machu Picchu lies in the southern hemisphere, 13.164 degrees south of the equator. It is 80 kilometres (50 miles) northwest of Cusco, on the crest of the mountain Machu Picchu, located about 2,430 metres (7,970 feet) above mean sea level, over 1,000 metres (3,300 ft) lower than Cusco, which has an elevation of 3,600 metres (11,800 ft). As such, it had a milder climate than the Inca capital. It is one of the most important archaeological sites in South America, one of the most visited tourist attractions in Latin America and the most visited in Peru. Machu Picchu has wet and dry seasons, with the majority of annual rain falling from October through to April. Machu Picchu is situated above a bow of the Urubamba River, which surrounds the site on three sides, where cliffs drop vertically for 450 metres (1,480 ft) to the river at their base. The area is subject to morning mists rising from the river. The location of the city was a military secret, and its deep precipices and steep mountains provided natural defenses. The Inca Bridge, an Inca grass rope bridge, across the Urubamba River in the Pongo de Mainique, provided a secret entrance for the Inca army. Another Inca bridge was built to the west of Machu Picchu, the tree-trunk bridge, at a location where a gap occurs in the cliff that measures 6 metres (20 ft). It could be bridged by two tree trunks, but with the trees removed, there was a 570 metres (1,870 ft) fall to the base of the cliffs. The city sits in a saddle between the two mountains Machu Picchu and Huayna Picchu, with a commanding view down two valleys and a nearly impassable mountain at its back. It has a water supply from springs that cannot be blocked easily, and enough land to grow food for about four times as many people as ever lived there. The hillsides leading to it were terraced, to provide more farmland to grow crops, and to steepen the slopes that invaders would have to ascend. The terraces reduced soil erosion and protected against landslides. Two high-altitude routes from Machu Picchu cross the mountains back to Cusco, one through the Sun Gate, and the other across the Inca bridge. Both could be blocked easily, should invaders approach along them. The site is roughly divided into an urban sector and an agricultural sector, and into an upper town and a lower town. The temples are in the upper town, the warehouses in the lower. The architecture is adapted to the mountains. Approximately 200 buildings are arranged on wide parallel terraces around an east-west central square. The various compounds, called kanchas, are long and narrow in order to exploit the terrain. Sophisticated channeling systems provided irrigation for the fields. Stone stairways set in the walls allowed access to the different levels across the site. The eastern section of the city was probably residential. The western, separated by the square, was for religious and ceremonial purposes. This section contains the Torreón, the massive tower which may have been used as an observatory. Located in the first zone are the primary archaeological treasures: the Intihuatana, the Temple of the Sun and the Room of the Three Windows. These were dedicated to Inti, their sun god and greatest deity. The Popular District, or Residential District, is the place where the lower-class people lived. It includes storage buildings and simple houses. The royalty area, a sector for the nobility, is a group of houses located in rows over a slope; the residence of the amautas (wise persons) was characterized by its reddish walls, and the zone of the ñustas (princesses) had trapezoid-shaped rooms. The Monumental Mausoleum is a carved statue with a vaulted interior and carved drawings. It was used for rites or sacrifices. The Guardhouse is a three-sided building, with one of its long sides opening onto the Terrace of the Ceremonial Rock. The three-sided style of Inca architecture is known as the wayrona style. In 2005 and 2009, the University of Arkansas made detailed laser scans of the entire site and of the ruins at the top of the adjacent Huayna Picchu mountain. The scan data is available online for research purposes. The Intihuatana stone is one of many ritual stones in South America. These stones are arranged to point directly at the sun during the winter solstice. The name of the stone (perhaps coined by Bingham) derives from Quechua language: inti means ""sun"", and wata-, ""to tie, hitch (up)"". The suffix -na derives nouns for tools or places. Hence Intihuatana is literally an instrument or place to ""tie up the sun"", often expressed in English as ""The Hitching Post of the Sun"". The Inca believed the stone held the sun in its place along its annual path in the sky. The stone is situated at 13°9\'48"" S. At midday on 11 November and 30 January, the sun stands almost exactly above the pillar, casting no shadow. On 21 June, the stone casts the longest shadow on its southern side, and on 21 December a much shorter shadow on its northern side. Inti Mach\'ay is a special cave used to observe the Royal Feast of the Sun. This festival was celebrated during the Incan month of Qhapaq Raymi. It began earlier in the month and concluded on the December solstice. On this day, noble boys were initiated into manhood by an ear-piercing ritual as they stood inside the cave and watched the sun rise. Architecturally, Inti Mach\'ay is the most significant structure at Machu Picchu. Its entrances, walls, steps and windows are some of the finest masonry in the Incan Empire. The cave also includes a tunnel-like window unique among Incan structures, which was constructed to only allow sunlight into the cave during several days around the December solstice. For this reason, the cave was inaccessible for much of the year. Inti Mach\'ay is located on the eastern side of Machu Picchu, just north of the ""Condor Stone."" Many of the caves surrounding this area were prehistorically used as tombs, yet there is no evidence that Mach\'ay was a burial ground. The central buildings use the classical Inca architectural style of polished dry-stone walls of regular shape. The Incas were masters of this technique, called ashlar, in which blocks of stone are cut to fit together tightly without mortar. The section of the mountain where Machu Picchu was built provided various challenges that the Incas solved with local materials. One issue was the seismic activity due to two fault lines. It made mortar and similar building methods nearly useless. Instead, the Inca mined stones from the quarry at the site, lined them up and shaped them to fit together perfectly, stabilizing the structures. Inca walls have many stabilizing features: doors and windows are trapezoidal, narrowing from bottom to top; corners usually are rounded; inside corners often incline slightly into the rooms; and outside corners were often tied together by ""L""-shaped blocks; walls are offset slightly from row to row rather than rising straight from bottom to top. Heavy rainfall required terraces and stone chips to drain rain water and prevent mud slides, landslides, erosion and flooding. Terraces were layered with stone chips, sand, dirt and top soil, to absorb water and prevent it from running down the mountain. Similar layering protected the large city center from flooding. Multiple canals and reserves provide water throughout the city that could be supplied to the terraces for irrigation and to prevent erosion and flooding. The Incas never used wheels in a practical way, although its use in toys shows that they knew the principle. Its use in engineering may have been limited due to the lack of strong draft animals, steep terrain and dense vegetation. The approach to moving and placing the enormous stones remains uncertain, probably involving hundreds of men to push the stones up inclines. A few stones have knobs that could have been used to lever them into position; after which they were generally sanded away, with a few overlooked. The Inca road system included a route to the Machu Picchu region. The people of Machu Picchu were connected to long-distance trade, as shown by non-local artifacts found at the site. For example, Bingham found unmodified obsidian nodules at the entrance gateway. In the 1970s, Burger and Asaro determined that these obsidian samples were from the Titicaca or Chivay obsidian source, and that the samples from Machu Picchu showed long-distance transport of this obsidian type in pre-Hispanic Peru. Thousands of tourists walk the Inca Trail to visit Machu Picchu each year. They congregate at Cusco before starting on the one-, two-, four- or five-day journey on foot from Kilometer 82 (or 77 or 85, four/five-day trip) or Kilometer 104 (one/two-day trip) near the town of Ollantaytambo in the Urubamba valley, walking up through the Andes to the isolated city. Megalithic Builders is an index of ancient sites from around the world that contain stone megaliths or interlocking stones. Genus Dental Sacramento', '']","In the Quechua language, machu means ""old"" or ""old person"", while picchu means ""peak; mountain or prominence with a broad base that ends in sharp peaks"", hence the name of the site means ""old peak""."
who created the first flag in the world,"[""You don't have permission to access this resource."", '']","In antiquity, field signs or standards were used in warfare that can be categorized as vexilloid or' flag-like'. Examples include the Sassanid battle standard Derafsh Kaviani, and the standards of the Roman legions such as the eagle of Augustus Caesar's Xth legion, or the dragon standard of the Sarmatians; the latter was let fly freely in the wind, carried by a horseman, but judging from depictions it was more similar to an elongated dragon kite than to a simple flag."
why is bcd code used in digital system,"['Stack Exchange network consists of 181 Q&A communities including Stack Overflow, the largest, most trusted online community for developers to learn, share their knowledge, and build their careers. Retrocomputing Stack Exchange is a question and answer site for vintage-computer hobbyists interested in restoring, preserving, and using the classic computer and gaming systems of yesteryear. It only takes a minute to sign up. Connect and share knowledge within a single location that is structured and easy to search. Programming language development has been influenced by hardware design. One example from this answer mentions how C pointers were, at least in part, influenced by the design of the PDP-11. Has the reverse taken place, where a construct provided by a language drove the development of hardware? To be clear, I\'m wondering about core language constructs, like pointers for example, rather than industry consortiums coming up with something like OpenGL then being implemented in hardware. Perhaps hardware floating-point support? Interesting question with an interesting answer. It\'s a myth to suggest C\'s design is based on the PDP-11. People often quote, for example, the increment and decrement operators because they have an analogue in the PDP-11 instruction set. This is, however, a coincidence. Those operators were invented before the language was ported to the PDP-11. In the former category we have most of the interesting eventual dead ends in computer hardware history. Perhaps the one of the earliest examples of a CPU architecture being targeted at a high level language is the Burroughs B5000 and its successors. This is a family of machines targeted at Algol. In fact, there wasn\'t really a machine language as such that you could program in. The B5000 had a lot of hardware features designed to support the implementation of Algol. It had a hardware stack and all data manipulations were performed on the stack. It used tagged descriptors for data so the CPU had some idea of what it was dealing with. It had a series of registers called display registers that were used to model static scope* efficiently. Other examples of machines targeted at specific languages include the Lisp machine already mentioned, arguably the Cray series of supercomputers for Fortran - or even just Fortran loops, the ICL 2900 series (also block structured high level languages), some machines targeted at the Java virtual machine (some ARM processors have hardware JVM support) and many others. One of the drivers behind creating RISC architectures was the observation that compilers tended to use only a small subset of the available combinations of instructions and addressing modes available on most CPU architectures, so RISC designers ditched the unused ones and filled the space previously used for complex decoding logic with more registers. In the second category, we have individual features in processors targeted at high level languages. For example, the hardware stack is a useful feature for an assembly language programmer, but more or less essential for any language that allows recursive function calls. The processor may build features on top of that for example, many CPUs have an instruction to create a stack frame (the data structure on the stack that represents a function\'s parameters and local variables). *Algol allowed you to declare functions inside other functions. Static scope reflects the way functions were nested in the program source - an inner function could access the variables and functions defined in it and in the scope in which it was defined and the scope in which that scope was defined all the way up to global scope. And not just a few instructions, but whole CPUs have been developed with languages in mind. Most prominent maybe Intel\'s 8086. Already the basic CPU was designed to support the way high level languages handle memory management, especially stack allocation and usage. With BP a separate register for stack frames and addressing was added in conjunction with short encodings for stack related addressing to make HLL programs perform. The 80186/286 went further in this direction by adding Enter/Leave instructions for stack frame handling. While it can be said that the base 8086 was geared more toward languages like Pascal or PL/M (*1,2), later incarnations added many ways to support the now prevalent C primitives - not at least scaling factors for indices. Since many answers pile now various details of CPUs where instructions may match up (or not), there are maybe two other CPUs worth mentioning: The Pascal Microengine and Rockwells 65C19 (as well as the RTX2000). The Pascal Microengine was a WD MCP1600 chipset (*3) based implementation of the virtual 16 bit UCSD p-code processor. Contrary to what the name suggests, it wasn\'t tied to Pascal as a language, but a generic stack machine tailored to support concepts for HLL operations. Beside a rather simple, stack based execution, the most important part was a far reaching and comfortable management of local memory structures for functions and function linking as well as data. Modern time Java Bytecode and its interpreter as a native Bytecode CPU (e.g. PicoJava) isn\'t in any way a new idea (*4). The Rockwell R65C19 is a 6500 variant with added support for Forth. Its 10 new threaded code instructions (*5) implemented the core functions (like Next) of a Forth system as single machine instructions. Forth as a language was developed with a keen eye on the way it is executed. It got more in common with Assemblers than many other HLL (*6). So it\'s no surprise that, already in 1983, its inventor Charles Moore created a Forth CPU called N4000 (*7). *1 - Most remarkable here the string functions which make only sense in languages supporting strings as discrete data type. *2 - Stephen Morse\'s 8086 primer is still a good read - especially when he talks about the finer details. Similar and quite recommended his 2008 interview about the 8086 creation where he describes his approach as mostly HLL driven. *3 - Which makes it basically a LSI-11 with different microcode. *4 - As IT historians, we have seen each and every implementation already before, haven\'t we? So let\'s play a round of Zork. *5 - There are other nice additions as well, like mathematical operations that ease filter programming - after all, the 65C19/29/39 series was the heart of many modems. *6 - The discrimination with assembler as not being a HLL and miles apart becomes quite blurry when looking close anyway. *7 - Later sold to Harris, who developed it into the RTX2000 series - with radiation hardened versions that power several deep space probes. One interesting example of programming languages driving hardware development is the LISP machine. Since ""normal"" computers of the time period couldn\'t execute lisp code efficiently, and there was a high demand for the language in academia and research, dedicated hardware was built with the sole purpose of executing lisp code. Although lisp machines were initially developed for MIT\'s AI lab, they also saw sucess in computer animation. These computers provided increased speed by using a stack machine instead of the typical register based design, and had native support for type checking lisp types. Some other important hardware features aided in garbage collection and closures. Here\'s a series of slides that go into more detail on the design: Architecture of Lisp Machines (PDF) (archive). The architecture of these computers are specialized enough that in order to run c code, the c source is transpiled into lisp, and then run normally. The Vacietis compiler is an example of such a system. Yes.  Case in point, the VAX.  The instruction set design was influenced by the requirements of the compiled languages of the day.  For example, the orthogonality of the ISA; the provision of instructions that map to language constructs such as \'case\' statements (in the numbered-case sense of Hoare\'s original formulation, not the labelled-case of C), loop statements, and so on. VAX Architecture Ref - see the Introduction. I am not claiming the VAX is unique in this respect, just an example I know a little about. As a second example, I\'ll mention the Burroughs B6500 \'display\' registers.  A display, in 1960s speak, is a mechanism for efficient uplevel references. If your language, such as Algol60, permits declaration of nested procedures to any depth, then arbitrary references to the local variables of different levels of enclosing procedure require special handling.  The mechanism used (the \'display\') was invented for KDF9 Whetstone Algol by Randell and Russell, and described in their book Algol 60 Implementation. The B6500 incorporates that into hardware: In particular, C and other high-level languages use the stack for arguments and local variables.  The 8086 has both a stack pointer (SP) and a frame pointer (BP) which address memory using the stack segment (SS) rather than other segments (CS, DS, ES). Programs for the 8087 can be written in Intel\'s high-level languages for 8086/8088 and 80186/80188 systems; ASM-86 (the 8086, 8088 assembly language), PL/M-86, FORTRAN-86, and PASCAL-86. The 80186 added several instructions to the architecture to aid high-level languages.  PUSHA, POPA, ENTER, and LEAVE help with subroutine calls.  The BOUND instruction was useful for array bounds checking and switch-style control statements.  Other instructions unrelated to high-level languages were added as well. The 80386 added bitfield instructions, which are used in C. 2.2.2  Structured Modular Programming The 68020 added bitfield instructions, which are used in C. Whereas the above processors added instructions to support programming languages, Reduced Instruction-Set Computers (RISC) took the opposite approach.  By analyzing which instructions compilers actually used, they were able to discard many complex instructions that weren\'t being used.  This allowed the architecture to be simplified, shorten the instruction cycle length, and reduce instructions to one cycle, speeding up processors significantly. When C was invented, many different string forms were in used at the same time. String operations were probably handled mostly in software, therefore people can use whatever format they want. Null-terminated string wasn\'t a new idea, however special hardware support, if any, might not be meant for it. This had some influence on CPU instruction set design. Some CPUs in the 1970s and 1980s, such as the Zilog Z80 and the DEC VAX, had dedicated instructions for handling length-prefixed strings. However, as the NUL-terminated string gained traction, CPU designers began to take it into account, as seen for example in IBM\'s decision to add the ""Logical String Assist"" instructions to the ES/9000 520 in 1992. https://en.wikipedia.org/wiki/Null-terminated_string#History On x86 Intel introduced many instructions for text processing in SSE4.2, which do things in parallel until the first null-termination character. Before that there was the SCAS - scan string instruction that can be used to look for the position of the termination character https://devblogs.microsoft.com/oldnewthing/20190130-00/?p=100825 We all know that nowadays it\'s a bad idea. Unfortunately it was baked into C, hence used by every modern platform and can\'t be changed anymore. Luckily we have std::string in C++ http://bitsavers.trailing-edge.com/pdf/dec/pdp7/PDP-7_AsmMan.pdf However a real null-termination character can be seen in used on the PDP-8 (see the last line in the code block). Then the ASCIZ keyword was introduced in the assembly language for PDP-10/11 Null-terminated strings were produced by the .ASCIZ directive of the PDP-11 assembly languages and the ASCIZ directive of the MACRO-10 macro assembly language for the PDP-10. These predate the development of the C programming language, but other forms of strings were often used. Dennis M. Ritchie, Development of the C Language Arguably, VLIW architectures were designed mainly for smart compilers. They rely on efficient building of individual very complex instructions (a single ""instruction"" can do many things at the same time), and while it\'s not impossible to write the code manually, the idea was that you could get better performance for your applications by using a better compiler, rather than having to upgrade your CPU. In principle, the difference between e.g. a x86 superscalar CPU and something like SHARC or i860 is that x86 achieves instruction level parallelism at runtime, while SHARC is a very simple CPU design (comparatively) that relies on the compiler. In both cases, there\'s many tricks to reorder instructions, rename registers etc. to allow multiple instructions to run at the same time, while still appearing to execute them sequentially. The VLIW approach would be especially handy in theory for platforms like JVM or .NET, which use a just-in-time compiler - every update to .NET or JVM could make all your applications faster by allowing better optimizations. And of course, during compilation, the compiler has a lot better idea of what all of your application is trying to do, while the runtime approach only ever has a small subset to work with, and has to rely on techniques like statistical branch prediction. In practice, the approach of having the CPU decide won out. This does make the CPUs incredibly complex, but it\'s a lot easier to just buy a new better CPU than to recompile or update all your applications; and frankly, it\'s a lot easier to sell a compatible CPU that just runs your applications faster :) Some ARM CPUs used to have partial support for executing Java bytecode in hardware with https://en.wikipedia.org/wiki/Jazelle Direct Bytecode eXecution (DBX). With modern JITing JVMs, that became obsolete, so there was later a variant of Thumb2 mode (compact 16-bit instructions) called ThumbEE designed as a JIT target for managed languages like Java and C# https://en.wikipedia.org/wiki/ARM_architecture#Thumb_Execution_Environment_(ThumbEE) Apparently ThumbEE has automatic NULL-pointer checks, and an array-bounds instruction.  But that was deprecated, too, in 2011. Over time, there have been various language-specific CPUs, some so dedicated that it would be awkward to use them for a different language. For example, the Harris RTX-2000 was designed to run Forth.  One could almost say it and other Forth CPUs were the language in hardware form. I\'m not saying they understand the language, but they are designed to execute it at the ""assembler"" level. Early on, Forth was known for being extremely memory efficient, fast, and, for programmers who could think bass-ackwards, quick to develop in. Having a CPU that could execute it almost directly was a no-brainer. However, memory got cheaper, CPU\'s got quicker, and programmers who liked thinking Forth got scarcer.  (How many folks still use calculators in reverse Polish notation mode?) Arguably, the relatively simple logical structure of DO loops in Fortran motivated the development of vector hardware on the early Cray and Cyber supercomputers. There may be some ""chicken and egg"" between hardware and software development though, since CDC Fortran included array slicing operations to encourage programmers to write ""logic-free"" loops long before that syntax became standardized in Fortran 90. Certainly the Cray XMP hardware enhancements compared with the Cray 1, such as improved ""chaining"" (i.e. overlapping in time) of vector operations, vector mask instructions, and gather/scatter vector addressing, were aimed at improving the performance of typical code written in ""idiomatic"" Fortran. The need to find a way to overcome the I/O bottlenecks caused by faster computation, without the prohibitive expense of large fast memory, led to the development of the early Cray SSD storage devices as an intermediate level between main memory conventional disk and tape storage devices. Fortran I/O statements made it easy to read and write a random-access file as if it were a large two-dimensional array of data. See section 2 of http://www.chilton-computing.org.uk/ccd/supercomputers/p005.htm for an 1988 paper by the head of the Cray XMP design team. There was a downside to this, in that the performance of the first Cray C compilers (and hence the first implementation of the Unix-like Cray operating system UNICOS) was abysmal, since the hardware had no native character-at-a-time instructions, and there was little computer science theory available to attempt to vectorize idiomatic ""C-style"" loops with a relatively unstructured combination of pointer manipulation and logical tests, compared with Fortran\'s more rigidly structured DO loops. Another specific example of hardware design to match the languages was Rekursiv, which was designed to implement object oriented language features in hardware. Our Rekursiv has been preserved in a museum. See https://en.wikipedia.org/wiki/Rekursiv I recall, back in the 80’s, and referenced in the Wikipedia article, Bellmac 32 CPU, which became the AT&T Western Electric WE32100 CPU was supposedly designed for the C programming language. This CPU was used by AT&T in their 3B2 line of Unix systems. There was also a single board VME bus version of it that some third parties used. Zilog also came out with a line of Unix systems using this chip - I think they were a second source for it for AT&T. I did a lot of work with these in the 80’s and probably early 90’s. It was pretty much a dog in terms of performance, if I remember. In the past it was common for computers to be decimal or have instructions for decimal operations. For example x86 has AAM, AAD, AAA, FBLD... for operating on packed, unpacked and 10-byte BCD values. Many other classic architectures also have similar features Several microprocessor families offer limited decimal support. For example, the 80x86 family of microprocessors provide instructions to convert one-byte BCD numbers (packed and unpacked) to binary format before or after arithmetic operations.[3] These operations were not extended to wider formats and hence are now slower than using 32-bit or wider BCD \'tricks\' to compute in BCD (see [1]). The x87 FPU has instructions to convert 10-byte (18 decimal digits) packed decimal data, although it then operates on them as floating-point numbers. The Motorola 68000 provided instructions for BCD addition and subtraction;[4] as does the 6502. In the much later 68000 family-derived processors, these instructions were removed when the Coldfire instruction set was defined, and all IBM mainframes also provide BCD integer arithmetic in hardware. The Zilog Z80, Motorola 6800 and its derivatives, together with other 8-bit processors, and also the Intel x86 family have special instructions that support conversion to and from BCD. The Psion Organiser I handheld computer’s manufacturer-supplied software implemented its floating point operations in software using BCD entirely. All later Psion models used binary only, rather than BCD. https://en.wikipedia.org/wiki/Decimal_computer#More_modern_computers However they\'re rarely used, since modern languages often don\'t have a way to access those instructions. They either lack a decimal integer type completely (like C or Pascal), or doesn\'t have a decimal type that can map cleanly to BCD instructions The result is that BCD instructions started to disappear. In x86 they\'re micro-coded, therefore very slow, which makes people further avoid them. Later AMD removed BCD instructions in x64-64. Other manufacturers did the same in newer versions of their architectures. Having said that, a remnant of BCD operations is still there in the FLAGS register in x86-64 and many other platforms that use flags: the half-carry flag. Newly implemented architectures like ARM, MIPS, Sparc, RISC-V also didn\'t get any BCD instructions and most of them don\'t use a flag register In fact C and C++ allow float, double and long double to be decimal, however none of the implementations use it for the default floating-point types, because modern computers are all binary and are bad at decimal operations. Very few architectures have decimal floating-point support Many C and C++ compilers do have decimal floating-point types as an extension, such as gcc with _Decimal32, _Decimal64, and _Decimal128. Similarly some other modern languages also have decimal types, however those are mostly big floating-point types for financial or scientific problems and not an integer BCD type. For example decimal in C# is a floating-point type with the mantissa stored in binary, thus BCD instructions would be no help here. Arbitrary-precision decimal types like BigInteger in C# and BigDecimal in Ruby or Java also store the mantissa as binary instead of decimal for performance. A few languages do have a fixed-point decimal monetary type, but the significant part is also in binary That said, a few floating-point formats can still be stored in BCD or a related form. For example the mantissa in IEEE-754 decimal floating-point types can be stored in either binary or DPD (a highly-packed decimal format which can then be converted to BCD easily). However I doubt that decimal IEEE-754 libraries use BCD instructions, because they\'re often not exist at all in modern computers, or in case they really exist they\'d be extremely slow BCD was used in many early decimal computers, and is implemented in the instruction set of machines such as the IBM System/360 series and its descendants, Digital Equipment Corporation\'s VAX, the Burroughs B1700, and the Motorola 68000-series processors. Although BCD per se is not as widely used as in the past and is no longer implemented in newer computers\' instruction sets (such as ARM; x86 does not support its BCD instructions in long mode any more), decimal fixed-point and floating-point formats are still important and continue to be used in financial, commercial, and industrial computing, where subtle conversion and fractional rounding errors that are inherent in floating point binary representations cannot be tolerated. https://en.wikipedia.org/wiki/Binary-coded_decimal#Other_computers_and_BCD Yes, definitely. A very good example is how Motorola moved from the 68k architecture to the (somewhat) compatible ColdFire range of CPUs. (It is also an example of how such an evolution might go wrong, but that is another story). The Motorola Coldfire range of CPUs and Microcontrollers was basically a 68000 CPU32 core with lots of instructions and addressing modes removed that ""normal"" C compilers wouldn\'t use frequently (like arithmetic instructions on byte and word operands, some complex addressing modes and addressing modes that act only on memory in favor of registers,...). They also simplified the supervisor mode model and removed some rarely used instructions completely. The whole instruction set was ""optimized for C and C++ compilers"" (This is how Motorola put it) and the freed up chip space used to train the CPUs for performance (like with adding larger data and instruction caches). In the end, the changes made the CPUs quite a bit too incompatible for customers to stay within the product family, and the MC68k range of CPUs went towards its demise. Yet another example: The Prime minicomputer had a segmented architecture, and anything in segment 07777 was a null pointer (Prime used octal, and the top 4 bits of the 16-bit word had other uses).  Segment 0 was a kernel segment, and just loading 0 into a segment register in user code was an access violation.  This would have been fine in properly written C (int* p = 0; stored bit pattern 7777/0 into p). However it turns out that a lot of C code assumes that if you memset a block of memory to all bits zero, that any contained pointers will have been set to NULL.  They eventually had to add a whole new instruction called TCNP (Test C Null Pointer). Another interesting example are Java processors, CPUs that execute (a subset of) Java Virtual Machine bytecode as their instruction sets. If you’re interested enough to ask this question, you might want to read one of the later editions of Andrew Tanenbaum’s textbook, Structured Computer Organization¹, in which he walks the reader step-by-step through the design of a simple Java processor. ¹ Apparently not the third edition or below.  It’s in Chapter 4 of the fifth edition. The MIPS RISC ISA often seems strange to newcomers: instructions like ADD generate exceptions on signed integer overflow. It is necessary to use ADDU, add unsigned, to get the usual 2’s complement wrap. Now, I wasn’t there at the time, but I conjecture that MIPS provided this behavior because it was designed with the Stanford benchmarks - which were originally written in the Pascal programming language, which requires overflow detection. The C programming language does not require overflow traps. The MIPSr6 new (circa 2012) ISA gets rid of the integer overflow trapping instructions - at least those with a 16 bit immediate - in order to free up opcode space. I was there when this was done. I can testify that programming languages influenced many modern x86 features, at least from P6 onwards. Mainly C/C++; to some extent JavaScript. Not yet retro (as of 2019), but on topic: the ARM Cortex-M design was influenced by the C language (may also apply to Cortex-A and -R, but I don\'t have experience with them). Originally there were only IMUL r/m16 and IMUL r/m8 that output a product twice as wide as the operands. However in reality modern high-level languages generally produce a multiplication result that has the same type as the two operands unless you cast the them to a wider type. For example in C if we have int a and int b then a*b will also have type int. Same to most other languages. Doing a non-widening multiplication is also faster than getting the full result, so Intel added the 2 and 3-operand forms that don\'t calculate the high bits There are two additional forms for the IMUL instruction which do not fit the above pattern. The first is a two-operand version that follows the pattern for ADD: This is a more traditional-looking two-operand instruction² that updates the destination register in place. There is even a (gasp) three-operand version similar to what you see in other processors. This three-operand version accepts an immediate as the third operand, and it\'s the one the compiler typically generates. For example, These additional forms produce only single-precision results, but that\'s what the C and C++ languages produce, so it fits well with those languages. If you need a double-precision result, then you can use the single-operand MUL and IMUL instructions. Note that there is no unsigned version of these additional forms. Fortunately, you can use the signed version for unsigned multiplication because the single-precision result is the same for both signed and unsigned multiplication. However, the flags are always set according to the signed result, so you cannot use them to detect unsigned overflow. In practice, this is not a problem because the C language doesn\'t give you access to the overflow flags anyway. Since they\'re more flexible, fit perfectly with the type model, and don\'t care about signness (because non-widening multiplication is the same for signed and unsigned values), compilers began to use it exclusively for almost all multiplications. As a result, Intel focused to optimize even more for those forms of imul. In fact nowadays single-operand mul and imul are very rarely used and may be slow on many μarchs. See Why is imul used for multiplying unsigned numbers? To subscribe to this RSS feed, copy and paste this URL into your RSS reader. Site design / logo © 2023 Stack Exchange Inc; user contributions licensed under CC BY-SA.                    rev\xa02023.5.8.43419 By clicking “Accept all cookies”, you agree Stack Exchange can store cookies on your device and disclose information in accordance with our Cookie Policy.', '']","BCD was used in many early decimal computers, and is implemented in the instruction set of machines such as the IBM System / 360 series and its descendants, Digital Equipment Corporation's VAX and the Motorola 68000-series processors. Although BCD per se is not as widely used as in the past and is no longer implemented in newer computers' instruction sets (such as ARM; x86 does not support BCD instructions in long mode any more), decimal fixed-point and floating-point formats are still important and continue to be used in financial, commercial, and industrial computing, where subtle conversion and fractional rounding errors that are inherent in floating point binary representations cannot be tolerated."
how many years since mayo won all ireland,"['', 'Mathieu is both a surname and a given name. Notable people with the name include: Capitaine Mathieu Marie Joseph Antoine Tenant de la Tour (5 December 1883 - 17 December 1917) was a World War I flying ace credited with nine aerial victories. He was a prewar pioneer in aviation who went on to score one of the first aerial victories over an observation balloon. He was born on 5 December 1883 in Paris. In 1910 he attempted to fly a round trip from Paris to Brussels to win the Automobile Club prize of $20,000, but failed to finish the return flight. Tenant de la Tour began his military service in the cavalry. He became an air force pilot on 6 May 1915 when he was awarded Pilot\'s Brevet No. 1919. He underwent advanced training, then survived an accident on 30 October 1915. On 29 December 1915, he was assigned to Escadrille 57. On 25 January 1916, flying in a literal fog of war, de la Tour helped down a German kite balloon from an altitude of fifty meters in one of the first air-to-air wins over an observation balloon. The feat earned him the Legion d\'honneur. Free is The Party\'s second studio album. Teddy Riley wrote three songs for the album, including the new jack swing-tinged title song, ""Free,"" which was also remixed by house-music legends Steve ""Silk"" Hurley and E-Smoove. Dr. Dre produced the song ""Let\'s Get Right Down to It,"" and the group itself also got involved in the writing and producing of the album, which would once again land it another concert tour opening spot with Color Me Badd, its last special for the Disney Channel, ""All About The Party,"" and an appearance on Blossom. However, the album was not as successful on the charts as previous ones, which prompted Damon Pampolina to leave the group. Free: The Future of a Radical Price  is the second book written by Chris Anderson, Editor in chief of Wired magazine. The book was published on July 7, 2009 by Hyperion. He is also the author of  The Long Tail,  published in 2006. Free follows a thread from the previous work. It examines the rise of pricing models which give products and services to customers for free, often as a strategy for attracting users and up-selling some of them to a premium level. That class of model has become widely referred to as ""freemium"" and has become very popular for a variety of digital products and services. Free was released in the United States on July 7, 2009, though the night before, on his blog, Chris Anderson posted a browser readable version of the book and the unabridged audiobook version. Anderson generated controversy for plagiarizing content from the online encyclopedia Wikipedia in Free. Anderson responded to the claim on his The Long Tail blog, stating that there were disagreements between him and the publisher over accurate citation of Wikipedia due to the changing nature of its content, leading him to integrate footnotes into the text. Also on his blog, he took full responsibility for the mistakes and noted that the digital editions of Free were corrected. The notes and sources were later provided as a download on his blog. Gratis /ˈɡrɑːtᵻs/ or /ˈɡreɪtᵻs/ is the quality of an action where the action is willingly provided without any requirement by the provider for compensation or monetary remuneration. It is often referred to in English and Dutch as free of charge (FOC), complimentary, or on the house. Companies, producers, and service providers often provide certain things free of charge as part of a larger business model, pricing strategy, or as a donation. The English term gratis has its origins in late Middle English; from Latin. A contraction of gratiis, meaning \'as a kindness\' or \'a show of goodwill\', which in turn stems from the root gratia meaning \'grace\' or \'kindness\'. It is widely used in the Afrikaans, Slovakia, Czech, Hungarian, Croatian, Serbian, Polish, French, Dutch, Spanish, Italian, Portuguese, Romanian, Indonesian, Swedish, Norwegian, Danish, German and some of the other Germanic languages, with the same meaning. In a standard business model where goods and services are exchanged for a monetary compensation, pricing of the goods is a fundamental element of the marketing process. While it would defeat the business model if companies provide all of their goods and services free of charge, it is common for them to provide limited amount of free goods in their promotional mix. Many companies often provide free samples to the press in order to generate media coverage for their products. Depending on the product, companies may provide free samples to prospective buyers. Mathieu is both a surname and a given name. Notable people with the name include:']","Mayo's senior Gaelic football team play in the Connacht Senior Football Championship. Holding having three All-Ireland Senior Football Championship wins -- 1936, 1950 and 1951 -- and holding having an unequalled number of consecutive National Football League titles. Mayo also hold the record of staying the longest time in the top flight of the National Football League, being present there since 1997. Mayo have in recent times become known for their propensity to reach All-Ireland Senior Football Championship Finals only to fall at the ultimate hurdle. Mayo hold the Championship record for consecutive losing All-Ireland Senior Football Final appearances -- this currently stands at nine."
what is the population of the greater denver area,"['', 'email: jjaeger@datacontrolllc.com Copyright 2020 DataControl, LLC. All Rights Reserved', '', 'Our portable stacking racks and rack systems are designed to handle and store even the most fragile, odd-shaped, and awkward merchandise. They can be designed to transport two loads at a time. Our stack racks reduce handling time, stack four to six high, and they\xa0are capable of supporting thousands of pounds per unit load. All styles of racking are engineered to meet and/or exceed the “2-to-1” safety factor established by the Rack Manufacturers Institute (RMI) for portable rack design specifications. Tier-Rack LLC. has been a leader in rack solutions and flexible warehouse racking systems for fifty years. The original\xa0TIER-RACK LLC.® pallet stacking frame\xa0converts regular warehouse pallets into sturdy storage racks in seconds without screws or bolts. And the\xa0Load-Nester® all-steel storage rack\xa0features light and heavy duty models of solid all-welded, knock-down, or nestable designs for all your material handling needs SnellManufacturing.comAmericanToolAndDie.comNewDealTrailerParts.comQuadindustriesinc.com © Copyright 2023 Tier-Rack LLC. All Rights Reserved.', '', 'The City and County of Denver ( Arapaho: Niineniiniiciihehe) is the capital and most populous municipality of the U.S. state of Colorado. As of 2014, Denver is also the most populous county in Colorado. Denver is located in the South Platte River Valley on the western edge of the High Plains just east of the Front Range of the Rocky Mountains. The Denver downtown district is located immediately east of the confluence of Cherry Creek with the South Platte River, approximately 12 miles (19\xa0km) east of the foothills of the Rocky Mountains. Denver is nicknamed the Mile-High City because its official elevation is exactly one mile (5,280 feet or 1,609.344 meters) above sea level, making it one of the highest major cities in the United States. The 105th meridian west of Greenwich, the longitudinal reference for the Mountain Time Zone, passes directly through Denver Union Station. Denver is ranked as a beta world city by the Globalization and World Cities Research Network. With a 2013 estimated population of 649,495, Denver ranks as the 22nd-most populous U.S. city. The 10-county Denver-Aurora-Lakewood, CO Metropolitan Statistical Area had an estimated 2013 population of 2,697,476 and ranked as the 21st most populous U.S. metropolitan statistical area. The 12-county Denver-Aurora, CO Combined Statistical Area had an estimated 2013 population of 3,277,309, which ranks as the 16th most populous U.S. metropolitan area. Denver is the most populous city of the Front Range Urban Corridor, an oblong urban region stretching across two states with population of 5,467,633 in 2010. Denver is the most populous city within a 500-mile (800\xa0km) radius and the most populous city in the Mountain West and the third-most populous city in the Southwestern United States after Phoenix, Arizona and El Paso, Texas. Its metropolitan population is the second-largest in the Southwest after that of Phoenix. Denver City was founded in November 1858 as a mining town during the Pikes Peak Gold Rush in western Kansas Territory. That summer, a group of gold prospectors from Lawrence, Kansas, had arrived and established Montana City on the banks of the South Platte River. This was the first settlement in what was later to become the city of Denver. The site faded quickly, however, and by the summer of 1859 it was abandoned in favor of Auraria (named after the gold mining town of Auraria, Georgia), and St. Charles City. On November 22, 1858, General William Larimer, a land speculator from eastern Kansas Territory, placed cottonwood logs to stake a claim on the bluff overlooking the confluence of the South Platte River and Cherry Creek, across the creek from the existing mining settlement of Auraria, and on the site of the existing townsite of St. Charles. Larimer named the town site Denver City to curry favor with Kansas Territorial Governor James W. Denver. Larimer hoped that the towns name would help make it the county seat of Arapaho County, but unknown to him Governor Denver had already resigned from office. The location was accessible to existing trails and was across the South Platte River from the site of seasonal encampments of the Cheyenne and Arapaho. The site of these first towns is now the site of Confluence Park near downtown Denver. Larimer, along with associates in the St. Charles City Land Company, sold parcels in the town to merchants and miners, with the intention of creating a major city that would cater to new emigrants. Denver City was a frontier town, with an economy based on servicing local miners with gambling, saloons, livestock and goods trading. In the early years, land parcels were often traded for grubstakes or gambled away by miners in Auraria. In May 1859, Denver City residents donated 53 lots to the Leavenworth & Pikes Peak Express in order to secure the regions first overland wagon route. Offering daily service for ""passengers, mail, freight, and gold,"" the Express reached Denver on a trail that trimmed westward travel time from twelve days to six. In 1863, Western Union furthered Denvers dominance of the region by choosing the city for its regional terminus. The Colorado Territory was created on February 28, 1861, Arapahoe County was formed on November 1, 1861, and Denver City was incorporated on November 7, 1861. Denver City served as the Arapahoe County Seat from 1861 until consolidation in 1902. In 1867, Denver City became the Territorial Capital. With its new-found importance, Denver City shortened its name to Denver. On August 1, 1876, Colorado was admitted to the Union. Although by the close of the 1860s, Denver residents could look with pride at their success establishing a vibrant supply and service center, the decision to route the nations first transcontinental railroad through Cheyenne, rather than Denver, threatened the prosperity of the young town. A daunting 100 miles away, citizens mobilized to build a railroad to connect Denver to the transcontinental railroad. Spearheaded by visionary leaders including Territorial Governor John Evans, David Moffat, and Walter Cheesman, fundraising began. Within three days, $300,000 had been raised, and citizens were optimistic. Fundraising stalled before enough was raised, forcing these visionary leaders to take control of the debt-ridden railroad. Despite challenges, on June 24, 1870, citizens cheered as the Denver Pacific completed the link to the transcontinental railroad, ushering in a new age of prosperity for Denver. Finally linked to the rest of the nation by rail, Denver prospered as a service and supply center. The young city grew during these years, attracting millionaires with their mansions, as well as the poverty and crime of a rapidly growing city. Denver citizens were proud when the rich chose Denver and were thrilled that Horace Tabor, the Leadville mining millionaire, built an impressive business block at 16th and Larimer as well as the elegant Tabor Grand Opera House. Luxurious hotels, including the much-loved Brown Palace Hotel, soon followed, as well as splendid homes for millionaires like the Croke, Patterson, Campbell Mansion at 11th and Pennsylvania and the now-demolished Moffat Mansion at 8th and Grant. Intent on transforming Denver into one of the worlds great cities, leaders wooed industry and enticed laborers to work in these factories. Soon, in addition to the elite and a large middle class, Denver had a growing population of German, Italian, and Chinese laborers, soon followed by African-Americans and Spanish-surname workers. Unprepared for this influx, the Silver Crash of 1893 unsettled political, social, and economic balances, laying the foundation for ethnic bigotry, such as the Red Scare and the rise of the Ku Klux Klan, as well as corruption and crime. Between 1880 and 1895 the city experienced a huge rise in corruption, as crime bosses, such as Soapy Smith, worked side by side with elected officials and the police to control elections, gambling, and the bunko gangs. The city also experienced a depression in 1893 after the crash of silver prices. In 1887, the precursor to the international charity United Way was formed in Denver by local religious leaders who raised funds and coordinated various charities to help Denvers poor. By 1890, Denver had grown to be the second-largest city west of Omaha, Nebraska, but by 1900 it had dropped to third place behind San Francisco and Los Angeles. In 1900, whites represented 96.8% of Denvers population. In 1901, the Colorado General Assembly voted to split Arapahoe County into three parts: a new consolidated City and County of Denver, a new Adams County, and the remainder of the Arapahoe County to be renamed South Arapahoe County. A ruling by the Colorado Supreme Court, subsequent legislation, and a referendum delayed the creation of the City and County of Denver until November 15, 1902. Denver has hosted the Democratic National Convention twice, during the years of 1908, and again in 2008, taking the opportunity to promote the citys status on the national, political, and socioeconomic stage. Early in the 20th century, Denver, like many other cities, was home to a pioneering Brass Era car company. The Colburn Automobile Company made cars copied from the contemporary Renault. From 1953 to 1989, the Rocky Flats Plant, a DOE nuclear weapon facility formerly located about 15 miles from Denver, produced fissile plutonium ""pits"" for nuclear warheads. A major fire at the facility in 1957, as well as leakage from nuclear waste stored at the site between 1958 and 1968, resulted in the contamination of some parts of Denver, to varying degrees, with plutonium-239, a harmful radioactive substance with a half-life of 24,200 years. A study by the Jefferson County health director, Dr. Carl Johnson, in 1981 linked the contamination to an increase in birth defects and cancer incidence in central Denver and nearer Rocky Flats. Later studies confirmed many of his findings. Plutonium contamination was still present outside the former plant site as of August 2010, and presents risks to building the envisioned Jefferson Parkway, which would complete Denvers automotive beltway. Denver was selected in 1970 to host the 1976 Winter Olympics to coincide with Colorados centennial celebration, but in November 1972 Colorado voters struck down ballot initiatives allocating public funds to pay for the high costs of the games, which were subsequently moved to Innsbruck, Austria. The notoriety of becoming the only city ever to decline to host an Olympiad after being selected has made subsequent bids difficult. The movement against hosting the games was based largely on environmental issues and was led by State Representative Richard Lamm, who was subsequently elected to three terms (1975–87) as Colorado governor. Denver explored a potential bid for the 2022 Winter Olympics, but no bid will be submitted. In 2010, Denver adopted a comprehensive update of its zoning code. The new zoning was developed to guide development as envisioned in adopted plans such as Blueprint Denver, Transit Oriented Development Strategic Plan, Greenprint Denver, and the Strategic Transportation Plan. Denver has also been known historically as the Queen City of the Plains and the Queen City of the West, because of its important role in the agricultural industry of the high-plains region in eastern Colorado and along the foothills of the Colorado Front Range. Several US Navy ships have been named USS Denver in honor of the city. Denver is located in the center of the Front Range Urban Corridor, between the Rocky Mountains to the west and the High Plains to the east. Denvers topography consists of plains in the city center with hilly areas to the north, west and south. According to the United States Census Bureau the city has a total area of 155 square miles (401\xa0km2), of which 153 square miles (396\xa0km2) is land and 1.6 square miles (4.1\xa0km2) (1.1%) is water. The City and County of Denver is surrounded by only three other counties: Adams County to the north and east, Arapahoe County to the south and east, and Jefferson County to the west. Although Denvers nickname is the ""Mile-High City"" because its official elevation is one mile above sea level, defined by the elevation of the spot of a benchmark on the steps of the State Capitol building, the elevation of the entire city ranges from 5,130 to 5,690 feet (1,560 to 1,730\xa0m). According to Geographic Names Information System (GNIS) and the National Elevation Dataset, the citys elevation is 5,278 feet (1,609\xa0m), which is reflected on various websites such as that of the National Weather Service. The Denver MSA has a gross metropolitan product of $157.6 billion in 2010, making it the 18th largest metro economy in the United States. Denvers economy is based partially on its geographic position and its connection to some of the major transportation systems of the country. Because Denver is the largest city within 500 miles (800\xa0km), it has become a natural location for storage and distribution of goods and services to the Mountain States, Southwest states, as well as all western states. Another benefit for distribution is that Denver is nearly equidistant from large cities of the Midwest, such as Chicago and St. Louis and some large cities of the West Coast, such as Los Angeles and San Diego. Apollo Hall opened quickly after the citys founding in 1859 and staged many plays for eager settlers. In the 1880s Horace Tabor built Denvers first Opera House. After the start of the 20th century, city leaders embarked on a city beautification program that created many of the citys parks, parkways, museums, and the Municipal Auditorium, which was home to the 1908 Democratic National Convention and is now known as the Ellie Caulkins Opera House. Denver and the metropolitan areas around it continued to support culture. In 1988, voters in the Denver Metropolitan Area approved the Scientific and Cultural Facilities Tax (commonly known as SCFD), a 1 cent sales tax that contributes money to various cultural and scientific facilities and organizations throughout the Metro area. The tax was renewed by voters in 1994 and 2004 and allows the SCFD to operate until 2018. Denver is home to many nationally recognized museums, including a new wing for the Denver Art Museum by world-renowned architect Daniel Libeskind, the second largest Performing Arts Center in the nation after Lincoln Center in New York City and bustling neighborhoods such as LoDo, filled with art galleries, restaurants, bars and clubs. That is part of the reason why Denver was recently recognized for the third year in a row as the best city for singles. Denvers neighborhoods also continue their influx of diverse people and businesses while the citys cultural institutions grow and prosper. The city acquired the estate of abstract expressionist painter Clyfford Still in 2004 and built a museum to exhibit his works near the Denver Art Museum. The Denver Museum of Nature and Science currently holds an aquamarine specimen valued at over one million dollars, as well as specimens of the state mineral, rhodochrosite. Every September the Denver Mart, located at 451 E. 58th Avenue hosts a gem and mineral show. The state history museum, History Colorado Center, opened in April 2012. It features hands-on and interactive exhibits, artifacts and programs about Colorado history. It was named in 2013 by True West Magazine as one of the top-ten ""must see"" history museums in the country. History Colorados Byers-Evans House Museum and the Molly Brown House are nearby. Denver has numerous art districts around the city, including Denvers Art District on Santa Fe and the River North Art District (RiNo). While Denver may not be as recognized for historical musical prominence as some other American cities, it still manages to have a very active pop, jazz, jam, folk, and classical music scene, which has nurtured several artists and genres to regional, national, and even international attention. Of particular note is Denvers importance in the folk scene of the 1960s and 1970s. Well-known folk artists such as Bob Dylan, Judy Collins and John Denver lived in Denver at various points during this time, and performed at local clubs. Also, three members of the widely popular group Earth, Wind, and Fire are from Denver. More recent Denver-based artists include The Lumineers, Air Dubai, The Fray, Flobots, Cephalic Carnage, Axe Murder Boyz, Deuce Mob, and Five Iron Frenzy. Because of its proximity to the mountains, and generally sunny weather, Denver has gained a reputation as being a very active, outdoor oriented city. Many Denver residents spend the weekends in the mountains; either skiing in the winter or hiking, climbing, kayaking and camping in the summer. Additionally, Denver and the surrounding cities of the Front Range are home to a large number of local and national breweries. Many restaurants in the region have on-site breweries, and some of the larger brewers, including Coors and the New Belgium Brewing Company, offer tours. The city also welcomes visitors from around the world when it hosts the annual Great American Beer Festival each fall. Denver used to be a major trading center for beef and livestock when ranchers would drive (or later transport) cattle to the Denver Union Stockyards for sale. As a celebration of that history, each year for more than a century, Denver hosts the National Western Stock Show, attracting as many as 10,000 animals and 700,000 attendees. The National Western Stock Show is held every January at the National Western Complex, northeast of downtown. Denver hosts four large Mexican American celebrations: Cinco de Mayo (with over 500,000 attendees), in May, El Grito de la Independencia, in September, the annual Lowrider show, and the Dia De Los Muertos art shows/events in North Denvers Highland neighborhood, and the Lincoln Park neighborhood in the original section of West Denver. Denver is also famous for its dedication to New Mexican cuisine and the Chile. Its best known for its Green and Red Chile sauce, Colorado Burrito, Southwest (Denver) Omelette, Breakfast Burrito, Chiles rellenos, and Tamales most notably. Denver has a very large population of Mexican Americans (one of the countrys largest), and is famous for many other southwest cuisine dishes as well. Denver is also well known for other types of food such as Rocky Mountain oysters, Rainbow trout, and the Denver sandwich. The Dragon Boat Festival in July, Moon Festival in September and Chinese New Year are annual events in Denver for the Chinese and Asian residents. Chinese hot pot (huo guo) and Korean BBQ restaurants have been growing in popularity. The Denver area has 2 Chinese newspapers, the Chinese American Post and the Colorado Chinese News. Denver is also the setting for The Bill Engvall Show, and the setting for the 18th season of MTVs The Real World. It was also the setting for the prime time drama Dynasty from 1981 to 1989 (although the show was mostly filmed in Los Angeles). From 1998 to 2002, the citys Alameda East Veterinary Hospital was home to the Animal Planet series Emergency Vets, which spun off three one-off documentary specials and the current Animal Planet series E-Vet Interns. The city is also the setting for the Disney Channel Original TV Show, Good Luck Charlie, which is currently in its third season.', 'the capital of Colorado, U.S., on a plain 5196 ft. above the sea-level; originally founded as a mining station in 1858, now a large and flourishing and well-appointed town; is the centre of a great trade, and a great mining district. According to the U.S. Census Bureau, Denver is ranked #36695 in terms of the most common surnames in America.The Denver surname appeared 609 times in the 2010 census and if you were to sample 100,000 people in the United States, approximately 0 would have the surname Denver.84.8% or 517 total occurrences were White.3.9% or 24 total occurrences were Black.3.7% or 23 total occurrences were of two or more races.3.7% or 23 total occurrences were of Hispanic origin. There are four significant locations where gunfire took place in the City and County of Denver. Denver Public Schools now promoting racially-segregated playtime—for ‘equity,’. They offered a private waiting area, rerouted my luggage, allowed me to board first, and packed a lunch for when I got off the plane in Denver, my luggage was delivered to where I was staying, and I even received a call from Southwest asking how my son was doing. Denver signed Rayjon Tucker, Carlik Jones and Davon Reed to 10-day contracts to fill out the roster. While certainly not happy at the situation that gave Rayjon Tucker the opportunity, Carlik Jones was excited to have Rayjon Tucker first chance to serve as a head coach in an NBA game. \' It’s a thrill, i knew it would be. You wait for this moment and it was a lot of fun. I enjoy this job, running the Denver International Airport, and I’ll do the best that I possibly can. I am honored by the nomination. And if that happens – if confirmation happens, I’ll do the best job I can there as well, we’ll see what happens. ""Denver."" Definitions.net. STANDS4 LLC, 2023. Web. 8 May 2023. <https://www.definitions.net/definition/Denver>. We\'re doing our best to make sure our content is useful, accurate and safe.If by any chance you spot an inappropriate comment while navigating through our website please use this form to let us know, and we\'ll take care of it shortly.']","Denver is ranked as a Beta-world city by the Globalization and World Cities Research Network. With an estimated population of 704,621 in 2017, Denver is the 19th-most populous U.S. city, and with a 17.41% increase since the 2010 United States Census, it has been one of the fastest-growing major cities in the United States. The 10-county Denver-Aurora-Lakewood, CO Metropolitan Statistical Area had an estimated 2017 population of 2,888,227 and is the 19th most populous U.S. metropolitan statistical area. The 12-city Denver-Aurora, CO Combined Statistical Area had an estimated 2016 population of 3,470,235 and is the 16th most populous U.S. metropolitan area. Denver is the most populous city of the 18-county Front Range Urban Corridor, an oblong urban region stretching across two states with an estimated 2016 population of 4,833,260. Denver is the most populous city within a 500-mile (800 km) radius and the second-most populous city in the Mountain West after Phoenix, Arizona. In 2016, Denver was named the best place to live in the United States by U.S. News & World Report."
who was involved in the atlantic charter and what was its purpose,"['War leads to the erosion of liberty for the benefit of the military-industrial complex. \xa0World War II set in motion the destruction of privacy and the formation of an Orwellian Police State controlled by the National Security Agency (NSA) of the United States of America. \xa0Under the guise of cooperation and mutual respect, countries signed secret agreements with the NSA to share signals intelligence (SIGINT) which in layman’s terms means your phone calls, instant messages, and more. \xa0[1] Shortly after World War II, the United States and its allies built the ECHELON system to spy on land and satellite-based communications worldwide. [2] Their closest allies, dubbed The Five Eyes (FVEY), received privileged treatment from the NSA community wherein these five countries share resources on a grand scale. [3] The Five Eyes are also know as AUSCANNZUKUS, short for AUStralia, CANada, New Zealand, UK, and US. \xa0 As time progressed the Five Eyes added two more tiers to their club: the Nine Eyes and Fourteen Eyes.\xa0\xa0The Fourteen Eyes are officially known as\xa0SIGINT Seniors Europe, or “SSEUR” but I think we can unofficially call them: The New World Order. This Anglosphere-based NWO group is now hell-bent on a United Nations based one-world government, with a single digital currency\xa0worldwide, and a completely disarmed populace. [4] The recent Snowden-disclosures should be enough to wake the people, however informal gas station polls show that Average Joe has no clue. Each member of The Fourteen Eyes of the New World Order is subservient to the Five Eyes, and all other nations are enemies of the one-world government. \xa0To see this any other way is to have eyes and yet be blind. The Fourteen Eyes use their combined technocratic might to infiltrate, subjugate, and excommunicate all who oppose their political or financial agendas. \xa0The Five Eyes use their illuminated status to enslave the Nine side-kicks, as was the case during the Wikileaks disclosure of the US. government pushing Monsanto GMO corn into Paris, a Nine Eyes member. \xa0The US. State department also used their NSA and 14 Eyes to spy on anti-GMO activists in Paris, and “calibrate a\xa0target retaliation list that causes some pain across the EU\xa0since this is a collective responsibility, but that also focuses in part on the worst culprits.” Occupy Wall Street suffered a similar fate. [5] \xa0Through a combined lame-stream propaganda campaign and targeted domestic spying by the Department of Homeland Security, the will of the people was mocked, shunned, and silenced. \xa0The Fourteen Eyes form a freedom-slaying Voltron that is worse than Orwell’s nightmares and what Willis was talkin’ about. The Fourteen Eyes feed a brain in Nevada at the Utah Data Center. \xa0The NSA uses this massive database to silence activists, silence Congressmen, and even silence Generals. Still the question remains, who controls the NSA? How can any progress toward less government, less war, free energy, more freedom, and common abundance ever occur when globalist ideologies and Big Brother are hell-bent on destroying our borders, taking our guns, and ensuring nothing you do can stop our progress towards a one-world government. \xa0The Fourteen Eyes will have their New World Order so don’t protest, buy the GMO corn, and\xa0go shopping, stay scared! Britain’s GCHQ intelligence agency can spy on anyone but British nationals, the NSA can conduct surveillance on anyone but Americans, and Germany’s BND foreign intelligence agency can spy on anyone but Germans. That’s how a matrix is created of boundless surveillance in which each partner aids in a division of roles. The documents show that, in this situation, the services did what is not only obvious, but also anchored in German law: They exchanged information. And they worked together extensively. That applies to the British and the Americans, but also to the BND, which assists the NSA in its Internet surveillance. [53] According to previously unpublished material from a bail hearing, Delisle walked into the embassy wearing a red ball cap and civilian clothes. He flashed his Canadian military identification and asked to meet with someone from GRU, the Russian military intelligence. Delisle was posted to the security unit HMCS Trinity, an intelligence facility at the naval dockyard in Halifax. It tracks vessels entering and exiting Canadian waters via satellites, drones and underwater devices. While there he worked on a system called the Stone Ghost, said CBC reporter Rob Gordon. “It’s a computer system that links the five eyes. The five eyes are the United States, Britain, Australia, New Zealand and Canada. All their information is shared on the Stone Ghost computer. “He would go to work every time with a thumb drive and download reams of information, which he would then send to the Russians on a monthly basis. This went on for years and years and years.”\xa0He was paid between $2,800 and $3,000 a month for the information.\xa0In 2009, when Delisle wanted to stop dealing with the Russians, they sent him a picture of his daughter walking to school in Halifax. [6][7] The National Security Agency routinely shares raw intelligence data with Israel without first sifting it to remove information about US citizens, a top-secret document [8] provided to the Guardian by whistle-blower Edward Snowden reveals. Details of the intelligence-sharing agreement are laid out in a memorandum of understanding between the NSA and its Israeli counterpart that shows the US government handed over intercepted communications likely to contain phone calls and emails of American citizens. The agreement places no legally binding limits on the use of the data by the Israelis. [9] Some foreign (and domestic —Ed.) observers regard any U.S. surveillance efforts with suspicion, fearing that intelligence products will be used against their national interests, the\xa0privacy rights of their citizens, or\xa0to advance the interests of U.S. firms in competition for international business. This view is held even though it is well-known that many countries have long undertaken similar efforts. Nonetheless, some argue that electronic surveillance, except in a narrow, court-approved, law enforcement context, should not be undertaken by democratic governments. [2] HBGary Federal, a US defense department cyber security firm, was\xa0hacked\xa0(allegedly by a\xa016 year old girl) and its emails were uploaded to\xa0torrents\xa0and websites. In those emails, the public learned that prominent law firms hired Berico Technologies, Palantir Technologies, and HBGary to\xa0create\xa0fake Facebook, Twitter, and YouTube accounts\xa0to post online as if they were real people and influence your opinion. [10][11][12][13] One person can run more than 50 different accounts, all with complete “online” life histories to add authenticity. Their purpose? Discredit all associated with Wikileaks through coercion and convince the public that Wikileaks,\xa0Glenn Greenwald, and Julian Assange are terrorists. The U.S. government uses StoneGhost, the\xa0United States SIGINT System (USSS),\xa0[14]\xa0and\xa0Fourteen Eyes mass surveillance\xa0to attack, harass, and intimidate citizens on behalf of U.S. based corporate interests. Moratoriums on Monsanto’s famous “MON 810” genetically modified (GMO) corn are being passed all across Europe due to people’s belief that these products are unsafe. Instead of respecting the people’s will, our state department considers making a “target retaliation list that causes some pain across the EU” to help out their struggling buddies at Monsanto. 4. (C) France’s new “High Authority” on agricultural biotech is designed to roll back established science-based decision making. The recently formed authority is divided into two colleges, a scientific college and a second group including civil society and social scientists to assess the “common interest” of France. The authority’s first task is to review MON 810. In the meantime, however, the draft biotech law submitted to the National Assembly and the Senate for urgent consideration, could make any biotech planting impossible in practical terms. The law would make farmers and seed companies legally liable for pollen drift and sets the stage for inordinately large cropping distances. The publication of a registry identifying cultivation of GMOs at the parcel level may be the most significant measure given the propensity for activists to destroy GMO crops in the field. 5. (C) Both the GOF and the Commission have suggested that their respective actions should not alarm us since they are only cultivation rather than import bans. We see the cultivation ban as a first step, at least by anti-GMO advocates, who will move next to ban or further restrict imports. (The environment minister’s top aide told us that people have a right not to buy meat raised on biotech feed, even though she acknowledged there was no possible scientific basis for a feed based distinction.) Further, we should not be prepared to cede on cultivation because of our considerable planting seed business in Europe and because farmers, once they have had experience with biotech, become its staunchest supporters. 6.\xa0Country team Paris recommends that we calibrate a\xa0target retaliation list that causes some pain across the EU\xa0since this is a collective responsibility, but that also focuses in part on the worst culprits. The list should be measured rather than vicious and must be sustainable over the long term, since we should not expect an early victory. [15] Let it be known: if you are an anti-GMO activist living in the United States of America or abroad, the full might of the Fourteen Eyes, the NSA, and the\xa0StoneGhost\xa0surveillance machine will bear down on you in defense of Monsanto. \xa0How many more companies are on the “cool kids” list? “The common interests very largely elude public opinion entirely, and can be managed only by a specialized class whose personal interests reach beyond the locality.” \xa0Former CFR board member\xa0Walter Lippman,\xa0Public Opinion(1922) “The real truth of the matter is, as you and I know, that a financial element in the larger centers has owned the Government since the days of Andrew Jackson.” “… once having joined the One-World Federated Government, no nation could secede or revolt … because with the Atom Bomb in its possession the Federal Government [of the World] would blow that nation off the face of the earth.” ” We must haul down the American flag … haul it down, stamp on it, spit on it. “ This organization was founded in Asheville, North Carolina as the result of a merger of five existing world government groups: American United for World Government; World Federalists, U.S.A.; Student Federalists; Georgia World Citizens Committee; and the Massachusetts Committee for World Federation.\xa0The United World Federalists is a non-partisan, non-profit organization with members in forty-eight states. It has 350 chapters in thirty-nine states and one chapter in Hawaii. State branches exist in twenty-seven states. The primary purpose of the organization is: Membership is open to any American except persons Communist or Fascist oriented. “We shall have world government whether or not you like it – by conquest or consent.” “Today Americans would be outraged if U.N. troops entered Los Angeles to restore order; tomorrow they will be grateful! This is especially true if they were told there was an outside threat from beyond, whether real or promulgated, that threatened our very existence. It is then that all peoples of the world will plead with world leaders to deliver them from this evil. The one thing every man fears is the unknown. When presented with this scenario, individual rights will be willingly relinquished for the guarantee of their well being granted to them by their world government.” TLB recommends at visit to ClimateViewer News for more pertinent information. U.S. Intelligence Community Has a New ‘Disinformation’ Center U.S. Needs to Reduce Reliance on Foreign Energy & Combat Enviro Change Enter your email address to subscribe to this blog and receive notifications of new posts by email.', 'The home front covers the activities of the civilians in a nation at war. World War II was a total war; homeland production became even more invaluable to both the Allied and Axis powers. Life on the home front during World War II was a significant part of the war effort for all participants and had a major impact on the outcome of the war. Governments became involved with new issues such as rationing, manpower allocation, home defense, evacuation in the face of air raids, and response to occupation by an enemy power. The morale and psychology of the people responded to leadership and propaganda. Typically women were mobilized to an unprecedented degree. All of the powers involved had learned from their experiences good and bad on the home front during World War I. Their success in mobilizing economic output was a major factor in supporting combat operations. Among morale-boosting activities that also benefited combat efforts, the home front engaged in a variety of scrap drives for materials crucial to the war effort such as metal, rubber, and rags. The major powers devoted 50–61 percent of their total GDP to munitions production. The Allies produced about three times as much in munitions as the Axis powers. Source: Goldsmith data in Harrison (1988) p.\xa0172 The Allies called themselves the ""United Nations"" (even before that organization formed in 1945), and pledged their support to the Atlantic Charter of 1941. The Charter stated the ideal goals of the war: no territorial aggrandizement; no territorial changes made against the wishes of the people; restoration of self-government to those deprived of it; free access to raw materials; reduction of trade restrictions; global cooperation to secure better economic and social conditions for all; freedom from fear and want; freedom of the seas; and abandonment of the use of force, as well as the disarmament of aggressor nations. The sudden German invasion of neutral Belgium in May 1940 led in a matter of 18 days to the collapse of the Belgian army; King Leopold obtained an armistice that involved direct German military administration. The King refused the demand of the government that he flee with them to Britain; he remained as a puppet ruler under German control. The Belgian bureaucracy remained in place and generally cooperated with the German rulers. Two pro-German movements, the Flemish National Union comprising Flemish (Dutch-speaking ) separatists and the Walloon (French-speaking ) Rexists led by Léon Degrelle (1906–94)  supported the invaders and encouraged their young men to volunteer for the German army.[1] Small but active resistance movements, largely Communist, provided intelligence to the Allies. During the Holocaust in Belgium, the Nazis hunted down the 70,000 Jews living in Belgium, most of them refugees, and killed 29,000 of them.[2] The Germans expected to exploit Belgium\'s industrial resources to support their war machine. Their policies created severe shortages for the Belgian people, but shipped out far less than Germany had expected. They set up the ""Armaments Inspection Board"" in 1940 to relay munitions orders to factories; the Board came under the control of the German Minister of Armaments, Albert Speer in 1943, and had offices in industrial areas that were supposed to facilitate orders for materiél, and supervise production. However, factory production fell sharply after 1942. Although collaboration with the Nazis, especially among the Flemish, was evident in 1940, it soon faded in importance. Labor strikes and systematic sabotage slowed production, as did the emigration of workers to rural areas, Allied bombing, food shortages, and worker resentment to forced labor.[3] The Allies retook all of Belgium in September 1944 as the Germans retreated. They reappeared briefly during the hard fighting of the Battle of the Bulge in December 1944, but were finally expelled in January 1945. The London‐based government‐in‐exile returned, but had to confront the resistance movements that demanded radical political change.[4] China suffered the second highest number of casualties of the entire war. Civilians in the occupied territories had to endure many large-scale massacres, including that in Nanking. In a few areas, Japanese forces also unleashed newly developed biological weapons on Chinese civilians leading to an estimated 200,000 dead.[5] Tens of thousands died when Nationalist troops broke the levees of the Yangtze to stop the Japanese advance after the loss of the Chinese capital, Nanjing. Millions more Chinese died because of famine during the war. Japan captured major coastal cities like Shanghai early in the war; cutting the rest of China off from its chief sources of finance and industry. Millions of Chinese moved to remote regions to avoid invasion. Cities like Kunming ballooned with new arrivals. Entire factories and universities were often taken along so the society could still function. Japan replied with hundreds of air raids on the new capital of Chongqing. Although China received much aid from the United States, China did not have sufficient infrastructure to properly arm or even feed its military forces, let alone its civilians. China was divided into three zones, with the Nationalists in the southwest and the Communists led by Mao Zedong (Mao) in control of much of the northwest. Coastal areas were occupied by the Japanese and civilians were treated harshly; young men were drafted into a puppet Chinese army. After the stunningly quick victory in June 1940, France was knocked out of the war and part of it, with its capital in Vichy, became an informal ally of the Germans. A powerful Resistance movement sprang up, as the Germans fortified the coast against an Allied invasion and occupied the northern half of the country.[6] The Germans captured 2,000,000 French soldiers, and kept them in prisoner of war camps inside Germany for the duration of the war, using them as hostages to guarantee French cooperation. The Vichy French government, cooperated closely with the Germans, sending food, machinery and workers to Germany. Several hundred thousand Frenchmen and women were forced to work in German factories, or volunteered to do so, as the French economy itself deteriorated. Nevertheless, there was a strong Resistance movement, with fierce anti-resistance activities carried out by the Nazis and the French police. Most Jews were rounded up by the Vichy police and handed over to the Germans, who sent them to death camps.[7][8] The two million French soldiers held as POWs and forced laborers in Germany throughout the war were not at risk of death in combat, but the anxieties of separation for their 800,000 wives were high. The government provided a modest allowance, but one in ten became prostitutes to support their families.[9] Meanwhile, the Vichy regime promoted a highly traditional model of female roles.[10] After the war, France gave women the vote and additional legal and political rights, although nothing on the scale of the enfranchisement that followed World War I. Women suffered shortages of all varieties of consumer goods and the absence of the men in POW camps.[11] The rationing system was stringent and badly mismanaged, leading to pronounced malnourishment, black markets and hostility to state management of the food supply. The Germans seized about 20% of the French food production, which caused severe disruption to the household economy of the French people.[12] French farm production fell by half because of the lack of fuel, fertilizer and workers; even so, the Germans seized half the meat and 20% of the produce.[13] Supply problems quickly affected French stores, which lacked most items. The government responded by rationing, but German officials set the policies and hunger prevailed, especially affecting young people in urban areas. At shops, the queues lengthened. Some people—including German soldiers who could take advantage of arbitrary exchange rates that favored Germany—benefited from the black market, where food was sold without coupons at very high prices. Farmers diverted meat to the black market, which meant that there was much less for the open market. Counterfeit food coupons were also in circulation. Direct buying from farmers in the countryside and barter against cigarettes became common. These activities were strictly forbidden, and carried the risk of confiscation and fines. Food shortages were most acute in the large cities. Vitamin deficiencies and malnutrition were prevalent.[14] Advice about eating a healthier diet and home growing produce was distributed. Slogans like \'Digging for Victory\' and \'Make Do and Mend\' appeared on national posters and became a part of the war effort. The city environment made these efforts nearly negligible.[15] In the more remote country villages, however, clandestine slaughtering, vegetable gardens and the availability of milk products permitted survival. The official ration provided starvation-level diets of 1,300 or fewer calories a day (5400 kJ), supplemented by home gardens and, especially, black market purchases.[16] The Dutch famine of 1944, known as the Hongerwinter (""Hunger winter"") was a man-made famine imposed by Germany in the occupied western provinces during the winter of 1944–1945. A German blockade cut off food and fuel shipments from farm areas. A total of 4.5 million people were affected, of whom 18,000 died, despite an elaborate system of emergency soup kitchens.[17] The Nazi Hunger Plan was to kill the Jews of Poland quickly, and slowly to force the Poles to leave by threat of starvation, so that they could be replaced by German settlers. The Nazis coerced Poles to work in Germany by providing favorable food rations for families who had members working in the Reich. The ethnic German population in Poland (Volksdeutsche) were given good rations and were allowed to shop for food in special stores. The German occupiers created a draconian system of food controls, including severe penalties for the omnipresent black market. There was a sharp increase in mortality due to the general malnutrition, and a decline in birth rates.[18][19][20][21] By mid 1941, the German minority in Poland received 2,613 calories (11,000 kJ) per day, while Poles received 699 and Jews in the ghetto 184.[22] The Jewish ration fulfilled just 7.5% of their daily needs; Polish rations only 26%. Only the ration allocated to Germans provided the full required calorie intake.[23] Additionally the Generalplan Ost of the Nazis, which envisioned the elimination of the Slavic population in the occupied territories and artificial famines-as proposed in the Hunger Plan, were to be used. On September 1, 1939, Germany invaded Poland, conquering it in three weeks, as the Soviets invaded the eastern areas. During the German occupation, there were two distinct civilian uprisings in Warsaw, one in 1943, the other in 1944. The first took place in an entity, less than two square miles (5 km2) in area, which the Germans had carved out of the city and called Ghetto Warschau. The Germans built high walls around the ghetto, and crowded 550,000 Polish Jews into it, many from the Polish provinces. At first, people were allowed to enter and leave the ghetto, but soon its border became an ""iron curtain"". Unless on official business, Jews could not leave, and non-Jews, including Germans, could not enter. Entry points were guarded by German soldiers. Because of extreme conditions and hunger, mortality in the ghetto was high. In 1942, the Germans moved 400,000 ghetto residents to Treblinka where they were gassed on arrival. By April 19, 1943, when the Ghetto Uprising commenced, the population of the ghetto had dwindled to 60,000 individuals. In the following three weeks, virtually all died as the Germans fought and systematically destroyed the buildings in the ghetto.[25] The uprising by Poles began on August 1, 1944, when the Polish underground, the ""Home Army"", aware that the Soviet Army had reached the eastern bank of the Vistula, sought to liberate Warsaw much as the French resistance had liberated Paris a few weeks earlier. Joseph Stalin had his own group of Communist leaders for the new Poland and did not want the Home Army or its leaders (based in London) to control Warsaw. So he halted the Soviet offensive and gave the Germans free rein to suppress it. During the ensuing 63 days, 250,000 Poles of the Home Army surrendered to the Germans. After the Germans forced all the surviving population to leave the city, Hitler ordered that any buildings left standing be dynamited – 98 percent of the buildings in Warsaw were destroyed.[26] During the invasion of the Soviet Union in the early months of the war, rapid German advances almost captured the cities of Moscow and Leningrad. The bulk of Soviet industry which could not be evacuated was either destroyed or lost due to German occupation. Agricultural production was interrupted, with grain crops left standing in the fields  This caused hunger reminiscent of the early 1930s. In one of the greatest feats of war logistics, factories were evacuated on an enormous scale, with 1,523 factories dismantled and shipped eastwards along four principal routes to the Caucasus, Central Asia, the Ural, and Siberia.[27] In general, the tools, dies and production technology were moved, along with the blueprints and their management, engineering staffs and skilled labor. The whole of the Soviet Union become dedicated to the war effort. The people of the Soviet Union were probably better prepared than any other nation involved in World War II to endure the material hardships of the war – primarily because they were so used to shortages and economic crisis in the past, especially during wartime—World War I had brought similar restrictions on food.[28] Conditions were nevertheless severe. World War II was especially devastating to citizens of the USSR because it was fought on Soviet territory and caused massive destruction. In Leningrad, under German siege, over a million people died of starvation and disease. Many factory workers were teenagers, women and old people. The government implemented rationing in 1941 and first applied it to bread, flour, cereal, pasta, butter, margarine, vegetable oil, meat, fish, sugar and confectionery all across the country. The rations remained largely stable in other places during the war. Off-ration food was often so expensive that it could not add substantially to a citizen\'s food supply unless they were especially well-paid. Peasants received no rations and had to make do with any local resources they farmed themselves. Most rural peasants struggled and lived in unbearable poverty, but others sold their surplus food at a high price; a few became rouble millionaires, until a currency reform two years after the end of the war wiped out their wealth.[29] Despite harsh conditions, the war led to a spike in Soviet nationalism and unity. Soviet propaganda toned down extreme Communist rhetoric of the past as the people now rallied to protect their Motherland against the evils of the German invaders. Ethnic minorities thought to be collaborators were forced into exile. Religion, which was previously shunned, became a part of a Communist Party propaganda campaign to mobilize religious people. Soviet society changed drastically during the war. There was a burst of marriages in June and July 1941 between people about to be separated by the war, and in the next few years the marriage rate dropped off steeply, with the birth rate following shortly thereafter to only about half of what it would have been in peacetime. For this reason mothers with several children during the war received substantial honors and money benefits if they had several children—mothers could earn around 1,300 rubles for having their fourth child and up to 5,000 rubles for their tenth.[30] The city of Leningrad endured more suffering and hardships than any other city in the Soviet Union during World War II. Hunger, malnutrition, disease, starvation, and even cannibalism became common during the siege, which lasted from September 1941 until January 1944. Many people lost weight, and grew weaker and more vulnerable to disease. If malnutrition persisted for long enough, its effects were irreversible. People\'s feelings of loyalty disappeared if they got hungry enough; they would steal from their closest family members in order to survive.[31] Only some of the citizens of Leningrad survived. Only 400,000 were evacuated before the siege began; this left 2.5 million in Leningrad, including 400,000 children. Subsequently, more managed to escape; especially when the nearby Lake Ladoga froze over and people could walk over the ice road—or ""road of life""—to safety.[32] Those in influential political or social positions used their connections to other elites to leave Leningrad both before and after the siege began. Some factory owners even looted state funds to secure transport out of the city during the first summer of the war.[33] The most risky means of escape, however, was to defect to the enemy and hope to avoid governmental punishment. Most survival strategies during the siege, though, involved staying within the city and facing the problems through resourcefulness or luck: for instance by securing factory employment, because many factories became autonomous and possessed more of the requirements for survival during the winter, such as food and heat. Workers received larger rations than other civilians, and factories were likely to have electricity if they produced vital goods. Factories also served as mutual support centers, and had clinics and other services like cleaning crews and teams of women who would sew and repair clothes. Factory employees were still driven to desperation on occasion and people resorted to eating glue or horsemeat in factories where food was scarce, but factory employment was the most consistently successful method of survival, and at some food production plants not a single person died.[34] Survival opportunities open to the wider Soviet community included barter and farming on private land. Black markets thrived as private barter and trade became more common, especially between soldiers and civilians. Soldiers, who had more food to spare, were eager to trade with civilians who had extra warm clothes to exchange. Planting vegetable gardens in the spring became popular, primarily because citizens could keep everything grown on their own plots. The campaign also had a potent psychological effect and boosted morale, a survival component almost as crucial as bread.[35] Many of the most desperate Soviet citizens turned to crime to support themselves. Most common was the theft of food and of ration cards; this could prove fatal for a malnourished person if their card was stolen more than a day or two before a new card was issued. For these reasons, the stealing of food was severely punished and a person could be shot for as little as stealing a loaf of bread. More serious crimes such as murder and cannibalism also occurred, and special police squads were set up to combat these crimes, though by the end of the siege, roughly 1,500 had been arrested for cannibalism.[36] In the United States, farming and other production was increased. For example, citizens were encouraged to plant ""victory gardens"", personal farms that children sometimes worked on.[37] Standlee (2010) argues that during the war the traditional gender division of labor changed somewhat, as the ""home"" or domestic female sphere expanded to include the ""home front""; meanwhile the public sphere—the male domain—was redefined as the international stage of military action.[38] The Philippines was an American possession on the way to independence (scheduled in 1946) and controlled its own internal affairs. The Japanese invaded and quickly conquered the islands in early 1942. The Japanese military authorities immediately began organizing a new government structure in the Philippines and established the Philippine Executive Commission. They initially organized a Council of State, through which they directed civil affairs until October 1943, when they declared the Philippines an independent republic. The Japanese-sponsored Second Philippine Republic headed by President José P. Laurel proved to be ineffective and unpopular as Japan maintained very tight controls.[39] Japanese occupation of the Philippines was opposed by large-scale underground and guerrilla activity. The Philippine Army, as well as remnants of the U.S. Army Forces Far East continued to fight the Japanese in a guerrilla war. They formed an auxiliary unit of the United States Army. Their effectiveness was such that by the end of the war, Japan controlled only twelve of the forty-eight provinces. One element of resistance in the Central Luzon area was furnished by the Hukbalahap, which armed some 30,000 people and extended their control over much of Luzon.[40] The Americans invaded in 1944–45; the battle for Manila was contested street by street with large numbers of civilians killed. As in most occupied countries, crime, looting, corruption, and black markets were endemic.[41] With a view of building up the economic base of the Greater East Asia Co-Prosperity Sphere, the Japanese Army envisioned using the islands as a source of agricultural products needed by its industry. For example, Japan had a surplus of sugar from Taiwan, and a severe shortage of cotton, so they try to grow cotton in on sugar lands with disastrous results. They lacked the seeds, pesticides, and technical skills to grow cotton. Jobless farm workers flock to the cities, where there was minimal relief and few jobs. The Japanese Army also tried using cane sugar for fuel, castor beans and copra for oil, derris for quinine, cotton for uniforms, and abaca (hemp) for rope. The plans were very difficult to implement in the face of limited skills, collapsed international markets, bad weather, and transportation shortages. The program was a failure that gave very little help to Japanese industry, and diverted resources needed for food production.[42] As Karnow reports, Filipinos ""rapidly learned as well that \'co-prosperity\' meant servitude to Japan\'s economic requirements."" [43] Living conditions were bad throughout the Philippines during the war. Transportation between the islands was difficult because of lack of fuel. Food was in very short supply, with sporadic famines and epidemic diseases[44][45] The Japanese tried to remove all Western and American cultural influences. They met fierce resistance when they tried to undermine the Catholic Church by arresting 500 Christian missionaries. The Filipinos came to feel morally superior to the brutal Japanese and rejected their advances.[46] Newspapers and the media were tightly censored. The Japanese tried to reshape schools and impose the Japanese language. They formed neighborhood associations to inform on the opposition.[47] Britain\'s total mobilization during this period proved to be successful in winning the war, by maintaining strong support from public opinion. The war was a ""people\'s war"" that enlarged democratic aspirations and produced promises of a postwar welfare state.[48][49] Historians credit Britain with a highly successful record of mobilizing the home front for the war effort, in terms of mobilizing the greatest proportion of potential workers, maximizing output, assigning the right skills to the right task, and maintaining the morale and spirit of the people.[50] Much of this success was due to the systematic planned mobilization of women, as workers, soldiers and housewives, enforced after December 1941 by conscription.[51] The women supported the war effort, and made the rationing of consumer goods a success. In some ways, the government over-responded, evacuating too many children in the first days of the war, closing cinemas as frivolous then reopening them when the need for cheap entertainment was clear, sacrificing cats and dogs to save a little space on shipping pet food, only to discover an urgent need to keep the rats and mice under control.[52] In the balance between compulsion and voluntarism, the British relied successfully on voluntarism. The success of the government in providing new services, such as hospitals, and school lunches, as well as egalitarian spirit, contributed to widespread support for an enlarged welfare state. Munitions production rose dramatically, and the quality remained high. Food production was emphasized, in large part to free shipping for munitions. Farmers increased the number of acres under cultivation from 12,000,000 to 18,000,000 (from about 50,000 to 75,000 km2), and the farm labor force was expanded by a fifth, thanks especially to the Women\'s Land Army.[53] Parents had much less time to supervise their children, and there were fears of juvenile delinquency, especially as older teenagers took jobs and emulated their older siblings in the service. The government responded by requiring all young people over 16 to register, and expanded the number of clubs and organizations available to them.[54] In mid-1940, the RAF (Royal Air Force) was called on to fight the Battle of Britain but it had suffered serious losses. It lost 458 aircraft—more than current production—in France and was hard pressed. The government decided to concentrate on only five types of aircraft in order to optimize output. They were: Wellingtons, Whitley Vs, Blenheims, Hurricanes and Spitfires. These aircraft received extraordinary priority. Covering the supply of materials and equipment and even made it possible to divert from other types the necessary parts, equipment, materials and manufacturing resources. Labor was moved from other aircraft work to factories engaged on the specified types. Cost was not an object. The delivery of new fighters rose from 256 in April to 467 in September—more than enough to cover the losses—and Fighter Command emerged triumphantly from the Battle of Britain in October with more aircraft than it had possessed at the beginning.[55] Starting in 1941, the US provided munitions through Lend lease that totaled $15.5 billion[56] Food, clothing, petrol, leather and other items were rationed. However, items such as sweets and fruits were not rationed, as they would spoil. Access to luxuries was severely restricted, although there was also a significant black market. Families also grew ""victory gardens"", and small home vegetable gardens. Many things were conserved to turn into weapons later, such as fat for nitroglycerin production. People in the countryside were less affected by rationing as they had greater access to locally-sourced unrationed products than people in cities, and were more able to grow their own. The rationing system, which had been originally based on a specific basket of goods for each consumer, was much improved by switching to a points system which allowed housewives to make choices based on their own priorities. Food rationing also permitted the upgrading of the quality of the food available, and housewives approved—except for the absence of white bread and the government\'s imposition of an unpalatable wheat meal ""national loaf"". Surveys of public opinion showed that most Britons were pleased that rationing brought equality and a guarantee of a decent meal at an affordable cost.[58] From very early in the war, it was thought that the major industrial cities of Britain, especially London, would come under Luftwaffe air attack; this did happen with The Blitz. Some children were sent to Canada, the USA and Australia and millions of children and some mothers were evacuated from London and other major cities to safer parts of the country when the war began, under government plans for the evacuation of civilians, but they often filtered back. When the Blitz bombing began on September 6, 1940, they evacuated again. The discovery of the poor health and hygiene of evacuees was a shock to many Britons, and helped prepare the way for the Beveridge Report. Children were evacuated if their parents agreed; but in some cases they had no choice. The children were only allowed to take a few things with them, including a gas mask, books, money, clothes, ration book and some small toys.[59][60] Belfast in Northern Ireland was a representative British city that has been well studied by historians.[61][62] It was a key industrial city producing ships, tanks, aircraft, engineering works, arms, uniforms, parachutes and a host of other industrial goods. The unemployment that had been so persistent in the 1930s disappeared, and labour shortages appeared. There was a major munitions strike in 1944.[63] As a key industrial city, Belfast became a target for German bombing missions, but it was thinly defended; there were only 24 anti-aircraft guns in the city for example. The Northern Ireland government under Richard Dawson Bates (Minister for Home Affairs) had prepared too late, assuming that Belfast was too distant. When Germany conquered France in spring 1940 it gained closer airfields. The city\'s fire brigade was inadequate, there were no public air raid shelters as the Northern Ireland government was reluctant to spend money on them and there were no searchlights in the city, which made shooting down enemy bombers all the more difficult. After seeing the Blitz in London in the autumn of 1940, the government began the construction of air raid shelters. The Luftwaffe in early 1941, flew reconnaissance missions that identified the docks and industrial areas to be targeted. Especially hard hit were the working class areas in the north and east of the city where over a thousand were killed and hundreds were seriously injured. Many people left the city afraid of future attacks. The bombing revealed the terrible slum conditions. In May 1941, the Luftwaffe hit the docks and the Harland and Wolff shipyard, closing it for six months. Apart from the numbers of dead, the Belfast blitz saw half of the city\'s houses destroyed. Approximately twenty million pounds worth of damage was caused. The Northern Ireland government was criticized heavily for its lack of preparation. The criticism forced the resignation of Northern Ireland\'s Prime Minister J. M. Andrews. The bombing raids continued until the invasion of Russia in the summer of 1941. The American army arrived in 1942–44, setting up bases around Northern Ireland, and spending freely. An Emergency Hospital Service was established at the beginning of the war, in the expectation that it would be required to deal with large numbers of casualties. A common theme called for an expansion of the welfare state as a reward to the people for their wartime sacrifices [64] The goal was operationalized in a famous report by William Beveridge  It recommended that the various income maintenance services that a grown-up piecemeal since 1911 be systematized and made universal. Unemployment benefits and sickness benefits were to be universal. There would be new benefits for maternity. The old-age pension system would be revised and expanded, and require that a person retired. A full-scale National Health Service would provide free medical care for everyone. All the major parties endorsed the principles and they were largely put into effect when peace returned.[65] The themes of equality and sacrifice were dominant during the war, and in the memory of the war. Harris points out that the war was seen at the time and by a generation of writers as a period of outstanding national unity and social solidarity. There was little antiwar sentiment during or after the war. Furthermore, Britain turned more toward the collective welfare state during the war, expanding it in the late 1940s and reaching a broad consensus supporting it across party lines. By the 1970s and 1980s, however, historians were exploring the subtle elements of continuing diversity and conflict in  society during the war period.[66] For example, at first historians emphasized that strikes became illegal in July 1940, and no trade union called one during the war. Later historians pointed to the many localized unofficial strikes, especially in coal mining, shipbuilding, the metal trades, and engineering, with as many as 3.7 million man days lost in 1944.[67] The BBC collected 47,000 wartime recollections and 15,000 images in 2003-6 and put them online.[68] The CD audiobook Home Front 1939–45 also contains a selection of period interviews and actuality recordings.[69] Canada joined the war effort on September 10, 1939; the government deliberately waited after Britain\'s decision to go to war, partly to demonstrate its independence from Britain and partly to give the country extra time to import arms from the United States as a non-belligerent.[70] War production was ramped up quickly, and was centrally managed through the Department of Munitions and Supply. Unemployment faded away. Canada became one of the largest trainers of pilots for the Allies through the British Commonwealth Air Training Plan. Many Canadian men joined the war effort, so with them overseas and industries pushing to increase production, women took up positions to aid in the war effort. The hiring of men in many positions in civilian employment was effectively banned later in the war through measures taken under the National Resources Mobilization Act.. Shipyards and repair facilities expanded dramatically as over a thousand warships and cargo vessels were built, along with thousands of auxiliary craft, small boats and others.[71] Canada expanded food production, but shipped so much to Britain that food rationing had to be imposed. In 1942 it shipped to Britain 25 per cent of total meat production (including 75% of the bacon), 65% of the cheese and 13% of the eggs.[72] Since 20% of Canada\'s population were not of British or French origin, their status was of special concern. The main goal was to integrate the marginalized European ethnicities—as opposed to the First World War policy of internment camps for Ukrainians and Germans. In the case of Germany, Italy and especially Japan, the government watched the ethnics closely for signs of loyalty to their homelands. The fears proved groundless.[73] In February 1942 21,000 Japanese Canadians were rounded up and sent to internment camps that closely resembled similar camps in the US because the two governments had agreed in 1941 to coordinate their evacuation policies.[74] Most had lived in British Columbia, but in 1945 they were released from detention and allowed to move anywhere in Canada except British Columbia, or they could go to Japan. Most went to the Toronto area.[75][76] Canadian women responded to urgent appeals to make-do, recycle and salvage in order to come up with needed supplies. They saved fats and grease; gathered recycled goods, handed out information on the best methods to use that one may get the most out of recycled goods and organized many other events to decrease the amount of waste. Volunteer organizations led by women also prepared packages for the military overseas or for prisoners of war in Axis countries. With World War II came the dire need for employees in the workplace, without women to step-in, the economy would have collapsed. By autumn 1944 the number of women working full-time in Canada\'s paid labor force was twice what it had been in 1939, and that figure of between 1,000,000 and 1,200,000 did not include part-time workers or women working on farms.""[77] Women had to take on this intensive labor and while they did this they still had to find time to make jam, clothes and other such acts of volunteering to aid the men overseas. The government greatly expanded its powers in order to better direct the war effort, and Australia\'s industrial and human resources were focused on supporting the Australian and American armed forces. There were a few Japanese attacks, most notably on Darwin in February 1942, along with the widespread fear in 1942, that Australia would be invaded. Australia entered the war in 1939 and sent its forces to fight the Germans in the Middle East (where they were successful) and Singapore (where they were captured by the Japanese in 1942). By 1943, 37% of the Australian GDP was directed at the war effort. Total war expenditure came to £2,949\xa0million between 1939 and 1945.[78] The Curtin Labor Government took over in October 1941, and energized the war effort, with rationing of scarce fuel, clothing and some food. When Japan entered the war in December 1941, the danger was at hand, and all women and children were evacuated from Darwin and northern Australia. The Commonwealth Government took control of all income taxation in 1942, which gave it extensive new powers and greatly reduced the states\' financial autonomy.[79] Manufacturing grew rapidly, with the assembly of high performance guns and aircraft a specialty. The number of women working in factories rose from 171,000 to 286,000.[80] The arrival of tens of thousands of Americans was greeted with relief, as they could protect Australia where Britain could not. The US sent in $1.1 billion in Lend Lease, and Australia returned about the same total in services, food, rents and supplies to the Americans.[81] New Zealand, with a population of 1.7 million, including 99,000 Maori, was highly mobilized during the war. The Labour party was in power and promoted unionization and the welfare state. The armed forces peaked at 157,000 in September 1942; 135,000 served abroad, and 10,100 died. Agriculture expanded, sending record supplies of meat, butter and wool to Britain. When American forces arrived, they were fed as well. The nation spent £574 million on the wear, of which 43% came from taxes, 41% from loans and  16% from American Lend Lease. It was an era of prosperity as the national income soared from £158 million in 1937 to £292 million in 1944. Rationing and price controls kept inflation to only 14% during 1939–45.[82][83] Montgomerie shows that the war dramatically increased the roles of women, especially married women, in the labour force. Most of them took traditional female jobs. Some replaced men but the changes here were temporary and reversed in 1945. After the war, women left traditional male occupations and many women gave up paid employment to return home. There was no radical change in gender roles but the war intensified occupational trends under way since the 1920s.[84][85] During World War II, India was a colony of Britain known as British Raj. Britain declared war on behalf of India without consulting with Indian leaders.[86] This resulted in resignation of Congress Ministries.[87] The British recruited some 2.5 million Indian volunteers, who played major roles as soldiers in the Middle East, North Africa, and Burma in the British Indian Army. India became the main base for British operations against Japan, and for American efforts to support China. In Bengal, with an elected Muslim local government under British supervision, the cutoff of rice imports from Burma led to severe food shortages, made worse by maladministration. Prices soared and millions starved because they could not buy food. In the Bengal famine of 1943, three million people died.[88] A small anti-British force of about 40,000 men (and a few women) formed in Southeast Asia, the Indian National Army (INA) under Subhas Chandra Bose. It was under Japanese army control and performed poorly in combat. Its members were captured Indian soldiers from British Indian Army who gained release from extreme conditions in POW camps by joining the Japanese-sponsored INA. It participated in Battle Of Kohima and Battle of Imphal. In postwar Indian politics, some Indians called them heroes. The Congress Party in 1942 demanded immediate independence, which Britain rejected. Congress then demanded the British immediately ""Quit India"" in August 1942, but the Raj responded by immediately jailing tens of thousands of national, state and regional leaders; knocking Congress out of the war. Meanwhile, the Muslim League supported the war effort and gained prestige and membership, as well as British support for its demands for a separate Muslim state (which became Pakistan in 1947). Hong Kong was a British colony captured by Japan on December 25, 1941, after 18 days of fierce fighting. The conquest was swift, but was followed by days of large-scale looting; over ten thousand Chinese women were raped or gang-raped by the Japanese soldiers.[89] The population halved, from 1.6 million in 1941 to 750,000 at war\'s end because of fleeing refugees; they returned in 1945.[90] The Japanese imprisoned the ruling British colonial elite and sought to win over the local merchant gentry by appointments to advisory councils and neighborhood watch groups. The policy worked well for Japan and produced extensive collaboration from both the elite and the middle class, with far less terror than in other Chinese cities. Hong Kong was transformed into a Japanese colony, with Japanese businesses replacing the British. However, the Japanese Empire had severe logistical difficulties and by 1943 the food supply for Hong Kong was problematic. The overlords became more brutal and corrupt, and the Chinese gentry became disenchanted. With the surrender of Japan the transition back to British rule was smooth, for on the mainland the Nationalist and Communists forces were preparing for a civil war and ignored Hong Kong. In the long run the occupation strengthened the pre-war social and economic order among the Chinese business community by eliminating some conflicts of interests and reducing the prestige and power of the British.[91] Germany had not fully mobilized in 1939, nor even in 1941. Not until 1943, under Albert Speer (the minister of armaments in the Reich), did Germany finally redirect its entire economy and manpower to war production. Instead of using all available Germans, it brought in millions of foreign workers from conquered countries, treating them badly (and getting low productivity in return).[92] Germany\'s economy was simply too small for a longer all-out war. Hitler\'s strategy was to change this by a series of surprise blitzkriegs. This failed with defeats in Russia in 1941 and 1942, and against the economic power of the allies.[93] Instead of expanding the economies of the occupied nations, the Nazis seized the portable machinery and rail cars, requisitioned most of their industrial output, took large quantities of food (15% of French output), and forced the victims to pay for their military occupation.[94] The Nazis forced 15 million people to work in Germany (including POWs); many died from bad living conditions, mistreatment, malnutrition, and executions. At its peak, forced laborers comprised 20% of the German work force and were a vital part of the German economic exploitation of the conquered territories. They were especially concentrated in munitions and agriculture.[95] For example, 1.5 million French soldiers were kept in POW camps in Germany as hostages and forced workers and, in 1943, 600,000 French civilians were forced to move to Germany to work in war plants.[96] Although Germany had about double the population of Britain (80 million versus 40 million), it had to use far more labor to provide food and energy. Britain imported food and employed only a million people (5% of the labour force) on farms, while Germany used 11 million (27%). For Germany to build its twelve synthetic oil plants with a capacity of 3.3 million tons a year required 2.4 million tons of structural steel and 7.5 million man-days of labor. (Britain imported all its oil from Iraq, Persia and North America). To overcome this problem, Germany employed millions of forced laborers and POWs; by 1944, they had brought in more than five million civilian workers and nearly two million prisoners of war—a total of 7.13 million foreign workers. Rationing in Germany was introduced in 1939 immediately upon the outbreak of hostilities. Hitler was at first convinced that it would affect public support for the war if a strict rationing program was introduced. The Nazi popularity was in fact partially due to the fact that Germany under the Nazis was relatively prosperous, and Hitler did not want to lose popularity or faith. Hitler felt that food and other shortages had been a major factor in destroying civilian morale during World War I which led to defeatism and surrender. Despite the rationing, civilians had sufficient amounts of food and clothing; witness Howard K. Smith later wrote that ""[f]or a people engaged in a life-and-death war ... the German people for two years of war ate amazingly well."" The meat ration, for example, was 500g per week per person. After the German invasion of the Soviet Union in June 1941, however, this changed to 400g per week, then fell further. Estimating that the meat ration had dropped by up to 80% in five months of fighting in Russia, and citing many other changes in living conditions that suddenly occurred, Smith wrote that by the time he left Germany in late 1941, ""for the first time ... the German people are undernourished"".[97] The system gave extra rations for men involved in heavy industry, and extremely low starvation rations for Jews and Poles in the areas occupied by Germany, but not to the Poles inside Germany many of whom had been brought in to perform heavy labor in German war industries. The amounts available under rationing were sufficient to live from, but clearly did not permit luxuries. Whipped cream became unknown from 1939 until 1948, as well as chocolates, cakes with rich crèmes etc. Meat could not be eaten every day. Other items were not rationed, but simply became unavailable as they had to be imported from overseas: coffee in particular, which throughout was replaced by substitutes made from roasted grains. Vegetables and local fruit were not rationed; imported citrus fruits and bananas were unavailable. In more rural areas, farmers continued to bring their products to the markets, as large cities depended on long distance delivery. Many people kept rabbits for their meat when it became scarce in shops, and it was often a child\'s job to care for them each day. By the spring of 1945, food distribution and the ration system was increasingly in collapse due to insurmountable transportation disruption and the rapid advance of the Allied armies from west and east with consequent loss of food storage facilities. In Berlin, during the beginning of the Battle of Berlin, the authorities announced the allocation of a special supplementary food ration on April 20, 1945. It consisted of a pound of bacon or sausage, half a pound of rice, half a pound of peas or pulses, a pound of sugar, four ounces of coffee substitute, one ounce of real coffee, and a tin of vegetables or fruit. Additionally, the authorities announced that standard food ration allocations for the next fortnight could be claimed in advance.[99] The extra allocation of rations were dubbed by Berliners Himmelfahrtsrationen, Ascension-day rations, ""Because with these rations we shall now ascend to heaven""[100] Germany had a very large and well organized nursing service, with three main organizations, one for Catholics, one for Protestants, and the DRK (Red Cross). In 1934 the Nazis set up their own nursing unit, the Brown nurses, and absorbed one of the smaller groups, bringing it up to 40,000 members. It set up kindergartens, hoping to seize control of the minds of the younger Germans, in competition with the other nursing organizations. Civilian psychiatric nurses who were Nazi party members participated in the killing of invalids, although the process was shrouded in euphemisms and denials.[101] Military nursing was primarily handled by the DRK, which came under partial Nazi control. Frontline medical services were provided by male doctors and medics. Red Cross nurses served widely within the military medical services, staffing the hospitals that perforce were close to the front lines and at risk of bombing attacks. Two dozen were awarded the highly prestigious Iron Cross for heroism under fire. They are among the 470,000 German women who served with the military.[102] The conquest of Germany in 1945 freed 11 million foreigners, called ""displaced persons"" (DPs)- chiefly forced laborers and POWs. In addition to the POWs, the Germans seized 2.8 million Soviet workers to labor in factories in Germany. Returning them home was a high priority for the Allies. However, in the case of Russians and Ukrainians returning often meant suspicion or prison or even death. The UNRRA, Red Cross and military operations provided food, clothing, shelter and assistance in returning home. In all, 5.2 million were repatriated to the Soviet Union, 1.6 million to Poland, 1.5 million to France, and 900,000 to Italy, along with 300,000 to 400,000 each to Yugoslavia, Czechoslovakia, the Netherlands, Hungary, and Belgium.[103] In 1944–45, over 2.5 million ethnic Germans fled from Eastern Europe in family groups, desperately hoping to reach Germany before being overtaken by the Russians.[104][105] Half a million died in the process, the survivors were herded into refugee camps in East and West Germany for years. Meanwhile, Moscow encouraged its troops to regard German women as targets for revenge. Russian Marshal Georgi Zhukov called on his troops to, ""Remember our brothers and sisters, our mothers and fathers, our wives and children tortured to death by Germans....We shall exact a brutal revenge for everything."" Upwards of two million women inside Germany were raped in 1945 in a tidal wave of looting, burning and vengeance.[106] The Japanese home front was elaborately organized, block by block, with full-scale food rationing and many controls over labor. The government used propaganda heavily and planned in minute detail regarding the mobilization of manpower, identification of critical choke points, food supplies, logistics, air raid shelters, and the evacuation of children and civilians from targeted cities. Food supplies were very tight before the heavy bombing began in fall 1944, then grew to a crisis. There was only a small increase of 1.4 million women entering the labor force between 1940 and 1944. The minister of welfare announced, ""In order to secure its labor force, the enemy is drafting women, but in Japan, out of consideration for the family system, we will not draft them.""[107] The weaknesses in the maximum utilization of womanpower was indicated by the presence of 600,000 domestic servants in wealthy families in 1944. The government wanted to raise the birthrate, even with 8.2 million men in the armed forces, of whom three million were killed. Government incentives helped to raise the marriage rate, but the number of births held steady at about 2.2 million per year, with a 10% decline in 1944–45, and another 15% decline in 1945–46. Strict rationing of milk led to smaller babies. There was little or no long-term impact on the overall demographic profile of Japan.[108] The government began making evacuation plans in late 1943, and started removing entire schools from industrial cities to the countryside, where they were safe from bombing and had better access to food supplies. In all 1.3 million children were moved—with their teachers but not their parents.[109] When the American bombing began in earnest in late 1944, 10 million people fled the cities to the safety of the countryside, including two-thirds of the residents of the largest cities and 87% of the children. Left behind were the munitions workers and government officials. By April 1945, 87% of the younger children had been moved to the countryside. Agricultural production in the home islands  held up well during the war until the bombing started. It fell from an index of 110 in 1942 to 84 in 1944 and only 65 in 1945. Worse, imports dried up.[112] The Japanese food rationing system was effective throughout the war, and there were no serious incidences of malnutrition. A government survey in Tokyo showed that in 1944 families depended on the black market for 9% of their rice, 38% of their fish, and 69% of their vegetables.[113] The Japanese domestic food supply depended, however, on imports, which were largely cut off by the American submarine and bombing campaigns. Likewise there was little deep sea fishing, so that the fish ration by 1941 was mostly squid harvested from coastal waters. The result was a growing food shortage, especially in the cities. There was some malnutrition but no reported starvation.[114]  Despite government rationing of food, some families were forced to spend more than their monthly income could offer on black market food purchases. They would rely on savings or exchange food for clothes or other possessions.[115] The American aerial bombing of a total of 65 Japanese cities took from 400,000 to 600,000 civilian lives, with 100,000+ in Tokyo alone, over 200,000 in Hiroshima and Nagasaki combined. The Battle of Okinawa resulted in 80,000–150,000 civilian deaths. In addition civilian death among settlers who died attempting to return to Japan from Manchuria in the winter of 1945 were probably around 100,000. The total of Japanese military fatalities between 1937 and 1945 were 2.1 million; most came in the last year of the war and were caused by starvation or severe malnutrition in garrisons cut off from supplies.[117] Health and living conditions worsened after the surrender in September 1945. Most of the housing stock in large cities was destroyed, just as refugees tried to return from the rural areas. Adding to the crisis there was an influx of 3.5 million returning soldiers and 3.1 million Japanese civilians forcibly repatriated from Imperial outposts in Manchuria, China, Indochina, Formosa, Korea, Saipan and the Philippines; about 400,000 civilians were left behind and not heard of again. Meanwhile, 1.2 million Koreans, POWs and other non-Japanese left Japan. The government implemented pro-natalist policies, which led to an increase in the marriage rate, but birth rates remained steady until they declined by 10% in the stress of the last year of the war, and another 15% during the hardship of the postwar period.[118] The American bombing campaign of all major cities severely impacted the economy, as did the shortages of oil and raw materials that intensified when Japanese merchant shipping was mostly sunk by American submarines. When industrial production was available to the military, for example, 24 percent of Japan\'s finished steel in 1937 was allocated to the military, compared to 85 percent in 1945.[119] By the end of the war, output percent of the highest capacity was still 100 percent for steel, although only 75 percent for aluminum, 63 percent for machine tools, 42 percent for vacuum tubes, 54 percent cement, 32 percent cotton fabric, and 36 percent for wool.[120] Severe food shortages were common throughout the war zones, especially in Europe where Germany used starvation as a military weapon. Japan did not use it as a deliberate policy, but the breakdown of its transportation and distribution systems led to famine and starvation conditions among its soldiers on many Pacific islands.[121] Bose (1990) studies the three great Asian famines that took place during the war: Bengal in India, Honan in China, and Tonkin in Vietnam. In each famine at least two million people died. They all occurred in densely populated provinces where the subsistence foundations of agriculture was failing under the weight of demographic and market pressures. In each cases famine played a role in undermining the legitimacy of the state and the preexisting social structure.[122] A great deal of housing was destroyed or largely damaged during the war, especially in the Soviet Union,[123] Germany, and Japan. In Japan, about a third of the families were homeless at the end of the war.[124] In Germany, about 25% of the total housing stock was destroyed or heavily damaged; in the main cities the proportion was about 45%.[125] Elsewhere in Europe, 22% of the prewar housing in Poland was totally destroyed; 21% in Greece; 9% in Austria, 8% in the Netherlands; 8% in France, 7% in Britain, 5% Italy and 4% in Hungary.[126]', '', '', 'In one sense, the meeting of President Roosevelt and Prime Minister Churchill was a logical culmination of some fifteen months of ardent wooing of America by the British. As soon as he took office in May 1940, Churchill launched a campaign to bring the United States into the war on Britain\'s side. Gradually, Roosevelt and the American people responded to Churchill\'s plea to have the ""New World"" come to ""the rescue of the Old."" Via such steps as the destroyer-bases deal, Roosevelt\'s commitment to make America the ""Arsenal of Democracy,"" and Lend-Lease, the United States adopted a pro-British and anti-Nazi stance. But Churchill and his advisors wanted more—full scale American participation in the war and quickly before the British public\'s resolve to fight on gave way to despair. The events of spring–summer 1941 revealed that President Roosevelt was not yet prepared to take that epochal decision for war. The President of the United States of America and the Prime Minister, Mr. Churchill, representing His Majesty\'s Government in the United Kingdom, being met together, deem it right to make known certain common principles in the national policies of their respective countries on which they base their hopes for a better future for the world. Eighth, they believe that all of the nations of the world, for realistic as well as spiritual reasons must come to the abandonment of the use of force. Since no future peace can be maintained if land, sea or air armaments continue to be employed by nations which threaten, or may threaten, aggression outside of their frontiers, they believe, pending the establishment of a wider and permanent system of general security, that the disarmament of such nations is essential. They will likewise aid and encourage all other practicable measures which will lighten for peace-loving peoples the crushing burden of armaments. Franklin D. Roosevelt Winston S. Churchill Long after the circumstances that led to the August 1941 meeting between Roosevelt and Churchill had faded into the mists of memory, the Atlantic Charter remained a live issue. Dismissed by Berlin and such collaborators as Vichy France as ""mere propaganda,"" the unrealistic ravings of advocates of a discredited ideology, the Charter nonetheless fired the imagination of men and women throughout the world. Hitler appears already to have concluded that the United States was in the war, and some scholars go so far as to suggest that his violent reaction against the Atlantic Charter contributed to his executing the final solution of the Jewish problem. He had promised that should the war become a world war, the outcome would be the destruction of European Jewry. He kept his word. Viewed by its creators as an assertion of aspirations for those nations that fought the Axis, the Charter became the vehicle of Allied Powers war aims and the guiding manifesto that led directly to the establishment of the United Nations. Though the charter was officially no more than a press release by the leader of a belligerent power and the head of a neutral nation, the U.S. Department of State\'s listing of treaties still in force includes the Atlantic Charter and identifies as its signatories all of the adherents to the Declaration by the United Nations. As a result, the Atlantic Charter is in the early twenty-first century considered a pivotal document in the struggle to achieve acceptance of universal principles of human rights and justice. See alsoNATO; United Nations; Universal Declaration of Human Rights; World War II. Facey-Crowther, David, and Douglas Brinkley, eds. The Atlantic Charter. New York, 1994. Gilbert, Martin. Churchill and America. New York, 2005. Kimball, Warren F. Forged in War: Roosevelt, Churchill, and the Second World War. New York, 1997. Wilson, Theodore A. The First Summit: Roosevelt and Churchill at Placentia Bay, 1941. Rev. ed. Lawrence, Kans., 1991. Theodore A. Wilson Cite this article   Pick a style below, and copy the text for your bibliography. Encyclopedia.com gives you the ability to cite reference entries and articles according to common styles from the Modern Language Association (MLA), The Chicago Manual of Style, and the American Psychological Association (APA). Within the “Cite this article” tool, pick a style to see how all available information looks when formatted according to that style. Then, copy and paste the text into your bibliography or works cited list. Because each style has its own formatting nuances that evolve over time and not all information is available for every reference entry or article, Encyclopedia.com cannot guarantee each citation it generates. Therefore, it’s best to use Encyclopedia.com citations as a starting point before checking the style against your school or publication’s requirements and the most-recent information available at these sites: http://www.mla.org/style http://www.chicagomanualofstyle.org/tools_citationguide.html http://apastyle.apa.org/ The Atlantic Charter was signed August 14, 1941, four months before the United States officially entered World War II . It was a joint statement by President Franklin D. Roosevelt (1882–1945; served 1933–45) of the United States and Prime Minister Winston Churchill (1874–1965) of Great Britain. The charter reflected their countries’ eight common objectives for a postwar world. The objectives emphasized the different philosophies of the two democracies and the other main Allied power, the Soviet Union. President Roosevelt hoped the charter would encourage support in the United States for entering the war alongside the Allies . The Atlantic Charter was written during a secret meeting between Roosevelt and Churchill when the United States was still technically a neutral country. It was becoming clear to Roosevelt that the United States would probably enter the war soon, so the meeting covered many issues concerning the war. Churchill was not convinced of the need for a joint declaration, but he introduced ideas in a draft statement. A number of points proved to be controversial, but at the end of the meeting a final statement was formed. The ideas it contained would prove to be highly important in guiding Allied initiatives throughout the war and in establishing postwar peace. The Atlantic Charter included eight basic points. It set forth the concept that each country should have the right of self-determination. This meant that territorial changes would happen only with the approval of the people concerned. Furthermore, each country would be allowed to establish the government of its choosing. Both powers declared that they sought no territorial gains from the war. Other points reflected their hopes for a world in which all nations would have access to trade and prosperity. They included thoughts on a new system of international security that would allow freedom of the seas, encourage fewer arms, and reduce fear in the world. The Atlantic Charter was welcomed in both countries. Its importance, however, became clear only after the United States entered the war. The Charter helped define Allied goals when it was included as part of the Declaration by the United Nations in January 1942. Twenty-six nations embraced the aims of the Atlantic Charter when they signed the Declaration by the United Nations. That number eventually doubled. The Atlantic Charter had a significant impact on the postwar world. The notion of an international system of security prompted the formation of the United Nations (UN), created in 1945. By grounding itself in the declaration of 1942, the UN embraced the principles of the Atlantic Charter. The right of self-determination thus became a guiding principle in international politics. In the thirty years following the war, important transfers of political power happened throughout the world. With encouragement from the Atlantic Charter, many countries were motivated to establish their independence from outside rule. Cite this article   Pick a style below, and copy the text for your bibliography. Encyclopedia.com gives you the ability to cite reference entries and articles according to common styles from the Modern Language Association (MLA), The Chicago Manual of Style, and the American Psychological Association (APA). Within the “Cite this article” tool, pick a style to see how all available information looks when formatted according to that style. Then, copy and paste the text into your bibliography or works cited list. Because each style has its own formatting nuances that evolve over time and not all information is available for every reference entry or article, Encyclopedia.com cannot guarantee each citation it generates. Therefore, it’s best to use Encyclopedia.com citations as a starting point before checking the style against your school or publication’s requirements and the most-recent information available at these sites: http://www.mla.org/style http://www.chicagomanualofstyle.org/tools_citationguide.html http://apastyle.apa.org/ ATLANTIC CHARTER was signed 14 August 1941, by President Franklin D. Roosevelt and Prime Minister Winston Churchill of Great Britain at a meeting in Argentia Bay off the coast of Newfoundland. The United States, still technically neutral in World War II, had already taken a number of steps that brought it closer to war. The charter resembled President Woodrow Wilson\'s Fourteen Points in that both declarations expressed idealistic objectives for a postwar world. The charter included the following points: the renunciation of territorial aggrandizement; opposition to territorial changes not approved by the people concerned; the right of people to choose their own form of government; equal access to trade and raw materials of the world; promotion of economic advancement, improved labor standards, and social security; freedom from fear and want; freedom of the seas; and disarmament of aggressor nations pending the establishment of a permanent system of peace. Although only a press release as first issued, the charter was nonetheless well understood to be a pronouncement of considerable significance. It acquired further authority when, on 1 January 1942, twenty-six countries (including the United States and Great Britain) signed the United Nations Declaration, which included among its provisions formal endorsement of the charter. Dallek, Robert. Franklin D. Roosevelt and American Foreign Policy, 1932–1945. New York: Oxford University Press, 1979. Kimball, Warren F. Forged in War: Roosevelt, Churchill, and the Second World War. New York: Morrow, 1997. Charles S.Campbell/a. g. See alsoFour Freedoms ; Great Britain, Relations with ; Treaties with Foreign Nations . Cite this article   Pick a style below, and copy the text for your bibliography. Encyclopedia.com gives you the ability to cite reference entries and articles according to common styles from the Modern Language Association (MLA), The Chicago Manual of Style, and the American Psychological Association (APA). Within the “Cite this article” tool, pick a style to see how all available information looks when formatted according to that style. Then, copy and paste the text into your bibliography or works cited list. Because each style has its own formatting nuances that evolve over time and not all information is available for every reference entry or article, Encyclopedia.com cannot guarantee each citation it generates. Therefore, it’s best to use Encyclopedia.com citations as a starting point before checking the style against your school or publication’s requirements and the most-recent information available at these sites: http://www.mla.org/style http://www.chicagomanualofstyle.org/tools_citationguide.html http://apastyle.apa.org/ introductionThe Atlantic Charter, a declaration of principles issued by U.S. president Franklin D. Roosevelt and British prime minister Winston Churchill in 1941, echoed Woodrow Wilson\'s Fourteen Points and called for the rights of self-determination, self-government, and free speech for all peoples. The charter stipulated that at the end of World War II, all Allied nations could determine their own political destinies. Many African and Asian nationalists capitalized on the promise of the Atlantic Charter to argue for political independence from colonial control. The President of the United States of America and the Prime Minister, Mr. Churchill, representing His Majesty\'s Government in the United Kingdom, being met together, deem it right to make known certain common principles in the national policies of their respective countries on which they base their hopes for a better future for the world. Eighth, they believe that all of the nations of the world, for realistic as well as spiritual reasons must come to the abandonment of the use of force. Since no future peace can be maintained if land, sea or air armaments continue to be employed by nations which threaten, or may threaten, aggression outside of their frontiers, they believe, pending the establishment of a wider and permanent system of general security, that the disarmament of such nations is essential. They will likewise aid and encourage all other practicable measure which will lighten for peace-loving peoples the crushing burden of armaments. Cite this article   Pick a style below, and copy the text for your bibliography. Encyclopedia.com gives you the ability to cite reference entries and articles according to common styles from the Modern Language Association (MLA), The Chicago Manual of Style, and the American Psychological Association (APA). Within the “Cite this article” tool, pick a style to see how all available information looks when formatted according to that style. Then, copy and paste the text into your bibliography or works cited list. Because each style has its own formatting nuances that evolve over time and not all information is available for every reference entry or article, Encyclopedia.com cannot guarantee each citation it generates. Therefore, it’s best to use Encyclopedia.com citations as a starting point before checking the style against your school or publication’s requirements and the most-recent information available at these sites: http://www.mla.org/style http://www.chicagomanualofstyle.org/tools_citationguide.html http://apastyle.apa.org/ Atlantic Charter, a declaration of solidarity made by Great Britain and the United States on 14 August 1941. Prior to U.S. entry into World War II, President Franklin Delano Roosevelt met with Winston Churchill, the prime minister of Great Britain. Together the two leaders issued the Atlantic Charter, a broadly conceived statement affirming the two nations\' solidarity in the face of impending threats to international security. The Atlantic Charter cited the rights of all nations to self-determination and ""the abandonment of the use of force"" in international disputes. The charter was eventually approved by all members of the United Nations, including the countries of Latin America, for whom the charter\'s repudiation of aggression and insistence on unrestricted free travel on the seas bore particular significance. See alsoWorld War II . Donald M. Dozer, Are We Good Neighbors? (1959). Coggiola, Osvaldo, and André R. Martin. Segunda Guerra Mundial: Um balanço histórico. São Paulo, SP: Xamã, 1995. Friedman, Max Paul. Nazis and Good Neighbors: The United States Campaign against the Germans of Latin America in World War II. Cambridge, U.K.: Cambridge University Press, 2003. Leonard, Thomas M. and John F. Bratzel. Latin America During World War II. Lanham, MD: Rowman & Littlefield, 2007. Cite this article   Pick a style below, and copy the text for your bibliography. Encyclopedia.com gives you the ability to cite reference entries and articles according to common styles from the Modern Language Association (MLA), The Chicago Manual of Style, and the American Psychological Association (APA). Within the “Cite this article” tool, pick a style to see how all available information looks when formatted according to that style. Then, copy and paste the text into your bibliography or works cited list. Because each style has its own formatting nuances that evolve over time and not all information is available for every reference entry or article, Encyclopedia.com cannot guarantee each citation it generates. Therefore, it’s best to use Encyclopedia.com citations as a starting point before checking the style against your school or publication’s requirements and the most-recent information available at these sites: http://www.mla.org/style http://www.chicagomanualofstyle.org/tools_citationguide.html http://apastyle.apa.org/ C. J. Bartlett Cite this article   Pick a style below, and copy the text for your bibliography. Encyclopedia.com gives you the ability to cite reference entries and articles according to common styles from the Modern Language Association (MLA), The Chicago Manual of Style, and the American Psychological Association (APA). Within the “Cite this article” tool, pick a style to see how all available information looks when formatted according to that style. Then, copy and paste the text into your bibliography or works cited list. Because each style has its own formatting nuances that evolve over time and not all information is available for every reference entry or article, Encyclopedia.com cannot guarantee each citation it generates. Therefore, it’s best to use Encyclopedia.com citations as a starting point before checking the style against your school or publication’s requirements and the most-recent information available at these sites: http://www.mla.org/style http://www.chicagomanualofstyle.org/tools_citationguide.html http://apastyle.apa.org/ Cite this article   Pick a style below, and copy the text for your bibliography. Encyclopedia.com gives you the ability to cite reference entries and articles according to common styles from the Modern Language Association (MLA), The Chicago Manual of Style, and the American Psychological Association (APA). Within the “Cite this article” tool, pick a style to see how all available information looks when formatted according to that style. Then, copy and paste the text into your bibliography or works cited list. Because each style has its own formatting nuances that evolve over time and not all information is available for every reference entry or article, Encyclopedia.com cannot guarantee each citation it generates. Therefore, it’s best to use Encyclopedia.com citations as a starting point before checking the style against your school or publication’s requirements and the most-recent information available at these sites: http://www.mla.org/style http://www.chicagomanualofstyle.org/tools_citationguide.html http://apastyle.apa.org/ © 2019\xa0Encyclopedia.com | All rights reserved.', '', 'In August 1941 President Franklin D. Roosevelt of the United States and Prime Minister Winston Churchill of Great Britain held secret meetings aboard warships in the North Atlantic off the coast of Canada. World War II had begun in Europe nearly two years earlier, and Churchill sought assistance from the United States to combat German aggression. At the conclusion of their conference the two leaders issued the Atlantic Charter, a joint declaration, drafted by Churchill, that stated British-American goals for the postwar world. The charter stated that (1) neither nation sought any aggrandizement; (2) they desired no territorial changes without the free assent of the peoples concerned; (3) they respected every people’s right to choose their own form of government and wanted sovereign rights and self-government restored to those forcibly deprived of them; (4) they would try to promote equal access for all states to trade and raw materials; (5) they hoped for worldwide collaboration to promote improved living standards; (6) they would seek a postwar peace in which all nations could live with security within their boundaries; (7) peace should enable all people to traverse the oceans and seas without hindrance; and (8) all nations should abandon the use of force to settle disputes. The Atlantic Charter was subsequently incorporated into the Declaration of the United Nations on Jan. 1, 1942 (see United Nations, “Origin of the United Nations”). We’ve been busy, working hard to bring you new features and an updated design.  We hope you and your family enjoy the NEW Britannica Kids. Take a minute to check out all the enhancements! Choose a language from the menu above to view a computer-translated version of this page. Please note: Text within images is not translated, some features may not work properly after translation, and the translation may not accurately convey the intended meaning. Britannica does not review the converted text. After translating an article, all tools except font up/font down will be disabled. To re-enable the tools or to convert back to English, click ""view original"" on the Google Translate toolbar.']","The Atlantic Charter was a pivotal policy statement issued during World War II on 14 August 1941, which defined the Allied goals for the post war world. The leaders of the United Kingdom and the United States drafted the work and all the Allies of World War II later confirmed it. The Charter stated the ideal goals of the war -- no territorial aggrandizement; no territorial changes made against the wishes of the people, self-determination; restoration of self-government to those deprived of it; reduction of trade restrictions; global cooperation to secure better economic and social conditions for all; freedom from fear and want; freedom of the seas; and abandonment of the use of force, as well as disarmament of aggressor nations. Adherents of the Atlantic Charter signed the Declaration by United Nations on 1 January 1942, which became the basis for the modern United Nations."
when can you call in a missing person,"[""Private Investigator in Miami, FL. Surveillance Investigation Miami and Divorce Investigation. South Beach Investigator. Miami Investigator A missing person is a person who has disappeared and whose status as alive or dead cannot be confirmed as his or her location and fate are not known. Laws related to missing persons are often complex since, in many jurisdictions, relatives, and third parties may not deal with a person's assets until their death is considered proven by law and a formal death certificate issued. The situation, uncertainties, and lack of closure or a funeral resulting when a person goes missing may be extremely painful with long lasting effects on family and friends.A person may go missing due to an accident, crime, death in a location where they cannot be found (such as at sea), or many other reasons, including voluntary disappearance. In some countries, missing persons' photographs are posted on bulletin boards, milk cartons, postcards, and websites, to publicize their description. People go missing for many reasons. Some individuals choose to disappear alone; most of these soon return. Reasons for non-identification may include: A common misconception is that a person must be missing for at least 24 hours before being legally classed as missing, but this is rarely the case; in instances where there is evidence of violence or of an unusual absence, law enforcement agencies often stress the importance of beginning an investigation promptly. A number of organizations seek to connect, share best practices, and disseminate information and images of missing people or children to improve the effectiveness of missing children investigations, including the International Centre for Missing & Exploited Children (ICMEC), as well as national centers, including the National Center for Missing & Exploited Children in the US, Child Focus in Belgium, and The Smile of the Child in Greece. Missing person’s reports are a popular story component on crime and legal shows but in real life, the situation is much more dramatic. By the time a missing person’s report is filed, tensions are often running high and that can mean important details are missed. It doesn't help that TV and movies don't tell the whole story about how to file missing person’s reports. There are important things to consider that are often left out. And there are some details that just aren't true. Knowing the facts before a crisis can be critical when things go wrong. Find out the important facts you need to know if you ever file a missing person’s report. There is no waiting period. Many shows and movies have publicized the 24 or 48 hour waiting period to report missing people but that doesn't exist in real police offices. As soon as you know an adult or child is missing, report it to police. Anyone can be a missing person. It's not just limited to children. Adults can be reported as missing too. If you suspect that someone you love can't be located and may need medical, legal, or other help, it's time to file a missing person’s report. Bring the right information. Police need as complete a description as possible to locate a missing person. When filing a report bring one or more clear photographs, preferably from the shoulders up. Also have a clear description of height, weight, age, and any identifying marks such as tattoos or birthmarks. Know what they were last seen wearing and who they were seen with before they went missing. Give all the details. Police may do an expedited search depending on the factors involved. Very young children and people who are mentally or physically impaired or in need of medical attention are in more danger the longer they are missing. Those who were likely the victim of a crime or other foul play may also get particular attention from police. Once police have all the facts about a potential missing person they will be better equipped to respond appropriately. Know what to expect after they're found. Hopefully, the missing person will be found quickly and before any harm happens. If they turn up on their own, make sure to inform police to call off the search. If police find a missing adult whose actions were voluntary, they might not disclose where the person is unless the person gives permission. Filing a missing person report for an adult doesn't entitle you to know where they are, only that they are safe. Interview people to gather information, search public or court records to uncover clues, conduct surveillance, collect evidence to present in court or to a client, verify employment and income, check for civil judgments and criminal history, investigate computer crimes and information theft, Private detectives, and investigators offer many services for individuals, attorneys, and businesses. Private investigators use a variety of tools when researching the facts in a case. Much of their work is done with a computer, allowing them to obtain information such as telephone numbers, details about social networks, descriptions of online activities, and records of a person’s prior arrests. They make phone calls to verify facts and interview people when conducting a background investigation. Investigators may go undercover to observe people and to obtain information. Detectives also conduct surveillance when investigating a case. They may watch locations, such as a person’s home or office, often from a hidden position. Using cameras and binoculars, detectives gather information on people of interest. Detectives and investigators must be mindful of the law when conducting investigations. Because they lack police authority, their work must be done with the same authority as a private citizen. As a result, they must have a good understanding of federal, state, and local laws, such as privacy laws, and other legal issues affecting their work. Otherwise, evidence they collect may not be useable in court and they could face prosecution. Computer forensics investigators specialize in recovering, analyzing, and presenting information from computers to be used as evidence. Many focus on recovering deleted emails and documents. Legal investigators help prepare criminal defenses, verify facts in civil lawsuits, locate witnesses, and serve legal documents. They often work for lawyers and law firms. Corporate investigators conduct internal and external investigations for corporations. Internally, they may investigate drug use in the workplace or ensure that expense accounts are not abused. Externally, they may try to identify and stop criminal schemes, such as fraudulent billing by a supplier. Financial investigators may be hired to collect financial information on individuals and companies attempting to make large financial transactions. These investigators are often certified public accountants (CPAs) who work closely with investment bankers and other accountants. Investigators might search for assets to recover damages awarded by a court in fraud and theft cases. Missing person investigators are licensed private investigators or sworn law enforcement officers who use standard police methods and specialized training to search for and locate people who have disappeared. Investigators may confront a variety of cases, including runaway children, potential or actual victims of kidnapping or other violent crimes, and persons with mental disabilities who have become lost. Investigators use digital and physical surveillance techniques, specialized database software, and interpersonal skills to solve cases. Going missing is not a crime in any country, so police cannot make every missing person a priority. Private investigators aren’t cheap, but when it is about your feeling to you beloved ones it is worthwhile any cost. Any important information uncovered by a private investigator should be shared with police. If the immediate search is not successful, you may be tempted to try almost anything. Some parents turn to private detectives to aid in the search. Consider hiring a private detective or investigator only if you are convinced that he or she can do something better or different than what is being done by law enforcement. Be certain that you are not simply wasting money that could be spent more productively in another way. If you decide to use a private detective, the following tips can help: Always ask for and check references to find out if the investigator is legitimate. Be wary of people who say they can bring your missing person back immediately for a specific sum of money. If you run into this situation, report it to law enforcement. Make sure you are paying a reasonable rate. Insist that the investigator itemizes expenses. Make sure the investigator or detective has experience working with law enforcement. Law enforcement must be notified immediately of any leads you receive from a private investigator. Inform your assigned law enforcement investigator about your decision to hire a private investigator. In most instances, this individual will need to talk to law enforcement before becoming involved in the case. Be prepared to encounter a few people who are fanatical or obsessive in their behavior or in their desire to help. Keep in mind that some people may try to use your loss to gain attention for themselves. Protect yourself from people who might be delusional or who may prey on victims through scams or by offering false hopes and expectations. The key is to keep your focus and exercise caution. At the Wasser Agency, we offer investigators specialized in missing persons and we carry out investigations we professional tools and the best human resources. We are located in Miami Beach/South Beach, Florida. Visit us now."", 'A common misconception is that one must wait at least 24 hours before filing a missing person’s report, but this is rarely the case; in instances where there is evidence of violence or of an unusual absence, law enforcement agencies in the United\xa0States often stress the importance of beginning an investigation promptly. Entrapment law in the United\xa0States does not require police officers to identify themselves as police in the case of a sting or other undercover work. The law is specifically concerned with enticing people to commit crimes they would not have considered in the normal course of events. While people accused of crimes have certain rights, law enforcement does not have an obligation to tell the truth. Notify me of new comments via email. Notify me of new posts via email. Enter your email address to follow this blog and receive notifications of new posts by email.', 'There’s an excellent list of common misconceptions on Wikipedia, which Kottke has helpfully pointed out. Among them, some of my favourites: In\xa0ancient Rome, the architectural feature called a\xa0vomitorium\xa0was the entranceway through which crowds entered and exited a stadium, not a special room used for purging food during meals.[1]\xa0Vomiting was not a regular part of\xa0Roman dining customs.[2] It is true that\xa0mean\xa0life expectancy\xa0in the Middle Ages and earlier was low; however, many take this to mean that people usually died around the age of 30.[5]\xa0In fact, the low life expectancy is an average very strongly influenced by high infant mortality, and the life expectancy of people who lived to adulthood was much higher. A 21-year-old man in medieval England, for example, could by one estimate expect to live to the age of 64.[6] George Washington\xa0did not have wooden teeth. His dentures were made of gold, hippopotamus ivory, lead, and human and animal teeth (including horse and donkey teeth).[34] Some people believe that\xa0food items cooked with wine or liquor\xa0will be totally non-alcoholic, because\xa0alcohol’s\xa0low boiling point causes it to evaporate quickly when heated. However, a study found that some of the alcohol remains: 25% after 1 hour of baking or simmering, and 10% after 2 hours.[88][89] Meteorites\xa0are not necessarily hot when they reach the Earth. In fact, many meteorites are found with frost on them. As they enter the atmosphere, having been warmed only by the sun, meteors have a temperature below freezing. The intense heat produced during passage through the upper atmosphere at very high speed then melts a meteor’s outside layer, but molten material is blown off and the interior does not have time to warm appreciably. Most meteorites fall through the relatively cool lower atmosphere for as long as several minutes at subsonic velocity before reaching the ground, giving plenty of time for their exterior to cool off again.[170] When a spacecraft reenters the atmosphere,\xa0the heat of reentry\xa0is not (primarily) caused by friction, but by\xa0adiabatic compression of air\xa0in front of the spacecraft.[171][172] There is a legend that\xa0Marco Polo\xa0imported pasta from China[20]\xa0which originated with the\xa0Macaroni Journal, published by an association of food industries with the goal of promoting the use of pasta in the United States.[21]\xa0Marco Polo describes a food similar to “lagana” in his\xa0Travels, but he uses a term with which he was already familiar.\xa0Durum wheat, and thus pasta as it is known today, was introduced by\xa0Arabs\xa0from\xa0Libya, during their conquest of\xa0Sicilyin the late 7th century, according to the newsletter of the\xa0National Macaroni Manufacturers Association,[22]\xa0thus predating Marco Polo’s travels to China by about six centuries. It is rarely necessary to wait 24 hours before filing a\xa0missing person’s\xa0report; in instances where there is evidence of violence or of an unusual absence, law enforcement agencies in the United States often stress the importance of beginning an investigation promptly.[77][78][79]\xa0The UK government Web site says explicitly in large type “You don’t have to wait 24 hours before contacting the police”[80]. Searing\xa0meat does not “seal in” moisture, and in fact may actually cause meat to lose moisture. Generally, the value in searing meat is that it creates a brown crust with a rich flavor via the\xa0Maillard reaction.[86][87] All different\xa0tastes\xa0can be detected on all parts of the\xa0tongue\xa0by\xa0taste buds,[261]\xa0with slightly increased sensitivities in different locations depending on the person, contrary to the popular belief that specific tastes only correspond to specific mapped sites on the tongue.[262]\xa0The original\xa0tongue map\xa0was based on a mistranslation of a 1901 German thesis[263]\xa0by\xa0Edwin Boring. In addition, there are not 4 but 5 primary tastes. In addition to\xa0bitter,\xa0sour,\xa0salty, and\xa0sweet, humans have taste receptors for\xa0umami, which is a savory or meaty taste.[264][265][266] Humans have more than the commonly cited five\xa0senses. Although definitions vary, the actual number ranges from 9 to more than 20. In addition to\xa0sight,\xa0smell,\xa0taste,\xa0touch, and\xa0hearing, which were the senses identified by\xa0Aristotle, humans can sense balance and acceleration (equilibrioception), pain (nociception), body and limb position (proprioception\xa0or kinesthetic sense), and relative temperature (thermoception).[267]\xa0Other senses sometimes identified are the sense of time, itching, pressure, hunger, thirst, fullness of the stomach, need to urinate, need to defecate, and blood\xa0carbon dioxide\xa0levels.[268][269] Toilet waste is never intentionally jettisoned from an aircraft. All waste is collected in tanks which are emptied on the ground by\xa0toilet waste vehicles.[431]\xa0Blue ice\xa0is caused by accidental leakage from the waste tank. Passenger trains, on the other hand, have historicallyflushed onto the tracks; however, modern trains usually have retention tanks on board. …it involves doodles, a bit of tracing paper or some cheese wrap and a lot of fun. Found it on boooooooooom, one of my favourite arty sites. Such a genius idea, I love it. Was screened at Pictoplasma last year. “My girlfriend and I left London in September 2011 to go travelling around the world. On the way, we spent 3 weeks volunteering as English teachers in a rural Cambodian school. Whilst we were there, we decided to set the kids a challenge: to learn how to say the hardest word in English… “Here’s how they got on.” Support the kids at http://www.aboutasiaschools.org/donation (all donations are made securely through paypal). Several physicists weigh in on what would happen if you put your hand in the proton stream of the Large Hadron Collider at CERN, whether there’s a multiverse, you know, that sort of thing. What started as algebra lessons for his cousins has turned into a world-changing project. Hundreds of thousands of users worldwide have benefited from Sal Khan’s friendly, accessible Youtube videos explaining math, science, and other subjects. Sal has a vision of teaching the entire world, for free. His not-for-profit Khan Academy has the mission of “providing a high quality education to anyone, anywhere.” In this outstanding Gel video, Sal describes the elements of the good experience he’s trying to create. Enter your email address to subscribe to this blog and receive notifications of new posts by email.']","A common misconception is that a person must be absent for at least 24 hours before being legally classed as missing, but this is rarely the case; in instances where there is evidence of violence or of an unusual absence, law enforcement agencies often stress the importance of beginning an investigation promptly."
why are there no roads between panama and colombia,"['The\xa0Darién Gap\xa0is a break in the\xa0Pan-American Highway\xa0consisting of a large swath of undeveloped swampland and forest within\xa0Panama‘s\xa0Darién Province\xa0in\xa0Central America\xa0and the northern portion of\xa0Colombia‘s\xa0Chocó Department\xa0in\xa0South America. The gap begins in Yaviza, Panama and ends in Turbo, Colombia, and is 106\xa0km long.\xa0Roadbuilding through this area is expensive and the environmental cost is high. Political consensus in favour of road construction has not emerged. Consequently, there is no road connection through the Darién Gap connecting North America with South America and it is the missing link of the Pan-American Highway. So , instead of shipping Lipstick from Panama to Columbia and because of the Coasta Rica no sense rule regarding RHD Team Lipstick took the option to ship the car from Honduras to Columbia and proceed to the southern parts of Central America by alternative means of transport. A Taxi was chartered in Puerto Cortez to take the boys to the close by airport in San Pedro de Sul which is about 45 km away from Puerto Cortes going inland. From there it was a 2 hour flight to arrive in Panama\xa0 although Costa Rica would have been closer but unfortunately there is no direct flight connection form San Pedro de Sul to Costa Rica. being happy that the shipment of Lipstick so far seems to have had no complications. Having driven through 5 of the bigger continents on earth it was just a matter of time for Team Lipstick to complete their world tour and explore the smallest of the 6 continents -AUSTRALIA. Read More..', 'One day I was sitting around talking to the “Q.” No, not the Q from the bible where “Q”\xa0comes from the German word “quelle” meaning “source,” although he’s sometimes a source of inspiration for blog posts as he was for this one. He’d be mad if I revealed too much about him, but I think it’s safe to say, he is\xa0a lover of maps! In the middle of our discussion, in a comment I almost missed, he said “that’s why you can’t drive from North America to South America.” Freeze Frame! Back up! “What” I said. As he re-iterated his point, I began to hash out some thoughts in my head (imagine that), and a statement I remember hearing in a movie…….”having driven all the way from Denver to Santiago, Chile”………. One thing led to another, and soon we were deep in an online session of Google Maps. This is nothing new.\xa0https://zuludelta45.net/2015/07/21/go-to-hell/ The “Q” correctly pointed out that there are no roads that \xa0lead from Panama in Central America to Columbia in South America. What there is, is the Darian Gap. According to Wikepedia;\xa0The Darién Gap (Spanish: Región del Darién or Tapón del Darién) is a break in the Pan-American Highway consisting of a large swath of undeveloped swampland and forest within Panama‘s Darién Province in Central America and the northern portion of Colombia‘s Chocó Department in South America. It measures just over 160\xa0km (99\xa0mi) long and about 50\xa0km (31\xa0mi) wide. Roadbuilding through this area is expensive, and the environmental cost is high. Political consensus in favor of road construction has not emerged. Consequently there is no road connection through the Darién Gap connecting North America with South America and it is the missing link of the Pan-American Highway. The next time on my way to South America, I think I’ll take the escalator down. On your way north, keep to the left. We have enough traffic in Dallas! Oh, I know! We have a facility in Midlothian and another in Wise County…. Tough rides to the airport… Notify me of new comments via email. Notify me of new posts via email.', 'Carpe Diem Haiku Kai is the place to be if you like to write and share Japanese poetry forms like haiku and tanka. It’s a warmhearted family of haiku poets created by Chèvrefeuille, a Dutch haiku poet.  Japanese poetry is the poetry of nature and it gives an impression of a moment as short as the sound of a pebble thrown into water. ++ ALL WORKS PUBLISHED ARE COPYRIGHTED AND THE RIGHTS BELONG TO THE AUTHORS ++ !!! Anonymous comments will be seen as SPAM !!! Dear Haijin, visitors and travelers, A few months ago (Oct 2021) I started a new feature here at Carpe Diem Haiku Kai, the place to be if ...', 'The Darién Gap\xa0is a break in the Pan-American Highway consisting of a large swath of undeveloped swampland and forest within Panama’s Darién Province in Central America and the northern portion of Colombia’s Chocó Department of South America. It measures just over 160\xa0km (99\xa0mi) long and about 50\xa0km (31\xa0mi) wide. Roadbuilding through this area is expensive, and the environmental toll is steep. Political consensus in favor of road construction has not emerged. Consequently there is no road connection through the Darién Gap connecting North/Central America with South America and it is the missing link of the Pan-American Highway. The geography of the Darién Gap on the Colombian side is dominated primarily by the river delta of the Atrato River, which creates a flat marshland at least 80\xa0km (50\xa0mi) wide, half of this being swampland. The Serranía del Baudó occupy Colombia’s Pacific coast and extend into Panama. The Panamanian side, in sharp contrast, is a mountainous rainforest, with terrain reaching from 60\xa0m (200\xa0ft) in the valley floors to 1,845\xa0m (6,053\xa0ft) at the tallest peaks (Cerro Tacarcuna). The Pan-American Highway is a system of roads measuring about 48,000\xa0km (30,000\xa0mi) long that crosses through the entirety of North, Central, and South America, with the sole exception of the Darién Gap. On the South American side, the highway terminates at Turbo, Colombia. On the Panamanian side, the road terminus is the town of Yaviza at. This marks a straight-line separation of about 100\xa0km (60\xa0mi). In between is marshland and forest. Efforts have been made for decades to remedy this missing link in the Pan-American highway. Planning began in 1971 with the help of United States funding, but this was halted in 1974 after concerns raised by environmentalists. Another effort to build the road began in 1992, but by 1994 a United Nations agency reported that the road, and the subsequent development, would cause extensive environmental damage. There is evidence that the Darién Gap has prevented the spread of diseased cattle into Central and North America, which have not seen foot-and-mouth disease since 1954, and since at least the 1970s this has been a substantial factor in preventing a road link through the Darién Gap. The Embera-Wounaan and Kuna have also expressed concern that the road would bring about the potential erosion of their cultures. The gap has been crossed by adventurers on bicycle, motorbike, all-terrain vehicle, and foot, dealing with jungle, swamp, insects, and other hazards. This place looks like a mosquito and snake infested hot box. End of the road, Panama side. Notify me of new comments via email. Notify me of new posts via email. This site uses Akismet to reduce spam. Learn how your comment data is processed.', '']","The Darién Gap is a break in the Pan-American Highway consisting of a large swath of undeveloped swampland and forest within Panama's Darién Province in Central America and the northern portion of Colombia's Chocó Department in South America. The gap begins in Yaviza, Panama and ends in Turbo, Colombia, and is 106 km (66 miles) long. Roadbuilding through this area is expensive and the environmental cost is high. Political consensus in favor of road construction has not emerged."
where and when was the tsunami that caused the most casualties,"['The 2004 Indian Ocean earthquake and tsunami (also known as the Boxing Day Tsunami and, by the scientific community, the Sumatra–Andaman earthquake[8] [9]) occurred at 07:58:53 local time (UTC+7) on 26 December, with an epicentre off the west coast of northern Sumatra, Indonesia. It was an undersea megathrust earthquake that registered a magnitude of 9.1–9.3, reaching a Mercalli intensity up to IX in certain areas. The earthquake was caused by a rupture along the fault between the Burma Plate and the Indian Plate. A series of massive tsunami waves grew up to high once heading inland, after being created by the underwater seismic activity offshore. Communities along the surrounding coasts of the Indian Ocean were devastated, and the tsunamis killed an estimated 227,898 people in 14 countries, making it one of the deadliest natural disasters in recorded history. The direct results caused major disruptions to living conditions and commerce in coastal provinces of surrounded countries, including Aceh (Indonesia), Sri Lanka, Tamil Nadu (India) and Khao Lak (Thailand). Banda Aceh reported the largest number of deaths. The earthquake was the third-largest ever recorded, the largest in the 21st century and had the longest duration of faulting ever observed, between eight and ten minutes.[10] It caused the planet to vibrate as much as,[11] and also remotely triggered earthquakes as far away as Alaska.[12] Its epicentre was between Simeulue and mainland Sumatra.[13] The plight of the affected people and countries prompted a worldwide humanitarian response, with donations totalling more than US$14 billion.[14] The 2004 Indian Ocean earthquake was initially documented as having a moment magnitude of 8.8. In February 2005, scientists revised the estimate of the magnitude to 9.0.[15] Although the Pacific Tsunami Warning Center has accepted these new numbers, the United States Geological Survey has, as of 2022, so far not changed its estimate of 9.1.[16] A 2006 study estimated a magnitude of 9.1–9.3; Hiroo Kanamori of the California Institute of Technology estimates that 9.2 is representative of the earthquake\'s size.[17] The hypocentre of the main earthquake was approximately off the western coast of northern Sumatra, in the Indian Ocean just north of Simeulue island at a depth of below mean sea level (initially reported as). The northern section of the Sunda megathrust ruptured over a length of .[13] The earthquake (followed by the tsunami) was felt in Bangladesh, India, Malaysia, Myanmar, Thailand, Sri Lanka and the Maldives.[18] Splay faults, or secondary ""pop up faults"", caused long, narrow parts of the seafloor to pop up in seconds. This quickly elevated the height and increased the speed of waves, destroying the nearby Indonesian town of Lhoknga.[19] Indonesia lies between the Pacific Ring of Fire along the north-eastern islands adjacent to New Guinea, and the Alpide belt that runs along the south and west from Sumatra, Java, Bali, Flores to Timor. The 2002 Sumatra earthquake is believed to have been a foreshock, preceding the main event by over two years.[20] Great earthquakes, such as the 2004 Indian Ocean earthquake, are associated with megathrust events in subduction zones. Their seismic moments can account for a significant fraction of the global seismic moment across century-scale periods. Of all the moment released by earthquakes in the 100 years from 1906 through 2005, roughly one eighth was due to the 2004 Indian Ocean earthquake. This quake, together with the Great Alaskan earthquake (1964) and the Great Chilean earthquake (1960), account for almost half of the total moment. Since 1900, the only earthquakes recorded with a greater magnitude were the 1960 Valdivia earthquake (magnitude 9.5) and the 1964 Alaska earthquake in Prince William Sound (magnitude 9.2). The only other recorded earthquakes of magnitude 9.0 or greater were off Kamchatka, Russia, on 4 November 1952 (magnitude 9.0) and Tōhoku, Japan (magnitude 9.1) in March 2011. Each of these megathrust earthquakes also spawned tsunamis in the Pacific Ocean. In comparison to the 2004 Indian Ocean earthquake, the death toll from these earthquakes was significantly lower, primarily because of the lower population density along the coasts near affected areas, the much greater distances to more populated coasts, and the superior infrastructure and warning systems in MEDCs (More Economically Developed Countries) such as Japan. Other huge megathrust earthquakes occurred in 1868 (Peru, Nazca Plate and South American Plate); 1827 (Colombia, Nazca Plate and South American Plate); 1812 (Venezuela, Caribbean Plate and South American Plate) and 1700 (western North America, Juan de Fuca Plate and North American Plate). All of them are believed to be greater than magnitude 9, but no accurate measurements were available at the time. See main article: Plate tectonics. The 2004 Indian Ocean earthquake was unusually large in geographical and geological extent. An estimated of fault surface slipped (or ruptured) about along the subduction zone where the Indian Plate slides (or subducts) under the overriding Burma Plate. The slip did not happen instantaneously but took place in two phases over several minutes:Seismographic and acoustic data indicate that the first phase involved a rupture about long and wide, beneath the sea bed—the largest rupture ever known to have been caused by an earthquake. The rupture proceeded at about, beginning off the coast of Aceh and proceeding north-westerly over about 100 seconds.After a pause of about another 100 seconds, the rupture continued northwards towards the Andaman and Nicobar Islands. The northern rupture occurred more slowly than in the south, at about, continuing north for another five minutes to a plate boundary where the fault type changes from subduction to strike-slip (the two plates slide past one another in opposite directions). The Indian Plate is part of the great Indo-Australian Plate, which underlies the Indian Ocean and Bay of Bengal, and is moving north-east at an average of . The India Plate meets the Burma Plate (which is considered a portion of the great Eurasian Plate) at the Sunda Trench. At this point, the India Plate subducts beneath the Burma Plate, which carries the Nicobar Islands, the Andaman Islands, and northern Sumatra. The India Plate sinks deeper and deeper beneath the Burma Plate until the increasing temperature and pressure drive volatiles out of the subducting plate. These volatiles rise into the overlying plate, causing partial melting and the formation of magma. The rising magma intrudes into the crust above and exits the Earth\'s crust through volcanoes in the form of a volcanic arc. The volcanic activity that results as the Indo-Australian Plate subducts the Eurasian Plate has created the Sunda Arc. As well as the sideways movement between the plates, the 2004 Indian Ocean earthquake resulted in a rise of the seafloor by several metres, displacing an estimated of water and triggering devastating tsunami waves. The waves radiated outwards along the entire length of the rupture (acting as a line source). This greatly increased the geographical area over which the waves were observed, reaching as far as Mexico, Chile, and the Arctic. The raising of the seafloor significantly reduced the capacity of the Indian Ocean, producing a permanent rise in the global sea level by an estimated .[21] See also: List of earthquakes in Indonesia and List of earthquakes in 2004. Numerous aftershocks were reported off the Andaman Islands, the Nicobar Islands and the region of the original epicentre in the hours and days that followed. The magnitude 8.7 2005 Nias–Simeulue earthquake, which originated off the coast of the Sumatran island of Nias, is not considered an aftershock, despite its proximity to the epicentre, and was most likely triggered by stress changes associated with the 2004 event.[22] The earthquake produced its own aftershocks (some registering a magnitude of as high as 6.1) and presently ranks as the third-largest earthquake ever recorded on the moment magnitude or Richter magnitude scale. Other aftershocks of up to magnitude 6.6 continued to shake the region daily for three or four months.[23] As well as continuing aftershocks, the energy released by the original earthquake continued to make its presence felt well after the event. A week after the earthquake, its reverberations could still be measured, providing valuable scientific data about the Earth\'s interior. The 2004 Indian Ocean earthquake came just three days after a magnitude 8.1 earthquake in the sub-antarctic Auckland Islands, an uninhabited region west of New Zealand, and Macquarie Island to Australia\'s north. This is unusual since earthquakes of magnitude eight or more occur only about once per year on average.[24] The U.S. Geological Survey sees no evidence of a causal relationship between these events.[25] The 2004 Indian Ocean earthquake is thought to have triggered activity in both Leuser Mountain[26] and Mount Talang,[27] volcanoes in Aceh along the same range of peaks, while the 2005 Nias–Simeulue earthquake had sparked activity in Lake Toba, an ancient crater in Sumatra.[28] The energy released on the Earth\'s surface (ME, which is the seismic potential for damage) by the 2004 Indian Ocean earthquake was estimated at 1.1E+17J.[29] This energy is equivalent to over 1,500 times that of the Hiroshima atomic bomb, but less than that of Tsar Bomba, the largest nuclear weapon ever detonated.[30] The earthquake generated a seismic oscillation of the Earth\'s surface of up to, equivalent to the effect of the tidal forces caused by the Sun and Moon. The seismic waves of the earthquake were felt across the planet, as far away as the U.S. state of Oklahoma, where vertical movements of were recorded. By February 2005, the earthquake\'s effects were still detectable as a complex harmonic oscillation of the Earth\'s surface, which gradually diminished and merged with the incessant free oscillation of the Earth more than four months after the earthquake.[31] Because of its enormous energy release and shallow rupture depth, the earthquake generated remarkable seismic ground motions around the globe, particularly due to huge Rayleigh (surface) elastic waves that exceeded in vertical amplitude everywhere on Earth. The record section plot displays vertical displacements of the Earth\'s surface recorded by seismometers from the IRIS/USGS Global Seismographic Network plotted with respect to time (since the earthquake initiation) on the horizontal axis, and vertical displacements of the Earth on the vertical axis (note the 1\xa0cm scale bar at the bottom for scale). The seismograms are arranged vertically by distance from the epicentre in degrees. The earliest, lower amplitude signal is that of the compressional (P) wave, which takes about 22 minutes to reach the other side of the planet (the antipode; in this case near Ecuador). The largest amplitude signals are seismic surface waves that reach the antipode after about 100 minutes. The surface waves can be clearly seen to reinforce near the antipode (with the closest seismic stations in Ecuador), and to subsequently encircle the planet to return to the epicentral region after about 200 minutes. A major aftershock (magnitude 7.1) can be seen at the closest stations starting just after the 200-minute mark. The aftershock would be considered a major earthquake under ordinary circumstances but is dwarfed by the mainshock. The shift of mass and the massive release of energy slightly altered the Earth\'s rotation. Weeks after the earthquake, theoretical models suggested the earthquake shortened the length of a day by 2.68 microseconds, due to a decrease in the oblateness of the Earth. [32] It also caused the Earth to minutely ""wobble"" on its axis by up to in the direction of 145° east longitude,[33] or perhaps by up to .[34] Because of tidal effects of the Moon, the length of a day increases at an average of 15 microseconds per year, so any rotational change due to the earthquake will be lost quickly. Similarly, the natural Chandler wobble of the Earth, which in some cases can be up to, will eventually offset the minor wobble produced by the earthquake. There was movement laterally and vertically along the fault line. Early speculation was that some of the smaller islands south-west of Sumatra, which is on the Burma Plate (the southern regions are on the Sunda Plate), might have moved south-west by up to, but more accurate data released more than a month after the earthquake found the movement to be about .[35] Since movement was vertical as well as lateral, some coastal areas may have been moved to below sea level. The Andaman and Nicobar Islands appear to have shifted south-west by around and to have sunk by .[36] In February 2005, the Royal Navy vessel surveyed the seabed around the earthquake zone, which varies in depth between . The survey, conducted using a high-resolution, multi-beam sonar system, revealed that the earthquake had made a considerable impact on the topography of the seabed. 1500m (4,900feet) thrust ridges created by previous geologic activity along the fault had collapsed, generating landslides several kilometres wide. One such landslide consisted of a single block of rock some high and long. The momentum of the water displaced by tectonic uplift had also dragged massive slabs of rock, each weighing millions of tonnes, as far as across the seabed. An oceanic trench several kilometres wide was exposed in the earthquake zone.[37] The TOPEX/Poseidon and Jason-1 satellites happened to pass over the tsunami as it was crossing the ocean.[38] These satellites carry radars that measure precisely the height of the water surface; anomalies in the order of were measured. Measurements from these satellites may prove invaluable for the understanding of the earthquake and tsunami.[39] Unlike data from tide gauges installed on shores, measurements obtained in the middle of the ocean can be used for computing the parameters of the source earthquake without having to compensate for the complex ways in which proximity to the coast changes the size and shape of a wave. The sudden vertical rise of the seabed by several metres during the earthquake displaced massive volumes of water, resulting in a tsunami that struck the coasts of the Indian Ocean. A tsunami that causes damage far away from its source is sometimes called a teletsunami and is much more likely to be produced by the vertical motion of the seabed than by horizontal motion.[40] The tsunami, like all others, behaved differently in deep water than in shallow water. In deep ocean water, tsunami waves form only a low, broad hump, barely noticeable and harmless, which generally travels at high speed of ; in shallow water near coastlines, a tsunami slows down to only tens of kilometres per hour but, in doing so, forms large destructive waves. Scientists investigating the damage in Aceh found evidence that the wave reached a height of when coming ashore along large stretches of the coastline, rising to in some areas when travelling inland.[41] Radar satellites recorded the heights of tsunami waves in deep water: maximum height was at two hours after the earthquake, the first such observations ever made.[42] [43] According to Tad Murty, vice-president of the Tsunami Society, the total energy of the tsunami waves was equivalent to about 5MtonTNT, which is more than twice the total explosive energy used during all of World War II (including the two atomic bombs) but still a couple of orders of magnitude less than the energy released in the earthquake itself. In many places, the waves reached as far as inland.[44] Because the fault affected by the earthquake was in a nearly north–south orientation, the greatest strength of the tsunami waves was in an east–west direction. Bangladesh, which lies at the northern end of the Bay of Bengal, had few casualties despite being a low-lying country relatively near the epicentre. It also benefited from the fact that the earthquake proceeded more slowly in the northern rupture zone, greatly reducing the energy of the water displacements in that region. Coasts that have a landmass between them and the tsunami\'s location of origin are usually safe; however, tsunami waves can sometimes diffract around such landmasses. Thus, the state of Kerala was hit by the tsunami despite being on the western coast of India, and the western coast of Sri Lanka suffered substantial impacts. Distance alone was no guarantee of safety, as Somalia was hit harder than Bangladesh despite being much farther away. Because of the distances involved, the tsunami took anywhere from fifteen minutes to seven hours to reach the coastlines.[45] [46] The northern regions of the Indonesian island of Sumatra were hit quickly, while Sri Lanka and the east coast of India were hit roughly 90 minutes to two hours later. Thailand was struck about two hours later despite being closer to the epicentre because the tsunami travelled more slowly in the shallow Andaman Sea off its western coast. The tsunami was noticed as far as Struisbaai in South Africa, about away, where a 1.5m (04.9feet) tide surged on shore about 16 hours after the earthquake. It took a relatively long time to reach Struisbaai at the southernmost point of Africa, probably because of the broad continental shelf off South Africa and because the tsunami would have followed the South African coast from east to west. The tsunami also reached Antarctica, where tidal gauges at Japan\'s Showa Base recorded oscillations of up to a metre (1m (03feet)), with disturbances lasting a couple of days.[47] Some of the tsunami\'s energy escaped into the Pacific Ocean, where it produced small but measurable tsunamis along the western coasts of North and South America, typically around .[48] At Manzanillo, Mexico, a crest-to-trough tsunami was measured. As well, the tsunami was large enough to be detected in Vancouver, which puzzled many scientists, as the tsunamis measured in some parts of South America were larger than those measured in some parts of the Indian Ocean. It has been theorized that the tsunamis were focused and directed at long ranges by the mid-ocean ridges which run along the margins of the continental plates.[49] Despite a delay of up to several hours between the earthquake and the impact of the tsunami, nearly all of the victims were taken by surprise. There were no tsunami warning systems in the Indian Ocean to detect tsunamis or to warn the general population living around the ocean.[50] Tsunami detection is not easy because while a tsunami is in deep water, it has little height and a network of sensors is needed to detect it. Tsunamis are more frequent in the Pacific Ocean than in other oceans because of earthquakes in the ""Ring of Fire"". Although the extreme western edge of the Ring of Fire extends into the Indian Ocean (the point where the earthquake struck), no warning system exists in that ocean. Tsunamis there are relatively rare despite earthquakes being relatively frequent in Indonesia. The last major tsunami was caused by the 1883 eruption of Krakatoa. Not every earthquake produces large tsunamis: on 28 March 2005, a magnitude 8.7 earthquake hit roughly the same area of the Indian Ocean but did not result in a major tsunami. The first warning sign of a possible tsunami is the earthquake itself. However, tsunamis can strike thousands of kilometres away where the earthquake is felt only weakly or not at all. Also, in the minutes preceding a tsunami strike, the sea sometimes recedes temporarily from the coast, which was observed on the eastern earthquake rupture zone such as the coastlines of Aceh, Phuket island, and Khao Lak area in Thailand, Penang island of Malaysia, and the Andaman and Nicobar islands. This rare sight reportedly induced people, especially children, to visit the coast to investigate and collect stranded fish on as much as of exposed beach, with fatal results.[51] However, not all tsunamis cause this ""disappearing sea"" effect. In some cases, there are no warning signs at all: the sea will suddenly swell without retreating, surprising many people and giving them little time to flee. One of the few coastal areas to evacuate ahead of the tsunami was on the Indonesian island of Simeulue, close to the epicentre. Island folklore recounted an earthquake and tsunami in 1907, and the islanders fled to inland hills after the initial shaking and before the tsunami struck. These tales and oral folklore from previous generations may have helped the survival of the inhabitants.[52] On Maikhao Beach in north Phuket City, Thailand, a 10-year-old British tourist named Tilly Smith had studied tsunamis in geography at school and recognised the warning signs of the receding ocean and frothing bubbles. She and her parents warned others on the beach, which was evacuated safely.[53] John Chroston, a biology teacher from Scotland, also recognised the signs at Kamala Bay north of Phuket, taking a busload of vacationers and locals to safety on higher ground. Anthropologists had initially expected the aboriginal population of the Andaman Islands to be badly affected by the tsunami and even feared the already depopulated Onge tribe could have been wiped out.[54] Many of the aboriginal tribes evacuated and suffered fewer casualties, however.[55] [56] Oral traditions developed from previous earthquakes helped the aboriginal tribes escape the tsunami. For example, the folklore of the Onges talks of ""huge shaking of ground followed by high wall of water"". Almost all of the Onge people seemed to have survived the tsunami.[57] The tsunami devastated the coastline of Aceh province, about 20 minutes after the earthquake. Banda Aceh, the closest major city, suffered severe casualties. The sea receded and exposed the seabed, prompting locals to collect stranded fish and explore the area. Local eyewitnesses described three large waves, with the first wave rising gently to the foundation of the buildings, followed minutes later by a sudden withdrawal of the sea near the port of Ulee Lheue. This was succeeded by the appearance of two large black-coloured steep waves which then travelled inland into the capital city as a large turbulent bore. Eyewitnesses described the tsunami as a ""black giant"", ""mountain"" and a ""wall of water"". Video footage revealed torrents of black water, surging by windows of a two-story residential area situated about inland. Additionally, amateur footage recorded in the middle of the city captured an approaching black surge flowing down the city streets, full of debris, inundating them.[58] The level of destruction was extreme on the northwestern areas of the city, immediately inland of the aquaculture ponds, and directly facing the Indian Ocean. The tsunami height was reduced from at Ulee Lheue to a further to the north-east. The inundation was observed to extend inland throughout the city. Within of the shoreline, houses, except for strongly-built reinforced concrete ones with brick walls, which seemed to have been partially damaged by the earthquake before the tsunami attack, were swept away or destroyed by the tsunami.[59] [60] The area toward the sea was wiped clean of nearly every structure, while closer to the river, dense construction in a commercial district showed the effects of severe flooding. The flow depth at the city was just at the level of the second floor, and there were large amounts of debris piled along the streets and in the ground-floor storefronts. In the seaside section of Ulee Lheue, the flow depths were over . Footage showed evidence of back-flowing of the Aceh River, carrying debris and people from destroyed villages at the coast and transporting them up to inland.[61] A group of small islands: Weh, Breueh, Nasi, Teunom, Bunta, Lumpat, and Batee lie just north of the capital city. The tsunami reached a run-up of on the western shorelines of Breueh Island and Nasi Island. Coastal villages were destroyed by the waves. On the island of Pulau Weh, strong surges were experienced in the port of Sabang, yet there was little damage with reported runup values of, most likely due to the island being sheltered from the direct attack by the islands to the south-west.[60] Lhoknga is a small coastal community about south-west of Banda Aceh, located on a flat coastal plain in between two rainforest-covered hills, overlooking a large bay and famous for its large swathe of white sandy beach and surfing activities. The locals reported 10 to 12 waves, with the second and third being the highest and most destructive. Interviews with the locals revealed that the sea temporarily receded and exposed coral reefs. In the distant horizon, gigantic black waves about high made explosion-like sounds as it broke and approached the shore. The first wave came rapidly landward from the south-west as a turbulent bore about high.The second and third waves were high at the coast and appeared like gigantic surfing waves but ""taller than the coconut trees and was like a mountain"".[62] The second wave was the largest; it came from the west-southwest within five minutes of the first wave. The tsunami stranded cargo ships, barges and destroyed a cement mining facility near the Lampuuk coast, where it reached the fourth level of the building.[4] [63] [64] Meulaboh, a remote coastal city, was among the hardest hit by the tsunami. The waves arrived after the sea receded about, followed by an advancing small tsunami. The second and third destructive waves arrived later, which exceeded the height of the coconut trees. The inundation distance is about . Other towns on Aceh\'s west coast hit by the disaster included Leupung, Lhokruet, Lamno, Patek, Calang, and Teunom. Affected or destroyed towns on the region\'s north and east coast were Pidie Regency, Samalanga, Panteraja, and Lhokseumawe. The high fatality rate in the area was mainly due to lack of preparation of the community towards a tsunami and limited knowledge and education among the population regarding the natural phenomenon. Helicopter surveys showed entire settlements virtually destroyed with destruction within miles inland, and only some mosques left standing.[65] The greatest run-up height of the tsunami was measured at a hill between Lhoknga and Leupung, on the western coast of the northern tip of Sumatra, near Banda Aceh, and reached .[4] [66] The island country of Sri Lanka, located about from Sumatra, was ravaged by the tsunami around 2 hours after the earthquake. The tsunami first struck the eastern coastline and subsequently refracted around the southern point of Sri Lanka (Dondra Head). The refracted tsunami waves then inundated the southwestern part of Sri Lanka after some of its energy was reflected from impact with the Maldives.[67] In Sri Lanka, the civilian casualties were second only to those in Indonesia, with approximately 35,000 killed. The eastern shores of Sri Lanka were the hardest hit since it faced the epicentre of the earthquake, while the southwestern shores were hit later, but the death toll was just as severe. The southwestern shores are a hotspot for tourists and fishing.[68] The degradation of the natural environment in Sri Lanka contributed to the high death tolls. Approximately 90,000 buildings and many wooden houses were destroyed.[68] The tsunami arrived on the island as a small brown-orange-colored flood. Moments later, the ocean floor was exposed as much as in places, which was followed by massive second and third waves. Amateur video recorded at the city of Galle showed a large deluge flooding the city, carrying debris and sweeping away people while in the coastal resort town of Beruwala, the tsunami appeared as a huge brown-orange colored bore which reached the first level of a hotel, causing destruction and taking people unaware. Other videos recorded showed that the tsunami appeared like a flood raging inland. The construction of seawalls and breakwaters reduced the power of waves at some locations. The largest run-up measured was at with inundation distance of in Yala.[69] In Hambantota, run-ups measured with the greatest inundation distance of . Run-up measurements along the Sri Lankan coasts are at .[69] [67] Waves measured on the east coast ranged from at Pottuvill to Batticaloa at in the north-east around Trincomalee and in the west coast from Moratuwa to Ambalangoda. A regular passenger train operating between Maradana and Matara was derailed and overturned by the tsunami and claimed at least 1,700 lives, the largest single rail disaster death toll in history.[70] Estimates based on the state of the shoreline and a high-water mark on a nearby building place the tsunami above sea level and higher than the top of the train. The tsunami travelled eastward through the Andaman Sea and hit the south-western coasts of Thailand, about 2 hours after the earthquake. Located about from the epicentre, at the time, the region was popular with tourists because of Christmas. Many of these tourists were caught off-guard by the tsunami, as they had no prior warning. The tsunami hit during high tide. Major locations damaged included the western shores of Phuket island, the resort town of Khao Lak in Phang Nga Province, the coastal provinces of Krabi, Satun, Ranong and Trang and small offshore islands like Ko Racha Yai, the Phi Phi islands, the Surin Islands and the Similan archipelago. Approximately 8,000 people were killed. Thailand experienced the second largest tsunami run-up. The tsunami heights recorded:[71] The province of Phang Nga was the most affected area in Thailand. The quiet resort town of Khao Lak is located on a stretch of golden sandy beach, famed for its hotels overlooking the Andaman Sea and hilly rainforests. A video, taken by a local restaurant manager from a hill adjacent to the beach, showed that the tsunami\'s arrival was preceded by a sudden retreat of the sea exposing the seafloor. Many tourists and locals can be seen trying to gather fish. Moments later, the tsunami arrives as a wall of foaming water that slams into the coast, washing away numerous people who had no time to escape. Another amateur video, captured by a German family at beach level, showed the tsunami appearing as a white horizontal line in the distant horizon, gradually becoming bigger (bore-like), engulfing a jet skier and lifting two police boats.[72] A maximum inundation of approximately was measured, the inundated depths were and there was evidence that the tsunami reached the third floor of a resort hotel. The tsunami in Khao Lak was bigger due to offshore coral reefs and shallow seafloor which caused the tsunami to pile-up. This was similar to eyewitness accounts of the tsunami at Banda Aceh. Khao Lak also experienced the largest tsunami run-up height outside of Sumatra.[73] . The highest-recorded tsunami run-up was measured at Ban Thung Dap, on the south-west tip of Ko Phra Thong Island and the second-highest at at Ban Nam Kim.[71] Moreover, the largest death toll occurred at Khao Lak, with about 5,000 people killed. In addition, the tsunami inflicted damage to the popular resort town of Ao Nang in Krabi Province. Video footage showed that the tsunami appeared as multiple white surfs violently lifting up yachts, boats and crashing onto beaches. Footage captured at Koh Lanta showed a wall of water swamping the beach, while another video taken at another location showed a large surfing wave like tsunami approaching the shore, lifting up a yacht and flooding the beach. At Koh Sriboya, the tsunami advanced inland as a turbulent medium bore, while at Koh Phayam, Ranong Province, the tsunami appeared as a wall of water. At Phuket Province, the island province\'s western beaches were struck by the tsunami. At Patong Beach, a popular tourist destination, the tsunami first arrived as a small flood, which swept away cars and surprised people. About 10 minutes later, the sea receded for a while before the tsunami arrived again as a large wall of water looming over the skyline and flooding the coast. Another video from Kamala Beach showed the tsunami flooding the ground floor of a restaurant sweeping away an elderly couple. On Karon Beach, Kamala Beach and Kata Beach, the tsunami came in like a surging flood inland carrying people and cars. On some locations, a coastal road was built which was higher than the shore, protecting a hotel which was behind it. On the east coast of Phuket Island, the tsunami height was about 2 m. In one river mouth, many boats were damaged. The tsunami moved counter-clockwise around Phuket Island, as was the case at Okushiri Island in the 1993 Hokkaido earthquake. According to interviews, the second wave was the largest.[73] The tsunami heights were and the inundated depth was about . The tsunami surprised many tourists at Koh Racha Yai, where it flooded the resorts. About 250 people perished directly in the tsunami. The Phi Phi Islands are a group of small islands that were affected by the tsunami. The north bay of Phi Phi Don Island opens to the north-west in the direction of the tsunami. The measured tsunami height on this beach was . According to eyewitness accounts, the tsunami came from the north and south. The ground level was about 2 m above sea level, where there were many cottages and hotels. The south bay opens to the south-east and faces in the opposite direction from the tsunami. Furthermore, Phi Phi Le Island shields the port of Phi Phi Don Island. The measured tsunami height was in the port.[73] Amateur camcorder footage taken by Israeli tourists showed the tsunami advancing inland suddenly as a small flood, gradually becoming more powerful and engulfing the whole beach and resort, with the tsunami carrying a yacht out to sea. Moreover, the tsunami was detected by scuba divers around offshore islands like the Similan Islands and the Surin Islands. The divers reported being caught in a violent, swirling current suddenly while underwater. Local camcorder footage showed the tsunami surging inland and flooding camping equipment at the Similan Islands while the tsunami caught tourists unaware at the Surin Islands, and dragging them out towards the sea. The tsunami reached the states of Andhra Pradesh and Tamil Nadu along the southeastern coastline of the Indian mainland about 2 hours after the earthquake. At the same time, it arrived in the state of Kerala, on the southwestern coast. There were two to five tsunamis that coincided with the local high tide in some areas.[74] [75] [76] [77] Along the coast of Tamil Nadu, the Marina Beach in Chennai was battered by the tsunami which swept across the beach taking morning walkers unaware. Amateur video recorded taken at a resort beach showed the tsunami arriving as a large wall of water as it approached the coast and flooding it as it advanced inland. Besides that, a black muddy tsunami ravaged the city of Karaikal, where 492 lives were lost. The city of Pondicherry, protected by seawalls was relatively unscathed. Local video recorded that before the arrival of the tsunami, people can be seen swarming the beach to check on stranded fish from the exposed beach. Furthermore, at the coastal town of Kanyakumari, the seabed was exposed briefly before a large wall of water can be seen on the horizon and subsequently flooding the town. Other footage showed the tsunami dramatically crashed into the Vivekananda Rock Memorial.[77] The worst affected area in Tamil Nadu was Nagapattinam district, with 6,051 fatalities caused by a tsunami, followed by Cuddalore district, with many villages destroyed.[77] Most of the people killed were members of the fishing community.[77] Velankanni a sea shore town with a Catholic Basilica and a popular pilgrimage destination was also one of the worst hit by this tsunami that struck at around 9.30 am on that Sunday, when pilgrims who were mostly from Kerala among others were inside the church attending the Malayalam Mass. The rising sea water did not enter the shrine, but the receding waters swept away hundreds of pilgrims who were on the beach.[78] The shrine\'s compound, nearby villages, hundreds of shops, homes and pilgrims were washed away into the sea. About 600 pilgrims died.[79] Rescue teams extricated more than 400 bodies from the sand and rocks in the vicinity and large number of unidentified bodies were buried in mass graves. The state of Kerala experienced tsunami-related damage in three southern densely populated districts, Ernakulam, Alappuzha, and Kollam, due to diffraction of the waves around Sri Lanka. The southernmost district of Thiruvananthapuram, however, escaped damage, possibly due to the wide turn of the diffracted waves at the peninsular tip. Major damage occurred in two narrow strips of land bound on the west by the Arabian Sea and on the east by the Kerala backwaters. The waves receded before the first tsunami with the highest fatality reported from the densely populated Alappad panchayat (including the villages of Cheriya Azhikkal and Azhikkal) at Kollam district, caused by a tsunami.[77] A video recorded by locals showed the tsunami flooding the beach and villages, causing despair amongst the villagers. Many villages in the state of Andhra Pradesh were destroyed. In the Krishna district, the tsunami created havoc in Manginapudi and on Machalipattanam Beach. The most affected was Prakasham District, recording 35 deaths, with maximum damage at Singraikonda.[77] Given the enormous power of the tsunami, the fishing industry suffered the greatest. Moreover, the cost of damage in the transport sector was reported in the tens of thousands.[77] The tsunami run-up was only in areas in the state of Tamil Nadu shielded by the island of Sri Lanka but was in coastal districts such as Nagapattinam in Tamil Nadu directly across from Sumatra. On the western coast, the runup elevations were at Kanyakumari District in Tamil Nadu and each at Kollam and Ernakulam districts in Kerala. The time between the waves ranged from about 15 minutes to 90 minutes.[74] [76] [80] The tsunami varied in height from to based on survivors\' accounts.[77] The tsunami travelled at its maximum inland at Karaikal, Puducherry.[77] The inundation distance varied between in most areas, except at river mouths, where it was more than . Areas with dense coconut groves or mangroves had much smaller inundation distances, and those with river mouths or backwaters saw larger inundation distances. Presence of seawalls at the Kerala and Tamil Nadu coasts reduced the impact of the waves. However, when the seawalls were made of loose stones, the stones were displaced and carried a few metres inland.[74] [76] [80] Due to close proximity to the earthquake, the tsunami took just minutes to devastate the Andaman and Nicobar Islands. The Andaman Islands were moderately affected while the island of Little Andaman and the Nicobar Islands were severely affected by the tsunami. In South Andaman island, based on local eyewitnesses, there were three tsunami waves, with the third being the most destructive. Flooding occurred at the coast and low-lying areas inland, which were connected to open sea through creeks. Inundation was observed, along the east coast of South Andaman Island, restricted to Chidiyatapu, Burmanallah, Kodiaghat, Beadnabad, Corbyn\'s cove and Marina Park/Aberdeen Jetty areas. Along the west coast, the inundation was observed around Guptapara, Manjeri, Wandoor, Collinpur and Tirur regions. Several near-shore establishments and numerous infrastructures such as seawalls and a 20 MW diesel-generated power plant at Bamboo Flat were destroyed.[81] At Port Blair, the water receded before the first wave, and the third wave was the tallest and caused the most damage. Meanwhile, in the Little Andaman, tsunami waves impinged on the eastern shore about 25 to 30 minutes after the earthquake in a four-wave cycle of which the fourth tsunami was the most devastating with a wave height of about . The tsunami destroyed settlements at Hut Bay within a range of from the seashore. Run up level up to have been measured.[81] In Malacca, located on the island of Car Nicobar, there were three tsunami waves. The sea was observed to rise suddenly before the onset of the first wave. The first wave came 5 minutes after the earthquake, preceded by a recession of the sea up to .. The second and third waves came in 10 minutes intervals after the first wave. The third wave was the strongest, with a maximum tsunami wave height of . Waves nearly three stories high devastated the Indian Air Force base, located just south of Malacca. The maximum tsunami wave height of . Inundation limit was found to be up to inland. The impact of the waves was so severe that four oil tankers were thrown almost from the seashore near Malacca to the Air force colony main gate.[81] In Chuckchucha and Lapati, the tsunami arrived in a three-wave cycle with a maximum tsunami wave height of . In Campbell Bay of Great Nicobar Island, the tsunami waves hit the area three times with an inundation limit of . A rise in sea level was observed before the first wave came within 5 minutes of the earthquake. The second and third waves came in 10-minute intervals after the first. The second wave was the strongest. The tsunami waves wreaked havoc in the densely populated Jogindar Nagar area, situated south of Campbell Bay. According to local accounts, tsunami waves attacked the area three times. The first wave came five minutes after the mainshock (0629 hrs.) with a marginal drop in sea level. The second wave came 10 minutes after the first one with a maximum height of to 8\xa0m (26\xa0ft) and caused the major destruction. The third wave came within 15 minutes after the second with lower wave height. The maximum inundation limit due to tsunami water was about .[81] The worst affected island in the Andaman & Nicobar chain is Katchall Island, with 303 people confirmed dead and 4,354 missing out of a total population of 5,312.[82] [83] [84] The significant shielding of Port Blair and Campbell Bay by steep mountainous outcrops contributed to the relatively low wave heights at these locations, whereas the open terrain along the eastern coast at Malacca and Hut Bay contributed to the great height of the tsunami waves.[83] [85] The tsunami severely affected the Maldives at a distance of from the epicentre. Similar to Sri Lanka, survivors reported three waves with the second wave being the most powerful. Being rich in coral reefs, the Maldives provides an opportunity for scientists to assess the impact of a tsunami on coral atolls. The significantly lower tsunami impact on the Maldives compared to Sri Lanka is mostly due to the topography and bathymetry of the atoll chain with offshore coral reefs, deep channels separating individual atolls and its arrival within low tide which decreased the power of the tsunami. After the tsunami, there was some concern that the country might be submerged entirely and become uninhabitable. However, this was proven untrue.The highest tsunami wave measured was at Vilufushi Island. The tsunami arrived approximately 2 hours after the earthquake. The greatest tsunami inundation occurred at North Male Atoll, Male island at along the streets. Local footage recorded showed the tsunami flooding the streets up to knee level in town, while another video taken at the beach showed the tsunami slowly flooding and gradually surging inland. In Myanmar, the tsunami caused only moderate damage, which arrived between 2 and 5.5 hours after the earthquake. Although the country\'s western Andaman Sea coastline lies at the proximity of the rupture zone, there were smaller tsunamis than the neighbouring Thai coast, because the main tsunami source did not extend to the Andaman Islands. Another factor is that some coasts of Taninthayi Division were protected by the Myeik Archipelago. Based on scientific surveys from Ayeyarwaddy Delta through Taninthayi Division, it was revealed that tsunami heights along the Myanmar coast were between . Eyewitnesses compared the tsunami with the ""rainy-season high tide""; although at most locations, the tsunami height was similar or smaller than the ""rainy-season high tide"" level.[88] Interviews with local people indicate that they did not feel the earthquake in Taninthayi Division or Ayeyarwaddy Delta. The 71 casualties can be attributed to poor housing infrastructure and additionally, the fact that the coastal residents in the surveyed areas live on flat land along the coast, especially in the Ayeyarwaddy Delta, and that there is no higher ground to which to evacuate. The tsunami heights from the 2004 December earthquake were not more than along the Myanmar coast, the amplitudes were slightly large off the Ayeyarwaddy Delta, probably because the shallow delta caused a concentration in tsunami energy.[88] The tsunami travelled west across the open ocean before striking the East African country of Somalia. Around 289 fatalities were reported in the Horn of Africa, drowned by four tsunami waves. The hardest-hit was a stretch of the Somalia coastline between Garacad (Mudug region) and Xaafuun (Bari region), which forms part of the Puntland province. Most of the victims were reported along the low-lying Xaafuun Peninsula.[89] The Puntland coast in northern Somalia was by far the area hardest hit by the waves to the west of the Indian subcontinent. The waves arrived around noon local time.[89] Consequently, tsunami runup heights vary from to with inundation distances varying from to . The maximum runup height of almost was recorded in Bandarbeyla. An even higher runup point was measured on a cliff near the town of Eyl, solely on an eyewitness account. The highest death toll was in Hafun, with 19 dead and 160 people presumed missing out of its 5,000 inhabitants. This was the highest number of casualties in a single African town and the largest tsunami death toll in a single town to the west of the Indian subcontinent. In Xaafuun, small drawbacks were observed before the third and most powerful tsunami wave flooded the town.[89] The tsunami also reached Malaysia, mainly on the northern states such as Kedah, Perak and Penang and on offshore islands such as Langkawi island. Peninsular Malaysia was shielded by the full force of the tsunami due to the protection offered by the island of Sumatra, which lies just off the western coast.[90] Bangladesh escaped major damage and deaths because the water displaced by the strike-slip fault was relatively little on the northern section of the rupture zone, which ruptured slowly. In Yemen, the tsunami killed two people with a maximum runup of .[91] The tsunami was detected in the southern parts of east Africa, where rough seas were reported, specifically on the eastern and southern coasts that face the Indian Ocean. A few other African countries also recorded fatalities; one in Kenya, three in Seychelles, ten in Tanzania, and South Africa, where two were killed as a direct result of the tsunami—the furthest from the epicentre.[92] [93] Tidal surges also occurred along the Western Australian coast that lasted for several hours, resulting in boats losing their moorings and two people needing to be rescued.[94] See main article: Countries affected by the 2004 Indian Ocean earthquake and tsunami. According to the U.S. Geological Survey, a total of 227,898 people died.[1] Measured in lives lost, this is one of the ten worst earthquakes in recorded history, as well as the single worst tsunami in history. Indonesia was the worst affected area, with most death toll estimates at around 170,000.[95] An initial report by Siti Fadilah Supari, the Indonesian Minister of Health at the time, estimated the death total to be as high as 220,000 in Indonesia alone, giving a total of 280,000 fatalities.[96] However, the estimated number of dead and missing in Indonesia were later reduced by over 50,000. In their report, the Tsunami Evaluation Coalition stated, ""It should be remembered that all such data are subject to error, as data on missing persons especially are not always as good as one might wish"".[5] A much higher number of deaths has been suggested for Myanmar based on reports from Thailand. The tsunami caused severe damage and deaths as far as the east coast of Africa, with the furthest recorded fatality directly attributed to the tsunami at Rooi-Els, close to Cape Town, from the epicentre. In total, eight people in South Africa died due to high sea levels and waves. Relief agencies reported that one third of the dead appeared to be children. This was a result of the high proportion of children in the populations of many of the affected regions and because children were the least able to resist being overcome by the surging waters. Oxfam went on to report that as many as four times more women than men were killed in some regions because they were waiting on the beach for the fishers to return and looking after their children in the houses.[97] States of emergency were declared in Sri Lanka, Indonesia, and the Maldives. The United Nations estimated at the outset that the relief operation would be the costliest in human history. Then-UN Secretary-General Kofi Annan stated that reconstruction would probably take between five and ten years. Governments and non-governmental organizations feared that the final death toll might double as a result of diseases, prompting a massive humanitarian response. In addition to a large number of local residents, up to 9,000 foreign tourists (mostly Europeans) enjoying the peak holiday travel season were among the dead or missing, especially people from the Nordic countries.[98] Sweden was the European country most severely affected both in absolute numbers, and by a wide margin when considered in relation to the country\'s population, with a death toll of 543. Germany was close behind with 539 identified victims. Beyond the heavy toll on human lives, the Indian Ocean earthquake has caused an enormous environmental impact that will affect the region for many years to come. It has been reported that severe damage has been inflicted on ecosystems such as mangroves, coral reefs, forests, coastal wetlands, vegetation, sand dunes and rock formations, animal and plant biodiversity and groundwater. Also, the spread of solid and liquid waste and industrial chemicals, water pollution and the destruction of sewage collectors and treatment plants threaten the environment even further, in untold ways. The environmental impact will take a long time and significant resources to assess.[117] According to specialists, the main effect is being caused by poisoning of the freshwater supplies and of the soil by saltwater infiltration and a deposit of a salt layer over arable land. It has been reported that in the Maldives, 16 to 17 coral reef atolls that were overcome by sea waves are without fresh water and could be rendered uninhabitable for decades. Uncountable wells that served communities were invaded by sea, sand, and earth; and aquifers were invaded through porous rock. On the island\'s east coast, the tsunami contaminated wells on which many villagers relied for drinking water. The Colombo-based International Water Management Institute monitored the effects of saltwater and concluded that the wells recovered to pre-tsunami drinking water quality one-and-a-half years after the event.[118] The IWMI developed protocols for cleaning wells contaminated by saltwater; these were subsequently officially endorsed by the World Health Organization as part of its series of Emergency Guidelines.[119] Salted-over soil becomes sterile, and it is difficult and costly to restore for agriculture. It also causes the death of plants and important soil micro-organisms. Thousands of rice, mango, and banana plantations in Sri Lanka were destroyed almost entirely and will take years to recover.[118] In addition to other forms of aid,[120] the Australian government sent ecological experts to help develop strategies for reef-monitoring and rehabilitation of marine environments and coral reefs in the Maldives, Seychelles and other areas. Scientists had developed significant ecological expertise from work with the Great Barrier Reef, in Australia\'s northeastern waters.[121] In response to the unprecedented situation, the United Nations Environment Programme (UNEP) worked with governments in the region to determine the severity of the ecological impact and how to address it.[122] UNEP established an emergency fund, set up a Task Force to respond to requests for assistance from countries affected by the tsunami, and was able to mobilize and distribute approximately US$9.3 million for environmental recovery and disaster risk reduction between 2004 and 2007. Funding came from other international agencies and from countries including Finland, Norway, Spain, Sweden and the United Kingdom.[123] [124] Evidence suggested that the presence of mangroves in coastal areas had provided some protection, when compared to areas that had been cleared for aquaculture or development. As a result, mangrove restoration become a focus of a number of projects, with varied success. Such approaches to ecosystem-based disaster risk reduction appear to be most successful when local communities are closely involved as stakeholders throughout the process, and when careful attention is paid to the physical conditions of chosen sites to ensure that mangroves can thrive there.[125] The level of damage to the economy resulting from the tsunami depends on the scale examined. While the overall impact on the national economies was minor, local economies were devastated. The two main occupations affected by the tsunami were fishing and tourism.[126] Some economists believe that damage to the affected national economies will be minor because losses in the tourism and fishing industries are a relatively small percentage of the GDP. However, others caution that damage to infrastructure is an overriding factor. In some areas drinking water supplies and farm fields may have been contaminated for years by saltwater from the ocean.[127] The impact on coastal fishing communities and the people living there, some of the poorest in the region, has been devastating with high losses of income earners as well as boats and fishing gear.[128] [129] In Sri Lanka, artisanal fishery, in which the use of fish baskets, fishing traps, and spears are commonly used, is an important source of fish for local markets; industrial fishery is the major economic activity, providing direct employment to about 250,000 people. In recent years the fishery industry has emerged as a dynamic export-oriented sector, generating substantial foreign exchange earnings. Preliminary estimates indicated that 66% of the fishing fleet and industrial infrastructure in coastal regions were destroyed by the wave surges.[130] While the tsunami destroyed many of the boats vital to Sri Lanka\'s fishing industry, it also created a demand for fibreglass-reinforced plastic catamarans in the boatyards of Tamil Nadu. Given that over 51,000 vessels were lost to the tsunami, the industry boomed. However, the huge demand has led to lower quality in the process, and some important materials were sacrificed to cut prices for those who were impoverished by the tsunami.[131] Even though only coastal regions were directly affected by the waters of the tsunami, the indirect effects have spread to inland provinces as well. Since the media coverage of the event was so extensive, many tourists cancelled vacations and trips to that part of the world, even though their travel destinations may not have been affected. This ripple effect could especially be felt in the inland provinces of Thailand, such as Krabi, which acted as a starting point for many other tourist destinations in Thailand.[132] Countries in the region appealed to tourists to return, pointing out that most tourist infrastructure is undamaged. However, tourists were reluctant to do so for psychological reasons. Even beach resorts in parts of Thailand which were untouched by the tsunami were hit by cancellations.[133] Both the earthquake and the tsunami may have affected shipping in the Malacca Straits, which separate Malaysia and the Indonesian island of Sumatra, by changing the depth of the seabed and by disturbing navigational buoys and old shipwrecks. In one area of the Strait, water depths were previously up to, and are now only in some areas, making shipping impossible and dangerous. These problems also made the delivery of relief aid more challenging. Compiling new navigational charts may take months or years. Officials also hoped that piracy in the region would drop off, since the tsunami had killed pirates and destroyed their boats.[134] Due to multiple factors, there was a 71.6% drop in the number of piracy incidents between 2004 and 2005, from 60 to 17 incidents. Levels remained relatively low for some years. However, between 2013 and 2014, piracy incidents rose dramatically by 73.2% to exceed pre-tsunami levels.[135] See also: Library damage resulting from the 2004 Indian Ocean earthquake. The last major tsunami in the Indian Ocean was about A.D. 1400.[136] [137] In 2008, a team of scientists working on Phra Thong, a barrier island along the hard-hit west coast of Thailand, reported evidence of at least three previous major tsunamis in the preceding 2,800 years, the most recent from about 700 years ago. A second team found similar evidence of previous tsunamis in Aceh, a province at the northern tip of Sumatra; radiocarbon dating of bark fragments in the soil below the second sand layer led the scientists to estimate that the most recent predecessor to the 2004 tsunami probably occurred between A.D. 1300 and 1450.[138] The 2004 earthquake and tsunami combined is the world\'s deadliest natural disaster since the 1976 Tangshan earthquake. The earthquake was the third-most-powerful earthquake recorded since 1900. The deadliest-known earthquake in history occurred in 1556 in Shaanxi, China, with an estimated death toll of 830,000, though figures from this period may not be as reliable.[139] Before 2004, the tsunami created in both Indian and Pacific Ocean waters by the 1883 eruption of Krakatoa, thought to have resulted in anywhere from 36,000 to 120,000 deaths, had probably been the deadliest in the region. In 1782, about 40,000 people are thought to have been killed by a tsunami (or a cyclone) in the South China Sea.[140] The deadliest tsunami before 2004 was Italy\'s 1908 Messina earthquake on the Mediterranean Sea where the earthquake and tsunami killed about 123,000.[141] Many health professionals and aid workers have reported widespread psychological trauma associated with the tsunami.[142] Traditional beliefs in many of the affected regions state that a relative of the family must bury the body of the dead, and in many cases, no body remained to be buried. Women in Aceh required a special approach from foreign aid agencies, and continue to have unique needs. The hardest-hit area, Aceh, is a religiously conservative Islamic society and has had no tourism nor any Western presence in recent years due to the insurgency between the Indonesian military and Free Aceh Movement (GAM). Some believe that the tsunami was divine punishment for lay Muslims shirking their daily prayers or following a materialistic lifestyle. Others have said that Allah was angry that Muslims were killing each other in an ongoing conflict.[143] Saudi cleric Muhammad Al-Munajjid attributed it to divine retribution against non-Muslim vacationers ""who used to sprawl all over the beaches and in pubs overflowing with wine"" during Christmas break.[144] The widespread devastation caused by the tsunami led GAM to declare a cease-fire on 28 December 2004 followed by the Indonesian government, and the two groups resumed long-stalled peace talks, which resulted in a peace agreement signed 15 August 2005. The agreement explicitly cites the tsunami as a justification.[145] In a poll conducted in 27 countries, 15% of respondents named the tsunami the most significant event of the year. Only the Iraq War was named by as many respondents.[146] [147] The extensive international media coverage of the tsunami, and the role of mass media and journalists in reconstruction, were discussed by editors of newspapers and broadcast media in tsunami-affected areas, in special video-conferences set up by the Asia Pacific Journalism Centre.[148] The tsunami left both the people and government of India in a state of heightened alert. On 30 December 2004, four days after the tsunami, Terra Research notified the India government that its sensors indicated there was a possibility of 7.9 to 8.1 magnitude tectonic shift in the next 12 hours between Sumatra and New Zealand.[149] In response, the Indian Minister of Home Affairs announced that a fresh onslaught of deadly tsunami was likely along the southern Indian coast and the Andaman and Nicobar Islands, even as there was no sign of turbulence in the region.[149] The announcement generated panic in the Indian Ocean region and caused thousands to flee their homes, which resulted in jammed roads.[150] The announcement was a false alarm, and the Home Affairs minister withdrew their announcement.[150] On further investigation, the India government learned that the consulting company Terra Research was run from the home of a self-described earthquake forecaster who had no telephone listing and maintained a website where he sold copies of his detection system.[151] The tsunami had a severe humanitarian and political impact in Sweden. The hardest-hit country outside Asia, Sweden, lost 543 tourists, mainly in Thailand. The Persson Cabinet was heavily criticized for its inaction.[152] Smith Dharmasaroja, a meteorologist who had predicted that an earthquake and tsunami ""is going to occur for sure"" way back in 1994,[153] [154] was assigned the development of the Thai tsunami warning system. The Indian Ocean Tsunami warning system was formed in early 2005 to provide an early warning of tsunamis for inhabitants around the Indian Ocean coasts.[155] The changes in the distribution of masses inside the Earth due to the earthquake had several consequences. It displaced the North Pole by . It also slightly changed the shape of the Earth, specifically by decreasing Earth\'s oblateness by about one part in 10 billion, consequentially increasing Earth\'s rotation a little and thus shortening the length of the day by 2.68 microseconds.[156] See main article: Humanitarian response to the 2004 Indian Ocean earthquake. A great deal of humanitarian aid was needed because of widespread damage to the infrastructure, shortages of food and water, and economic damage. Epidemics were of particular concern due to the high population density and tropical climate of the affected areas. The main concern of humanitarian and government agencies was to provide sanitation facilities and fresh drinking water to contain the spread of diseases such as cholera, diphtheria, dysentery, typhoid and hepatitis A and . There was also a great concern that the death toll could increase as disease and hunger spread. However, because of the initial quick response, this was minimized.[157] In the days following the tsunami, significant effort was spent in burying bodies hurriedly due to fear of disease spreading. However, the public health risks may have been exaggerated, and therefore this may not have been the best way to allocate resources. The World Food Programme provided food aid to more than 1.3 million people affected by the tsunami.[158] Nations all over the world provided over US$14 billion in aid for damaged regions,[159] with the governments of Australia pledging US$819.9 million (including a US$760.6 million aid package for Indonesia), Germany offering US$660 million, Japan offering US$500 million, Canada offering US$343 million, Norway and the Netherlands offering both US$183 million, the United States offering US$35 million initially (increased to US$350 million), and the World Bank offering US$250 million. Also, Italy offered US$95 million, increased later to US$113 million of which US$42 million was donated by the population using the SMS system[160] Four countries, Australia, India, Japan and the United States formed an ad-hoc corroborative group, and it was the origin of Quadrilateral Security Dialogue.[161] According to USAID, the US has pledged additional funds in long-term U.S. support to help the tsunami victims rebuild their lives. On 9 February 2005, President Bush asked Congress to increase the U.S. commitment to a total of US$950 million. Officials estimated that billions of dollars would be needed. Bush also asked his father, former President George H. W. Bush, and former President Bill Clinton to lead a U.S. effort to provide private aid to the tsunami victims.[162] In mid-March, the Asian Development Bank reported that over US$4 billion in aid promised by governments was behind schedule. Sri Lanka reported that it had received no foreign government aid, while foreign individuals had been generous.[163] Many charities were given considerable donations from the public. For example, in the United Kingdom, the public donated roughly £330 million sterling (nearly US$600 million). This considerably outweighed the allocation by the government to disaster relief and reconstruction of £75 million and came to an average of about £5.50 (US$10) donated by every citizen.[164] [165] In August 2006, fifteen local aid staff working on post-tsunami rebuilding were found executed in north-east Sri Lanka after heavy fighting between government troops and the Tamil Tiger rebels, the main umbrella body for aid agencies in the country said.[166] This article is licensed under the GNU Free Documentation License. It uses material from the Wikipedia article ""2004 Indian Ocean earthquake and tsunami"". Except where otherwise indicated, Everything.Explained.Today is © Copyright 2009-2022, A B Cryer, All Rights Reserved. Cookie policy.', 'The authors have deleted this site.', 'The 2004 Indian Ocean earthquake, known by the scientific community as the great Sumatra-Andaman earthquake,[1] an undersea earthquake, occurred at 00:58:53 UTC (07:58:53 local time) December 26, 2004, with an epicenter off the west coast of Sumatra, Indonesia. The earthquake triggered a series of devastating tsunamis along the coasts of most landmasses bordering the Indian Ocean, killing large numbers of people and inundating coastal communities across South and Southeast Asia, including parts of Indonesia, Sri Lanka, India, and Thailand. The disaster has been variously named the Boxing Day Tsunami in Australia, Canada, New Zealand, and the United Kingdom, because it took place on Boxing Day. The tsunami occurred exactly one year after the 2003 earthquake that devastated the southern Iranian city of Bam and exactly two years before the 2006 Hengchun earthquake. The 2004 Indian Ocean earthquake, and series of catastrophic tsunamis that followed in its wake, had a lesson to teach. The world community needs to put in place early detection systems, possibly sponsored by the United Nations, that would undoubtedly save lives. Although this earthquake happened close to large population centers that had little time to act even with warnings, nations farther away would have had time to issue life-saving warnings. Poorer nations are usually in the greatest need of early warning technology but the least able to pay for it. A United Nations sponsored initiative to put in place early warning systems for earthquakes, cyclones, typhoons, tornadoes, and tsunamis would take the world a great distance closer to creating a safe planet for all people, rich and poor. Initially, reports identified the earthquake as moment magnitude, Mw 9.0 (note that this is not the Richter scale or local magnitude scale, Ml, which is known to saturate at higher magnitudes). In February 2005 scientists revised the estimate of the magnitude to Mw9.3.[2] The Hypocenter of the main earthquake sits at 3°18′58″N 95°51′14″E\ufeff / \ufeff3.316, 95.854, approximately 160\xa0km (100\xa0mi) west of Sumatra, at a depth of 30\xa0km (19\xa0mi) below mean sea level (initially reported as 10\xa0km). People felt the earthquake itself (apart from the tsunami) as far away as Bangladesh, India, Malaysia, Myanmar, Thailand, Singapore, and the Maldives. Indonesia lies between the Pacific Ring of Fire along the north-eastern islands adjacent to and including New Guinea and the Alpide belt along the south and west from Sumatra, Java, Bali, Flores, and Timor. Great earthquakes such as the Sumatra-Andaman event, invariably associated with megathrust events in subduction zones, have seismic moments that can account for a significant fraction of the global earthquake moment across century-scale time periods. The Sumatra-Andaman earthquake measured the largest earthquake since 1964, and the second largest since the Kamchatka earthquake of October 16, 1737. Of all the seismic moment released by earthquakes in the 100 years from 1906 through 2005, roughly one-eighth arose as a result of the Sumatra-Andaman event. That quake, together with the Good Friday Earthquake (Alaska, 1964) and the Great Chilean Earthquake (1960), account for almost half of the total moment. The much smaller but still catastrophic 1906 San Francisco earthquake has been included in the diagram at right for perspective. Mw denotes the magnitude of an earthquake on the moment magnitude scale. Since 1900, the 1960 Great Chilean Earthquake (magnitude 9.5) and the 1964 Good Friday Earthquake in Prince William Sound (9.2) constitute the only earthquakes recorded with a greater magnitude. An earthquake off Kamchatka, Russia, on November 4, 1952, (magnitude 9.0 represents the only other recorded earthquake of magnitude 9.0 or greater). Each of those megathrust earthquakes also spawned tsunamis in the Pacific Ocean, but the death toll from those measured significantly lower. The worst of those caused only a few thousand deaths, primarily because of the lower population density along the coasts near affected areas and the much greater distances to more populated coasts. Other very large megathrust earthquakes occurred in 1868 (Peru, Nazca Plate and South American Plate); 1827 (Colombia, Nazca Plate and South American Plate); 1812 (Venezuela, Caribbean Plate and South American Plate) and 1700 (Cascadia Earthquake, western U.S. and Canada, Juan de Fuca Plate and North American Plate). Geologists calculate that those all had a magnitude 9, but no accurate measurements exist. The earthquake covered an unusually large area in geographical extent. An estimated 1,600\xa0km (994\xa0mi) of faultline slipped about 15\xa0m (50\xa0ft) along the subduction zone where the India Plate slides under the Burma Plate. The slip took place in two phases over a period of several minutes. Seismographic and acoustic data indicate that the first phase involved a rupture about 400\xa0km (250\xa0mi) long and 100\xa0km (60\xa0mi) wide, located 30\xa0km (19\xa0mi) beneath the sea bed—the longest rupture ever known to have been caused by an earthquake. The rupture proceeded at a speed of about 2.8\xa0km/s (1.7\xa0mi/s) or 10,000\xa0km/h (6,300\xa0mph), beginning off the coast of Aceh and proceeding north-westerly over a period of about 100 seconds. A pause of about another 100 seconds took place before the rupture continued northwards towards the Andaman and Nicobar Islands. The northern rupture occurred more slowly than in the south, at about 2.1\xa0km/s (1.3\xa0mi/s) or 7,600\xa0km/h (4,700\xa0mph), continuing north for another five minutes to a plate boundary where the fault changes from subduction to strike-slip (the two plates push past one another in opposite directions). That reduced the speed of the water displacement and so reducing the size of the tsunami that hit the northern part of the Indian Ocean.[3] The India Plate constitutes a part of the great Indo-Australian Plate, which underlies the Indian Ocean and Bay of Bengal, drifting north-east at an average of 6\xa0cm/year (2\xa0inches per year). The India Plate meets the Burma Plate (considered a portion of the great Eurasian Plate) at the Sunda Trench. At that point the India Plate subducts beneath the Burma Plate, which carries the Nicobar Islands, the Andaman Islands and northern Sumatra. The India Plate slips deeper and deeper beneath the Burma Plate until the increasing temperature and pressure drive volatiles out of the subducting plate. Those volatiles rise into the crust above and trigger melt which exits the earth\'s crust through volcanoes in the form of a volcanic arc. The volcanic activity that results as the Indo-Australian plate subducts the Eurasian plate has created the Sunda Arc. As well as the sideways movement between the plates, estimates put the rise of the sea bed at several metres, displacing an estimated 30\xa0km³ (7\xa0cu mi) of water and triggering devastating tsunami waves. Rather than originating from a point source, as inaccurately depicted in some illustrations of their paths of travel, the waves radiated outwards along the entire 1,600\xa0km (994\xa0mi) length of the rupture (acting as a line source). That greatly increased the geographical area waves covered, reaching as far as Mexico, Chile and the Arctic. The raising of the sea bed significantly reduced the capacity of the Indian Ocean, producing a permanent rise in the global sea level by an estimated 0.1\xa0mm.[4] Reports of numerous aftershocks off the Andaman Islands, the Nicobar Islands and the region of the original epicentre had been received in the hours and days that followed. The largest aftershock, originating off the coast of the Sumatran island of Nias, registered a magnitude of 8.7, prompting debate among seismologists as to whether to classify the event as an aftershock of the December 2004 quake or as a ""triggered earthquake"" (which typically differs from an aftershock in laying along a different fault line, often as large or larger than the earthquake which triggered it).[5] That earthquake produced its own aftershocks (some registering a magnitude of as great as 6.1) and presently ranks as the seventh largest earthquake on record since 1900. Other aftershocks of up to magnitude 6.6 continued to shake the region daily for up to three or four months.[6] As well as continuing aftershocks, the energy released by the original earthquake continued to make its presence felt well after the event. A week after the earthquake, scientists still measured reverberations, providing valuable scientific data about the Earth\'s interior. The 2004 Indian Ocean earthquake came just three days after a magnitude 8.1 earthquake in an uninhabited region west of New Zealand\'s sub-Antarctic Auckland Islands, and north of Australia\'s Macquarie Island. Geologists note that as unusual, since earthquakes of magnitude 8 or more occur only about once per year on average.[7] Some seismologists have speculated about a connection between those two earthquakes, saying that the former one might have been a catalyst to the Indian Ocean earthquake, as the two earthquakes happened on opposite sides of the Indo-Australian Plate. The U.S. Geological Survey sees no evidence of a causal relationship in this incident. Coincidentally, the earthquake struck almost exactly one year (to the hour) after a 6.6 magnitude earthquake killed an estimated 30,000 people in the city of Bam in Iran on December 26, 2003. Early estimated placed the total energy released by the 2004 Indian Ocean earthquake as high as 3.35 exajoules (3.35×1018 joules). That equals over 930 terawatt hours, 0.8 gigatons of TNT, or about as much energy used in the United States in 11 days. A new seismic energy release estimate, generated on September 30, 2005, using new data, placed the amount of energy released by the earthquake at the somewhat smaller figure of 1.1×1018 joules, equivalent to about 250 megatons of TNT. The earthquake generated seismic oscillation of the Earth\'s surface of up to 20–30\xa0cm (8–12\xa0in), equivalent to the effect of the tidal forces caused by the Sun and Moon. People felt the shock waves of the earthquake across the planet; as far away as the U.S. state of Oklahoma, where scientists recorded vertical movements of 3\xa0mm (0.12\xa0in). Because of its enormous energy release and shallow rupture depth, the earthquake generated remarkable seismic ground motions around the globe, particularly due to huge Rayleigh (surface) elastic waves that exceeded 1 cm in vertical amplitude everywhere on Earth. The record section plot below displays vertical displacements of the Earth\'s surface recorded by seismometers from the IRIS/USGS Global Seismographic Network plotted with respect to time (since the earthquake initiation) on the horizontal axis, and vertical displacements of the Earth on the vertical axis (note the 1 cm scale bar at the bottom for scale). The seismograms have been arranged vertically by distance from the epicenter in degrees. The earliest, lower amplitude, signal represents the compressional (P) wave, which takes about 22 minutes to reach the other side of the planet (the antipode; in this case near Ecuador). The largest amplitude signals represent seismic surface waves that reach the antipode after about 100 minutes. The surface waves can be clearly seen to reinforce near the antipode (with the closest seismic stations in Ecuador), and to subsequently encircle the planet to return to the epicentral region after about 200 minutes. A major aftershock (magnitude 7.1) can be seen at the closest stations starting just after the 200 minute mark. That aftershock would be considered a major earthquake under ordinary circumstances, but the mainshock dwarfed it. In February 2005, the British Royal Navy vessel HMS Scott surveyed the seabed around the earthquake zone, which varies in depth between 1,000\xa0m and 5,000\xa0m (3,300\xa0ft and 16,500\xa0ft). The survey, conducted using a high-resolution, multi-beam sonar system, revealed that the earthquake had made a huge impact on the topography of the seabed. 1,500-meter (5,000 ft) high thrust ridges created by previous geologic activity along the fault had collapsed, generating landslides several kilometers wide. One such landslide consisted of a single block of rock some 100\xa0m high and 2\xa0km long (300\xa0ft by 1.25\xa0mi). The momentum of the water displaced by tectonic uplift had also dragged massive slabs of rock, each weighing millions of tons, as far as 10\xa0km (7\xa0mi) across the seabed. An oceanic trench several kilometers wide appeared in the earthquake zone.[8] The sudden vertical rise of the seabed by several meters during the earthquake displaced massive volumes of water, resulting in a tsunami that struck the coasts of the Indian Ocean. Tsunamis which cause damage far away from its source is referred to as a ""teletsunami.""[9] Tsunamis behave very differently in deep water than in shallow water. In deep ocean water, tsunami waves form only a small hump, barely noticeable and harmless, which generally travels at a very high speed of 500 to 1,000\xa0km/h (310 to 620\xa0mph); in shallow water near coastlines, a tsunami slows down to only tens of kilometers an hour but in doing so forms large destructive waves. Scientists investigating the damage in Aceh found evidence that the wave reached a height of 24\xa0m (80\xa0ft) when coming ashore along large stretches of the coastline, rising to 30\xa0m (100\xa0ft) in some areas when traveling inland. Radar satellites recorded the heights of tsunami waves in deep water: at two hours after the earthquake, the maximum height reached 60\xa0cm (2\xa0ft). Those represent the first such observations ever made although they lacked the capacity to provide a warning since the satellite data took hours to analyze.[10] According to Tad Murty, vice-president of the Tsunami Society, the total energy of the tsunami waves equaled about five megatons of TNT (20\xa0petajoules). That amounts to more than twice the total explosive energy used during all of World War II (including the two atomic bombs), but still a couple of orders of magnitude less than the energy released in the earthquake itself. In many places the waves reached as far as 2\xa0km (1.24\xa0mi) inland. The 1,600\xa0km (994\xa0mi) of faultline affected by the earthquake lay in a nearly north-south orientation, the greatest strength of the tsunami waves moved in an east-west direction. Bangladesh, which lies at the northern end of the Bay of Bengal, had very few casualties despite being a low-lying country relatively near the epicentre, benefiting from the earthquake proceeded more slowly in the northern rupture zone. That greatly reducing the energy of the water displacements in the region. Coasts that have a landmass between them and the tsunami\'s location of origin usually escaped damage, although on occasion tsunami waves sometimes diffract around such landmasses. Thus, the tsunami hit the Indian state of Kerala despite sitting on the western coast of India, and the western coast of Sri Lanka also suffered substantial impacts. Also distance alone lacks a guarantee of safety; Somalia got hit harder than Bangladesh despite being much farther away. Because of the distances involved, the tsunami took anywhere from fifteen minutes to seven hours (for Somalia) to reach the various coastlines.[11] The northern regions of the Indonesian island of Sumatra received waves very quickly, while Sri Lanka and the east coast of India suffered hits roughly 90\xa0minutes to two hours later. Waves also Thailand struck about two hours later despite being closer to the epicenter, because the tsunami traveled more slowly in the shallow Andaman Sea off its western coast. Observers noticed the tsunami as far as Struisbaai in South Africa, some 8,500\xa0km (5,300\xa0mi) away, where a 1.5\xa0m (5\xa0ft) high tide surged on shore about 16 hours after the earthquake. It took a relatively long time to reach that spot at the southernmost point of Africa, probably because of the broad continental shelf off South Africa and because the tsunami would have followed the South African coast from east to west. The tsunami also reached Antarctica, where tidal gauges at Japan\'s Showa Base recorded oscillations of up to a meter, with disturbances lasting a couple of days.[12] Some of the tsunami\'s energy escaped into the Pacific Ocean, where it produced small but measurable tsunamis along the western coasts of North and South America, typically around 20 to 40 cm (7.9 to 15.7\xa0in). At Manzanillo, Mexico, a tsunami measured 2.6\xa0m (8.5\xa0ft) crest-to-trough, large enough for detection in Vancouver, British Columbia, Canada. That puzzled many scientists, as the tsunamis in some parts of South America measured larger than those in some parts of the Indian Ocean. Some scientists theorized that the tsunamis focused, directed at long ranges by the mid-ocean ridges running along the margins of the continental plates. Despite a lag of up to several hours between the earthquake and the impact of the tsunami, the killer waves took nearly all of the victims completely by surprise. No tsunami warning systems in the Indian Ocean exist to detect tsunamis or to warn the general populace living around the ocean. Tsunami physics complicate detection; while a tsunami runs in deep water it has little height. Secondly, detection requires a network of sensors to detect it. Setting up the communications infrastructure to issue timely warnings constitutes an even bigger problem, particularly in a relatively poor part of the world. Tsunamis occur much more frequently in the Pacific Ocean because of earthquakes in the ""Ring of Fire,"" and an effective tsunami warning system has long been in place there. Although the extreme western edge of the Ring of Fire extends into the Indian Ocean (the point where this earthquake struck), no warning system exists in that ocean. Tsunamis have been relatively rare despite earthquakes frequently hitting Indonesia. The Krakatoa eruption of 1883 caused the last major tsunami. Large earthquakes only occasionally produce large tsunamis; on March 28, 2005, a magnitude 8.7 earthquake hit roughly the same area of the Indian Ocean without resulting in a major tsunami. In the aftermath of the disaster, awareness has increased for the need of a tsunami warning system for the Indian Ocean. The United Nations started working on an Indian Ocean Tsunami Warning System and by 2005 had the initial steps in place. Some have even proposed creating a unified global tsunami warning system, to include the Atlantic Ocean and Caribbean. The earthquake itself serves as the first warning sign of a possible tsunami, although a tsunami can strike thousands of kilometers away from the epicenter of the earthquake with slight or negligible movement felt. In the minutes preceding a tsunami strike, the sea often recedes temporarily from the coast, proving another warning sign. Around the Indian Ocean, that rare sight reportedly induced people, especially children, to visit the coast to investigate and collect stranded fish on as much as 2.5\xa0km (1.6\xa0mi) of exposed beach, with fatal results.[13] People on the Indonesian island of Simeulue, very close to the epicenter, number among the few coastal areas to evacuate ahead of the tsunami. Island folklore recounted an earthquake and tsunami in 1907, and the islanders fled to inland hills after the initial shaking yet before the tsunami struck. The aboriginal population of the Andaman Islands was feared to have been badly affected by the tsunami. Many of the aboriginal tribes evacuated and suffered fewer casualties, however. Oral traditions developed from previous earthquakes helped the aboriginal tribes escape the tsunami. For example, the folklore of the Onge people talks of ""huge shaking of ground followed by high wall of water."" All 96 tribesmen of the semi-nomadic Onge survived by taking shelter in the highlands.[14] On Maikhao beach in northern Phuket, Thailand, a ten-year-old British tourist named Tilly Smith who had studied tsunamis in geography class at school, recognized the warning signs of the receding ocean and frothing bubbles. She and her parents warned others on the beach, leading to everyone evacuating safely.[15] John Chroston, a biology teacher from Scotland, also recognized the signs at Kamala Bay north of Phuket, taking a busload of vacationers and locals to safety on higher ground. The tsunami constituted a succession of several waves, occurring in retreat and rise cycles with a period of over thirty minutes between each peak. The third wave proved the most powerful and reached highest, occurring about an hour and a half after the first wave. Smaller tsunamis continued to occur for the rest of the day. Receding waters after the second tsunami, 10:20 A.M. 3rd tsunami wave, 11:00 A.M. 4th tsunami wave, 11:22 A.M. The U.S. Geological Survey initially recorded the toll as 283,100\xa0killed, 14,100\xa0missing, and 1,126,900\xa0people displaced. Early news reports after the earthquake spoke of a toll in the hundreds, but the numbers rose steadily over the following week. More recent figures indicate that the actual casualties numbered 186,983\xa0dead and 42,883\xa0missing, for a total of 229,866, as more and more displaced survivors have been found and name duplications eliminated from the lists of victims. Measured in lives lost, the disaster makes the list of the top ten worst earthquakes in recorded history, as well as the single worst tsunami in history. Relief agencies report that children appeared to total one-third of the dead, a result of the high proportion of children in the populations of many of the affected regions. Also children had the least ablity to resist being overcome by the surging waters. Oxfam went on to report that as many as four times more women than men died in some regions because they waited on the beach for the fishermen to return and they looked after their children in the houses.[16] In addition to the large number of local residents, up to 9,000\xa0foreign tourists (mostly Europeans) enjoying the peak holiday travel season numbered among the dead or missing, especially people from the Nordic countries. Sri Lanka, Indonesia, and the Maldives declared states of emergency. The United Nations estimated at the outset that the relief operation would become the costliest in human history. The earthquake and resulting tsunami affected many countries in Southeast Asia and beyond, including Indonesia, Sri Lanka, India, Thailand, the Maldives, Somalia, Myanmar, Malaysia, Seychelles and others. Many other countries, especially Australia and those in Europe, had large numbers of citizens traveling in the region on holiday. Both Sweden and Germany lost over 500\xa0citizens each in the disaster. This earthquake measured the fourth most powerful earthquake recorded since 1900, and the confirmed death toll numbered just under 200,000 due to the ensuing tsunami. The deadliest earthquakes since 1900 include the Tangshan, China earthquake of 1976, with at least 255,000 killed; the earthquake of 1927 in Xining, Qinghai, China (200,000); the Great Kanto earthquake which struck Tokyo in 1923 (143,000); and the Gansu, China, earthquake of 1920 (200,000). The 2004 tsunami has been deemed the deadliest in recorded history. Prior to 2004, in 1782 the deadliest recorded tsunami in the Pacific Ocean with 40,000 people killed by a tsunami in the South China Sea. The tsunami created by the 1883 eruption of Krakatoa resulted in an estimated 36,000\xa0deaths. The most deadly tsunami between 1900 and 2004 occurred in 1908 in Messina, Italy, on the Mediterranean Sea, where the earthquake and tsunami killed 70,000. The most deadly tsunami in the Atlantic Ocean resulted from the 1755 Lisbon earthquake, which, combined with the toll from the actual earthquake and resulting fires, killed over 100,000. The 2004 earthquake and tsunami combined have been described as the deadliest natural disaster since either the 1976 Tangshan earthquake or the 1970 Bhola cyclone, or could conceivably exceed both of those. Because of uncertainty over death tolls, doubt may always exist over which of those natural disasters measured the deadliest. The human destruction of coral reefs played a significant role in the destruction caused by the tsunami. Many countries across Asia, including Indonesia, Sri Lanka, and Bangladesh, have put forth efforts to destroy the coral surrounding their beaches, and instead make way for shrimp farms and other economic choices. On the Surin Island chain of Thailand\'s coast, many people survived as the tsunami rushed against the coral reefs protecting the islands. Many fewer people on lived on those islands, which also helps explain the lower death toll. Many reefs areas around the Indian Ocean have been exploded with dynamite because they impede shipping, an important part of the South Asian economy Similarly, the removal of coastal mangrove trees may have intensified the effect of the tsunami in some locations. Those trees, which had lined the coast before builders removed them to make way for coastal residences, might have blocked the force of the tsunami. The removal of coastal sand dunes constitutes another factor. Populations needed enormous humanitarian aid because of widespread damage of the infrastructure, shortages of food and water, and economic damage. Epidemics posed a special concern due to the high population density and tropical climate of the affected areas. Humanitarian and government agencies concentrated on providing sanitation facilities and fresh drinking water to contain the spread of diseases such as cholera, diphtheria, dysentery, typhoid and hepatitis A and B. Governments and humanitarian organizations, concerned that the death toll could rise further as diseases and hunger spread, took quick action, minimizing the loss.[17] In the days following the tsunami, people worked quickly to bury bodies for fear of disease. In retrospect the public health risks may have been exaggerated, leading to the speculation that resources may have been better allocated. The World Food Programme provided food aid to more than 1.3\xa0million people affected by the tsunami. Nations all over the world provided over US$7 billion in aid for damaged regions, with the governments of Australia pledging US$819.9 million (including a US$760.6-million aid package for Indonesia), Germany offering US$660 million, Japan offering US$500 million, Canada offering US$343 million, Norway and The Netherlands offering both US$183 million, the United States offering US$35 million initially (increased to US$350 million), and the World Bank offering US$250 million. Also Italy offered US$ 95 million, increased later to US$ 113 million of which US$ 42 million where donated by the population using the SMS system[18] According to USAID, the US pledged additional funds in long-term U.S. support to help the tsunami victims rebuild their lives. On February 9, 2005, President Bush asked the U.S. Congress to increase the U.S. commitment to a total of $950 million. Officials estimated that billions of dollars would be needed. Bush also asked his father, former President George H. W. Bush, and former President Bill Clinton to lead a U.S. effort to provide private aid to the tsunami victims.[19] In mid-March the Asian Development Bank reported that over US$4 billion in aid promised by governments behind schedule. Sri Lanka reported that it had yet to receive foreign government aid, while foreign individuals had been generous.[20] The public donated generously to many charities. For example, in the UK the public donated roughly £330,000,000 sterling (nearly US$600,000,000). That considerably outweighed the donation by the government and came to an average of about £5.50 (US$10) donated by every citizen. In August 2006, the bodies of 15 local aid staff working on post-tsunami rebuilding executed in northeast Sri Lanka after heavy fighting had been found, the main umbrella body for aid agencies in the country said. Reports and rumors circulated that the local aid workers had been killed. The impact on coastal fishing communities and fisherfolk, some of the poorest people in the region, has been devastating with high losses of income earners as well as boats and fishing gear.[21] In Sri Lanka artisanal fishery, fisherman commonly use fish baskets, fishing traps, and spears, an important source of fish for local markets; industrial fishery constitutes the major economic activity, providing direct employment to about 250,000 people. In recent years the fishery industry has emerged as a dynamic export-oriented sector, generating substantial foreign exchange earnings. Preliminary estimates indicated that 66 percent of the fishing fleet and industrial infrastructure in coastal regions were destroyed by the wave surges, with adverse economic effects both at local and national levels.[22] Countries in the region appealed to tourists to return, pointing out that most tourist infrastructure remained undamaged. Tourists have been slow to return out of reluctance of spending vacation time in the scene of recent unimaginable destruction and loss of life. Even resorts on the Pacific coast of Thailand, completely untouched, experienced heavy cancellations. One year after the tsunami hit, tourism had begun to climb again.[23] Beyond the heavy toll on human lives, the Indian Ocean earthquake has caused an enormous environmental impact that will affect the region for many years to come. Reports of severe damage inflicted on ecosystems such as mangroves, coral reefs, forests, coastal wetlands, vegetation, sand dunes and rock formations, animal and plant biodiversity and groundwater have been received by governments and media. In addition, the spread of solid and liquid waste and industrial chemicals, water pollution and the destruction of sewage collectors and treatment plants threaten the environment even further, in untold ways. According to specialists, poisoning of the freshwater supplies and the soil by saltwater infiltration and deposit of a salt layer over arable land has been the most serious damage. In the Maldives, 16 to 17 coral reef atolls, overcome by sea waves, standing totally without fresh water, could be rendered uninhabitable for decades. In response to a request from the Maldivian Government, the Australian Government sent ecological experts to help restore marine environments and coral reefs—the lifeblood of Maldivian tourism. Much of the ecological expertise has been rendered from work with the Great Barrier Reef, in Australia\'s north-eastern waters. Sea, sand and earth invaded countless wells that served communities, invading aquifers through porous rock. Salted-over soil becomes sterile, rendering restoration for agriculture difficult and costly, causes the death of plants and important soil micro-organisms as well. The event destroyed thousands of rice, mango, and banana plantations in Sri Lanka almost entirely. Many health professionals and aid workers have reported widespread psychological trauma associated with the tsunami. Traditional beliefs in many of the affected regions state that a relative of the family must bury the body of the dead, and in many cases, no body remained to be buried. The hardest hit area, Aceh, a religiously conservative Islamic society, has had no tourism nor any Western presence in recent years due to armed conflict between the Indonesian military and Acehnese separatists. Some believe that the tsunami represented divine punishment for lay Muslims shirking their daily prayers and/or following a materialistic lifestyle. Others have said that Allah felt angry that Muslims killed other Muslims in an ongoing conflict.[24] Women in Aceh required a special approach from foreign aid agencies, and continue to have unique needs. In what may be the most significant positive result of the tsunami, the widespread devastation led the main rebel group GAM to declare a cease-fire on December 28, 2004, followed by the Indonesian government, and the two groups resumed long-stalled peace talks, which resulted in a peace agreement signed August 15, 2005. The agreement explicitly cites the tsunami as a justification.[25] In another positive note of the tsunami, the water washed away centuries of sand from some of the ruins of a 1,200-year-old lost city at Mahabalipuram on the south coast of India. The site, containing such notable structures as a half-buried granite lion near a seventh century Mahablipuram temple and a relic depicting an elephant, belongs to what archaeologists deem an ancient port city swallowed by the sea hundreds of years ago.[26] All links retrieved October 16, 2020. Note: Some restrictions may apply to use of individual images which are separately licensed.', '. .\xa0By\xa0T.V. Antony Raj . On Sunday, December 26, 2004, an undersea megathrust earthquake, known as the Sumatra–Andaman earthquake occurred at 00:58:53 UTC in the Indian Ocean with an epicentre off the west coast of Sumatra, between Simeulue in the Aceh province of Indonesia and mainland Indonesia. The earthquake with a magnitude of Mw\xa09.1–9.3, is the third largest earthquake ever recorded on a seismograph. The duration of faulting, between 8.3 and 10 minutes, was the longest ever observed. The behemothic quake caused the entire planet to vibrate as much as 1 centimetre (0.4 inches) and triggered other minor earthquakes as far away as Alaska. The tsunami was then known by various other names such as: “The 2004 Indian Ocean tsunami,” “South Asian tsunami,” and “Indonesian tsunami.” Since the tsunami occurred on December 26, it was also known as the “Christmas tsunami” and the “Boxing Day tsunami.” The earthquake triggered a tsunami, considered to be one of the deadliest in history, which inundated coastal communities with waves up to 100 feet (30 meters) high and killed over 230,000 people in fourteen countries. It was one of the deadliest natural disasters in recorded history. The huge waves racing at the speed of a jet aircraft took fifteen minutes to seven hours to reach the various coastlines. The waves hit the northern regions of the Indonesian island of Sumatra immediately. Thailand was struck about two hours later, despite being closer to the epicentre because the tsunami waves travelled more slowly in the shallow Andaman Sea off its western coast. About an hour and a half to two hours after the quake, Sri Lanka and the east coast of India were hit. The waves then reached the Maldives. Indonesia was the hardest-hit country, followed by Sri Lanka, India, and Thailand. The earthquake and resulting tsunami in the Indian Ocean had a devastating effect on India. According to the Ministry of Home Affairs about 18,000 are estimated dead. The following table compiled by the U.S. Geological Survey shows that a total of 227,898 people died. According to this table, in mainland India and in its territories, the Andaman and Nicobar Islands, 12,405 people died in the tsunami, around 5,640 are missing and 647,599 people have been displaced. Figures\xa0compiled by the U.S. Geological Survey. . The Andaman and Nicobar Islands in the Indian Ocean were devastated by the tsunami, and by the initial quake and several aftershocks that occurred during the following days. The Great Nicobar and Car Nicobar islands were the worst hit among all the islands due to their proximity to the\xa0epicentre\xa0of the quake and because of the relatively flat terrain. One-fifth of the population in Nicobar Islands was reported dead, missing or wounded. Chowra Island lost two-thirds of its population of 1,500. Communication was cut off when many islands submerged. The Trinket Island was bifurcated. Fishing communities were destroyed and very little is known about the effects of the tsunami on the indigenous tribes of the Andaman and Nicobar islands. The official death toll in the Andaman and Nicobar Islands was 1,310, with about 5,600 missing from the islands. But the unofficial death toll, including those missing and presumed dead, was estimated to be around 7,000. The tsunami hit the southeastern regions of the Indian mainland. It inundated villages and devastated cities along the coast. Around 8,000 deaths were reported from Tamilnadu, and around 200 deaths from Kerala. The district of Nagapattinam was the worst hit in Tamil Nadu, with nearly 5,500 deaths. Surprisingly, Bangladesh, which lies at the northern end of the Bay of Bengal, had only two confirmed deaths, despite being a low-lying country and located relatively near the epicenter. Also, distance alone does not guarantee a safety since Somalia located in the Horn of Africa on the eastern coast was hit harder than Bangladesh even though it is much farther away. Coasts, with a landmass between them and the location of origin of a tsunami, are usually deemed safe, but tsunami waves can sometimes steer around such landmasses. Being a relatively small island, the western coast of Sri Lanka suffered substantial damages from the impact of the tsunami; likewise, the Indian state of Kerala too was hit by the tsunami, despite being on the western coast of India. The government of India announced a financial package of about US$200 million to Andaman and Nicobar islands after the tsunami, but the unbearable living conditions due to rise in sea level, constant aftershocks and fear of another similar tsunami, propelled thousands of settlers on the islands to relocate to the Indian mainland. According to the World Bank, reconstruction was expected to cost more than US$1.2 billion in India alone. . . . . Notify me of new comments via email. Notify me of new posts via email. This site uses Akismet to reduce spam. Learn how your comment data is processed. Enter your email address to follow this blog and receive notifications of new posts by email.']","According to the U.S. Geological Survey a total of 227,898 people died (see table below for details). Measured in lives lost, this is one of the ten worst earthquakes in recorded history, as well as the single worst tsunami in history. Indonesia was the worst affected area, with most death toll estimates at around 170,000. However, another report by Siti Fadilah Supari, the Indonesian Minister of Health at the time, estimated the death total to be as high as 220,000 in Indonesia alone, giving a total of 280,000 fatalities."
what is the movie won't you be my neighbor,"['The requested URL was not found on this server.', 'The requested URL was not found on this server.', '', '', 'The requested URL was not found on this server.', 'Enjoy\xa0the best of both worlds: Film & Festival News, exploring the best of the film festivals community. Launched in\xa01995, relentlessly\xa0connecting films to festivals, documenting and promoting festivals worldwide. Working on an upgrade soon. For collaboration, editorial contributions, or publicity, please send us an email here. Filmfestivals.com services and offers Named one of the world\'s Top 25 film festivals worth the entry fee by Movie Maker magazine in April 2013, and named one of the world\'s 5 coolest documen9tary film festivals by MovieMaker in November 2013, the American Documentary Film Festival\'s 11th annual event takes place\xa0 April 7-11, 2022. The Festival is located in the beautiful resort community of Palm Springs, California. Ideally located 2 hours east of Hollywood, this film mecca boasts a favorable viewing audience and a proven track record of supporting independent films. Already the largest documentary festival on the West Coast of the United States, we feature documentary features, doc shorts, and animated shorts from filmmakers around the world. Our main objective is to promote a world vision of film as seen through the eyes of the filmmaker. https://www.amdocfilmfest.com/ This Oscar nominated film and box office hit for a documentary, is co-helmed by AmDocs alum Julie Cohen, who has been to the festival no less than three times, with her works featured at the Film Fund Pitch Competition as well as Opening Night and national competitions.\xa0 This work is a biographical depiction of Ginsburg from her birth in\xa0Brooklyn,\xa0New York, her college education and subsequent career as a law professor, her appointment to the federal judiciary by President\xa0Jimmy Carter, and eventual appointment to the Supreme Court by President\xa0Bill Clinton. RBG\xa0is a 2018 American\xa0documentary film\xa0directed and produced by Betsy West and Julie Cohen, focusing on the life and career of the second female (after\xa0Sandra Day O\'Connor)\xa0Supreme Court of the United States\xa0Associate Justice\xa0Ruth Bader Ginsburg. After premiering at the\xa02018 Sundance Film Festival, the film was released in the United States on May 4, 2018. It received positive reviews from critics and grossed $14 million worldwide. It was chosen by the\xa0National Board of Review\xa0as the\xa0Best Documentary Film of 2018, and nominated for several other awards, including the\xa0BAFTA Award for Best Documentary. At the\xa091st Academy Awards, the film earned nominations for\xa0Best Documentary Feature\xa0and\xa0Best Original Song\xa0(""I\'ll Fight""). 04.04.2019  |  American Documentary Film Festival\'s blog Cat. : FILM Filmfestivals.com dailies live coverage from', 'Chatham Community Library will host a free performance of Shakespeare’s Macbeth on Thursday, September 20, beginning at 6:30 pm in the Holmes Meeting Room. PlayMakers Repertory Company will bring their mobile touring company for a sizzling 90-minute performance of the Bard’s psychological thriller. In this production, brilliant young general Macbeth has pulled off a glorious victory in battle, but before he can return to King Duncan’s court, he encounters a most enticing prophecy. Spurred on by his ambitious wife, Macbeth sets his sights on the throne, but as blood begets blood, he soon learns there is no rest for the wicked. Through partnerships with area non-profits, community organizations, and local schools and libraries, in locations across the Triangle, PlayMakers presents professional-quality, bare bones productions of Shakespeare plays and more, cut to ninety minutes or less connecting with new audiences in their own spaces, truly meeting them where they live. By revealing theatre to be accessible, relevant, and vital, PlayMakers Mobile builds a new audience for these timeless plays and allows PlayMakers to foster new relationships throughout the region. Chatham Community Library will host Titanic: Ship of Dreams on Thursday, September 13, at 6:30 pm in the Holmes Meeting Room. This program will be presented by Dr. Melinda Ratchford, an NC Humanities Council Road Scholar. Take a glimpse into 1912 and the 2,228 amazing people who boarded the most luxurious and largest ship in the world and sailed off into immortality. Having traveled to all the sites that have connections to the R.M.S. Titanic (Belfast, Southampton, sinking site in North Atlantic, Halifax, NS et al.), Dr. Ratchford takes the audience on a voyage in time to learn about the Titanic, as well as to see her extensive collection of Titanic memorabilia. She will “introduce” listeners to the young Robert Spedden and his Stief bear, Polar; the world’s richest man and his beautiful new wife who had to leave New York society under a cloud of shame; and the elderly man and wife who tested the vow of “til death do we part”. This program will offer the chance to experience the world of courage, fear, love, and cowardice that is still alive over one hundred years after\xa0the Titanic’s\xa0sinking. A native of Kannapolis, NC,\xa0Dr. Ratchford received her B.S. in Social Science and a Sixth Year degree in Curriculum from Appalachian State University.\xa0 She received her Masters in Library Education from UNC-Greensboro.\xa0 She also attended UNC-Chapel Hill where she received her Doctorate in Education. Her avocation has been a 60-year interest in the study of the R.M.S. Titanic and her history.\xa0 She has given presentations to over 225+ groups on the topic. This program is brought to you in conjunction with the NC Humanities Council and is free and open to the public. Written with the narrative tension of The Road and the exquisite terror of classic Stephen King, Bird Box is a propulsive, edge-of-your-seat horror thriller, set in an apocalyptic near-future world—a masterpiece of suspense from the brilliantly imaginative Josh Malerman. Something is out there . . . Something terrifying that must not be seen. One glimpse and a person is driven to deadly violence. No one knows what it is or where it came from. Five years after it began, a handful of scattered survivors remain, including Malorie and her two young children. Living in an abandoned house near the river, she has dreamed of fleeing to a place where they might be safe. Now, that the boy and girl are four, it is time to go. But the journey ahead will be terrifying: twenty miles downriver in a rowboat—blindfolded—with nothing to rely on but her wits and the children’s trained ears. One wrong choice and they will die. And something is following them. But is it man, animal, or monster? Engulfed in darkness, surrounded by sounds both familiar and frightening, Malorie embarks on a harrowing odyssey—a trip that takes her into an unseen world and back into the past, to the companions who once saved her. Under the guidance of the stalwart Tom, a motely group of strangers banded together against the unseen terror, creating order from the chaos. But when supplies ran low, they were forced to venture outside—and confront the ultimate question: in a world gone mad, who can really be trusted? Interweaving past and present, Josh Malerman’s breathtaking debut is a horrific and gripping snapshot of a world unraveled that will have you racing to the final page. Chatham Community Library will host its first screening of the new film RBG\xa0on Saturday, September 8 beginning at 1:00 pm in the Holmes Meeting Room.\xa0 The screening and discussion will be facilitated by District Court Judge (15B) Sherri Murrell. RBG\xa0is a 2018 American\xa0documentary film\xa0directed and produced by Betsy West and Julie Cohen, focusing on the life and career of United States\xa0Supreme Court of the United States\xa0Associate Justice\xa0Ruth Bader Ginsburg. After premiering at the\xa02018 Sundance Film Festival, the film was released in the United States on May 4, 2018. Judge Murrell served as an assistant public defender in Chatham and Orange counties before being elected in 2016. This event is free and open to the\xa0public. Funding for this program is made available by the Friends of the Chatham Community Library. “Moxie\xa0is sweet, funny, and fierce. Read this and then join the fight.”—Amy Poehler Vivian Carter is fed up. Fed up with an administration at her high school that thinks the football team can do no wrong. Fed up with sexist dress codes, hallway harassment, and gross comments from guys during class. But most of all, Viv Carter is fed up with always following the rules. Viv’s mom was a tough-as-nails, punk rock Riot Grrrl in the ’90s, and now Viv takes a page from her mother’s past and creates a feminist zine that she distributes anonymously to her classmates. She’s just blowing off steam, but other girls respond. As Viv forges friendships with other young women across the divides of cliques and popularity rankings, she realizes that what she has started is nothing short of a girl revolution. OverDrive magazines are back! You now have access to 50 different magazine titles through OverDrive with your Chatham County library card. Check out The Atlantic, Popular Mechanics, HGTV Magazine, Yoga Journal, OK!, Newsweek, Clean Eating, and many more! These checkouts do not count against your usual loan limits for eBooks and audiobooks. Access the magazine collection through a web browser at http://e-inc.overdrive.com, or with the Libby or OverDrive apps. Need help getting started? Call the reference desk at 545-8086. Every day, more than 16,000 kids miss school because of bullying. 45% of kids experience bullying before age 18. And 38% of kids believe that their school doesn’t take bullying seriously. Children entering grades K-5 and their parents/caregivers are invited to attend a 90-minute anti-bullying workshop presented by Bullyproof Pittsboro. In this 90-minute interactive parent/child Bullyproof America workshop, presenters Alex Changho and Cat Zohar will clearly define what bullying is, and what it is not. \xa0They will help simplify the situation by providing clear boundaries for understanding how bullying takes place, what kids can do when bullying takes place, and how parents can help their kids be more empowered to deal with bullying. \xa0Alex and Cat teach these lessons through foundational martial arts techniques and skills that have been proven to boost self-esteem and confidence in children. The workshop also includes anger management and self-control practices that help keep emotions in balance when frustration and sadness set in from bullying. \xa0These skills are essential to controlling the imbalance of power that occurs as a result of bullying. \xa0Participants of a Bullyproof America workshop will leave with usable skills and knowledge to help better prepare them for a positive school year and how to respond appropriately in a bullying situation. The ANTI-Bullying Workshop will be presented at the Chatham Community Library, 197 NC Hwy 87 N, Pittsboro on Saturday, August 25, at 1:00 p.m. Admission is free and open to the public. For more information, contact Katy at (919) 545-8085 or [email\xa0protected]. The 40th anniversary edition of the classic Newbery Medal-winning title by beloved author Katherine Paterson, with brand-new bonus materials including an author’s note by Katherine herself and a foreword by\xa0New York Times\xa0bestselling author Kate DiCamillo. Jess Aarons has been practicing all summer so he can be the fastest runner in the fifth grade. And he almost is, until the new girl in school, Leslie Burke, outpaces him. The two become fast friends and spend most days in the woods behind Leslie’s house, where they invent an enchanted land called Terabithia. One morning, Leslie goes to Terabithia without Jess and a tragedy occurs. It will take the love of his family and the strength that Leslie has given him for Jess to be able to deal with his grief. Bridge to Terabithia was also named an ALA Notable Children’s Book and has become a touchstone of children’s literature, as have many of Katherine Paterson’s other novels, including The Great Gilly Hopkins and Jacob Have I Loved.']","Won't You Be My Neighbor? is a 2018 American documentary film directed by Morgan Neville about the life and guiding philosophy of Fred Rogers, the host and creator of Mister Rogers' Neighborhood. The trailer for the film debuted on what would have been Rogers's 90th birthday, March 20, 2018. The film premiered at the 2018 Sundance Film Festival and was released in the United States on June 8, 2018. It received acclaim from critics and audiences and has grossed $21 million, making it the highest grossing biographical documentary of all-time."
how did mcculloch v maryland expand the power of the federal government in relation to the states,"['17 U.S. 316 (1819); a landmark United States Supreme Court decision.  In this case, the state of Maryland attempted to impede operation of a branch of the Second Bank of the United States by imposing a tax on all notes of banks not chartered in Maryland. Though the law, by its language, was generally applicable, the U.S. Bank was the only out-of-state bank then existing in Maryland, and the law is generally recognized as specifically targeting the U.S. Bank. The Court invoked the Elastic Clause in the Constitution, which allowed the Federal government to pass laws not expressly provided for in the Constitution\'s list of express powers as long as those laws are in useful furtherance of the express powers. 17 U.S. 316 McCulloch v. Maryland Congress has power to incorporate a bank. The Act of the 10th of April, 1816, ch. 44, to ""incorporate the subscribers to the Bank of the United States"" is a law made in pursuance of the Constitution. The Government of the Union, though limited in its powers, is supreme within its sphere of action, and its laws, when made in pursuance of the Constitution, form the supreme law of the land. There is nothing in the Constitution of the United States similar to the Articles of Confederation, which exclude incidental or implied powers. If the end be legitimate, and within the scope of the Constitution, all the means which are appropriate, which are plainly adapted to that end, and which are not prohibited, may constitutionally be employed to carry it into effect. The power of establishing a corporation is not a distinct sovereign power or end of Government, but only the means of carrying into effect other powers which are sovereign. Whenever it becomes an appropriate means of exercising any of the powers given by the Constitution to the Government of the Union, it may be exercised by that Government. If a certain means to carry into effect of any of the powers expressly given by the Constitution to the Government of the Union be an appropriate measure, not prohibited by the Constitution, the degree of its necessity is a question of legislative discretion, not of judicial cognizance. The Bank of the United States has, constitutionally, a right to establish its branches or offices of discount and deposit within any state. The State within which such branch may be established cannot, without violating the Constitution, tax that branch. The State governments have no right to tax any of the constitutional means employed by the Government of the Union to execute its constitutional powers. The States have no power, by taxation or otherwise, to retard, impede, burthen, or in any manner control the operations of the constitutional laws enacted by Congress to carry into effect the powers vested in the national Government. This principle does not extend to a tax paid by the real property of the Bank of the United States in common with the other real property in a particular state, nor to a tax imposed on the proprietary interest which the citizens of that State may hold in this institution, in common with other property of the same description throughout the State. This was an action of debt, brought by the defendant in error, John James, who sued as well for himself as for the State of Maryland, in the County Court of Baltimore County, in the said State, against the plaintiff in error, McCulloch, to recover certain penalties, under the act of the Legislature of Maryland hereafter mentioned. Judgment being rendered against the plaintiff in error, upon the following statement of facts agreed and submitted to the court by the parties, was affirmed by the Court of Appeals of the State of Maryland, the highest court of law of said State, and the cause was brought by writ of error to this Court. It is admitted by the parties in this cause, by their counsel, that there was passed, on the 10th day of April, 1816, by the Congress of the United States, an act entitled, ""an act to incorporate the subscribers to the Bank of the United States;"" and that there was passed on the 11th day of February, 1818, by the General Assembly of Maryland, an act, entitled, ""an act to impose a tax on all banks, or branches thereof, in the State of Maryland, not chartered by the legislature,"" [p318] which said acts are made part of this Statement, and it is agreed, may be read from the statute books in which they are respectively printed. It is further admitted that the President, directors and company of the Bank of the United States, incorporated by the act of Congress aforesaid, did organize themselves, and go into full operation, in the City of Philadelphia, in the State of Pennsylvania, in pursuance of the said act, and that they did on the ___ day of _____ 1817, establish a branch of the said bank, or an office of discount and deposit, in the City of Baltimore, in the State of Maryland, which has, from that time until the first day of May 1818, ever since transacted and carried on business as a bank, or office of discount and deposit, and as a branch of the said Bank of the United States, by issuing bank notes and discounting promissory notes, and performing other operations usual and customary for banks to do and perform, under the authority and by the direction of the said President, directors and company of the Bank of the United States, established at Philadelphia as aforesaid. It is further admitted that the said President, directors and company of the said bank had no authority to establish the said branch, or office of discount and deposit, at the City of Baltimore, from the State of Maryland, otherwise than the said State having adopted the Constitution of the United States and composing one of the States of the Union. It is further admitted that James William McCulloch, the defendant below, being the cashier of the said branch, or office of discount and [p319] deposit did, on the several days set forth in the declaration in this cause, issue the said respective bank notes therein described, from the said branch or office, to a certain George Williams, in the City of Baltimore, in part payment of a promissory note of the said Williams, discounted by the said branch or office, which said respective bank notes were not, nor was either of them, so issued on stamped paper in the manner prescribed by the act of assembly aforesaid. It is further admitted that the said President, directors and company of the Bank of the United States, and the said branch, or office of discount and deposit have not, nor has either of them, paid in advance, or otherwise, the sum of $15,000, to the Treasurer of the Western Shore, for the use of the State of Maryland, before the issuing of the said notes, or any of them, nor since those periods. And it is further admitted that the Treasurer of the Western Shore of Maryland, under the direction of the Governor and Council of the said State, was ready, and offered to deliver to the said President, directors and company of the said bank, and to the said branch, or office of discount and deposit, stamped paper of the kind and denomination required and described in the said act of assembly. The question submitted to the Court for their decision in this case is as to the validity of the said act of the General Assembly of Maryland on the ground of its being repugnant to the Constitution of the United States and the act of Congress aforesaid, or to one of them. Upon the foregoing statement of facts and the pleadings in this cause (all errors in [p320] which are hereby agreed to be mutually released), if the Court should be of opinion that the plaintiffs are entitled to recover, then judgment, it is agreed, shall be entered for the plaintiffs for $2,500 and costs of suit. B ut if the Court should be of opinion that the plaintiffs are not entitled to recover upon the statement and pleadings aforesaid, then judgment of non pros shall be entered, with costs to the defendant. It is agreed that either party may appeal from the decision of the County Court to the Court of Appeals, and from the decision of the Court of Appeals to the Supreme Court of the United States, according to the modes and usages of law, and have the same benefit of this statement of facts in the same manner as could be had if a jury had been sworn and impanneled in this cause and a special verdict had been found, or these facts had appeared and been stated in an exception taken to the opinion of the Court, and the Court\'s direction to the jury thereon. Copy of the act of the Legislature of the State of Maryland, referred to in the preceding Statement. This page is not available in other languages.', '', 'No. 03-44 v. THEODORE B. OLSON Solicitor General Counsel of Record CHRISTOPHER A. WRAY Assistant Attorney General MICHAEL R. DREEBEN Deputy Solicitor General JEFFREY A. LAMKEN Assistant to the Solicitor General JEFFREY P. SINGDAHLSEN Attorney Department of Justice Washington, D.C. 20530-0001 (202) 514-2217 Whether petitioner is entitled to the dismissal of the indictment charging him with bribing an agent of local government bodies that receive federal benefits, in violation of 18 U.S.C. 666(a)(2), (b), on the ground that the statute does not require a sufficient nexus to a federal interest and is, as a result, facially unconstitutional. No. 03-44 v. The opinion of the court of appeals (Pet. App. A1-A36) is reported at 326 F.3d 937. The opinion of the district court (J.A. A7-A40) is reported at 183 F. Supp. 2d 1145. The judgment of the court of appeals was entered on April 7, 2003. The petition for a writ of certiorari was filed on July 2, 2003, and was granted on October 14, 2003. The jurisdiction of this Court rests on 28 U.S.C. 1254(1). Relevant provisions of the United States Constitution and 18 U.S.C. 666 are reproduced infra, App. 1a-3a. Petitioner was indicted on three counts of bribing an agent of an entity receiving federal benefits, in violation of 18 U.S.C. 666(a)(2), (b). Pet. App. A63-A66. Before trial, the United States District Court for the District of Minnesota dismissed the indictment on the ground that Section 666 is unconstitutional on its face. J.A. A7-A40. The court of appeals reversed. Pet. App. A1-A36. 1. The Statutory Background Entitled ""Theft or bribery concerning programs receiving Federal funds,"" 18 U.S.C. 666 makes it unlawful corruptly to offer, give, or agree to give anything of value ""with intent to influence or reward an agent of an organization or of a State, local or Indian tribal government, or any agency thereof, in connection with any business, transaction, or series of transactions of such organization, government, or agency involving anything of value of $5,000 or more,"" 18 U.S.C. 666(a)(2), if the ""circumstance"" set forth in Section 666(b) exists. The circumstance required by Section 666(b) is that ""the organization, government, or agency receives, in any one year period, benefits in excess of $10,000 under a Federal program involving a grant, contract, subsidy, loan, guarantee, insurance, or other form of Federal assistance."" 18 U.S.C. 666(b). Section 666 defines the term ""government agency"" as ""a subdivision of the executive, legislative, judicial, or other branch of government, including a department, independent establishment, commission, administration, authority, board, and bureau,"" as well as certain government corporations. 18 U.S.C. 666(d)(2). Section 666 was enacted in 1984 to ""protect the integrity of the vast sums of money distributed through Federal programs from theft, fraud, and undue influence by bribery."" See S. Rep. No. 225, 98th Cong., 1st Sess. 370 (1983). Before Section 666\'s enactment, the United States had sought to protect its funds and programs through the federal theft statute, which makes it unlawful to steal money or things of value ""of the United States or of any department or agency thereof,"" 18 U.S.C. 641, and the federal bribery statute, which prohibits corrupt efforts to influence public officials acting for or on behalf of the United States, 18 U.S.C. 201. Those statutes, however, had proved inadequate for federal programs administered by private organizations, States, local governments, and their agencies, including many federally funded programs of ""cooperative federalism"" administered by States or local governments to achieve federal goals.1 Prosecuting theft under 18 U.S.C. 641 had often proved impossible because that statute required proof that the defendant misappropriated funds ""of the United States."" Under many federal programs, title to the money or property would often ""pass[] to the recipient before"" being ""stolen, or the funds [would be] so commingled that the Federal character of the funds cannot be shown."" S. Rep. No. 225, supra, at 369. That gave ""rise to a serious gap in the law, since even though title to the monies may have passed, the Federal Government clearly retain[ed] a strong interest in assuring the integrity of such program funds."" Ibid. Similarly, bribery prosecutions under 18 U.S.C. 201 proved difficult because that provision applied only to ""public official[s]."" There was ""some doubt as to whether or under what circumstances persons not employed by the Federal Government [could] be considered as a \'public official\' under the definition in 18 U.S.C. 201(a)."" S. Rep. No. 225, supra, at 370; see Salinas v. United States, 522 U.S. 52, 58 (1997) (noting the circuit conflict on that issue that existed before Section 666\'s enactment).2 The varying mechanisms for disbursing and accounting for federal funds created gaps in coverage as well. See Salinas, 522 U.S. at 58-59 (describing the impact of United States v. Del Toro, 513 F.2d 656, 661-662 (2d Cir.), cert. denied, 423 U.S. 826 (1975)); S. Rep. No. 225, supra, at 369. Section 666 sought to fill those gaps so as to restore the United States\' ""ability * * * to vindicate significant acts of theft, fraud, and bribery"" that might threaten ""Federal monies * * * disbursed to private organizations or State and local governments pursuant to a Federal program."" S. Rep. No. 225, supra, at 369. To that end, Section 666 ""does not require the Government to prove [that] federal funds were involved in the bribery transaction"" or that ""the bribe in question had any particular influence on federal funds."" Salinas, 522 U.S. at 60, 61. Instead, Congress shifted the focus to proscribe the corruption of those private and public organizations that receive and administer substantial federal funds (more than $10,000 per year) under federal programs. See 18 U.S.C. 666(b). 2. The Present Controversy a. At all relevant times, petitioner was a real estate developer and landlord doing business in the City of Minneapolis, Minnesota (the City). Pet. App. A64. In 2000 and 2001, petitioner was pursuing a large commercial real estate development project involving a proposed hotel and accompanying commercial retail concerns. The indictment charges that petitioner offered to and did bribe City Councilperson Brian Herron of the Minneapolis City Council to obtain favorable government action for the project. At the time, Mr. Herron represented the Eighth Ward, which included the area for which petitioner had planned his real estate development. Ibid. Mr. Herron was also on the City Council\'s Ways and Means/Budget Committee. Ibid. During the calendar year beginning January 1, 2001, the City received, and the City Council administered, approximately $28.8 million in federal assistance. Id. at A63. As a member of the City Council, Herron also served on the Board of Commissioners for the Minneapolis Community Development Agency (MCDA). Pet. App. A64. The MCDA was created by the City Council to fund housing and economic redevelopment projects and activities within the City. Id. at A63. The MCDA also had an executive director appointed by the mayor. Ibid. The MCDA and its programs were funded in part by federal assistance, including federal Community Development Block Grants. Ibid. In the calendar year beginning January 1, 2001, the MCDA received approximately $23 million in such federal assistance. Ibid. Councilman Herron, together with the mayor and the other members of the City Council, were members of the policy board that managed the Minneapolis Neighborhood Revitalization Program (MNRP). Pet. App. A64. Formed by the City and other local government entities to fund the economic revitalization of City neighborhoods, the MNRP was wholly funded by the MCDA. Id. at A63-A64. Count 1 of the indictment alleged that petitioner gave Herron $5000 for Herron\'s assistance in obtaining necessary regulatory approvals from the City. Count 2 alleged that petitioner offered Herron $10,000 to meet with the owners of property in the area of the planned development and to threaten that, absent cooperation with the development plan, the MCDA might exercise its eminent domain power to condemn their property. Count 3 alleged that petitioner offered to give Herron $80,000 as a 10% kickback in return for his assistance in obtaining $800,000 in federal community economic development grants for the real estate project through the City, the MCDA, and other entities. Pet. App. A64-A66. The government\'s evidence includes conversations between petitioner and Herron that had been recorded on a hidden video camera. See Gov\'t Trial Br. 3-11 (C.A. App. 41-49). In those conversations, petitioner offered Herron a secret investment interest in the development equal to sixty or seventy percent of any ""free"" government money Herron obtained for the project. Id. at 4, 5 (C.A. App. 42, 43). Petitioner later changed his offer to a kickback of ""ten percent . . . of what [he] get[s]"" in ""free money."" Id. at 7 (C.A. App. 45); see also id. at 8 (""Five when you say yes, I agree to the deal,"" and ""then ten percent"" of ""whatever free money I get""). In those discussions, petitioner asked Herron to help him obtain federal ""Empowerment Zone"" funds administered by a Minneapolis city employee. Gov\'t Trial Br. 8-9 (C.A. App. 46-47). He urged Herron to get his ""staff workin\' on this right now, like hawks."" Id. at 9 (C.A. App. 47). When Herron reported that there was a ""real good possibility [he could] get about eight hundred thousand"" in federal funds, petitioner confirmed that Herron\'s pay-off would be ten percent, or eighty-thousand dollars. Id. at 9-10 (C.A. App. 47-48). In another conversation, petitioner offered Herron $10,000 to threaten existing property owners with use of the MCDA\'s eminent domain power so as to secure their cooperation: ""If you threaten that * * * you\'re gonna exercise your right for eminent domain at this site,"" petitioner stated, the property owners ""will start thinkin\', \'okay, Brian Herron . . . is gonna tell the MCDA to go forward to eminent domain us. So let\'s try to work ourself in the project.\'"" Id. at 6 (C.A. App. 44). Before trial, petitioner moved to dismiss the indictment on the ground that Section ""666(a)(2) is unconstitutional on its face as it does not require a connection between the alleged bribe and the federal funds."" J.A. A4, A11. As part of its response, the government stated that the evidence would show a nexus between the bribery and federal funds: In the present case, the evidence similarly will demonstrate that (1) Councilperson Herron, the ""agent"" of the local government involved, had direct influence over the federal funds received by Minneapolis and the MCDA, (2) those federal funds were directly related to economic development programs of the City and the MCDA, (3) the economic development programs of the City and the MCDA were directly involved in the real estate development that was being proposed by the defendant and (4) that the bribe payments and offers of the defendant sought to directly corrupt the operation of the city\'s economic redevelopment process and even sought to corruptly obtain the very funds that the federal government had provided to the City and the MCDA. J.A. A5. The district court granted petitioner\'s motion to dismiss. The court ruled that Section 666(a)(2) ""does not require the government to prove a connection between the offense conduct and the expenditure of federal funds,"" J.A. A25, and therefore ""is an unconstitutional exercise of Congress\'s power under the Spending Clause,"" J.A. A35. The district court also held that the government\'s proffer that the evidence would establish a connection between the charged conduct and federal funds and programs was irrelevant, because the statute did not require such proof as an element of the offense. J.A. A25 n.9. b. The court of appeals reversed and remanded, holding that Section 666 is not unconstitutional on its face. Pet. App. A1-A29. i. The court of appeals began by examining Section 666\'s text to determine the elements of the offense it establishes. The court observed that Subsection (b) of Section 666 ""requires proof that the relevant organization, government, or agency received benefits under a federal program in excess of $10,000 in any one-year period."" Pet. App. A4. But the court concluded that Section 666 does not, by its terms, impose a ""requirement that the government prove some [other] connection between the offense conduct and federal funds beyond the express statutory requirement found in § 666(b)."" Ibid. The plain language encompasses the activity of local agents wherever subsection (b) [ob]tains. There is no qualification that the prohibited conduct must have some relation to federal funds. Indeed, the statute proscribes the conduct of local agents in connection with ""any"" agency business or transaction. The word ""any"" is unambiguous and unqualified. Id. at A8-A9. ""The statute applies to all offense conduct * * * so long as the relevant agency received the requisite amount of federal benefits ($10,000) within the defined time period as required by § 666(b)."" Id. at A9. Reviewing the legislative history, the court of appeals found nothing to contradict the statute\'s text. Pet. App. A11-A14. Congress had enacted Section 666, the court observed, to ""fill the gaps in the prior anticorruption scheme,"" id. at A12, and thereby ""\'safeguard finite federal resources from corruption and to police those with control of federal funds,\'"" id. at A11 (quoting United States v. Rooney, 37 F.3d 847, 851 (2d Cir. 1994)). Because the criminal laws that preceded Section 666 required proof that the affected funds were federal, the court further observed, those laws had proved inadequate where title had passed to the recipient before the funds were stolen and where the funds were commingled. Id. at A11-A12. Congress had therefore ""decided that the most effective way to insure the integrity of federal funds disbursed to subnational agencies was to change the enforcement paradigm from one that monitored federal funds to one that monitored the integrity of the recipient agencies."" Id. at A12. The court of appeals also rejected petitioner\'s argument that Section 666, so construed, is facially unconstitutional because it exceeds Congress\'s enumerated powers. Pet. App. A14-A29. The court first rejected the government\'s argument that Section 666 could be sustained under the Spending Clause itself. Relying on the fact that Section 666 does not impose a condition on a recipient of federal benefits but instead regulates the conduct of third parties, the court concluded that Section 666 is not the typical sort of spending condition previously upheld by this Court. Id. at A15-A19. Nonetheless, the court of appeals concluded that Section 666 is valid legislation under the Necessary and Proper Clause to protect and effectuate Congress\'s exercise of its spending powers. Pet. App. A19-A28. Far from seeking to regulate private conduct through an exercise of general police power, the court explained, Section 666 was designed to protect the efficacy of federal spending and Congress\'s control over federal funds by assuring the integrity of the entities receiving them. It is ""an incontestable proposition,"" the court stated, ""that the disbursement of federal funds to subnational agencies to advance the general welfare is a legitimate end within the scope of the Constitution."" Id. at A21. Congress ""has a legitimate right to protect these disbursements from misappropriation once made."" Ibid. The court also concluded that Section 666 is ""plainly adapted"" to protecting the integrity of federal disbursements and programs and is therefore ""necessary and proper to the execution of the spending power"" under M\'Culloch v. Maryland, 17 U.S. (4 Wheat.) 316 (1819). Pet. App. A24. Although Section 666 might have been more narrowly crafted, the court noted, Congress reasonably determined that ""the most effective way to protect the integrity of federal funds is to police the integrity of the agencies administering those funds."" Id. at A25. A more limited statutory regime had been ""rendered toothless because of the difficulty of tracing federal funds once they had been disbursed."" Ibid. In addition, the court observed, because ""money is fungible and its effect transcends program boundaries,"" the ""maladministration of funds in one part of an agency can affect the allocation of funds, whether federal or local in origin, throughout an entire agency."" Ibid. (quoting United States v. Grossi, 143 F.3d 348, 350 (7th Cir.), cert. denied, 525 U.S. 879 (1998)). Thus, to suggest that corruption involving a discrete department or section of an agency that does not itself receive federal funds or administer a federal program can have no effect on the integrity or efficacy of a federal program is to ignore the fact that money is fungible and that federal funds are often comingled with funds from other sources. Section 666 addresses this problem by policing the integrity of the entire organization that receives federal benefits. Id. at A25-A26. Finally, the court rejected the suggestion that Section 666 is not ""proper"" legislation under the Constitution on the theory that it interferes with state sovereignty, explaining that the statute does not regulate the States as such, but instead regulates individuals whose conduct can threaten federal funds and federally funded programs. Id. at A21-A22 n.6. ii. Judge Bye dissented. Pet. App. A29-A36. Although acknowledging that the majority\'s ""reading of M\'Culloch is, of course, received wisdom"" and that ""the majority makes a fairly convincing argument that the \'fit\' between § 666(a)(2) and Congress\' underlying objective to preserve the integrity of federal programs is rational,"" Judge Bye concluded that Section 666 is not ""proper,"" within the meaning of the Necessary and Proper Clause. Id. at A31. Drawing on Printz v. United States, 521 U.S. 898 (1997), and Alden v. Maine, 527 U.S. 706 (1999), Judge Bye perceived state sovereignty limits on the type of legislation that can be deemed ""proper."" Pet. App. A31-A33. Because of the breadth and quantity of federal assistance provided to state and local governments, Judge Bye concluded that Section 666 ""federaliz[es] anticorruption law"" and improperly ""usurp[s] the traditional domain of state authority."" Id. at A33. Section 666 protects federal benefits and federally funded programs against significant corruption in the entities that receive the benefits. That protection is a constitutionally valid exercise of Congress\'s power. I. Congress enacted Section 666 for the legitimate purpose of protecting the integrity of the federal funds it disburses to private organizations and State and local governments under federal programs. To that end, Section 666 proscribes corrupt efforts to influence a transaction or series of transactions of a private organization or State, local, or tribal government or an agency thereof involving something worth $5000 or more, if one further condition is met. 18 U.S.C. 666(a)(2). That condition is that ""the organization, government, or agency"" must have ""receive[d], in any one year period, benefits in excess of $10,000 under a Federal program involving a grant, contract, subsidy, loan, guarantee, insurance, or other form of Federal assistance."" 18 U.S.C. 666(b). Those requirements limit Section 666 to significant acts of corruption where, because the relevant agency receives the requisite federal benefits, there is a strong federal interest in the integrity of federal funds and programs. As a matter of the statute\'s text, there is no further federal nexus requirement. Congress enacted Section 666 because earlier criminal statutes, which required proof of an effect on specific federal funds or programs, had proved insufficient given the difficulty of tracing fungible funds, the peculiarities of funding mechanisms, and impediments arising from the passage of title to the funds from the United States to the fund recipient. Congress therefore ""decided that the most effective way to insure the integrity of federal funds disbursed by subnational agencies was to change the enforcement paradigm from one that monitored federal funds to one that monitored the integrity of the recipient agencies"" responsible for administering them. Pet. App. A12. II. Section 666 is necessary and proper legislation to protect Congress\'s exercise of the Spending Power. Under the Necessary and Proper Clause, U.S. Const. Art. I, § 8, Cl. 18, Congress has authority to enact legislation that is ""necessary,"" i.e., ""convenient, or useful"" and ""plainly adapted,"" to the execution of federal powers. M\'Culloch v. Maryland, 17 U.S. (4 Wheat.) 316, 354, 413, 421 (1819). Section 666 is ""necessary"" legislation. It ensures that federal funds are not diverted from their intended use and that corruption does not threaten the integrity of federal programs. Section 666 also ensures that federal funds do not subsidize acts of fraud and corruption. The Constitution does not require that a statute addressing a matter of profound federal concern be perfectly calibrated so that every one of the statute\'s conceivable applications directly implicates that concern. Rather, Congress may enact legislation that sweeps somewhat more broadly when a narrower approach to the problem might jeopardize federal interests. Section 666 is not invalid on the theory that it requires the Court to pile inference upon inference to find a permissible federal interest. Section 666 is closely tied to the United States\' strong interest in guarding against the threat to its funds and programs created by financial corruption in the agencies that administer them. While Section 666 may overlap with traditional areas of state criminal law, it does so in order to protect distinct federal interests. Section 666 is also ""proper"" legislation under the Necessary and Proper Clause. Section 666 neither regulates the States as sovereigns nor commandeers state officials. It therefore does not implicate state sovereignty interests. It imposes a requirement on individuals-subjecting acts of corruption to potential federal prosecution-only when an entity (private or governmental) has elected to accept and administer the requisite amount of federal funds under a federal program. Federalism principles do not preclude Congress from protecting the federal interests in those funds and programs. Petitioner argues that the analysis in conditional-funding cases like South Dakota v. Dole, 483 U.S. 203 (1987), describes the limits of Congress\'s Necessary and Proper authority to implement the Spending Power, and that, under Dole, regulation of private parties is invalid. That argument, like petitioner\'s contention that Section 666 violates the Tenth Amendment, is misplaced. If petitioner were correct, Dole would preclude the federal government from criminalizing acts of corruption involving the theft from grant recipients of the federal funds themselves, and would remit the government to withholding federal funds from recipients. Nothing in the Constitution prevents Congress from directly imposing penalties on individuals whose criminal acts would frustrate legitimate federal spending programs. III. Reduced to its essence, petitioner\'s argument is that, because Section 666 does not require case-specific proof that a federal interest has been adversely affected, the statute is capable of reaching instances where the federal interest is attenuated; accordingly, he concludes, it is facially unconstitutional. Congress, however, had sound reasons for dispensing with such a case-by-case inquiry that would potentially leave federal programs and funds without sufficient protection. The legislature was not required to direct courts and juries to make a potentially elusive factual inquiry into effects on federal funds and programs. In any event, a claim that some applications of Section 666 may be beyond federal concern does not meet petitioner\'s burden of showing that Section 666 is unconstitutional ""on its face."" This Court has twice upheld convictions under Section 666, thus recognizing the constitutionality of its application to straightforward fraud and bribery cases involving federal funds and programs. To the extent that there are peripheral applications that might exceed Congress\'s constitutional authority, such concerns should be addressed through as-applied challenges in individual cases. Congress has authority under the Spending Clause to appropriate federal monies to promote the general welfare. U.S. Const. Art. I, § 8, Cl. 1. Congress also has corresponding authority under the Necessary and Proper Clause, U.S. Const. Art. I, § 8, Cl. 18, to protect that money and the integrity of the federal programs it supports. Congress enacted 18 U.S.C. 666 to ""protect the integrity of the vast sums of money distributed through Federal programs from theft, fraud, and undue influence."" S. Rep. No. 225, 98th Cong., 1st Sess. 370 (1983). The legitimacy of that purpose is beyond dispute. As this Court has observed, ""grant funds to state and local governments \'are as much in need of protection * * * as any other federal money.\'"" Dixson v. United States, 465 U.S. 482, 501 (1984) (quoting United States ex rel. Marcus v. Hess, 317 U.S. 537, 544 (1943)). There can be no serious question that bribing a local government official whose duties include managing federally funded programs and influencing the allocation of federal funds implicates the federal government\'s interest in the integrity of its funds and the programs they support. Petitioner contends, however, that Section 666 is ""[f]acially [u]nconstitutional,"" Pet. Br. 24; Pet. Reply 1-2 (""The Petition is clear that the issue presented is a facial challenge to the constitutionality of 18 U.S.C. § 666.""), because, in petitioner\'s view, Congress extended Section 666 too broadly and thereby reached cases in which the misconduct affected no federal program or federal funds. Pet. Br. 7-8. According to petitioner, the jurisdictional nexus required by Section 666(b)-the requirement that the ""organization, government, or agency"" at which the corruption is directed have ""receive[d], in any one year period, benefits in excess of $10,000 under a Federal [assistance] program""-does not ensure that the prohibited corruption will ""uniformly have the requisite connection to federal spending."" Pet. Br. 33 (emphasis added). Petitioner\'s claim of facial unconstitutionality must be rejected. Congress may enact statutes of sufficient breadth to achieve the legislature\'s goal of protecting its spending programs, even if some applications of the statute do not directly advance that goal. Where legitimate federal goals might be underprotected and frustrated by narrower provisions, Congress may enact statutes to avoid that pitfall, even if such laws have the potential to sweep in some circumstances that are of remote federal interest. The failure of Congress\'s earlier and narrower efforts to combat corruption touching on federal funds and programs demonstrated to the legislature that it had to do more than enact a statute directed solely at corruption with a proven effect on the federal funds themselves. Instead, Congress turned to an approach that focused on protecting the integrity of the entities that receive federal funds. That approach is constitutional. I. Section 666, As Properly Construed By The Court of Appeals, Does Not Require Proof Of A Federal Nexus Beyond The Statutory Terms Relying on the text of the statute and its legislative history, the court of appeals in this case held that Section 666 does not require the government to prove a federal interest in its funds or programs beyond the fact that ""the relevant agency received the requisite amount of federal benefits ($10,000) within the defined time period as required in § 666(b)."" Pet. App. A9. The overwhelming majority of courts of appeals that have addressed the issue, including the Fifth, Sixth, Seventh, Eighth, and Eleventh Circuits, have agreed, see Pet. Br. 20 n.1, as does petitioner. Pet. Br. 17, 20-22. That conclusion is correct.3 A. The Text Of Section 666 Unambiguously Defines The Elements Of The Offense Section 666(a)(2) addresses corruption only when at least two conditions are met. First, the corruption must have concerned a transaction or series of transactions of an organization or State, local, or tribal government or an agency thereof involving something worth $5000 or more. 18 U.S.C. 666(a)(2). Second, ""the organization, government, or agency"" must have ""receive[d], in any one year period, benefits in excess of $10,000 under a Federal program involving a grant, contract, subsidy, loan, guarantee, insurance, or other form of Federal assistance."" 18 U.S.C. 666(b). The first requirement limits Section 666\'s application to significant acts of corruption. The second limits Section 666 to cases in which, because the organization, government, or agency receives substantial federal funds under a federal program, the United States has a significant interest in preventing corruption and theft. Section 666 thus ""limits its reach to entities that receive a substantial amount of federal funds and to agents who have the authority to effect significant transactions."" United States v. Westmoreland, 841 F.2d 572, 578 (5th Cir.), cert. denied, 488 U.S. 820 (1988). As this Court has observed, Section 666 provides a ""broad definition of the \'circumstances\' to which the statute applies""-those cases in which the ""organization, government, or agency"" the defendant sought to corrupt ""receive[d] the statutory amount of benefits under a federal program."" Salinas, 522 U.S. at 57 (quoting 18 U.S.C. 666(b)). The statute ""provides no textual basis for"" further ""limiting the reach of [its] bribery prohibition."" Ibid. To the contrary, ""[s]ubject to the $5,000 threshold for the business or transaction in question, the statute forbids"" corruption ""in connection with any business transactions, or series of transactions of"" the covered ""organization, government, or agency."" Ibid. (emphasis added). ""The word \'any,\' which prefaces the business or transaction clause, undercuts"" the argument that ""federal funds must be affected to violate"" the statute. Id. at 56-57. Although Salinas left open whether Section 666 ""requires some other kind of connection between a bribe and the expenditure of federal funds"" than the nexus expressly required by Section 666(b), 522 U.S. at 59, the same reasoning that supported the Court\'s conclusion in Salinas that no proof of an actual effect on federal funds is required, id. at 56-57, applies here as well. There is no language in the statute requiring some other nexus to federal funds beyond the requirement that the relevant entity received the statutory amount of benefits under a federal program. B. The Purpose And Background Of Section 666 Confirm That It Requires No Federal Nexus Beyond That Set Forth In The Text The conclusion drawn from Section 666\'s text-that no additional federal nexus is required beyond the explicit requirement that the covered entity have received the specified federal benefits-is reinforced by the provision\'s origin and purposes. Section 666 was designed to ""augment the ability of the United States to vindicate significant acts of theft, fraud, and bribery"" to protect ""the vast sums of money distributed through Federal programs."" S. Rep. No. 225, supra, at 370; see Salinas, 522 U.S. at 58-59. The provision was enacted in response to the government\'s previous inability to reach significant misappropriations and corruption in federally funded assistance programs. See pp. 2-5, supra. Before Section 666\'s enactment, federal prosecutions were often hindered by the fact that title to the relevant funds had ""passed to the recipient before"" the money was stolen, or because ""the funds [we]re so commingled that the Federal character of the funds [could] []not be shown."" S. Rep. No. 225, supra, at 369. That gave ""rise to a serious gap in the law, since even though title to the monies may have passed, the Federal Government clearly retain[ed] a strong interest in assuring the integrity of such program funds."" Ibid. Section 666 filled that gap by eliminating any requirement that the misconduct be traced to specific federal monies. Instead, Section 666(b) required that the institution, government, or agency at issue have received a specified amount of federal funds. 18 U.S.C. 666(b).4 As the court of appeals observed, Congress ""decided that the most effective way to insure the integrity of federal funds disbursed by subnational agencies was to change the enforcement paradigm from one that monitored federal funds to one that monitored the integrity of recipient agencies."" Pet. App. A12. ""[B]ecause § 666 changed the focus"" from the policing of identifiable ""federal funds to policing the agencies that receive and administer those funds, the argument that there must be a nexus between the offense conduct and the federal funds beyond that explicitly provided for in § 666(b) seems inconsistent"" with Congress\'s goals. Id. at A12-A13.5 The scope of Section 666 is also illuminated by one of the decisions that prompted it: United States v. Del Toro, 513 F.2d 656, 661-662 (2d Cir.), cert. denied, 423 U.S. 826 (1975), which had converted the happenstance of funding, disbursement, and accounting mechanisms into impediments to federal prosecution. See Salinas, 522 U.S. at 58-59; S. Rep. No. 225, supra, at 369. In Del Toro, the Second Circuit overturned the federal bribery conviction of a city employee, ""even though federal funds would eventually cover 100% of the costs and 80% of the salaries of the program he administered"" because, at the time of the bribe, the city ""had not yet entered a formal request for federal funding."" Salinas, 522 U.S. at 58-59. There could be no prosecution, Del Toro held, because ""[t]here were no existing committed federal funds"" when the misconduct occurred. Salinas, 522 U.S. at 59 (quoting Del Toro, 513 F.2d at 662). In Salinas, this Court explained that construing Section 666 to require proof that a bribe is traceable to federal funds ""would run contrary to the statutory expansion that redressed the negative effects of the Second Circuit\'s narrow construction of § 201 in Del Toro."" Ibid. Requiring the government to prove a particular nexus to federal funds or programs beyond that provided in Section 666(b) would have the same effect here. C. Section 666 Is Not Ambiguous In concluding that Section 666 requires a federal nexus not required by the statute\'s operative language, the Third Circuit reasoned principally that the statute\'s title (""Theft or bribery concerning programs receiving Federal funds"") introduced ambiguity into the statute\'s meaning; the court then applied the canon that an ambiguous statute should be construed to avoid serious constitutional doubts. United States v. Zwick, 199 F.3d 672, 682-687 (3d Cir. 1999). While a statutory title may be a ""tool[] available for the resolution of a doubt about the meaning of a statute,"" Almendarez-Torres v. United States, 523 U.S. 224, 234 (1998) (internal quotation marks omitted), it is not a tool for creating ambiguity. ""The title of a statute,"" this Court has held, ""cannot limit the plain meaning of the text""; rather, ""for interpretive purposes, it is of use only when it sheds light on some ambiguous word or phrase."" Pennsylvania Dep\'t of Corrections v. Yeskey, 524 U.S. 206, 212 (1998) (punctuation altered and brackets omitted). Here, the relevant textual provisions are clear and unambiguous: They reach corruption in ""any"" business of a covered entity. Salinas, 522 U.S. at 57 (emphasis added). And, absent ambiguity, there is no room for the application of the canon of constitutional avoidance. Id. at 60-61; Yeskey, 524 U.S. at 212. In any event, as discussed below, there is no serious doubt that Section 666 is facially constitutional. II. Section 666 Is Necessary And Proper Legislation To Ensure The Integrity Of Federal Funds And Programs Congress has the power to spend federal revenues to ""provide for * * * the general Welfare of the United States."" U.S. Const. Art. I, § 8, Cl. 1. Congress\'s authority ""to authorize expenditure of public moneys for public purposes is not limited by the direct grants of legislative power found in the Constitution."" United States v. Butler, 297 U.S. 1, 66 (1936); accord South Dakota v. Dole, 483 U.S. 203, 207 (1987). Congress also has the authority to ""make all Laws which shall be necessary and proper for carrying into Execution"" its powers, including the spending power. U.S. Const. Art. I, § 8, Cl. 18. Those grants of authority entitle Congress to enact criminal statutes that are designed to protect federal funds and the programs they support. Since M\'Culloch v. Maryland, 17 U.S. (4 Wheat.) 316 (1819), it has been settled that Congress has constitutional authority to enact not merely legislation that is ""indispensable"" to the exercise of its enumerated powers, but also such legislation as Congress in its judgment deems ""necessary and proper,"" U.S. Const. Art. I, § 8, Cl. 18, i.e., ""convenient, or useful"" and ""plainly adapted"" to the execution of federal power, so long as the means chosen are not prohibited by the Constitution. 17 U.S. (4 Wheat.) at 413, 421. It is ""an incontestable proposition that the disbursement of federal funds to subnational agencies to advance the general welfare is a legitimate end within the scope of the Constitution."" Pet. App. A21. Congress therefore also ""has a legitimate right to protect these disbursements from misappropriation once made."" Ibid. Section 666 is both ""necessary"" and ""proper"" to the attainment of important federal objectives, and thus is facially valid. Every court of appeals that has considered Section 666\'s facial constitutionality has upheld the statute. United States v. Edgar, 304 F.3d 1320, 1325 (11th Cir.) (""As a means of ensuring the efficacy of federal appropriations to comprehensive federal assistance programs, the anti-corruption enforcement mechanism strikes us as bearing a sufficient relationship to Congress\'s spending power to dispel any doubt as to its constitutionality.""), cert. denied, 537 U.S. 1078 (2002); Pet. App. A25 (""Section 666 is a legitimate exercise of Congress\'s undisputed power to make a law that is necessary and proper for the carrying out of its enumerated power to provide for the general welfare of the United States [through spending].""); United States v. Bynum, 327 F.3d 986, 991 (9th Cir.) (""We agree with the Eighth and Eleventh Circuits that § 666 is facially constitutional.""), cert. denied, 124 S. Ct. 279 (2003). This Court has repeatedly recognized that a statute is not unconstitutional on its face merely because it ""might operate unconstitutionally under some conceivable set of circumstances."" United States v. Salerno, 481 U.S. 739, 745 (1987). Rather, ""the challenger must establish that no set of circumstances exists under which the [law] would be valid."" Ibid. (emphasis added); see Anderson v. Edwards, 514 U.S. 143, 155-156 n.6 (1995) (parties challenging statute ""on its face"" cannot ""sustain their burden even if they show[] that a possible application of the rule"" is invalid); Reno v. Flores, 507 U.S. 292, 301 (1993) (""To prevail"" on ""a facial challenge,"" the party ""must establish that no set of circumstances exists under which the [regulation] would be valid"") (quoting Salerno, 481 U.S. at 745); United States v. Raines, 362 U.S. 17, 21 (1960) (""one to whom application of a statute is constitutional will not be heard to attack the statute on the ground that impliedly it might also be taken as applying to other persons or other situations in which its application might be unconstitutional""). Petitioner\'s challenge falls well short of that standard.6 A. Congress Has The Authority To Protect Federal Spending Under The Necessary And Proper Clause Congress\'s authority to enact criminal laws to protect federal funds and programs has long been recognized by this Court. In United States v. Hall, 98 U.S. 343 (1878), this Court upheld a federal statute making it a criminal offense for a guardian, agent, or attorney to embezzle a soldier\'s federal pension, rebuffing the claims (1) that such a law would effectively ""assume all the police regulation of the States,"" and (2) that, because ""State law authorized the guardian to receive the pension-money, the defendant cannot be subjected to an indictment under an act of Congress for embezzling it after he lawfully received it."" Id. at 349. ""Because the fund proceeds from the United States, * * * Congress may pass laws for its protection, certainly until it passes into the hands of the beneficiary."" Id. at 357-358. The Court observed: ""[T]hroughout the entire period since"" the Constitution\'s adoption, ""it has been the unchallenged practice of the legislative department of the government, with the sanction of every President, including the Father of the Country, to pass laws to prevent the diversion of [federal] pension-money from inuring solely to the use and benefit of those to whom the pensions are granted."" Id. at 354. If Congress may grant pensions, Congress ""may by all suitable laws guard and protect the fund thus devoted from being diverted from its object by either the craft or the extortion of unscrupulous agents."" Id. at 356 (citing United States v. Marks, 26 F. Cas. 1162 (C.C.D. Ky. 1869) (No. 15,721)). The same analysis applies when Congress appropriates the funds for programs administered by state and local governments pursuant to cooperative federalism agreements. Federal ""grant funds to state and local governments \'are as much in need of protection * * * as any other federal money.\'"" Dixson, 465 U.S. at 501 (quoting United States ex rel. Marcus v. Hess, 317 U.S. 537, 544 (1943)). For that reason, the Court in Dixson construed a federal statute barring the corruption of ""public officials"" to extend to local officials administering federal block grant funds. See ibid. Similarly, in Westfall v. United States, 274 U.S. 256 (1927), the Court rejected the argument that Congress could not punish frauds perpetrated against a ""State bank"" that participated in the Federal Reserve System where the statute ""applie[d] indifferently whether there is a loss to the [Federal] Reserve Banks or not."" Id. at 258-259. ""[E]very fraud like the one before us weakens the member bank and therefore weakens the System,"" the Court stated. Id. at 259. This Court has also upheld Congress\'s interest in ensuring the integrity of federal funds, programs, and the institutions receiving federal funds when addressing Section 666 itself. In Fischer v. United States, 529 U.S. 667 (2000), the Court concluded that the ""Government has a legitimate and significant interest in prohibiting financial fraud or acts of bribery being perpetrated upon Medicare providers,"" which receive federal benefits to achieve federal policy ends. Id. at 681. Likewise, in Salinas, 522 U.S. at 60-61, the Court held that ""there is no serious doubt about"" Congress\'s constitutional authority to punish the taking of bribes by a county official for according favorable treatment to a federal prisoner whom the County was holding for the United States under contract. Contrary to petitioner\'s suggestion (Br. 28), Salinas\'s constitutional holding was not mere ""dictum."" This Court squarely ""decide[d] that, as a matter of statutory construction, § 666(a)(1)(B) does not require the Government to prove the bribe in question had any particular influence on federal funds and that under this construction the statute is constitutional as applied in this case."" 522 U.S. at 61 (emphasis added). Just as the power ""to establish post offices and post roads"" encompasses the power to ""punish those who steal letters,"" M\'Culloch, 17 U.S. (4 Wheat.) at 417, the power to spend for the public welfare encompasses the power to punish those whose theft and corruption threatens federal spending and programs. B. Section 666 Is ""Necessary"" Federal Legislation To Protect Federal Benefits Programs Enacted to protect the integrity of federal funds and the programs they finance, Section 666 is necessary legislation to protect the effectiveness of Congress\'s exercise of its spending power. Section 666 ensures that federal funding is not diverted from its intended purpose and that federal programs are not impaired by corruption. United States v. Brunshtein, 344 F.3d 91, 97 (2d Cir. 2003) (""Congress enacted § 666 to \'safeguard finite federal resources from corruption and to police those with control of federal funds.\'"") (quoting United States v. Rooney, 37 F.3d 847, 851 (2d Cir. 1994)). Section 666 also ensures that fraudulent acts do not threaten federal programs by depriving program participants of necessary resources. In Fischer, the Court explained that ""financial fraud or acts of bribery * * * perpetrated upon Medicare providers"" impermissibly ""threaten the [Medicare] program\'s integrity"" by ""rais[ing] the risk participating organizations will lack the resources requisite to provide the level and quality of care envisioned by the program."" 529 U.S. at 681-682. Likewise, in Salinas, the Court upheld the conviction of a county official for taking bribes in return for affording preferential treatment to a federal prisoner housed in a local facility ""paid for in significant part by federal funds."" 522 U.S. at 59. Even though the corruption did not necessarily impose any additional costs on the United States, it represented ""a threat to the integrity and proper operation of the federal program"" at issue. Id. at 61. Judicial review of the ""necessity"" of employing a particular means to achieve Congress\'s purposes is deferential. As this Court explained shortly after this Nation\'s founding, Congress has discretion to ""employ those [means] which, in its judgment, would most advantageously effect the object to be accomplished."" M\'Culloch, 17 U.S. (4 Wheat.) at 419. ""[W]here the means adopted by Congress are not prohibited and are calculated to effect the object intrusted to it, this Court may not inquire into the degree of their necessity; as this would be to * * * tread upon legislative ground."" James Everard\'s Breweries v. Day, 265 U.S. 545, 559 (1924). ""Congress must possess the choice of means, and must be empowered to use any means which are in fact conducive to the exercise of a power granted by the Constitution."" Legal Tender Case, 110 U.S. 421, 441 (1884). Amicus Cato Institute invites this Court to reconsider the ""received wisdom"" of M\'Culloch and to adopt an intermediate scrutiny standard articulated by James Madison in a private letter-that ""laws executing federal powers must have a \'definite connection\' to and \'some obvious and precise affinity\' with permissible governmental ends."" See Cato Br. 3; see id. at 18-22. This Court, however, has employed M\'Culloch\'s ""plainly adapted,"" ""conducive,"" and ""appropriate"" formulations for the more than 180 years since M\'Culloch was decided. See, e.g., Katzenbach v. Morgan, 384 U.S. 641, 651 (1966); United States v. Butler, 297 U.S. 1, 69 (1936). Just last Term, this Court applied M\'Culloch to reject a Necessary and Proper Clause challenge to 28 U.S.C. 1367(d), which tolls the limitations period for certain state-law claims in state court: ""[I]t suffices that § 1367(d) is \'conducive to the due administration of justice\' in federal court, and is \'plainly adapted\' to that end."" Jinks v. Richland County, 123 S. Ct. 1667, 1671 (2003). Amicus offers no compelling justification for abandoning that longstanding constitutional formulation in favor of Madison\'s private critique of M\'Culloch\'s reasoning and the decision itself. Cato Br. 19 (citing Letter of Sept. 2, 1819 to Spencer Roane, in 8 The Writings of James Madison 447 (Gaillard Hunt ed. 1908)).7 1. Congress selected reasonable means of achieving its interest in the protection of federal funds and programs Congress enacted Section 666 to broaden the sweep of federal law only after attempting to protect federal funds and programs through more limited statutes that had proved ""toothless."" Pet. App. A25. Congress\'s long experience with those earlier statutes showed that focusing on the federal funds themselves rather than the recipient was inadequate because of the difficulty of tracing money, as well as the effects of commingling and varying accounting and disbursement methodologies. See pp. 3-5, 19-22 & n.4, supra; Pet. App. A25. Congress therefore made the sensible ""determination that the most effective way to protect the integrity of federal funds"" and federally funded programs was not to police the funds directly but ""to police the integrity of the agencies administering those funds."" Pet. App. A25; see Fischer, 529 U.S. at 678 (The language of Section 666 ""reveals Congress\' expansive, unambiguous intent to ensure the integrity of organizations participating in federal assistance programs.""); United States v. Bonito, 57 F.3d 167, 172 (2d Cir. 1995) (Section 666 ""seeks to preserve the integrity of federal funds by assuring the integrity of the organization that receives them."") (quoting Westmoreland, 841 F.2d at 578), cert. denied, 516 U.S. 1049 (1996). Congress\'s decision to focus on the corruption of institutions receiving federal funds also makes good sense even apart from the problems that plagued earlier statutes. The ""federal government has an obvious interest in the incorruptibility of the City officials who are responsible for ensuring the transmission of federal funds to specific City programs."" Brunshtein, 344 F.3d at 98. The ""integrity of federal funds is placed at risk when the agency that receives those funds is corrupted."" Id. at 100. An analogy to the private sector makes that clear: In the private sector, what would a reasonable funding partner who has advanced $[28] million do after learning that its service partner takes kickbacks, albeit regarding matters not within the partnership\'s scope? The funding partner might well dissolve the partnership rather than wait for the service partner\'s corruption to widen and infect the partnership\'s dealings. United States v. Lipscomb, 299 F.3d 303, 332 (5th Cir. 2002) (opinion of Wiener, J.); see also Edgar, 304 F.3d at 1327 (""It is reasonable for Congress to conclude that any corruption of such recipient organizations * * * endangers the comprehensive programs in which the organizations participate, and thus the effective exercise of the Congressional spending power as well.""). No principle of constitutional law requires Congress to wait until an official\'s corruption widens and infects a specific federal program and identifiable federal funds, when a reasonable, similarly situated private party would not. This case illustrates the wisdom of that approach. The corruption at issue here (which involved an effort to distort the allocation of federal funds) came to light as a result of Councilman Herron\'s arrest for acts of corruption in more local matters. See Trial Br. 3, 14-15; Gov\'t C.A. Br. 5. Once corruption begins, those involved rarely differentiate between the local and federal programs the agency administers or carefully confine their activities to the former. The presence of corrupt officials in an entity receiving federal benefits also may indicate that the entity has broader problems, such as inadequate controls, even if the specific corruption identified does not involve federal funds or a federally funded activity. In addition, ""[m]oney is fungible and its effect transcends program boundaries."" United States v. Grossi, 143 F.3d 348, 350 (7th Cir.) (Easterbrook, J.), cert. denied, 525 U.S. 879 (1998). As a result, even where an agency operates some programs that receive federal funds and some that do not, corruption in non-federal programs can impair the agency\'s administration of federal money. See Pet. App. A25 (""maladministration of funds in one part of an agency can affect the allocation of funds, whether federal or local in origin, throughout an entire agency""). Corruption in locally funded programs can drain commingled resources from or place additional burdens on federally funded programs, impairing their achievement of federal program goals. See, e.g., United States v. DeLaurentis, 230 F.3d 659, 662 (3d Cir. 2000). Indeed, as the court of appeals explained in Grossi, a program that (at least as an accounting matter) appears funded by local revenues will have ""more to spend * * * (or dangle as a lure for bribes) if the federal government meets some of the [agency]\'s other expenses."" 143 F.3d at 350. An agency that administers substantial federal funds will often be strengthened by the federal funds, increasing the opportunities for corruption and their oppressive effect. In this case, for example, petitioner paid Councilman Herron to threaten property owners with the MCDA\'s use of its eminent domain powers so that they would accede to his development plan on their own. See pp. 6, 7, supra. That threat was undoubtedly more credible because the MCDA, backed by millions of federal dollars, had the resources (for litigation and payment of just compensation) to make good on the threat. 2. Congress is not limited to protecting against corruption in federal instrumentalities Petitioner argues (Br. 26-31) that the federal government\'s authority to address corruption does not extend beyond federal institutions and instrumentalities. That argument fails to account for the obvious federal interest in foreclosing the theft and corruption of federal money held by organizations administering federal programs. And it overlooks a century of precedent recognizing the legitimacy of that interest- including cases like Hall, supra, which upheld the federal conviction of a guardian for embezzling a soldier\'s federal pension money; Salinas, supra, which upheld the conviction of a county official for corruptly favoring a federal prisoner in state facilities financed with federal monies; Westfall, supra, which upheld a conviction for defrauding a state bank participating in the Federal Reserve System; and Fischer, supra, which recognized the government\'s strong interest in prosecuting fraud aimed at Medicare providers. See pp. 25-27, supra. This Court\'s decision in Dixson all but forecloses petitioner\'s argument, interpreting the term ""public official"" in the federal criminal bribery statute, 18 U.S.C. 201(a), to include local officials administering federal funds: [W]hen one examines the structure of the program and sees that [it] vests in local administrators * * * the power to allocate federal fiscal resources for the purpose of achieving congressionally established goals, * * * it becomes clear that these local officials hold precisely the sort of positions of national public trust that Congress intended to cover * * * . The Federal Government has a strong and legitimate interest in prosecuting petitioners for their misuse of Government funds. 465 U.S. at 500-501. Petitioner does not meaningfully distinguish those cases, none of which involved ""instrumentalities of the United States"" as that phrase is ordinarily used.8 Nor does petitioner explain why, if the individuals and institutions at issue in those cases-the private person in Hall, the state bank in Westfall, the local officials in Dixson, the county prison in Salinas, and the Medicare providers in Fischer-would qualify as federal instrumentalities for purposes of determining the constitutionality of those statutes, the entities receiving and administering funds under federal programs covered by Section 666 would not. Indeed, petitioner effectively acknowledges that his position would draw into question ""the constitutionality of 18 U.S.C. § 201, as interpreted in Dixson,"" Pet. Br. 27 n.2, and relies on the Dixson dissent, see Pet. Br. 29. But not even the dissenters in Dixson questioned Congress\'s power to impose criminal liability on corrupt officials with responsibility over federal programs and those who corrupt them. The dissenters merely were of the view that Congress had not exercised that power there. See 465 U.S. at 510 (federal programs should ""not be interpreted to deputize States or their political subdivisions to act on behalf of the United States"" within the meaning of Section 201 ""unless such deputy status is expressly accepted or, where lawful, expressly imposed""; contrasting 1976 amendments to the Grain Standards Act). The Constitution does not ""make the extent"" of Congress\'s ability to ""safeguard"" federal funds dependent on the Treasury\'s continued possession of those funds or ""the bookkeeping devices used for their distribution."" Id. at 501; see Hess, 317 U.S. at 544 (""Government money is as truly expended whether by checks drawn directly against the Treasury to the ultimate recipient or by grants in aid to states.""). 3. This Court\'s decisions in Lopez and Morrison lend no support to a claim that Section 666 reaches too far Petitioner invokes this Court\'s Commerce Clause decisions in United States v. Lopez, 514 U.S. 549 (1995), and United States v. Morrison, 529 U.S. 598 (2000), in arguing that the corruption reached by Section 666 is too attenuated from federal interests. Pet. Br. 32-33.9 In particular, petitioner argues that Section 666, like the statutes at issue in those cases, can be sustained only if the Court is willing ""to pile inference upon inference in a manner that"" would accord the United States a ""general police power of the sort retained by the States."" Pet. Br. 33 (quoting Lopez, 514 U.S. at 567). The Commerce Clause analysis in Lopez and Morrison is not at issue here. This case does not involve an exercise of Congress\'s power to enact criminal laws to effectuate a specific enumerated grant of regulatory authority. Instead, it involves Congress\'s power to protect the integrity of benefits programs and federal funds established under its Spending Clause power. Congress\'s authority to prohibit criminal acts that threaten its expenditures and programs is not subject to analysis under Lopez and Morrison. In any event, no piling of inferences is necessary to sustain Section 666. That provision directly serves Congress\'s legitimate interest in preserving the integrity of federal funds and the programs they finance. It ensures the incorruptibility of entities to which Congress entrusts its funds and programs for administration. It eliminates impediments (e.g., tracing requirements) that impaired the effectiveness of earlier laws. And it ensures that federal funding does not subsidize corruption. To the extent that a demonstrable adverse effect on federal interests is not present in every case, Congress was permitted to dispense with one. The Constitution does not demand a perfect fit between the federal interest and every possible application of the statute Congress enacts to serve that interest. The standard is whether the statute is ""plainly adapted,"" or ""convenient"" and ""useful,"" to a legitimate federal end. See pp. 23, 28-30, supra. Consequently, where Congress enacts a statute to address a problem squarely within national competence, the legislation may sweep somewhat more broadly than the underlying purpose if necessary to ensure its effectiveness. As this Court explained when rejecting an argument virtually indistinguishable from petitioner\'s in Westfall, supra, see Br. for Plaintiff in Error, No. 766, at 15-17 (Feb. 24, 1927): ""[W]hen it is necessary in order to prevent an evil to make the law embrace more than the precise thing to be prevented [Congress] may do so."" 274 U.S. at 259. The fact that Section 666 reaches conduct that traditionally falls within the scope of state criminal law does not prevent Congress from protecting federal interests. As the court of appeals explained, ""were we to conclude that Congress lacked the authority to legislate in this area, then the protection of federal funds would be left to the whim of state and local officials-perhaps even the same officials who pose a threat to the integrity of the federal funds in the first place and who therefore possess a strong disincentive to protect them."" Pet. App. A28. The court concluded that ""[t]he proposition that the federal government is powerless to vindicate its own interests is clearly untenable."" Ibid. M\'Culloch makes the same point. ""To impose on [the United States] the necessity of resorting to means which it cannot control, which another government may furnish or withhold, would render its course precarious, the result of its measures uncertain, and create a dependence on other governments, which might disappoint its most important designs, and is incompatible with the language of the constitution."" 17 U.S. (4 Wheat.) at 424. Sustaining Section 666 would hardly accord the United States a general police power or ""obliterate the distinction between what is national and what is local."" Pet. Br. 32. Section 666 does not rest on putative authority to regulate all the activities on which Congress may spend federal funds, or all activities that may affect the success of federally funded programs. Section 666 instead rests on the proposition that, because the United States has an interest in ensuring the integrity of its funds and programs, it may pursue that interest by policing the integrity of the entities to which its funds and programs are entrusted. Consequently, the reach of Section 666, and Congress\'s ability to enact statutes like it, is limited both by the finite nature of the federal fisc, and by the direct connection between the prohibition on financial corruption in agencies administering federal program funds and the interest in protecting those federal funds and programs.10 C. Section 666 Is ""Proper"" Legislation Under The Constitution Petitioner suggests (Br. 40) that Section 666 violates ""the sovereignty of the States"" under Alden v. Maine, 527 U.S. 706 (1999), and Printz v. United States, 521 U.S. 898 (1997), and therefore is not ""proper"" legislation under the Necessary and Proper Clause. That argument lacks merit. Neither Alden nor Printz is applicable here. In Alden, the statute sought to allow private citizens seeking damages to hale the State into its own courts, notwithstanding the State\'s claim to sovereign immunity. 527 U.S. at 730. In Printz, the statute sought to ""conscript[] the States\' officers"" into service ""to administer [and] enforce a federal regulatory program."" 521 U.S. at 935. Section 666 does not run afoul of ""the postulate that States of the Union, still possessing attributes of sovereignty, shall be immune from suits, without their consent, save where there has been \'a surrender of this immunity in the plan of the convention.\'"" Alden, 527 U.S. at 730. Nor does it ""conscript[]"" or ""commandeer"" state officers into federal service. Printz, 521 U.S. at 929, 935. Quite the opposite: the federal obligation of public employees to refrain from corruption results from a decision by the agency, state, or local government to accept federal money and administer a federal program. Section 666 imposes precisely the same duties on the agents of private organizations that choose to receive federal money.11 Petitioner offers no reason why the United States cannot insist that the state and local government recipients of federal funds operate with the same level of freedom from corruption as private ones. Petitioner also asserts (Br. 36) that Section 666 blurs state and local accountability for prosecuting corruption in state entities. But many statutes of unquestioned constitutionality, including the mail and wire fraud statutes and the federal securities laws, create overlapping coverage. There is certainly no federalism objection where the federal legislation is plainly adapted to the service of legitimate federal interests and leaves the States both free to make their own enforcement decisions and to be held politically accountable for those choices. As the Court explained in Westfall: Of course an act may be criminal under the laws of both jurisdictions. * * * [I]f a state bank chooses to come into the System created by the United States, the United States may punish acts injurious to the System, although done to a corporation that the State also is entitled to protect. The general proposition is too plain to need more than statement. 274 U.S. at 258. D. Petitioner Is Not Assisted By His Reliance On The Standards Of South Dakota v. Dole 1. The Dole test for spending conditions does not exhaust Congress\'s ""necessary and proper"" authority Petitioner argues that, in the spending area, the ""necessary and proper"" test of M\'Culloch has been subsumed in and superseded by this Court\'s conditional funding cases, such as South Dakota v. Dole, 483 U.S. 203 (1987). Br. 37-40. He asserts that the Dole test incorporates all of Congress\'s necessary and proper power to implement the Spending Clause. According to petitioner, the United States\' interests are satisfied if the grant recipient complies with its contractual obligations-or if, in the event of breach, the recipient ""compensates the Federal Government or a third-party beneficiary * * * for the loss caused by that failure."" Pet. Br. 29-30. In arguing that Dole occupies the field and that Congress cannot reach beyond imposition of conditions on the grant recipient, petitioner is, in effect, arguing that the federal government could not prosecute a state official even if that official stole the federal funds themselves or accepted a bribe in direct connection with a federal program. Congress, petitioner seems to argue, is limited to the protection of its funds by imposing some sort of anti-corruption condition and then withdrawing the funds if the condition is not satisfied. That position cannot be correct. The present case illustrates the point. Like many similar cases, it does not involve a breach of conditions by the funding recipients. It involves the efforts of individuals like petitioner and the local official he bribed to corrupt the operations of otherwise innocent governmental entities administering federal program funds. Petitioner nowhere explains why it would make sense for those institutions, and the citizens they serve, to be punished for his and Herron\'s misconduct. See Lipscomb, 299 F.3d at 333 (Wiener, J.) (fiscal reprisals directed at a fund recipient would cause the local populace, which is ""by definition innocent of official corruption,"" to ""suffer a cut in federally funded services""). That would defeat the goal of the spending, which is to provide federal funding to serve public needs, not to take funds away from local government recipients to make up for federal corruption losses. Ibid. Nor would petitioner\'s proposed remedy deter individuals who seek to enrich themselves through the corruption of public agents in agencies that receive federal funds and administer federal programs, since the burdens of that remedy fall on the funding recipient rather than the criminally corrupt. Petitioner cites no case that prohibits Congress from protecting its interest in disbursed federal funds and federal programs by imposing criminal prohibitions on the individual wrongdoers. To the contrary, the interests in safeguarding federal benefits and programs have been held sufficient to sustain federal criminal penalties throughout this Nation\'s history, as Hall, Westfall, Salinas, and Fischer all make clear. 2. Petitioner\'s conditional funding arguments are without merit Petitioner also claims that Section 666 transgresses the limits of the Dole factors in several respects. Because Section 666 is properly understood as a valid exercise of Congress\'s power under the Necessary and Proper Clause, those arguments do not justify his position that Section 666 is facially unconstitutional. This Court\'s conditional funding decisions, including Dole, govern where Congress encourages or requires States to act in their sovereign capacity by conditioning the provision of federal funding on some undertaking by the States. In Dole, for example, the United States conditioned a portion of federal highway funds on the States\' enactment of legislation that increased the drinking age to 21, a requirement that Congress could not, because of the 21st Amendment, impose itself. 483 U.S. at 209. In this case, the United States did not encourage or require state governments to regulate. Instead, Congress enacted federal legislation itself to serve the national government\'s own legitimate ends in protecting federal spending. Even if viewed through the prism of conditional funding decisions like Dole, petitioner\'s arguments are mistaken.12 He contends (Br. 32) that Section 666 is invalid under Dole because it is not ""related to the purpose of the federal program."" See Dole, 483 U.S. at 207 (condition may be ""illegitimate"" if ""unrelated \'to the federal interest in particular national projects or programs\'""). That claim is answered above, in the discussion of how Section 666 is plainly adapted to serve Spending Power interests under the Necessary and Proper Clause. See pp. 25-33, supra. Petitioner\'s basic premise (Br. 33-34) that each and every possible application of Section 666 must have a nexus to a federal interest misconceives Dole\'s relatedness requirement. Dole mandates a ""reasonable relationship"" between the condition and the purpose of the funding, not a perfect fit in every conceivable application. See New York v. United States, 505 U.S. 144, 172 (1992) (spending conditions valid under Dole because they are ""reasonably related to the purpose of the expenditure""); Ivanhoe Irrigation Dist. v. McCracken, 357 U.S. 275, 295 (1958) (""[T]he Federal Government may establish and impose reasonable conditions relevant to federal interest in the project and to the over-all objectives thereof."").13 Petitioner\'s claim that Section 666 unconstitutionally coerces fund recipients is likewise without merit. This Court has suggested that ""in some circumstances the financial inducement offered by Congress might be so coercive as to pass the point at which \'pressure turns into compulsion.\'"" Dole, 483 U.S. at 211 (quoting Steward Machine Co. v. Davis, 301 U.S. 548, 590 (1937)). But the law has long ""been guided by a robust common sense which assumes the freedom of the will as a working hypothesis."" Steward Machine Co., 301 U.S. at 590. Here, no government entity claims coercion, and petitioner offers no evidence that the United States exerted ""a power akin to undue influence"" to overcome the ordinarily ""robust"" presumption of free will. Ibid. A large financial inducement is not necessarily coercive. ""In this context, a difficult choice remains a choice, and a tempting offer is still but an offer. If [the State or its citizenry] finds the [federal] requirements so disagreeable, [they are] ultimately free to reject both the conditions and the funding, no matter how hard that choice may be."" Kansas v. United States, 214 F.3d 1196, 1203 (10th Cir.), cert. denied, 531 U.S. 1035 (2000); see Oklahoma v. United States Civil Service Comm\'n, 330 U.S. 127, 143-144 (1947); Board of Educ. v. Mergens, 496 U.S. 226, 241 (1990). Petitioner\'s coercion theory also produces paradoxical results: the greater the federal benefits afforded to state, local, tribal, and private entities, the lesser the federal government\'s power to protect the integrity of its funds and programs. According to petitioner, because the price of declining to accept federal largesse is simply too great for a State (or, presumably, a local entity) to bear, Congress must make the funds available without putting in place federal means to protect the expenditures. Nothing in the Constitution, however, forbids Congress from affording protection commensurate with its legitimate expenditures. III. Section 666 Is At Most Subject To As Applied Challenges At bottom, petitioner\'s position is that ""Section 666 is facially invalid because the conduct it covers does not uniformly have the requisite connection to federal spending, and no element within the offense requires the jury to find the necessary connection in each specific case."" Br. 33 (emphases added). Petitioner posits the example of a Section 666 prosecution for the bribery of a parks department agent where the only federal benefits received by the governmental entity are for highway programs. Pet. 32. Such an observation does not come close to establishing facial invalidity. As discussed above, Congress legitimately framed Section 666 to sweep broadly enough to eliminate barriers to the protection of federal funds and programs that had hampered the effectiveness of earlier statutes and reasonably concluded that significant corruption anywhere in an entity receiving the requisite federal funds is at least a potential threat to federal funds and programs. See pp. 30-36, supra. That justification establishes the constitutionality of Section 666 in all of its applications, even those that might be viewed in isolation as tangential or remote from the underlying purpose of Section 666. In any event, the argument that some remote applications may be unconstitutional certainly cannot justify total invalidation of the statute on its face. This Court\'s cases, including United States v. Salerno, 481 U.S. 739 (1987), make that clear. See pp. 24-25, supra. Petitioner\'s contrary argument parallels the claim this Court rejected in United States v. Raines, 362 U.S. 17 (1960). In that case, the plaintiff challenged the Civil Rights Act of 1957 as facially unconstitutional because it purportedly reached some conduct-private discrimination-that was alleged to be beyond Congress\'s power to proscribe under the Fifteenth Amendment. 362 U.S. at 19-20. Although the Act on its face made no distinction between state action and private conduct, the Court held that purported defect insufficient to invalidate the statute in all its applications: [I]f the complaint here called for an application of the statute clearly constitutional under the Fifteenth Amendment, that should have been an end to the question of constitutionality. And as to the application of the statute called for by the complaint, * * * it is enough to say that the conduct charged * * * is certainly * * * \'state action\' * * * subject to the ban of that Amendment, and that legislation designed to deal with such discrimination is ""appropriate legislation"" under it. Id. at 24-25. The same reasoning applies here.14 This Court has suggested that facial invalidation may also be warranted where the statute is ""unconstitutional in the vast majority of its intended applications, and it can fairly be said that it was not intended to stand as valid, on the basis of fortuitous circumstances, only in a fraction of the cases it was originally designed to cover."" Raines, 362 U.S. at 23; see also Butts v. Merchants & Miners Transp. Co., 230 U.S. 126, 133 (1913) (law facially unconstitutional where Congress would not have intended ""to make a law which should be applicable to a minor part of that jurisdiction and inapplicable to the major part""). In Lopez and Morrison, the Court did not remit defendants to as-applied challenges in order to preserve statutory applications that, because of a factual showing unrelated to the design of the statute, would have been constitutional. But this Court has found Section 666 to be constitutional in its core applications-the ones Congress most clearly intended to reach-as this Court\'s decisions upholding convictions under it attest. See Salinas, 522 U.S. at 60-61 (holding that ""there is no serious doubt about the constitutionality of § 666(a)(1)(B) as applied to the facts"" there, and that ""the application of § 666(a)(1)(B) to Salinas did not extend federal power beyond its proper bounds""); Fischer, 529 U.S. at 681-682 (recognizing that the ""Government has a legitimate and significant interest in prohibiting financial fraud or acts of bribery"" given the threat to a federal ""program\'s integrity"" created there). The existence of a substantial body of such applications alone ""is enough to defeat [the] assertion that the [law] is facially unconstitutional."" Webster v. Reproductive Health Servs., 492 U.S. 490, 524 (1989) (O\'Connor, J., concurring in part and concurring in the judgment). As a matter of prosecutorial discretion, the Department of Justice\'s policy is that ""Federal prosecutors should be prepared to demonstrate that a violation of 18 U.S.C. § 666 affects a substantial and identifiable Federal interest before bringing charges,"" because ""[t]his policy ensures that Federal prosecutions will occur only when significant Federal interests are involved."" U.S. Attorney Manual § 9-46.110 (Sept. 1997). The adoption of such a policy as a matter of prosecutorial discretion suggests that there may be few cases brought to court in which the government\'s interest in applying Section 666 will not meet a federal nexus test.15 Nevertheless, if it were thought constitutionally problematic to apply Section 666 in a particular case in which the federal interest that supports the statute cannot be concretely identified, even in a ""highly attenuated"" fashion, United States v. Zwick, 199 F.3d at 672, 687 (3d Cir. 1999), the correct constitutional solution would be to consider such a challenge on an as-applied basis. Any theoretical potential for unconstitutional applications provides no basis for facial invalidation.16 The judgment of the court of appeals should be affirmed. Respectfully submitted. THEODORE B. OLSON Solicitor General CHRISTOPHER A. WRAY Assistant Attorney General MICHAEL R. DREEBEN Deputy Solicitor General JEFFREY A. LAMKEN Assistant to the Solicitor General JEFFREY P. SINGDAHLSEN Attorney 1 ""Federal grant programs to state and local governments as well as to private organizations have been in existence since the 19th century."" See Dixson v. United States, 465 U.S. 482, 506 (1984) (O\'Connor, J., dissenting). Currently, the United States and the States work together to administer numerous such programs, which range from Medicaid, see 42 U.S.C. 1396 et seq., which provides medical services to eligible needy persons, see Wisconsin Dep\'t of Health & Family Servs. v. Blumer, 534 U.S. 473, 495 (2002), to programs that finance massive public works projects spanning numerous States, see California v. United States, 438 U.S. 645, 650 (1978) (discussing the Reclamation Act of 1902). 2 Shortly after Section 666\'s enactment, this Court resolved that conflict in Dixson, holding that local officials administering federal programs could be ""public officials"" within the meaning of Section 201. 465 U.S. at 497, 501. 3 The Second and Third Circuits have held that the government must prove some further nexus between the corruption and federal funds or programs. See United States v. Zwick, 199 F.3d 672, 682 (3d Cir. 1999); United States v. Santopietro, 166 F.3d 88, 93 (2d Cir. 1999). No party to this case supports that construction. 4 Westmoreland, 841 F.2d at 577 (""Congress specifically chose"" to ""preserve the integrity of federal funds"" by ""enacting a criminal statute that would eliminate the need to trace the flow of federal monies and that would avoid inconsistencies caused by the different ways that various federal programs disburse funds""); United States v. Wyncoop, 11 F.3d 119, 122 (9th Cir. 1993) (""[W]hen Congress enacted section 666, it intended to \'protect federal funds by preserving the integrity of the entities that receive the federal funds rather than requiring the tracing of federal funds to a particular illegal transaction.\'"") (quoting United States v. Simas, 937 F.2d 459, 463 (9th Cir. 1991)); United States v. Zwick, 199 F.3d 672, 679 (3d Cir. 1999) (""By its terms, § 666 fills"" the ""voids"" in prior legislation because ""it imposes no title or tracing requirements and covers non-federal employees.""); United States v. Paradies, 98 F.3d 1266, 1288 (11th Cir. 1996) (""the government is not required under § 666 to trace the flow of federal funds""), cert. denied, 521 U.S. 1106 (1997); United States v. Foley, 73 F.3d 484, 492 (2d Cir. 1996) (""the government is not required to trace the agent\'s corrupt expenditures to the federal program funds""). 5 An earlier proposal from which Section 666 was derived, see S. Rep. No. 225, supra, at 369 & n.1, would have required the government to prove that ""the recipient\'s conduct [wa]s related to the administration of"" a federally funded ""program."" See S. Rep. No. 307, 97th Cong., 1st Sess. 726, 803 (1981) (discussing S. 1630, 97th Cong., 1st Sess. § 1751(c)(1)(I) (1981)). Congress\'s decision to dispense with such a requirement when enacting Section 666 in 1984 supports the conclusion that Congress did not wish to demand such proof in particular cases. 6 Even in those circumstances where members of this Court have supported a different formulation than the ""no set of circumstances"" test articulated in Salerno, they have at a minimum required that the statute\'s unconstitutional sweep be so great in relation to its constitutional applications, and so central to the statute, as to warrant the strong medicine of facial invalidation. See, e.g., Janklow v. Planned Parenthood, 517 U.S. 1174, 1176 n.1 (1996) (Stevens, J., respecting denial of certiorari); Chicago v. Morales, 527 U.S. 41, 55 n.22 (1999) (Stevens, J., joined by Ginsburg and Souter, JJ.). Even in the First Amendment context- where concerns about chilling effects have led this Court to permit overbreadth challenges-the Court will not apply ""the \'strong medicine\' of overbreadth invalidation"" unless the potentially unconstitutional applications are substantial both in absolute terms and in relationship to the law\'s legitimate applications. Virginia v. Hicks, 123 S. Ct. 2191, 2197-2198 (2003). 7 Contrary to Amicus\'s suggestion (Cato Br. 13-16), M\'Culloch (like its progeny) makes it unmistakably clear that Congress is entitled to considerable deference in judgments about necessity. See, e.g., 17 U.S. (4 Wheat.) at 415 (The Framers left it ""in the power of Congress to adopt any"" means ""which might be appropriate, and which were conducive to the end.""); id. at 420 (""[I]t cannot be construed to restrain the [express] powers of Congress, or to impair the right of the legislature to exercise its best judgment in the selection of measures to carry into execution the constitutional powers of the government."") (emphasis added). Some federal courts and commentators have equated M\'Culloch\'s ""plainly adapted,"" or ""appropriate"" and ""conducive,"" standard with the rational basis test. See, e.g., United States v. Plotts, 347 F.3d 873, 878 (10th Cir. 2003); Edgar, 304 F.3d at 1325-1326; Laro v. New Hampshire, 259 F.3d 1, 6 (1st Cir. 2001); United States v. Lue, 134 F.3d 79, 84 (2d Cir. 1998); 1 Laurence H. Tribe, American Constitutional Law § 5-3, at 805 (3d ed. 2000). This case does not require the Court to determine whether the ""plainly adapted"" test requires a closer fit than the rational basis test, because Section 666(a)(2) is more than merely a rational way to serve Congress\'s legitimate interest in protecting federal funds and programs that implement the Spending Power. Rather, it directly and substantially serves that goal in a reasonable manner, as is evidenced by experience that revealed that more limited means were inadequate. See pp. 3-5, 19-22 & n.4, supra; pp. 31-33, infra. And even Amicus Cato Institute does not question M\'Culloch\'s holding that the means chosen by Congress need not be indispensable to the achievement of a legitimate legislative purpose in order to be ""necessary and proper."" 8 Petitioner attempts to distinguish Salinas on the ground that the County, its prison, or the guards were ""instrumentalities of the United States."" Br. 28. Salinas certainly did not hold that to be the case. Nor is it clear that the principles articulated in Westfall, supra, cited in Salinas, 522 U.S. at 61, are limited to federal instrumentalities. Westfall itself stands for the proposition that no actual loss to a federal institution is required to establish congressional authority, so long as the conduct might threaten a federal program. 274 U.S. at 258-259. 9 Petitioner raises this issue in contending that Section 666, viewed as a condition on federal spending, fails the ""germaneness"" or ""relatedness"" requirements for such conditions under South Dakota v. Dole. Pet. Br. 32. The government addresses below the argument that Dole provides the proper lens through which to analyze Section 666. See pp. 41-45, infra. 10 The contrast between Section 666\'s scope and the hypothetical prohibition on the solicitation of adultery by officials of agencies receiving federal benefits posited by the Cato Institute (at 24) underscores that difference. It is not immediately obvious how the solicitation of adultery would pose a threat to federal funds or programs, since the misconduct involves the officials\' private lives and is not financial in nature. Consequently, the link to any federal interest would have to rest on an attenuated chain of reasoning- that the prohibited conduct demonstrates poor moral character; that those moral shortcomings may not be limited to the offending official\'s private life; and, that if the lack of moral rectitude extends to the official\'s public responsibilities, it might include a willingness to engage in financial corruption affecting federal funds and programs. Section 666, in contrast, directly addresses corruption itself, and only in connection with the business of an agency that receives substantial funds under a federal program. 11 It is therefore inaccurate to assert that Section 666 ""applies only to State and local institutions."" Pet. Br. 26. It applies to private ""organizations"" receiving the requisite amount of federal funds, such as the Medicare providers at issue in Fischer, and to state, local, and tribal institutions that do likewise. See 18 U.S.C. 666(a). 12 To the extent that petitioner relies on the Tenth Amendment as an independent theory, Br. 37, this Court recently declined to address ""whether private plaintiffs have standing to assert \'states\' rights\' under the Tenth Amendment where their States\' legislative and executive branches expressly approve and accept the benefits and terms of the federal statute in question."" Pierce County v. Guillen, 537 U.S. 129, 148 n.10 (2003); cf. Tennessee Elec. Power Co. v. TVA, 306 U.S. 118, 144 (1939). 13 In South Dakota v. Dole, for example, the Court did not require that every proscribed sip of beer by an underage drinker (such as one who is hiking in the mountains miles from a road) affect the safety of funded highways. Instead, it was sufficient that underage drinking, as a general matter, has a reasonable relationship to highway safety. 483 U.S. at 209-210. 14 Petitioner errs in arguing (Br. 34-35) that this case is analogous to the circumstances identified by Justice Scalia\'s dissenting opinion in Babbitt v. Sweet Home Chapter of Communities for a Great Oregon, 515 U.S. 687, 731-732 (1995). Section 666 is not at all like a regulation that fails to include an element required by the statute. To the contrary, Section 666 has a jurisdictional element. Petitioner merely argues that the element is not sufficient to ensure the statute\'s constitutional application in each and every case. As Raines demonstrates, that concern is not enough to render Section 666 unconstitutional on its face. 15 The government\'s policy, of course, does not indicate that Congress was constitutionally precluded from casting a wider net to ensure adequate protection of federal interests, without entrusting to a jury potentially difficult proof issues in each case about the degree of a federal nexus. 16 Based on the concern that Section 666 might otherwise be unconstitutional, two courts have limited Section 666\'s application to situations where the offense conduct implicates a federal interest, although ""a highly attenuated implication of a federal interest will suffice."" Zwick, 199 F.3d at 687; United States v. Foley, 73 F.3d 484, 488-493 (2d Cir. 1996). That statutory-interpretation approach may differ from considering challenges to Section 666 on an as-applied basis, because a statutory nexus requirement would require a jury determination of that issue in every case. See Brunshtein, 344 F.3d at 98-99; cf. Ring v. Arizona, 536 U.S. 584, 606-607 (2002). In Salinas, this Court resolved the ""constitutional as applied"" issue itself. 522 U.S. at 60-61. 1. The Spending Clause of the United States Constitution, Article I, Section 8, Clause 1, provides: The Congress shall have Power To lay and collect Taxes, Duties, Imposts and Excises, to pay the Debts and provide for the common Defence and general Welfare of the United States. 2. The Necessary and Proper Clause of the United States Constitution, Article I, Section 8, Clause 18, provides: The Congress shall have Power * * * To make all Laws which shall be necessary and proper for carrying into Execution the foregoing Powers, and all other Powers vested by this Constitution in the Government of the United States, or in any Department or Officer thereof. 3. Section 666 of Title 18, United States Code, provides: § 666. Theft or bribery concerning programs receiving Federal funds shall be fined under this title, imprisoned not more than 10 years, or both. (a) of this section is that the organization, government, or agency receives, in any one year period, benefits in excess of $10,000 under a Federal program involving a grant, contract, subsidy, loan, guarantee, insurance, or other form of Federal assistance. (c) This section does not apply to bona fide salary, wages, fees, or other compensation paid, or expenses paid or reimbursed, in the usual course of business. (5) the term ""in any one-year period"" means a continuous period that commences no earlier than twelve months before the commission of the offense or that ends no later than twelve months after the commission of the offense. Such period may include time both before and after the commission of the offense.', 'FindLaw columnist and Cornell law professor Michael Dorf discusses the complex, interesting law and precedent surrounding the issue of how, and to what extent, the rights enumerated in the Constitution\'s Bill of Rights apply -- or, in technical terms, are ""incorporated"" -- not just against the federal government, but also against the states. In particular, Dorf focuses on an upcoming Supreme Court case that raises the question whether the Second Amendment\'s right to bear arms applies against the states and their subdivisions. Since the Court recently struck down the District of Columbia\'s handgun ban on Second Amendment grounds, the Court\'s answer to the incorporation question in the Second Amendment context may affect the fate of state and local gun laws. FindLaw columnist and U.C., Davis, law professor Vikram Amar considers both the criteria that should be used in the search for a replacement for Supreme Court Justice David Souter, and the questions President Obama should ask of that person before nominating -- and the Senate, before confirming -- him or her. FindLaw columnist and Cornell law professor Michael Dorf comments on a recent, high-profile decision by the Supreme Court to direct that a hearing be held in the case of death row inmate Troy Davis, who has put forward strong evidence that he is innocent of the crime for which he was convicted and sentenced to death. Dorf clarifies the ins and outs of the Court\'s habeas corpus jurisdiction, which it exercised in this case; and details the split among the Justices regarding whether it is unconstitutional to execute someone for a crime he did not, in fact, commit but for which he was properly convicted and sentenced. FindLaw columnist and Cornell law professor Sherry Colb details and assesses the precedents and arguments that may inform the Supreme Court\'s deliberation as it considers, during its coming term, two important companion cases. The cases raise the question whether imposing sentences of life imprisonment without parole upon juvenile offenders violates the Eighth Amendment\'s prohibition on cruel and unusual punishment. Colb argues that, as a matter of policy, the case against sentencing juvenile offenders to life without parole is strong. However, after analyzing relevant Court precedents, she finds that they offer little support for an Eighth Amendment argument against sentencing juveniles to life without parole. Nevertheless, Colb expresses the hope that the Court will modify its doctrine in this case, and remove this harsh punishment as an option. FindLaw columnist and Cornell law professor Michael Dorf analyzes the legal doctrines in play in Citizens United v. Federal Election Comm\'n, a case in which the Supreme Court will hold a special oral argument on September 9. As Dorf explains, while the case directly concerns the question whether a feature-length film entitled ""Hillary: The Movie"" falls under campaign finance reform laws, it also is likely to raise key questions about First Amendment-based limitations upon campaign finance legislation. Indeed, as Dorf notes, the case may prove to be a forum for the Court to significantly change doctrine in this area -- but not necessarily in a way that would be optimal. FindLaw columnist and Cornell law professor Sherry Colb discusses an important First Amendment and animal cruelty case that the Supreme Court recently decided to review. The case involves the constitutionality of a statute through which Congress responded to the phenomenon of ""crush"" videos, in which a woman tortures and slowly kills animals to appeal to those with a sexual fetish for watching such abuse. However, as Colb notes, in the case the Court will review, Robert J. Stevens was convicted not of any crush-video offense, but of filming and distributing violent videos of pit-bull fights and pit-bull attacks. After the U.S. Court of Appeals for the Third Circuit struck down Stevens\'s conviction on First Amendment grounds, the Supreme Court opted to take the case. Colb covers the key First Amendment precedents that may influence the Court\'s ruling, drawing on cases from the context of child pornography to argue that the state has a legitimate interest in destroying the market for certain materials. She also contends that those who are horrified by crush videos, but who are not vegans, should look within to consider whether their practices of eating meat or animal products do not create a valid analogy between themselves and the repellent crush video makers. FindLaw guest columnist and Chairman of the Cato Institute, Robert Levy, explains why Judge Sotomayor\'s jurisprudence on the right to bear arms is no reason to oppose her confirmation. Levy, who was co-counsel to the plaintiff in the District of Columbia case which recently established Second Amendment rights as individual rights, argues that while other aspects of Sotomayor\'s jurisprudence may deserve questions, the much discussed recent Second Circuit panel decision regarding the Second Amendment, in which Sotomayor joined, was a correct following of Second Circuit and Supreme Court precedent. At FindLaw.com, we pride ourselves on being the number one source of free legal information and resources on the web. Contact us. Sign up for our consumer newsletter. FindLaw.com Free, trusted legal information for consumers and legal professionals SuperLawyers.com Directory of U.S. attorneys with the exclusive Super Lawyers rating Abogado.com The #1 Spanish-language legal website for consumers LawInfo.com Nationwide attorney directory and legal consumer resources Copyright © 2023, Thomson Reuters. All rights reserved.', 'In framing the U.S. Constitution, the leaders of the time gave certain specific powers to Congress, reserving all other powers to the individual states. This was done in order to ensure the new government would not become an oppressive entity, such as the government they had left behind in England. These men knew, however, that they could not foresee the needs of the country as it grew and developed. The final provision of Article 1, Section 8 of the U.S. Constitution gives Congress the power to enact laws that are “necessary and proper” in the execution of their enumerated powers. To explore this concept, consider the following\xa0necessary and proper clause\xa0definition. U.S. Constitution, Article 1, Section 8 The Necessary and Proper Clause, often referred to as the “Elastic Clause,” pertains to powers not expressly given to Congress in the United States Constitution, but which may be necessary and proper to accomplish their constitutional charges. Congressional powers are found in different places in the Constitution, but the Necessary and Proper Clause is contained in the last paragraph of Article 1, Section 8. This clause provides the federal government with flexibility when it comes to creating laws when the Constitution does not give Congress the specific authority to act, hence the moniker “Elastic Clause.” “To make all Laws which shall be necessary and proper for carrying into Execution the foregoing Powers, and all other Powers vested by this Constitution in the Government of the United States, or in any Department or Officer thereof.” The U.S. Constitution specifically lays out the powers granted to Congress. While many people look to the powers specifically listed in Article 1, Section 8 of the Constitution, Congress is granted other powers in various sections of the document, subject to the limitations in the Bill of Rights. The term “enumerated” means to mention certain things one by one, or to specify certain things individually in a list. The powers specifically listed in Section 8 of Article 1 are referred to as “Enumerated Powers.” The enumerated powers dictate how the branches of the federal government, including Congress can and should operate. There are some Congressional powers not specifically listed in the Constitution, but which are seen as obviously necessary to exercise the powers granted. These are referred to as “implied powers.” As an example, some of the enumerated powers in the U.S. Constitution give Congress the power to: Framers of the Constitution knew that not all of the powers Congress would need in an ever-changing world could be listed explicitly. To address this problem, the Necessary and Proper Clause was drafted. The Clause, however, immediately sparked a storm of dispute, as anti-federalists contended it would give the federal government unlimited powers. Federalists argued that the clause would only give the government the authority to accomplish those powers listed in the Constitution. Alexander Hamilton and James Madison argued on behalf of the Clause, believing that without it, the Constitution would not be effective. The Clause was eventually placed in the Constitution, and the first practical example of its use came into play in 1791 when Alexander Hamilton stretched the Elastic Clause to defend the formation of the First Bank of the United States. The bank was the first federal bank of the new nation, and James Madison argued that, while Congress does have the authority to print money, it does not have the authority to charter a bank. Hamilton, on the other hand, believed that the Necessary and Proper Clause related to constitutional powers, and therefore creating the bank was a reasonable means of carrying out its powers related to the economy. In 1816, Congress created an act actually titled “An Act to Incorporate the Subscribers to the Bank of the United States.” This addressed the issue of the taxes levied by the state of Maryland, where the Second Bank of the United States (successor to the First Bank of the United States), on all bank notes issued by banks not chartered by the state of Maryland. This meant that any bank, including the Second Bank of the U.S., not given specific governmental permission to operate in its location, would be taxed for bank notes, promissory notes, and other negotiable instruments. When the First Bank of the United States was formed, with branches in three cities, it began doing normal banking activities, such as issuing bank notes, marking down promissory notes, taking in deposits, and performing other normal banking activities. At that time, some questioned the authority of the federal government to establish a bank. When the branch was established in Baltimore, Maryland, a dispute arose on the topic, as James McCulloch, head of the Baltimore brand of the Second Bank, refused to pay the state tax. In the ensuing litigation, the state of Maryland argued that “the Constitution is silent on the subject of banks,” making such power a reserved power that may be solely exercised by the states. Interestingly enough, both sides agreed that neither the President of the United States, Congress, nor the directors and company of the Bank had the authority to establish a bank in Pennsylvania without the state’s consent. The trial court ruled in favor of the state, though that decision was appealed by the federal government. When the appellate court upheld the trial court’s decision, the matter was taken before the U.S. Supreme Court. The Supreme Court ruled that Congress did indeed have the power to create a bank. In the Court’s written decision, Chief Justice John Marshall cited several reasons for the Court’s decision, finally bringing to mind the Necessary and Proper Clause, which gives Congress the power to act, or to create legislation for the purpose of accomplishing any of the powers assigned to the federal government by the Constitution. Such authority is referred to as inferred powers. This holds true as long as the act or legislation can reasonably seen as necessary and proper to accomplishing the government’s goal, and that the act or legislation is not specifically forbidden by the Constitution. When the Court made this ruling, it nullified Maryland’s assumption that the word “necessary” in the Necessary and Proper clause of the Constitution gave Congress only the power to enact laws that are crucial to the performance of its enumerated powers. Justice Marshall pointed out, in the ruling, that many enumerated powers would be useless if Congress could only enact laws absolutely essential to the execution of an enumerated power. Finally, Justice Marshall made public note of the fact that the Necessary and Proper Clause is contained within the powers granted to Congress, not in the section listing its limitations.', 'U.S. Supreme CourtUnited States v. City of Detroit, 355 U.S. 466 (1958) United States v. City of Detroit No. 26 355 U.S. 466 Under Michigan Public Act 189 of 1953, the City of Detroit assessed against a private corporation engaged in business for profit taxes based upon the value of real property owned by the United States and leased to the corporation under a lease permitting the corporation to deduct from the agreed rental any such taxes paid by it but reserving to the Government the right to contest the validity of such taxes.  In effect, the Act provides that, when tax exempt real property is used by a private party in a business conducted for profit, such private party is subject to taxation in the same amount and to the same extent as though he owned the property; that such taxes shall be assessed and collected in the same manner as taxes assessed to the owners of real property, except that they shall not become a lien against the property, but shall be a debt due from the user and collectible by direct action; and that the Act shall not apply to federal property for which payments are made in lieu of taxes in amounts equivalent to taxes which otherwise might lawfully be assessed. Held:  the Act, on its face and as here applied, does not invade the constitutional immunity of federal property from taxation by the States or discriminate against the Government or those with whom it deals.  Pp.  355 U. S. 467-475. (a) The Government\'s constitutional immunity does not shield private parties from state taxes imposed on them merely because part or all of the financial burden of the taxes eventually falls on the Government.  Pp.  355 U. S. 469,  355 U. S. 472-473. (b) The tax here involved is not levied on the Government or its property, but on the private lessee who uses the property in a business conducted for profit.  P.  355 U. S. 469. (c) The fact that the tax is measured by the value of the property used does not justify treating it as a mere contrivance to tax the property itself.  Pp.  355 U. S. 470-471. (d) United States v. Allegheny County, 322 U. S. 174, distinguished.  Pp.  355 U. S. 471-472. (e) Neither on its face nor as here applied does this tax operate so as to discriminate against the Federal Government or those with whom it deals.  Pp.  355 U. S. 473-474. Page 355 U. S. 467 (f) A different result is not required by the fact that the Act creates an exception to the tax on users where payments in lieu of taxes are made by the United States ""in amounts equivalent to taxes which might otherwise be lawfully assessed""  P. 474,  n 6. (g) To hold that the tax imposed here on private business violates the Government\'s constitutional tax immunity would improperly impair the taxing power of the State.  P.  355 U. S. 475. 345 Mich. 601, 77 N.W.2d 79, affirmed. United States v. City of Detroit, 355 U.S. 466 (1958)', 'U.S. Supreme CourtJames v. Dravo Contracting Co., 302 U.S. 134 (1937) James v. Dravo Contracting Co. No. 3 302 U.S. 134 1. A State cannot lay a gross receipts tax on business carried on in another State.  P.  302 U. S. 138. 2. A State has no power to tax in a place within the State over which the United States has acquired exclusive jurisdiction.  P.  302 U. S. 140. 3. The title to beds of navigable streams within a State is vested in the State, subject to the right of the United States to use the land for the improvement of navigation.  P.  302 U. S. 140. Occupation of the river bed by the United States for the purpose of improving navigation does not divest the State of its title. 4. Locks and dams erected by the United States for the improvement of navigation are ""needful buildings"" within the meaning of the Const., Art. I, § 8, Cl. 17.  P.  302 U. S. 141. ""all places purchased by the consent of the legislature of the State in which the same shall be, for the erection of forts, magazines, arsenals, dock-yards, and other needful buildings."" ""Exclusive legislation"" is consistent only with exclusive jurisdiction. Page 302 U. S. 135 5. West Va.Code of 1931, Art. 1, Ch. 1, § 3, gives the consent of the State to acquisition by the United States of land within the State for locks, dams, needful buildings, works for improvement of the navigation of any water course, or for any other purpose for which the same may be required by the Government of the United States; authorizes gifts of land to the United States by municipalities for such described purposes; cedes to the United States ""concurrent jurisdiction with this State in and over any land so acquired . . . for all purposes;"" provides that the jurisdiction so ceded is to continue only during the ownership of the United States and is to cease if the United States fails for five consecutive years to use any such land for the purposes of the grant, and reserves to the State the right to execute process within the limits of the land acquired ""and such other jurisdiction and authority over the same as is not inconsistent with the jurisdiction ceded to the United States by virtue of such acquisition."" (1) The provision as to concurrent jurisdiction qualifies the provision giving consent, and applies to lands acquired by purchase or condemnation, as well as to lands given by municipalities.  P.  302 U. S. 143. (2) The provision reserving merely the right to execute process, repeated from an earlier statute, does not derogate from the broader reservation of jurisdiction in the statute as amended.  P.  302 U. S. 145. 6. When a State gives the legislative consent as contemplated by the Const., Art. I, § 8, Cl. 17, to purchase of land by the United States for ""needful buildings,"" as when, after prior purchase or condemnation by the United States, it cedes jurisdiction, it may reserve such a concurrent jurisdiction as will not operate to deprive the United States of the enjoyment of the property for the purposes for which it is acquired.  P.  302 U. S. 146. West Virginia, by a reservation qualifying her consent to their acquisition, retained her jurisdiction to tax over lands purchased or condemned by the United States for navigation improvements on a river. 7. An independent contractor engaged under his contract with the Government in the construction of locks and dams for the improvement of navigation is not an instrumentality of the Government.  P.  302 U. S. 149. 8. As applied to such a contractor, a nondiscriminatory state tax on his gross receipts under the contract is not unconstitutional as a Page 302 U. S. 136 tax laid on the contract itself, or as otherwise directly burdening the Government.  P.  302 U. S. 149. 9. Application of the principle that governmental instrumentalities of the United States are immune from taxation by the States, and vice-versa, requires close distinctions in order to maintain the essential freedom of government in performing its functions without unduly limiting the taxing power which is equally essential to both Nation and State under our dual system.  P.  302 U. S. 150. Decisions on immunity of government bonds and of government purchases of commodities held inapplicable in case of tax on earnings of independent contractor rendering services to the Government.  Pp.  302 U. S. 150-153. 10. The question of the taxability of a contractor upon the fruits of his services to the Government is closely analogous to that of the taxability of his property used in performing the services.  His earnings flow from his work; his property is employed in securing them.  In both cases, the taxes increase the cost of the work, and diminish his profits.  P.  302 U. S. 153. 11. The fact that the tax in this case was on gross, rather than net, receipts does not prove it an unconstitutional burden on the Government.  P.  302 U. S. 157. Distinguished from cases where taxes on gross receipts of individuals engaged in interstate commerce have been held invalid under the commerce clause. 12. Assuming (what is not necessarily so) that a state tax on contractor\'s gross receipts may increase cost of service to the Government, that fact would not invalidate the tax any more than it would a tax on the contractor\'s property equipment used in the performance of the contract.  P.  302 U. S. 159. 13. Semble that Congress has power to prevent interference with the operations of the Government through state taxation laid on receipts of those who render it services under contracts.  P.  302 U. S. 160. 16 F. Supp. 527 reversed. Appeal from a final decree of the three-judge District Court enjoining the collection of a State tax. Page 302 U. S. 137 James v. Dravo Contracting Co., 302 U.S. 134 (1937)']","McCulloch v. Maryland, 17 U.S. (4 Wheat.) 316 (1819), was a landmark decision by the Supreme Court of the United States. The state of Maryland had attempted to impede operation of a branch of the Second Bank of the United States by imposing a tax on all notes of banks not chartered in Maryland. Though the law, by its language, was generally applicable to all banks not chartered in Maryland, the Second Bank of the United States was the only out-of-state bank then existing in Maryland, and the law was recognized in the court's opinion as having specifically targeted the Bank of the United States. The Court invoked the Necessary and Proper Clause of the Constitution, which allowed the Federal government to pass laws not expressly provided for in the Constitution's list of express powers, provided those laws are in useful furtherance of the express powers of Congress under the Constitution."
what is the central city of shiite islam,"['Al-Aqsa Mosque is an Islamic holy place in the Old City of Jerusalem. The site that includes the mosque (along with the Dome of the Rock), also referred to as al-Haram ash-Sharif or “Sacred Noble Sanctuary”, is the Temple Mount, the holiest site in Judaism, the place where the First and Second Temples are generally accepted to have stood. Muslims believe that Muhammad (PBUH) was transported from the Sacred Mosque in Mecca to al-Aqsa during the Night Journey. Islamic tradition holds that Muhammad (PBUH) led prayers towards this site until the seventeenth month after the emigration, when Allah (SWT) directed him to turn towards the Ka’aba. Sultan Omar Ali Saifuddin Mosque is a royal Islamic mosque located in Bandar Seri Begawan, the capital of the Sultanate of Brunei. The mosque is one of the most spectacular mosques in the Asia Pacific and a major landmark and tourist attraction of Brunei. Named after Omar Ali Saifuddien III, the 28th Sultan of Brunei, the mosque as a symbol of the Islamic faith in Brunei dominates the skyline of Bandar Seri Begawan. The building was completed in 1958 and is an impressive example of modern Islamic architecture. The mosque unites Mughal architecture and Italian styles. The plans were done by Booty and Edwards Chartered Architects according to designs by the Italian architect Cavaliere Rudolfo Nolli, who had already for decades been working at the gulf of Siam. This state mosque is a masterpiece of architecture with its dove-grey walls and glittering majestic domes with gold inlay. It is centrally located at Jalan Tunku Abdul Raman and it is a proof of unique combination of Islamic architecture and contemporary design. Up to 5000 worshippers can be inside at one time; the mosque has become a popular place for visitors from all over the world. During prayer time, even Muslim women can visit the mosque as a special balcony is built that can fit 500 persons. If you are not a Muslim, avoid visiting the mosque on Fridays, as this is the day of prayer for Muslims. Never forget to respect the dress code when you are visiting a place of worship. Near the mosque is also Sabah’s State Mausoleum. The Hassan II Mosque is a religious buildings in Casablanca, Morocco, the largest mosque in the country and the fifth largest mosque in the world after the Masjid al-Haram (Grand Mosque) of Mecca and the Al-Masjid al-Nabawi (Prophet’s Mosque) in Medina. It was designed by the French architect Michel Pinseau and built by Bouygues. It stands on a promontory looking out to the Atlantic, which can be seen through a gigantic glass floor with room for 25,000 worshippers. A further 80,000 can be accommodated in the mosque’s adjoining grounds for a total of 105,000 worshippers present at any given time at the Hassan II mosque. Its minaret is the world’s tallest at 210 m (689 ft). The Faisal Mosque in Islamabad is the largest mosque in Pakistan and South Asia and one of the largest mosques in the world. It was the largest mosque in the world from 1986 until 1993, when it was overtaken in size by the completion of the Hassan II Mosque in Casablanca, Morocco. Subsequent expansions of the Masjid al-Haram (Grand Mosque) of Mecca and the Al-Masjid al-Nabawi (Prophet’s Mosque) in Medina, Saudi Arabia during the 1990s relegated Faisal Mosque to fourth place in terms of size. Faisal Mosque is conceived as the National Mosque of Pakistan. It has a covered area of 5,000 m2 (54,000 sq ft).[citation needed] It can accommodate 10,000 worshippers in its main prayer hall, 24,000 in its porticoes, 40,000 in its courtyard, and another 200,000 in its adjoining grounds. Although its covered main prayer hall is smaller than that of the Hassan II Mosque in Casablanca (the world’s third largest mosque), Faisal Mosque has the third largest capacity of accommodating worshippers in its adjoining grounds after the Masjid al-Haram (Grand Mosque) of Mecca, the Al-Masjid al-Nabawi (Prophet’s Mosque) in Medina. Each of the Mosque’s four minarets are 80 m (260 ft) high (the tallest minarets in South Asia) and measure 10 x 10 m in circumference. The Badshahi Mosque or the ‘King’s Mosque’ in Lahore, commissioned by the Mughal Emperor Aurangzeb in 1671 and completed in 1673, is the second largest mosque in Pakistan and South Asia and the fifth largest mosque in the world. Epitomising the beauty, passion and grandeur of the Mughal era, it is Lahore’s most famous landmark and a major tourist attraction. Capable of accommodating 5,000 worshippers in its main prayer hall and a further 95,000 in its courtyard and porticoes, it remained the largest mosque in the world from 1673 to 1986 (a period of 313 years), when overtaken in size by the completion of the Faisal Mosque in Islamabad. Today, it remains the second largest mosque in Pakistan and South Asia and the fifth largest mosque in the world after the Masjid al-Haram (Grand Mosque) of Mecca, the Al-Masjid al-Nabawi (Prophet’s Mosque) in Medina, the Hassan II Mosque in Casablanca and the Faisal Mosque in Islamabad. Petra (“rock”) is an ancient city and archaeological site in Jordan carved in cliffs of multicolored rocks. It was built roughly 2,000 years ago by an ancient Arab people, the Nabateans, at a site that was a center for trade routes carrying silk from China and spices and precious stones from India to the West. It fell into disuse when the Romans captured the area and changed the trade route. Since then, earthquakes and erosion have changed the landscape, making it even more stunning. Today, Petra is a national symbol for Jordan and its most visited tourist attraction. Located merely eleven miles north of Beirut, the Jeita Grotto is a site to behold. The compound has two separate but connected limestone caves that span nearly ten kilometers in length, making it the longest cave complex in the Middle East. The lower cave can only be visited by boat, since it sits on an underground river that is a principal source of water for Lebanese citizens. The caves were formed through the dissolution of limestone over millions of years and were first discovered in 1836 by Reverend William Thompson. Exploration into the depths of the caves is still taking place. Today, Jeita Grotto serves as a national symbol and major tourist destination for Lebanon. The Giza Necropolis is located on the outskirts of Cairo and includes the Great Pyramids and the famous sculpture, the Sphinx. The only Ancient Wonder of the World that remains standing, these pyramids have long been considered one of the most precious sites in the world. The Great Pyramid, the largest of the three pyramids pictured, was built over 4,500 years ago and was the world’s tallest building for an astounding 3,000 years. It remains a building of architectural wonder given the complexity and precision found in its design. The pyramids were built as tombs for ancient rulers of Egypt, who were considered to be immortal in the eyes of their followers; today, they are one of Egypt’s main tourist attractions. The Dead Sea is one of the most captivating and unique bodies of water in the world. The sea is most known for its incredibly high salinity levels; the water here is one third salt, making it eight times saltier than ocean-water. The high level of salinity makes it nearly impossible for animals to live here, hence the name “Dead” Sea. It is also very difficult to swim in these waters. The Dead Sea is the deepest hypersaline lake in the world (378 meters deep) and has the lowest elevation on dry land on the Earth’s surface (422 meters below sea level). The body of water also has historical significance and has been utilized for its massive reserves of salt. Built in the sixth century, the Hagia Sophia has a long and storied history. Originally a church, the Hagia Sofia was converted into a mosque after the Ottoman Turks conquered Constantinople (Istanbul) in 1453, whereupon the structure was renamed Ayasofya. Ayasofya’s towering dome has been used as a model for mosques for hundreds of years and is said to have changed modern architecture for its size and beauty. The interior of the building is filled with breath-taking pillars, mosaics and archways. Today, the building is a museum for members of all faiths to appreciate. Undisturbed by humans, Bu Tinah islands is a natural treasure lying off the coast of Abu Dhabi in the United Arab Emirates. The small archipelago is the region’s largest UNESCO marine biosphere reserve for its thriving ecosystem. The island is entirely closed off from humans and is patrolled to ensure that no one attempts to disrupt the habitat. The island is home to numerous endangered species and serves as a crucial research site for determining the effects of global warming. The island is also surrounded by an extensive coral reef, which survives the harsh temperatures and high salinity levels of the region. Located in the West African nation of Mali, Timbuktu once lay at the crossroads of four major trade routes that supplied the Arab world. Its geographic position made the city one of the wealthiest in the world during the 12th century. The city is home one of the first universities in the world, Koranic Sankore University, a celebrated Islamic university that taught over 20,000 students. Over time, Timbuktu developed into the intellectual and spiritual capital of Islam in Africa, and served as a focal point for regional expansion of the religion. While many of its buildings face the threat of desertification, Timbuktu remains an historically important location for intellectual scholarship in Islam. The Burj Al Arab is a luxury hotel located in Dubai, United Arab Emirates. At 321 m (1,053 ft), it is the second tallest hotel in the world. The Burj Al Arab stands on an artificial island 280 m (920 ft) out from Jumeirah beach, and is connected to the mainland by a private curving bridge. It is an iconic structure whose shape mimics the sail of a ship. The beachfront area where the Burj Al Arab and Jumeirah Beach Hotel are located was previously called Chicago Beach. The hotel is located on an island of reclaimed land 280 meters offshore of the beach of the former Chicago Beach Hotel. The locale’s name had its origins in the Chicago Bridge & Iron Company which at one time welded giant floating oil storage tankers on the site.', 'What is said regarding the Sahw (Forgetting how many Raka a person has prayed). If someone gets up (for the third Rak’a without sitting) after the second Rak’a of a compulsory Salat. Narrated By \'Abdullah bin Buhaina  : Allah\'s Apostle once led us in a prayer and offered two Rakat and got up (for the third Raka) without sitting (after the second Raka). The people also got up with him, and when he was about to finish his prayer, we waited for him to finish the prayer with Taslim but he said Takbir before Taslim and performed two prostrations while sitting and then finished the prayer with Taslim. Narrated By \'Abdullah bin Buhaina  : Allah\'s Apostle got up after the second Raka of the Zuhr prayer without sitting in between (the second and the third Rakat). When he finished the prayer he performed two prostrations (of Sahu) and then finished the prayer with Taslim. If one offers five Rak’a (instead of four). حَدَّثَنَا أَبُو الْوَلِيدِ، حَدَّثَنَا شُعْبَةُ، عَنِ الْحَكَمِ، عَنْ إِبْرَاهِيمَ، عَنْ عَلْقَمَةَ، عَنْ عَبْدِ اللَّهِ ـ رضى الله عنه ـ أَنَّ رَسُولَ اللَّهِ صلى الله عليه وسلم صَلَّى الظُّهْرَ خَمْسًا فَقِيلَ لَهُ أَزِيدَ فِي الصَّلاَةِ فَقَالَ \u200f""\u200f وَمَا ذَاكَ \u200f""\u200f\u200f.\u200f قَالَ صَلَّيْتَ خَمْسًا\u200f.\u200f فَسَجَدَ سَجْدَتَيْنِ بَعْدَ مَا سَلَّمَ\u200f Narrated By \'Abdullah : Once Allah\'s Apostle offered five Rakat in the Zuhr prayer, and somebody asked him whether there was some increase in the prayer. Allah\'s Apostle said, ""What is that?"" He said, ""You have offered five Rakat."" So Allah\'s Apostle performed two prostrations of Sahu after Taslim. If one finishes his Salat with Taslim after offering two or three Rak’a (by mistake), then he should perform two prostrations (of Sahw) like ordinary prostrations of the Salat, or longer. حَدَّثَنَا آدَمُ، حَدَّثَنَا شُعْبَةُ، عَنْ سَعْدِ بْنِ إِبْرَاهِيمَ، عَنْ أَبِي سَلَمَةَ، عَنْ أَبِي هُرَيْرَةَ ـ رضى الله عنه ـ قَالَ صَلَّى بِنَا النَّبِيُّ صلى الله عليه وسلم الظُّهْرَ أَوِ الْعَصْرَ فَسَلَّمَ، فَقَالَ لَهُ ذُو الْيَدَيْنِ الصَّلاَةُ يَا رَسُولَ اللَّهَ أَنَقَصَتْ فَقَالَ النَّبِيُّ صلى الله عليه وسلم لأَصْحَابِهِ \u200f""\u200f أَحَقٌّ مَا يَقُولُ \u200f""\u200f\u200f.\u200f قَالُوا نَعَمْ\u200f.\u200f فَصَلَّى رَكْعَتَيْنِ أُخْرَيَيْنِ ثُمَّ سَجَدَ سَجْدَتَيْنِ\u200f.\u200f قَالَ سَعْدٌ وَرَأَيْتُ عُرْوَةَ بْنَ الزُّبَيْرِ صَلَّى مِنَ الْمَغْرِبِ رَكْعَتَيْنِ فَسَلَّمَ وَتَكَلَّمَ ثُمَّ صَلَّى مَا بَقِيَ وَسَجَدَ سَجْدَتَيْنِ وَقَالَ هَكَذَا فَعَلَ النَّبِيُّ صلى الله عليه وسلم\u200f Narrated By Abu Huraira : The Prophet led us in the \'Asr or the Zuhr prayer and finished it with Taslim. Dhul-Yadain said to him, ""O Allah\'s Apostle! Has the prayer been reduced?"" The Prophet asked his companions in the affirmative. So Allah\'s Apostle I offered two more Rakat and then performed two prostrations (of Sahu). Sad said, ""I saw that \'Ursa bin Az-Zubair had offered two Rakat in the Maghrib prayer and finished it with Taslim. He then talked (and when he was informed about it) he completed the rest of his prayer and performed two prostrations, and said, \'The Prophet prayed like this.\'"" Whoever did not recite Tashah-hud (At-Tahiyyat) after the two prostrations of Sahw. وَسَلَّمَ أَنَسٌ وَالْحَسَنُ وَلَمْ يَتَشَهَّدَا\u200f.\u200f وَقَالَ قَتَادَةُ لاَ يَتَشَهَّدُ\u200f And Anas and Al-Hasan did not recite it. And Qatada said that Tasha-hud should not be recited (after the prostration of Sahw) To say Takbir in the prostrations of Sahw. حَدَّثَنَا حَفْصُ بْنُ عُمَرَ، حَدَّثَنَا يَزِيدُ بْنُ إِبْرَاهِيمَ، عَنْ مُحَمَّدٍ، عَنْ أَبِي هُرَيْرَةَ ـ رضى الله عنه ـ قَالَ صَلَّى النَّبِيُّ صلى الله عليه وسلم إِحْدَى صَلاَتَىِ الْعَشِيِّ ـ قَالَ مُحَمَّدٌ وَأَكْثَرُ ظَنِّي الْعَصْرَ ـ رَكْعَتَيْنِ ثُمَّ سَلَّمَ ثُمَّ قَامَ إِلَى خَشَبَةٍ فِي مُقَدَّمِ الْمَسْجِدِ فَوَضَعَ يَدَهُ عَلَيْهَا وَفِيهِمْ أَبُو بَكْرٍ وَعُمَرُ ـ رضى الله عنهما ـ فَهَابَا أَنْ يُكَلِّمَاهُ وَخَرَجَ سَرَعَانُ النَّاسِ فَقَالُوا أَقَصُرَتِ الصَّلاَةُ وَرَجُلٌ يَدْعُوهُ النَّبِيُّ صلى الله عليه وسلم ذُو الْيَدَيْنِ فَقَالَ أَنَسِيتَ أَمْ قَصُرَتْ فَقَالَ \u200f""\u200f لَمْ أَنْسَ وَلَمْ تُقْصَرْ \u200f""\u200f\u200f.\u200f قَالَ بَلَى قَدْ نَسِيتَ\u200f.\u200f فَصَلَّى رَكْعَتَيْنِ ثُمَّ سَلَّمَ ثُمَّ كَبَّرَ فَسَجَدَ مِثْلَ سُجُودِهِ أَوْ أَطْوَلَ، ثُمَّ رَفَعَ رَأْسَهُ فَكَبَّرَ، ثُمَّ وَضَعَ رَأْسَهُ فَكَبَّرَ فَسَجَدَ مِثْلَ سُجُودِهِ أَوْ أَطْوَلَ، ثُمَّ رَفَعَ رَأْسَهُ وَكَبَّرَ\u200f Narrated By Abu Huraira : The Prophet offered one of the evening prayers (the sub-narrator Muhammad said, ""I think that it was most probably the \'Asr prayer"") and he finished it after offering two Rakat only. He then stood near a price of wood in front of the Mosque and put his hand over it. Abu Bakr and \'Umar were amongst those who were present, but they dared not talk to him about that (because of excessive respect for him), and those who were in a hurry went out. They said, ""Has the prayer been reduced?"" A man who was called DhulYadain by the Prophet said (to the Prophet), ""Has the prayer been reduced or have you forgotten?"" He said, ""Neither have I forgotten, nor has the prayer been reduced."" He said, ""Certainly you have forgotten."" So the Prophet offered two more Rakat and performed Taslim and then said Takbir and performed a prostration of Sahu like his ordinary prostration or a bit longer and then raised his head and said Takbir and then put his head down and performed a prostration like his ordinary prostration or a bit longer, and then raised his head and said Takbir. حَدَّثَنَا قُتَيْبَةُ بْنُ سَعِيدٍ، حَدَّثَنَا لَيْثٌ، عَنِ ابْنِ شِهَابٍ، عَنِ الأَعْرَجِ، عَنْ عَبْدِ اللَّهِ ابْنِ بُحَيْنَةَ الأَسْدِيِّ، حَلِيفِ بَنِي عَبْدِ الْمُطَّلِبِ أَنَّ رَسُولَ اللَّهِ صلى الله عليه وسلم قَامَ فِي صَلاَةِ الظُّهْرِ وَعَلَيْهِ جُلُوسٌ، فَلَمَّا أَتَمَّ صَلاَتَهُ سَجَدَ سَجْدَتَيْنِ فَكَبَّرَ فِي كُلِّ سَجْدَةٍ وَهُوَ جَالِسٌ قَبْلَ أَنْ يُسَلِّمَ، وَسَجَدَهُمَا النَّاسُ مَعَهُ مَكَانَ مَا نَسِيَ مِنَ الْجُلُوسِ\u200f.\u200f تَابَعَهُ ابْنُ جُرَيْجٍ عَنِ ابْنِ شِهَابٍ فِي التَّكْبِيرِ\u200f Narrated By \'Abdullah bin Buhaina Al-Asdi : (The ally of Bani \'Abdul Muttalib) Allah\'s Apostle stood up for the Zuhr prayer and he should have sat (after the second Raka but he stood up for the third Raka without sitting for Tashah-hud) and when he finished the prayer he performed two prostrations and said Takbir on each prostration while sitting, before ending (the prayer) with Taslim; and the people too performed the two prostrations with him instead of the sitting he forgot. When a person forgets whether he has offered three or four Rak’a (then he should) perform two prostrations while sitting in his last Rak’a. Narrated By Abu Huraira : Allah\'s Apostle said, ""When the call for prayer is made, Satan takes to his heels passing wind so that he may not hear the Adhan and when the call is finished he comes back, and when the Iqama is pronounced, Satan again takes to his heels, and when the Iqama is finished he comes back again and tries to interfere with the person and his thoughts and say, ""Remember this and that (which he has not thought of before the prayer)"", till the praying person forgets how much he has prayed. If anyone of you does not remember whether he has offered three or four Rakat then he should perform two prostrations of Sahu while sitting. Sahw (i.e. forgetfulness) in compulsory Salat and Nawafil. Narrated By Abu Huraira : Allah\'s Apostle said, ""When anyone of you stands for the prayers, Satan comes and puts him in doubts till he forgets how many Rakat he has prayed. So if this happens to anyone of you, he should perform two prostrations of Sahu while sitting. If a person speaks to a person offering Salat, and the latter beckons with his hand and listens. حَدَّثَنَا يَحْيَى بْنُ سُلَيْمَانَ، قَالَ حَدَّثَنِي ابْنُ وَهْبٍ، قَالَ أَخْبَرَنِي عَمْرٌو، عَنْ بُكَيْرٍ، عَنْ كُرَيْبٍ، أَنَّ ابْنَ عَبَّاسٍ، وَالْمِسْوَرَ بْنَ مَخْرَمَةَ، وَعَبْدَ الرَّحْمَنِ بْنَ أَزْهَرَ ـ رضى الله عنهم ـ أَرْسَلُوهُ إِلَى عَائِشَةَ ـ رضى الله عنها ـ فَقَالُوا اقْرَأْ عَلَيْهَا السَّلاَمَ مِنَّا جَمِيعًا وَسَلْهَا عَنِ الرَّكْعَتَيْنِ بَعْدَ صَلاَةِ الْعَصْرِ وَقُلْ لَهَا إِنَّا أُخْبِرْنَا أَنَّكِ تُصَلِّينَهُمَا وَقَدْ بَلَغَنَا أَنَّ النَّبِيَّ صلى الله عليه وسلم نَهَى عَنْهَا\u200f.\u200f وَقَالَ ابْنُ عَبَّاسٍ وَكُنْتُ أَضْرِبُ النَّاسَ مَعَ عُمَرَ بْنِ الْخَطَّابِ عَنْهُمَا\u200f.\u200f فَقَالَ كُرَيْبٌ فَدَخَلْتُ عَلَى عَائِشَةَ ـ رضى الله عنها ـ فَبَلَّغْتُهَا مَا أَرْسَلُونِي\u200f.\u200f فَقَالَتْ سَلْ أُمَّ سَلَمَةَ\u200f.\u200f فَخَرَجْتُ إِلَيْهِمْ فَأَخْبَرْتُهُمْ بِقَوْلِهَا فَرَدُّونِي إِلَى أُمِّ سَلَمَةَ بِمِثْلِ مَا أَرْسَلُونِي بِهِ إِلَى عَائِشَةَ\u200f.\u200f فَقَالَتْ أُمُّ سَلَمَةَ ـ رضى الله عنها ـ سَمِعْتُ النَّبِيَّ صلى الله عليه وسلم يَنْهَى عَنْهَا ثُمَّ رَأَيْتُهُ يُصَلِّيهِمَا حِينَ صَلَّى الْعَصْرَ، ثُمَّ دَخَلَ عَلَىَّ وَعِنْدِي نِسْوَةٌ مِنْ بَنِي حَرَامٍ مِنَ الأَنْصَارِ فَأَرْسَلْتُ إِلَيْهِ الْجَارِيَةَ فَقُلْتُ قُومِي بِجَنْبِهِ قُولِي لَهُ تَقُولُ لَكَ أُمُّ سَلَمَةَ يَا رَسُولَ اللَّهِ سَمِعْتُكَ تَنْهَى عَنْ هَاتَيْنِ وَأَرَاكَ تُصَلِّيهِمَا\u200f.\u200f فَإِنْ أَشَارَ بِيَدِهِ فَاسْتَأْخِرِي عَنْهُ\u200f.\u200f فَفَعَلَتِ الْجَارِيَةُ فَأَشَارَ بِيَدِهِ فَاسْتَأْخَرَتْ عَنْهُ فَلَمَّا انْصَرَفَ قَالَ \u200f""\u200f يَا بِنْتَ أَبِي أُمَيَّةَ سَأَلْتِ عَنِ الرَّكْعَتَيْنِ بَعْدَ الْعَصْرِ وَإِنَّهُ أَتَانِي نَاسٌ مِنْ عَبْدِ الْقَيْسِ فَشَغَلُونِي عَنِ الرَّكْعَتَيْنِ اللَّتَيْنِ بَعْدَ الظُّهْرِ فَهُمَا هَاتَانِ \u200f""\u200f\u200f Narrated By Kuraib: I was sent to \'Aisha by Ibn Abbas, Al-Miswar bin Makhrama and \'Abdur-Rahman bin Azhar. They told me to greet her on their behalf and to ask her about the offering of the two Rakat after the \'Asr prayer and to say to her, ""We were informed that you offer those two Rakat and we were told that the Prophet had forbidden offering them."" Ibn Abbas said, ""I along with \'Umar bin Al-Khattab used to beat the people whenever they offered them."" I went to \'Aisha and told her that message. \'Aisha said, ""Go and ask Um Salama about them."" So I returned and informed them about her statement. They then told me to go to Um-e-Salama with the same question with which she sent me to \'Aisha. Um-e-Salama replied, ""I heard the Prophet forbidding them. Later I saw him offering them immediately after he prayed the \'Asr prayer. He then entered my house at a time when some of the Ansari women from the tribe of Bani Haram were sitting with me, so I sent my slave girl to him having said to her, \'Stand beside him and tell him that Um Salama says to you, ""O Allah\'s Apostle! I have heard you forbidding the offering of these (two Rakat after the \'Asr prayer) but I have seen you offering them."" If he waves his hand then wait for him.\' The slave girl did that. The Prophet beckoned her with his hand and she waited for him. When he had finished the prayer he said, ""O daughter of Bani Umaiya! You have asked me about the two Rakat after the \'Asr prayer. The people of the tribe of \'Abdul-Qais came to me and made me busy and I could not offer the two Rakat after the Zuhr prayer. These (two Rakat that I have just prayed) are for those (missed) ones. Narrated Kuraib, ""Umm Salma said as above on the authority of Prophet (s.a.w)"" حَدَّثَنَا قُتَيْبَةُ بْنُ سَعِيدٍ، حَدَّثَنَا يَعْقُوبُ بْنُ عَبْدِ الرَّحْمَنِ، عَنْ أَبِي حَازِمٍ، عَنْ سَهْلِ بْنِ سَعْدٍ السَّاعِدِيِّ ـ رضى الله عنه ـ أَنَّ رَسُولَ اللَّهِ صلى الله عليه وسلم بَلَغَهُ أَنَّ بَنِي عَمْرِو بْنِ عَوْفٍ كَانَ بَيْنَهُمْ شَىْءٌ فَخَرَجَ رَسُولُ اللَّهِ صلى الله عليه وسلم يُصْلِحُ بَيْنَهُمْ فِي أُنَاسٍ مَعَهُ، فَحُبِسَ رَسُولُ اللَّهِ صلى الله عليه وسلم وَحَانَتِ الصَّلاَةُ فَجَاءَ بِلاَلٌ إِلَى أَبِي بَكْرٍ ـ رضى الله عنه ـ فَقَالَ يَا أَبَا بَكْرٍ إِنَّ رَسُولَ اللَّهِ صلى الله عليه وسلم قَدْ حُبِسَ وَقَدْ حَانَتِ الصَّلاَةُ فَهَلْ لَكَ أَنْ تَؤُمَّ النَّاسَ قَالَ نَعَمْ إِنْ شِئْتَ\u200f.\u200f فَأَقَامَ بِلاَلٌ وَتَقَدَّمَ أَبُو بَكْرٍ ـ رضى الله عنه ـ فَكَبَّرَ لِلنَّاسِ وَجَاءَ رَسُولُ اللَّهِ صلى الله عليه وسلم يَمْشِي فِي الصُّفُوفِ حَتَّى قَامَ فِي الصَّفِّ، فَأَخَذَ النَّاسُ فِي التَّصْفِيقِ، وَكَانَ أَبُو بَكْرٍ ـ رضى الله عنه ـ لاَ يَلْتَفِتُ فِي صَلاَتِهِ، فَلَمَّا أَكْثَرَ النَّاسُ الْتَفَتَ فَإِذَا رَسُولُ اللَّهِ صلى الله عليه وسلم فَأَشَارَ إِلَيْهِ رَسُولُ اللَّهِ صلى الله عليه وسلم يَأْمُرُهُ أَنْ يُصَلِّيَ، فَرَفَعَ أَبُو بَكْرٍ ـ رضى الله عنه ـ يَدَيْهِ فَحَمِدَ اللَّهَ وَرَجَعَ الْقَهْقَرَى وَرَاءَهُ حَتَّى قَامَ فِي الصَّفِّ، فَتَقَدَّمَ رَسُولُ اللَّهِ صلى الله عليه وسلم فَصَلَّى لِلنَّاسِ فَلَمَّا فَرَغَ أَقْبَلَ عَلَى النَّاسِ فَقَالَ \u200f""\u200f يَا أَيُّهَا النَّاسُ مَا لَكُمْ حِينَ نَابَكُمْ شَىْءٌ فِي الصَّلاَةِ أَخَذْتُمْ فِي التَّصْفِيقِ، إِنَّمَا التَّصْفِيقُ لِلنِّسَاءِ، مَنْ نَابَهُ شَىْءٌ فِي صَلاَتِهِ فَلْيَقُلْ سُبْحَانَ اللَّهِ\u200f.\u200f فَإِنَّهُ لاَ يَسْمَعُهُ أَحَدٌ حِينَ يَقُولُ سُبْحَانَ اللَّهِ إِلاَّ الْتَفَتَ، يَا أَبَا بَكْرٍ مَا مَنَعَكَ أَنْ تُصَلِّيَ لِلنَّاسِ حِينَ أَشَرْتُ إِلَيْكَ \u200f""\u200f\u200f.\u200f فَقَالَ أَبُو بَكْرٍ ـ رضى الله عنه ـ مَا كَانَ يَنْبَغِي لاِبْنِ أَبِي قُحَافَةَ أَنْ يُصَلِّيَ بَيْنَ يَدَىْ رَسُولِ اللَّهِ صلى الله عليه وسلم\u200f Narrated By Sahl bin Sad As-Sa\'idi: The news about the differences amongst the people of Bani \'Amr bin \'Auf reached Allah\'s Apostle and so he went to them along with some of his companions to affect a reconciliation between them. Allah\'s Apostle was delayed there, and the time of the prayer was due. Bilal went to Abu Bakr and said to him, ""Allah\'s Apostle has been delayed (there) and the time of prayer is due. So will you lead the people in prayer?"" Abu Bakr said, ""Yes if you wish."" Bilal pronounced the Iqama and Abu Bakr, went forward and said Takbir for the people. In the mean-time, Allah\'s Apostle came crossing the rows (of the praying people) and stood in the (first) row and the people started clapping. Abu Bakr would never glance side-ways in his prayer but when the people clapped much he looked back and (saw) Allah\'s Apostle. Allah\'s Apostle beckoned him to carry on the prayer. Abu Bakr raised his hands and thanked Allah, and retreated till he reached the (first) row. Allah\'s Apostle went forward and led the people in the prayer. When he completed the prayer he faced the people and said, ""O people! Why did you start clapping when something unusual happened to you in the prayer? Clapping is only for women. So whoever amongst you comes across something in the prayer should say, \'Subhan-Allah\' for there is none who will not turn round on hearing him saying Subhan-Allah. O Abu Bakr! What prevented you from leading the people in the prayer when I beckoned you to do so?"" Abu Bakr replied, ""How dare the son of Abu Quhafa lead the prayer in the presence of Allah\'s Apostle ?"" حَدَّثَنَا يَحْيَى بْنُ سُلَيْمَانَ، قَالَ حَدَّثَنِي ابْنُ وَهْبٍ، حَدَّثَنَا الثَّوْرِيُّ، عَنْ هِشَامٍ، عَنْ فَاطِمَةَ، عَنْ أَسْمَاءَ، قَالَتْ دَخَلْتُ عَلَى عَائِشَةَ ـ رضى الله عنها ـ وَهِيَ تُصَلِّي قَائِمَةً وَالنَّاسُ قِيَامٌ فَقُلْتُ مَا شَأْنُ النَّاسِ فَأَشَارَتْ بِرَأْسِهَا إِلَى السَّمَاءِ\u200f.\u200f فَقُلْتُ آيَةٌ\u200f.\u200f فَقَالَتْ بِرَأْسِهَا أَىْ نَعَمْ\u200f Narrated By \'Aisha the wife of the Prophet : Allah\'s Apostle during his illness prayed in his house sitting, whereas some people followed him standing, but the Prophet beckoned them to sit down. On completion of the prayer he said, ""The Imam is to be followed. So, bow when he bows, and raise your head when he raises his head.""', 'Mashad\xa0(or Mashhad)\xa0is the\xa0second most populous\xa0city\xa0\xa0and the capital of\xa0Razavi Khorasan Province which\xa0located in the northeast of the Iran close to the border with Afghanistan and Turkmenistan\xa0.\xa0 Mashad\xa0is a popular destination for religious tourists and pilgrims.\xa0The shrine of Imam Reza, the eighth imam in Shia Islam, is the largest mosque in the world. Mashdad is also home to the tomb of Ferdowsi, the Persian poet behind the Shahnameh. The\xa0Imam Reza shrine\xa0is one of the tourism centers in Iran and\xa0largest mosque\xa0in the world by area which contains the mausoleum of\xa0Imam Reza, the eighth\xa0Imam\xa0of\xa0 Twelver Shiites. It is\xa0contained within the complex are the\xa0Goharshad Mosque, a\xa0library, a\xa0museum, four\xa0seminaries,\xa0a cemetery, the Razavi University of Islamic Sciences, a dining hall for pilgrims, vast prayer halls, and other buildings. Ferdowsi\xa0was a\xa0Persian\xa0poet\xa0and the author of\xa0 Book of Kings Shahnameh which is the world’s longest\xa0epic poem\xa0created by a single poet, and the\xa0national epic\xa0of\xa0Greater Iran. Ferdowsi’s tomb has been built and destroyed many times. The current area of the tomb is close to six hectares. Among other valuable and historic buildings in Mashhad is the tomb of Nadir Shah Afshar. Nader Shah Afshar\xa0\xa0was one of the most powerful Iranian rulers in the\xa0history\xa0of the nation, ruling as\xa0Shah\xa0of\xa0Iran\xa0from 1736 to 1747 when he was assassinated during a rebellion. Nader Shah Afshar ordered that small tomb should be built above Mashhad Street.', '192nd session of Supreme Council of AhlulBayt (a.s.) World Assembly started in Iraq 12 March 2023, 6:23:25 PMThe 192nd session of the Supreme Council of the AhlulBayt (a.s.) World Assembly began on Sunday, March 12, with the presence of members of this council in Iraq.AhlulBayt News Agency (ABNA): The 192nd session of the Supreme Council of the AhlulBayt (a.s.) World Assembly began on Sunday, March 12, with the presence of members of this council in Baghdad and hosted by Sayyed Ammar Hakim.The latest issues of the followers of the AhlulBayt (a.s.) in different parts of the world were discussed in the session.Ayatollah Mohammad Hassan Akhtari, Chairman of the Supreme Council of the AhlulBayt (a.s.) World Assembly, Ayatollah Reza Ramazani, Secretary General of the AhlulBayt (a.s.) World Assembly, Ayatollah Sayyed Mojtaba Hosseini, the representative of the Supreme Leader of the Revolution in Iraq and Hujaj al-Islam Sheikh Hassan Hamadeh (from Lebanon), Sayyed Ammar Hakim (from Iraq), Sheikh Nabil Halbawi (from Syria), Sayyed Morteza Morteza (about African issues) and many other attendees were among the speakers on the first day of the session.The 192nd session of the Supreme Council of the AhlulBayt (a.s.) World Assembly will end on Monday by issuing a statement. Source: https://www.en.abna24.com/ !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! 17:51 - March 10, 2023TEHRAN (IQNA) – Tehran and Riyadh have agreed to resume diplomatic relations and re-open embassies, seven years after their ties were broken off over several issues.The agreement was struck on Friday after several days of intensive negotiations between Secretary of Iran’s Supreme National Security Council (SNSC) Ali Shamkhani and his Saudi counterpart in Beijing. It was officially announced in a joint statement by Iran, Saudi Arabia and China.The statement was inked by Shakhani, Musaid Al Aiban, Saudi Arabia’s national security adviser, and Wang Yi, the director of the Office of the Central Foreign Affairs Commission of the Chinese Communist Party.Shamkhani has been involved in intensive talks with his Saudi counterpart in Beijing since Monday to find a final solution to the issues between Tehran and Riyadh. The negotiations followed a meeting between Iranian President Ebrahim Raeisi and his Chinese counterpart Xi Jinping in Beijing last month.“As a result of the talks, the Islamic Republic of Iran and the Kingdom of Saudi Arabia agreed to resume diplomatic relations and re-open embassies and missions within two months,” the joint statement said.It added that the Iranian and Saudi foreign ministers will meet to “implement this decision and make the necessary arrangements for the exchange of ambassadors.”According to the statement, Iran and Saudi Arabia highlighted the need to respect each others’ national sovereignty and refrain from interfering in the internal affairs of one another. They agreed to implement a security cooperation agreement signed in April 2001 and another accord reached in May 1998 to boost economic, commercial, investment, technical, scientific, cultural, sports and youth affairs cooperation.Iran, Saudi Arabia and China expressed their firm determination to make their utmost efforts to promote regional and international peace and security, it emphasized.The statement further explained that delegations from Iran and Saudi Arabia, led by Shamkhani and Aiban, held several meetings over the past five days following Chinese President Xi Jinping’s support for the expansion of ties between Tehran and Riyadh based on the principle of good neighborliness and his efforts to host meetings between Iranian and Saudi senior officials.The talks between Shamkhani and Aiban were also held as a result of the keenness of Tehran and Riyadh to resolve differences through dialogue and diplomacy based on fraternal ties and both sides’ adherence to the principles of the United Nations Charter and the Organization of Islamic Cooperation (OIC) Charter and international rules and principles, it added.Saudi Arabia severed diplomatic relations with Iran in January 2016 after Iranian protesters, enraged by the execution of prominent Shia cleric Sheikh Nimr Baqir al-Nimr by the Saudi government, stormed its embassy in Tehran.The two sides had held five rounds of negotiations in the Iraqi capital of Baghdad since April 2021.In their joint statement, Iran and Saudi Arabia also thanked Iraq and Oman for hosting the talks between the two sides in 2021 and 2022 as well as the leaders and government of the People’s Republic of China for hosting and supporting the talks held in that country.Source: PressTVSource: https://iqna.ir/en/news/ \xa0\xa0\xa0\xa0\xa0!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! 13:59 - January 25, 2023TEHRAN (IQNA) – Egypt denounced desecration of the Holy Quran in the Netherlands, warning that the action fuels hate speech.The Egyptian foreign ministry strongly condemned the tearing of a part of a copy of the Quran by a leader of an extremist movement in the Netherlands.In a statement carried by Ahram Online on Tuesday, the Egyptian Ministry of Foreign Affairs said, “The disgraceful incident goes beyond freedom of expression, violates Muslim sanctities, and fuels hate speech between religions and peoples in a way that threatens communal security and stability.”On Monday, Dutch politician Edwin Wagensveld, the head of the far-right PEGIDA, tore pages out of the holy book before setting them on fire in front of the parliamentary building in the Hague.A video posted on his social media accounts showed Wagensveld claiming he received permission from local authorities for “the destruction of the Quran.”His provocation followed another Islamophobic protest on Saturday in Sweden, where a Danish extremist burned a copy of the holy book in a police-approved demonstration.The Muslim community worldwide has been outraged since the weekend at anti-Islam activist Rasmus Paludan, who staged his provocative demonstration in front of the Turkish Embassy in Stockholm while delivering a hate-filled speech, and the Swedish authorities who allowed him under the guise of “freedom of expression.”Source: wam.aeSource: https://iqna.ir/en/news/ \xa0\xa0\xa0\xa0\xa0!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! 20:07 - January 25, 2023TEHRAN (IQNA) – Egypt’s Al-Azhar Islamic Center called for boycotting Swedish and Dutch products in response to the desecration of the Quran in the European states.In a statement on Wednesday, Al-Azhar called on the Arab and Muslim peoples “to boycott all Dutch and Swedish products and to take a strong and unified stance in support of our Noble Quran, the sacred scripture of the Muslims, and as a proper reaction to the governments of these two countries, who have offended 1.5 billion Muslims.”On Sunday, Edwin Wagensveld, a far-right Dutch politician, and leader of the Islamophobic group Pegida, tore out pages from the Quran in The Hague, the administrative capital of the Netherlands. Wagensveld\'s video on Twitter showed that he burned the torn-out pages of the holy book in a pan.The new provocation followed a similar Islamophobic protest on Saturday in Sweden, where a Danish extremist burned a copy of the Quran, in a police-approved protest.“They have gone to excess in guarding the mean and barbaric crimes perpetrated under the specious inhumane and immoral banner or their so-called ‘freedom of expression’,” it added.The Sunni religious institution called on all Arabs and Muslims “to adhere to the boycott, and to educate children, youth and women about it.”“These deviants will never appreciate the value of the religion – about which they know nothing – or be deterred unless they face the challenging material, monetary and economic necessities. That is the only language they know,” the statement said.The desecration of the Quran has triggered a storm of condemnations from across the Islamic world, including Turkey. Source: Anadolu AgencySource: https://iqna.ir/en/news/ \xa0\xa0\xa0\xa0\xa0!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! 12:13 - January 24, 2023TEHRAN (IQNA) – After the desecration of the Quran in Sweden on the weekend, there was another sacrilegious act by an Islamophobe in Europe, this time in the Netherlands.The Dutch leader of the far-right group, Patriotic Europeans Against the Islamisation of the West (PEGIDA), desecrated a copy of the Quran in the Netherlands, threatening to escalate the already tense situation following a similar anti-Muslim incident in Sweden.A video posted on social media on Monday showed anti-Muslim provocateur Edwin Wagensveld tearing apart Islam\'s holy book before showing it being set on fire.After he was arrested on two previous occasions because of his anti-Muslim activities, Wagensveld claimed in the video that he received permission from the city of The Hague for the ""destruction of the Quran."" A separate post on his Instagram account showed a letter, signed by Mayor of The Hague Jan van Zanen allowing him to use ""objects"" in his protest, but prohibiting him from burning it due to public safety.""The right to protest and the right to freedom of expression are constitutionally and treaty-protected human rights and freedoms,"" the letter said.But it added that ""in principle burning objects is not permitted, because this can cause danger.""As Wagensveld tore a page out of the holy book and scrunched it up, he said:""Soon, there will be registrations for similar actions in several cities, time to answer disrespect from Islam with disrespect.""He then continued to tear apart the Quran, throwing pages to the floor before saying: ""After having a nice bite to eat and a drink with our group, it was then time to burn the Quran\'s remains.""The video clip then shows the Quran and its torn-out pages burning in a fire in an object resembling a frying pan placed on a floor.""People who know and follow us know that we never give up, we do not let ourselves be intimidated by violence and death threats,"" he said.The destruction of a copy of Quran comes just days after another burning incident in Sweden on Saturday, which ignited condemnation and protests around the Muslim world.The anti-Muslim leader Rasmus Paludan had burned the Quran in front of the Turkish Embassy in Stockholm after receiving permission from the Swedish government.Detained several timesTwo months ago, Wagensveld had been detained by the police for insulting the Prophet Muhammad using a megaphone, according to local news and a written statement made by the Dutch Prosecutor\'s Office.The prosecutor\'s office decided, based on the existing case, that the statement made by Wagensveld could be considered as an insult to the religion of Islam.But it was ultimately decided that he had not committed any crime and therefore he would not be prosecuted for the act.Wagensveld was also detained a month prior for failing to comply with demonstration rules and warnings in accordance with a planned event to burn a copy of Quran.The PEGIDA movement had planned to burn the Quran opposite the temporary Dutch Parliament building but the event was cancelled, according to a statement from the city of The Hague, which said the demonstrators wanted to use the Quran in a ""provocative"" way.""It was decided that the demonstration could only be held without the Quran in order to prevent chaos. The demonstrators refused, after which the show was cancelled,” the statement said.The PEGIDA movement, in its social media account, argued that Wagensveld was detained on the grounds that he refused to give the Quran to the police.A counter-demonstration had also gathered in the region but dispersed after the police announced that the PEGIDA demonstration was cancelled. Source: TRT WorldSource: https://iqna.ir/en/news/ \xa0\xa0\xa0\xa0\xa0!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! 13:52 - November 08, 2022 \xa0TEHRAN (IQNA) – The International Union for Muslim Scholars (IUMS) welcomed a call by Al-Azhar Islamic Center for strengthening unity among Muslims within the framework of Islamic principles.“We agree to unity in the Islamic Ummah based on principles. This is a religious duty and a Wajib (compulsory act), IUMS Secretary-General Ali al-Qaradaghi said, Arabi21 website reported.“However, this unity requires a proper atmosphere,” he added.“All Muslim countries have duties and responsibilities (in this regard) and the correct way is for all to hold dialogue and take serious steps for realization of this.”He highlighted the responsibility of Arab countries in this regard and said if the right steps are taken, Islamic unity will soon be materialized, God-willing.Qaradaghi added that he supports any invitation to unity among Muslims and also human unity for peaceful coexistence.His remarks came after Al-Azhar Chief Sheikh Ahemd El-Tayeb called for dialogue among Shia and Sunni Muslims.Speaking on Friday in Bahrain, El-Tayeb said, “I and major scholars of Al-Azhar and Muslim Council of Elders are ready with open arms to sit down together on one roundtable with our Shia brothers to put aside our differences and strengthen our Islamic unity.”Such a dialogue, he maintained, will aim at chasing away any talk of hate, provocation and excommunication and setting aside ancient and modern conflict in all its forms.“I call on my brothers, Muslim scholars, across the world of every doctrine, sect and school of thought to hold an Islamic dialogue,” El-Tayeb stressed.The forum was held in Manama in the presence of Pope Francis who made his first-ever trip to the island.Source: https://iqna.ir/en/news/ \xa0\xa0\xa0\xa0\xa0!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! 7 November 2022,Senior Iranian Shia cleric has issued a message on Sunday to voice support for Shia-Sunni dialogue as proposed by al-Azhar grand mufti Sheikh Ahmed el-Tayyeb in his address to Bahrain interfaith meeting also attended by Pope Francis.AhlulBayt News Agency: Senior Iranian Shia cleric has issued a message on Sunday to voice support for Shia-Sunni dialogue as proposed by al-Azhar grand mufti Sheikh Ahmed el-Tayyeb in his address to Bahrain interfaith meeting also attended by Pope Francis.Hujjat-ul-Islam Hamid Shahriari, Secretary General of World Forum for Proximity of Islamic Schools of Thought hailed the call by Sheikh Ahmed el-Tayyeb for holding dialogue between Shia and Sunni scholars in an effort to reduce tensions in the world of Islam. The cleric in his letter addressing Ahmed el-Tayyeb said,” Once again al-Azhar, represented by your honorable scholar, called for Islamic dialogue urging the Shia and Sunni clerics for talks and eliminating factors which bring tensions in the world of Islam.” The cleric noted,” Al-Azhar announcement regarding preparation for hosting Islamic dialogue illustrates your commitment to the topic and also your intention and honesty to achieve the objective.” Hujjat-ul-Islam Hamid Shahriari stressed the constant support of Iran’s major Islamic unity center, World Forum for Proximity of Islamic Schools of Thought, for leading and civilized calls for closeness of hearts and going beyond division, tribalism and prioritization of interests of Muslim world to personal benefits. He stated,” Today we announce our solidarity with your call and our preparation for facilitating the project by all possible means.” Secretary General of World Forum for Proximity of Islamic Schools of Thought expressed hope for success of al-Azhar and that honor and security prevail across the world of Islam and that the voices of hostility, division and Takfir (excommunication) are beaten. Grand mufti from prestigious university in Egypt made speech at interfaith meeting in Bahrain, also attended by Pope Francis, calling for dialogue between Shia and Sunni clerics and “together chase away any talk of hate, provocation and excommunication and set aside ancient and modern conflict in all its forms.” Launched in 1990 at an order by Supreme Leader of Islamic Republic, Ayatollah Khamenei, World Forum for Proximity of Islamic Schools of Thought has been pursuing the objective to facilitate intra-Muslim meetings between Shia and Sunni clerics and boosting solidarity among all Islamic denominations.Source: https://www.en.abna24.com/ !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! 14:52 - November 04, 2022 TEHRAN (IQNA) – The grand imam of Cairo\'s Al-Azhar mosque has called on Sunni and Shia scholars to hold dialogue so as to settle differences and strengthen Islamic unity.Sheikh Ahmed al-Tayeb made the remarks on Friday while addressing Bahrain Dialogue Forum which is aimed at promoting religious harmony.“I and major scholars of Al-Azhar and Muslim Council of Elders are ready with open arms to sit down together on one roundtable with our Shia brothers to put aside our differences and strengthen our Islamic unity,” he said.Such a dialogue, he maintained, will aim at chasing away any talk of hate, provocation and excommunication and setting aside ancient and modern conflict in all its forms.“I call on my brothers, Muslim scholars, across the world of every doctrine, sect and school of thought to hold an Islamic dialogue,” al-Tayeb stressed.The forum was held in Manama in the presence of Pope Francis who is making his first-ever trip to the Persian Gulf nation.Source: https://iqna.ir/en/news/ \xa0\xa0\xa0\xa0\xa0!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! 17 October 2022Secretary-General of the AhlulBayt (a.s.) World Assembly stated, “Considering all aspects, I clearly emphasize that we got results beyond expectations from the 7th General Assembly. At the General Assembly, significant measures related to the content were carried out, and good commissions were held, all of which were somehow the introduction of new management and approach.”AhlulBayt News Agency (ABNA): On Sunday morning, September 1, 2022, on the occasion of holding the prestigious and distinguished conference “The 7th General Assembly of the AhlulBayt (a.s.) World Assembly”, the appreciation ceremony for the managers and staff of the Assembly was held in Tehran with the presence of Ayatollah Reza Ramazani, Secretary-General and the staff of various departments of the Assembly.In a speech at this ceremony, while appreciating those who were involved in holding this great and glorious conference, the Secretary-General of the AhlulBayt (a.s.) World Assembly stated, “It is not possible to enumerate the features and benefits of the 7th conference in just one session. But all the programs that had been approve were implemented well.”“I would like to express my gratitude and thanks to the committees and working groups, ceremonial, service, processing, transportation, strategic, legal, inspection and performance monitoring departments, Messrs. Rashed, Farmanian, Moinian, Jazzari, Sharifi, Rahbar, Hosseini Aref and Kazemi who worked diligently,” he said.“The management of affairs in different departments of the General Assembly was very important and it was done well. The 7th General Assembly was distinguished and powerful in the executive and content sections,” Ayatollah Ramazani added.“The conference was started from the Mausoleum of the late Imam Khomeini (r.a.), and the AhlulBayt (a.s.) International University hosted the guests. The screening of a video clip by this university of the late Imam’s prayer was a noble and valuable act that was interesting for many guests. The young staff of AhlulBayt (a.s.) International University managed this program well,” said the Secretary-General of the AhlulBayt (a.s.) World Assembly.“In the opening ceremony of the distinguished conference, the honorable president gave a speech, and the international practice of the conference was shown in his important statements and those of other speakers,” he added.“Five Shiite grand sources of emulation sent separate messages to the 7th General Assembly. Some other dignitaries also sent messages, and those who could not attend due to regional conditions apologized. The guests met with the Supreme Leader of the Revolution, the President, the President’s wife and the Minister of Foreign Affairs of Iran,” Ayatollah Ramazani stated.“In the conference, the meetings of four commissions: Economic of followers of AhlulBayt (a.s.), Local Assemblies of followers of AhlulBayt (a.s.) and missionaries, Media and Cyberspace and Communications were held. Finally, the participation of the guests in Friday prayers in Tehran was valuable,” he added.Secretary-General of the AhlulBayt (a.s.) World Assembly stated, “Considering all aspects, I clearly emphasize that we got results beyond expectations from the 7th General Assembly. At the General Assembly, significant measures related to the content were carried out, and good commissions were held, all of which were somehow the introduction of new management and approach.”In the end of his speech, while referring to the 24 side programs held in the 7th General Assembly, Ayatollah Ramazani mentioned some of them: Preparing and compiling 22 panels of the activities of the Assembly to meet with the supreme leader of the revolution, introducing and getting to know the situation of Shiites in the world, side exhibition with 34 booths, unveiling the collection of the proceedings and works of Hazrat Abu Talib conference, unveiling the book “Companions and the Assembly,” and “Mirror of the Works”, unveiling of five new languages in WikiShia, the activities of the Thaqalayn TV and the recording of the conference programs using 11 working teams, the activities of ABNA News Agency in producing 531 news articles and video reports, as well as conducting 160 interviews by the news agency, regional side meetings with the presence of prominent dignitaries, the presence of Tawashih group in the conference, and presenting a seven-year report.In worth mentioning hat in the beginning of this meeting, Dr. Abdolreza Rashed, Vice President in Development of Management and Resources of the Assembly and Secretary of the 7th General Assembly, Hojat al-Islam Mahdi Farmanian, Vice President in Scientific and Cultural Affairs of the Assembly, and Hojat al-Islam Mohammad Ali Moinian, Vice President in the International Affairs of the AhlulBayt (a.s.) World Assembly presented their reports on the preparations and the process of holding the 7th General Assembly. Source: https://www.en.abna24.com/ !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! 14:06 - July 08, 2022 \xa0TEHRAN (IQNA) – Huge crowds of Muslim pilgrims on Friday morning headed to Mount Arafat, also called Mount of Mercy, to ask for God\'s mercy and forgiveness as Hajj pilgrimage nears its end.“Wuquf at Arafat” is one of the final rituals of Hajj pilgrims performed at the site. Worshippers read the Quran and supplications and pray from noon to sunset.The day is known as the Day of Arafah and is annually marked on the 9th day of the lunar Hijri month of Dhul Hajja.The mount is believed to be where Prophet Mohammed (PBUH) delivered his final sermon and is of great importance to Muslims.The next destination of pilgrims is Muzdalifah which is located halfway between Arafat and Mina. Muslims will sleep under the stars at this area before leaving to perform the symbolic “stoning of the devil” ceremony on Saturday.The final tawaf of the Kaaba and eid al-Adha will mark the end of Hajj pilgrimage.Hajj pilgrimage is one of the pillars of Islam that Muslims who have the means should perform at least once in their lives. Muslims typically save for years to take part in the event.The Hajj consists of a series of religious rites that are completed over five days in Islam’s holiest city, Mecca, and surrounding areas of western Saudi Arabia.Source: https://iqna.ir/en/news/3479620/pilgrims-gather-at-mount-arafat-asking-god%E2%80%99s-mercy !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! AhlulBayt News Agency (ABNA): Researchers and scientists from all over the world must have access to the rich sources of Imam Reza holy shrine’s Central Library, says Hoj. Ahmad Marvi, custodian of Imam Reza holy shrine, in the opening ceremony of holy shrine’s huge treasure of written works.Stating that opening of this nine-thousand-square meter treasure adds a very unique section to the Central Library, Hoj. Marvi said: “All holy shrine’s previous endeavors in the areas of books, library, and preservation of Shia heritage during past years will come to fruition by opening this new hall”.Marvi added: “The first endowment of the holy complex was related to book and library. Based on this endowment, one of the salient rulers of Isfahan endowed a manuscript to shrine of Imam Reza (AS) around one thousand and one hundred years ago. The library and book repository of the holy shrine was formed about eight centuries ago”.The custodian went on to say: “Formation of such a unique library in Imam Reza shrine carries this message that the Islamic civilization is based on books, culture, science and knowledge”.He further noted: “All modern tools, facilities and technologies should be used to help world scholars benefit from this great heritage and valuable library”.Concluding his remarks, Hoj. Marvi said: “Providing necessary grounds for enjoyment of world people promotes not only science and knowledge but also school of thought of Ahl al-Bayt (AS) particularly Imam Reza (AS)”.Experts estimate that the new hall will have a storage capacity of up to 100 million sources including press archives, documents, manuscripts and lithographs, print, and museum resources for the next 50 years.The opening ceremony of this hall had a number of national and provincial officials including the head of Ayatollah Khamenei’s office in attendance”. Source: https://www.en.abna24.com/ !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! 15:51 - April 03, 2022 \xa0TEHRAN (IQNA) – Muslims perform rituals during the blessed month of Ramadan which bears special importance.What is the reason behind this importance?Mohsen Qara’ati, a prominent Quran teacher and scholar from Iran, answers this question:The importance of Ramadan is because of the Quran. When God wants to introduce the month of Ramadan, He says: “The month of Ramadan is the month in which the Quran was revealed” [2:185]. God does not say this is the month when we fast.When a car stops working, we should put it on a downward slope so as to move; Ramadan is the path of modifying our attention to the Quran. Ramadan is a great opportunity to compensate for our lack of attention to the Holy Book. We should consider contemplating the Quran as a wajib (compulsory) act because the Quran blames those who do not do so: “Will they not then contemplate on the Quran? Or are there locks upon their hearts!” [47:24]. This blaming refers to the obligatory nature of contemplation because God does not chastise individuals for doing Mustahabb acts such as Friday ghusl or night prayers. God chastises individuals two times here; He first says “Will they not then contemplate on the Quran?” before saying: “Or are there locks upon their hearts!”. A Mustahabb and peripheral act does not receive two consecutive reprimands! So it is an obligation to contemplate the Quran.Meanwhile, the month of Ramadan has special importance because of increased attention to the Quran. The Arabic word “tadabbor” is used in the Quran for thinking deeply about the Book’s concepts and does not have any other application other than in Quranic studies. The exact meaning of the word is understanding the wise arrangement that is present in the Quran.Source: https://iqna.ir/en/news/3478333/why-is-ramadan-important \xa0!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Photo iqna.ir March 13, 2022 - 7:52 AMAhlulBayt News Agency (ABNA): In a message to the 56th gathering of the Union of Islamic Students Associations in Europe, Imam Khamenei stressed the need to understand the various fronts, adopt a correct stance and prepare for playing one’s part in the global developments to the best interests of the camp of truth.His message is as follows:In the Name of God, the Beneficent, the MercifulDear students,The current political and military events form part of the historic turn in the world that had been predicted. The outstanding, prominent intellectuals of our great nation have special responsibilities at this stage. An understanding of the fronts and adopting a correct stance are their short-term responsibilities. And preparing to play one’s part in global developments to the advantage of the camp of truth is their longer-term responsibility.You dear youth can shine brightly in both areas and boost the hope in the Associations whose name is decorated with the blessed name of Islam.I ask God, the Almighty and Wise, to bestow increasing success on you.Sayyid Ali KhameneiMarch 11, 2022Source: http://www.en.abna24.com/!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! 16:27 - March 10, 2022 \xa0\xa0TEHRAN (IQNA) – The Leader of the Islamic Revolution says visions that are going to be designed for the country should be religious.Ayatollah Seyyed Ali Khamenei made the remarks in a meeting with organizers of an international congress featuring discussions on the Second Phase of the Islamic Revolution from the view of the Quran and Hadith.The congress kicked off this morning in Qom and the Leader\'s remarks were published at the outset of the event.""One of the most important tasks in the Islamic Revolution and in the Islamic Establishment is designing a vision to make the destination clear,"" said the Leader.""Of course, this vision should certainly be scientific and based on Islamic teachings, i.e. it should be religious,"" he added.The event has been organized by the Quran and Hadith Higher Education Complex of Al-Mustafa International University.According to organizers, more than 1,000 papers have been sent to the event.‘Lifestyle’, ‘Islamic Revolution, the West and the East in View of the Quran’, ‘Quranic and Islamic Sciences’, ‘Quranic and Hadith-based Futurology’, ‘International’, and ‘Women’ are the six committees of the congress, according to the organizers.The “Second Phase of the Revolution” or “Second Step of the Revolution” is a statement that was issued by the Leader of the Islamic Revolution to the country, particularly to the youth, and was published in February 2019, on the occasion of the fortieth anniversary of the victory of the Islamic Revolution.Source: https://iqna.ir/en/news/3478109/leader-stresses-role-of-religion-in-future-of-country !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! March 2, 2022 - 8:11 AMAhlulBayt News Agency (ABNA): In a statement, The International Union of Muslim Scholars (IUMS) urged for an end to the Russian war in Ukraine.According to the statement, the union also called for a ""serious dialogue to begin between the two sides based on neighbourly ties and common interests.""The IUMS said that it ""rejects and condemns the trend of military expansion and the relentless pursuit of expansion and military hegemony.""Meanwhile, the statement said that the IUMS ""extends prayers and supplications for the displaced and follows up with great concern on the situation of all the displaced women, children and the elderly who escaped the conflict and left their homes.""It called on all charities and humanitarian and international bodies in the Islamic world and elsewhere ""to expedite the delivery of humanitarian, food and health assistance to our displaced brothers.""It pointed out that Prophet Muhammad (peace be upon him) said: ""None of you will believe until you love for your brother what you love for yourself.""The IUMS reiterated that ""protecting and caring for any soul … is charity, and there is a great reward with God Almighty. Therefore, we call on health and medical organisations to do their duty towards the wounded and sick.""""We urgently call on countries that have good relations with both sides such as Turkiye and Pakistan to carry out sincere and serious mediation efforts to immediately stop the devastating war.""Source: http://www.en.abna24.com/!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! February 27, 2022 - 2:10 PMAhlulBayt News Agency (ABNA): The grand imam of Al-Ahzar called on Russia and Ukraine to heed the voice of reason and end the war between the two countries.In a statement released in Arabic and English, Sheikh Ahmed El-Tayyeb also called on world leaders and international institutions to support peaceful solutions to the conflict, elkalimanews.com reported.He stressed that wars will only bring more killing, destruction and hatred to the world.El-Tayyeb added that differences can be resolved only through dialogue.Many world leaders, including religious leaders, have called on Moscow and Kiev to resolve their issues diplomatically.Russian President Vladimir Putin on Thursday announced the launch of an operation to eliminate what he called a serious threat to his country, citing the need to “denazify” Ukraine and accusing its Western-backed leadership of genocide against Russian-speakers in eastern Ukraine.Western countries have announced a barrage of sanctions on Russia, including blacklisting its banks and banning technology exports. But they have stopped short of forcing it out of the SWIFT system for international bank payments, because it would harm their own economies.At the United Nations, Russia vetoed a draft Security Council resolution deploring its operation.Source: http://www.en.abna24.com/!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! February 11, 2022 - 10:19 AMRallies to mark Bahman 22 started nationwide to mark the 43rd anniversary of the victory of the Islamic Revolution in Iran on February 11, 1979.The rallies began at 09:30 hours local time in about 1,500 Iranian cities and over 3,000 villages.People in red zones attend the rallies on their motorcycles or in cars to observe health protocols necessary to prevent further spread of coronavirus.About 200 foreign correspondents and cameramen and more than 6,300 members of domestic media are covering the Bahman 22 rallies.Balloons are to fly in the sky and the Army parachutists are going to perform shows as part of celebrations to mark the day.President Ebrahim Raisi is to address the participants of the rallies in Tehran in Imam Khomeini Grand Prayer Grounds (Mosalla).Every year, millions of Iranians across the country observe ten days of celebrations marking the anniversary of the victory of the 1979 Islamic Revolution that put an end to the monarchy of the US-backed Pahlavi regime in the country.The day of Imam Khomeini’s return to Iran (February 1 this year) marks the beginning of the Ten Day Fajr (dawn), which culminates with rallies on the anniversary of the victory of the Islamic Revolution on February 11.The Iranian nation toppled the US-backed Pahlavi regime 43 years ago, ending the 2,500 years of monarchic rule in the country.The Islamic Revolution spearheaded by the late Imam Khomeini established a new political system based on Islamic values and democracy.Source: http://www.en.abna24.com/!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! December 26, 2021 - 9:13 AMAhlulBayt News Agency (ABNA): Russian President Vladimir Putin says insulting Holy Prophet Muhammad (Blessings of God upon him and his progeny) is a “violation of religious freedom”, according to Russian News Agency TASS.Insults to the Prophet are a “violation of religious freedom and the violation of the sacred feelings of people who profess Islam,” Putin said in his annual press conference on Thursday.Putin also criticized the publication of blasphemous sketches of Prophet Muhammad (PBUH) in French magazine Charlie Hebdo last September, saying that such acts give rise to extremist reprisals.“Praising artistic freedom in general has its limits and it shouldn’t infringe on other freedoms,” the Russian president said.He said Russia has evolved as a multi-ethnic and multi-confessional state, so Russians are used to respecting each other’s traditions.Pakistani Prime Minister Imran Khan, in a twitter post, welcomed Putin’s statement, saying, “Putin’s statement reaffirmed my stance that insulting our Holy Prophet (PBUH) is not freedom of expression.”The premier urged leaders of the Muslim countries to spread this message to heads of non-Muslim nations to counter Islamophobia.He also called on the Western world to respect sentiments of the Muslim communities while practicing ""freedom of expression"" for the past many years.Source: http://www.en.abna24.com/!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!In message felicitating Christmas to Pope Francis; December 25, 2021 - 7:37 AMAhlulBayt News Agency (ABNA): Iran\'s President sent a message to Pope Francis, the Leader of the world\'s Catholics, and all Christians around the world to congratulate the birthday of Jesus Christ.President Ayatollah Dr Seyyed Ebrahim Raisi\'s message is as follows:In the name of God, the Most Beneficent, the Most MercifulYour Holiness Pope Francis,Pope of the Catholic Church,I am delighted to offer my sincerest congratulations to Your Holiness and all Christians around the world on the birthday of Jesus Christ, the Prophet of Peace and Kindness, as well as the start of year 2022.The birthday of Jesus Christ is the manifestation of the will and power of God, and the spiritual position of Saint Mary shows the greatness of the status of women in the ontology of the divine religions; ""And remember when the angels said, “O Mary! Surely Allah has selected you, purified you, and chosen you over all women of the world"".Celebrating this blessed birthday is an opportunity to honour Saint Mary (PBUH), and to recall the moral qualities of the model of altruism and the herald of the salvation of the oppressed, Jesus Christ in standing against the tyranny of the oppressors and giving them hope for a better future.I thank you for your efforts to bring closer the hearts and views of the followers of the Abrahamic religions, and I pray to God Almighty for your health and success, and the happiness and pride of all the servants of God and all human beings.Seyyed Ebrahim RaisiPresident of the Islamic Republic of IranSource: http://www.en.abna24.com/!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!Islamophobia in UK; AhlulBayt News Agency (ABNA): A landmark report into the British media’s coverage of Muslims and Islam has found shocking levels of misinformation, stereotyping and Islamophobia.Conducted by the Muslim Council of Britain’s Centre for Media Monitoring (CFMM), the report analyses over 48,000 online articles and 5,500 broadcast clips between October 2018 and September 2019, finding that almost 60 percent of the articles and 47 percent of the television clips associated Muslims and/or Islam with negative aspects of behaviour.The report, entitled, British Media’s Coverage of Muslims and Islam (2018-2020), also presents 10 case studies in which Muslims are misrepresented, defamed and libelled in major publications, with damages paid in nine of the cases, alongside public apologies.Of the publications monitored, The Spectator, Daily Mail Australia, Mail on Sunday, Christian Today and the Jewish Chronicle were found to have particularly antagonistic coverage of Muslims and/or Islam.Right-wing and religious publications were found to have a ""higher percentage of articles either demonstrating a bias against, or generalising or misrepresenting, Muslim belief or behaviour"".The Times, which published the false “Christian Child Forced into Muslim Foster Care” story - still available on the newspaper\'s website despite having a complaint upheld against it by the UK\'s press standards organisation - is found to have repeatedly maligned Muslims and Muslim institutions.During the period covered by the CFMM’s analysis, the Jewish Chronicle, the Telegraph and the Mail on Sunday all paid out libel damages to Muslims and Muslim institutions.\'Well-worn tropes and generalisations\'The report\'s analysis of television clips found that national broadcasters were more likely to demonstrate bias against Muslims than regional ones. It also found that right-wing pundits were on many occasions ""left unchallenged when making generalisations against Muslims, including promoting falsehoods"".Rizwana Hamid, CFMM\'s director, said: “This latest report does not seek to place blame on any newspaper or broadcaster, nor on any individual journalist or reporter... However, it is time for the industry to admit that, on occasion and too often when it comes to Muslims and Islam, it gets things wrong.""The report\'s author, Faisal Hanif, said: “While neither Muslims nor Islam should be immune from criticism or inquiry, where warranted, we do expect this to be done fairly and with due care, without resorting to well-worn tropes and generalisations.”Two British newspaper editors, Emma Tucker of the Sunday Times and Alison Philips of The Mirror, welcomed the report. Tucker said this welcome came ""in the full knowledge that it contains criticisms of the press, my own paper included"".Philips said the report ""shows how much we as journalists must question ourselves and the work we are producing in relation to reporting of Muslims and Islam"".Almost one in ten online articles analysed misrepresented Muslims and/or Islam, with the majority of misrepresentation (82 percent) coming from news reporting.The report found that when it came to associating Muslims with negative behaviour and activity - something present in 60 percent of articles analysed - the news agencies Reuters, Associated Press (AP) and AFP were the top offenders.Those wire services were found to have almost exclusively bookended reporting on the harsh living conditions faced by Palestinians in Gaza with descriptions of the area being ruled by the ""Islamist militant"" group Hamas.Most articles did not mention the Egyptian and Israeli blockades of the coastal enclave, described by the Norwegian Refugee Council as ""the world\'s largest open-air prison"".The CFMM report describes wire agencies as ""incubators of negative aspect and behaviours"" connecting, often entirely unnecessarily, Muslims and Islam to terrorism, violent political events and strife in the Middle East. Source: http://www.en.abna24.com/!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! AhlulBayt News Agency (ABNA): A Sunni scholar says there is a need to adopt international laws on banning divisive measures among followers of different Islamic Madhhabs.“Today we see in the West that racism has been banned internationally and individuals who violate the norms are being punished. However, we still have adopted no measure at the level of OIC or Arab Union or other scholarly councils that exist in many Islamic and Arab countries for announcing any action that could provoke killing of a Muslim as Haram,” said head of the Assembly of Lebanese Muslim Scholars, Sheikh Ghazi Hanina, in an interview.He lamented that some media outlets have been turned into tools for sowing discord among Islamic Madhhabs instead of raising knowledge and providing guidance.Some satellite channels’ promotion of Takfirism and division among Muslims has led to the killing of Muslims in countries such as Afghanistan, Syria, and Yemen, he said.Talking about the need for unity in the Muslim Ummah, Hanina added that “One of the reasons for the power of Islam is the unity among members of the Islamic Ummah; therefore, unity is a fundamental guarantee of the Ummah’s power and stability.”The source of this unity, he added, is the belief in God, Prophet Muhammad (PBUH), and the Quran.Referring to the challenges ahead of achieving unity among Muslim nations, the scholar named jurisprudential differences as one of the most dangerous areas.These differences have been a source of discussions since early Islam, he said, adding that the issues should be studied by scholars at Islamic research centers, not by the public. Source: http://www.en.abna24.com/!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! November 15, 2021 - 9:32 AMAhlulBayt News Agency (ABNA): Ayatollah Reza Ramazani, Secretary-General of the AhlulBayt (a.s.) World Assembly, held talks with the Secretary General of the World Council of Churches (WCC).During the meeting, held at the invitation of WCC Secretary General Ioan Sauca and also attended by President of Ahl-ul-Bayt (AS) University Hojat-ol-Islam Saeed Jazari, ways for boosting interfaith dialogues were discussed.Sauca welcomed the Iranian clerics to the WCC headquarters in Geneva and noted that the two sides have had cooperation for a long time.He said since official starting to work together in 1995, the two sides have organized various interfaith dialogue forums in Geneva, Tehran, Qom and other Iranian cities.“Our effort and goal are to build bridges between different faiths and that is our mission, too,” he added.“We think of displaying common values and consider it to be the way to realize interaction among faiths and religions,” Sauca went on to say.Ayatollah Ramazani, for his part, underlined the need for peaceful coexistence among followers of different faiths and rejection of a racist look at human beings.He referred to verses of the Quran and Hadiths from the Holy Prophet (PBUH) and said according to these teachings, there is no priority given to any race or skin color or language and that respecting all human beings is a necessity.He cited verse 13 of Surah Al-Hujurat “People, We have created you all male and female and have made you nations and tribes so that you would recognize each other. The most honorable among you in the sight of God is the most pious of you. God is All-knowing and All-aware,” and said only piety and Taqwa (God-fearing) is the criterion of one\'s superiority over another before God.The cleric also stressed working on common teachings of religions.He further said that efforts should be made to counter extremism and radicalism.Ayatollah Ramazani hailed a new phase of dialogue among religious leaders and called for efforts to develop it.Source: http://www.en.abna24.com/!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! November 13, 2021 - 9:18 AMAhlulBayt News Agency (ABNA): A number of scholars from Egypt’s Al-Azhar Islamic Center visited the holy mausoleum of Imam Ali (AS) in Najaf, Iraq.They were accompanied by several Iraqi Sunni scholars during the visit.The Egyptian scholars also met with the officials of the Astan (custodianship) of the holy shrine, according to the website of the Astan.At the meeting, they underscored the sublime status of Imam Ali (AS) as the manifestation of justice and humanity.The Egyptian scholars also said the holy sites in Iraq, including the Imam Ali (AS) holy shrine, can play a major role in promoting the spirit of fraternity and peaceful coexistence.In September, the grand imam of Al-Azhar said he plans to visit Iraq.Sheikh Ahmed el-Tayeb described Iraq as a “dear country” and highlighted the commonalities between the two countries.El-Tayeb said he will visit Baghdad, Najaf, Mosul and Erbil during his trip.According to the Iraqi embassy in Cairo, the arrangement have been made for the upcoming visit.Ahmed Nayef Al-Dulaimi the two sides have agreed on the arrangements.He added there will be extensive and important programs and activities during the Al-Azhar chief’s trip to Iraq.Source: http://www.en.abna24.com/!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Photo abna24.comBook “Tafsir of Holy Quran based on works of Imam Khomeini” published in Turkish June 7, 2021 - 6:56 AMAhlulBayt News Agency (ABNA): The book “Tafsir of the Holy Quran based on the works of Imam Khomeini” was translated and published in Turkish.The book “Tafsir of the Holy Quran based on the works of Imam Khomeini” was translated and published in Turkish, by Kowsar Publication Institute in Turkey and presented for enthusiasts.This book, which is a collection of Quranic materials and exegesis based on the works of Imam Khomeini, and has been compiled in five volumes, was translated into Turkish in collaboration in collaboration of the “Deputy for International Affairs of the AhlulBayt (a.s.) World Assembly” and the “The Institute for the Compilation and Publication of the Works of Imam Khomeini”.This exquisite five-volume collection was published in Istanbul in the winter of 2020 by the publications of the Kowsar Institute, which belongs to the Turkish Shiites, and is now available to the public.Source: http://www.en.abna24.com/!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! January 26, 2021 - 1:00 PMThe office of Grand Ayatollah Sayyid Ali Sistani, Shia prominent religious authority in Najaf, has answered some questions pertaining to the Coronavirus vaccine.AhlulBayt News Agency (ABNA): The office of Grand Ayatollah Sayyid Ali Sistani, Shia prominent religious authority in Najaf, has answered some questions pertaining to the Coronavirus vaccine.The following questions pertaining to the Coronavirus vaccine were sent to his Eminence Ayatollah Sayyid Ali Sistani (DZ) from The Islamic Education Department at the World Federation.Question 1: Vaccines against Coronavirus have already been manufactured by Pfizer, AstraZeneca & Moderna, and others are expected, or already on the market. The medical authorities of several countries have approved these vaccines and authorised mass vaccination programmes, despite some side effects. Some muqallideen are apprehensive about the vaccines’ potential side effects, as the testing & approval processes were expedited by the authorities, given the urgency of the pandemic. Some ethnic groups, based on previous negative experiences with mass vaccination programmes, are sceptical about these vaccines, although no serious side-effects have been observed in most cases. In such circumstances, what does His Eminence advise?Answer 1: In such circumstances, it is appropriate to rely on the advice given by experienced medical experts. As per Shari’ah, it is mandatory to use an approved vaccine in a situation when the probability of suffering from the Coronavirus infection, with its potentially life threatening and/or serious untreatable complications, far outweigh the probable serious side effects of getting vaccinated.Question 2: Governments have set up prioritisation programmes, so that high-risk groups are vaccinated first. This includes, the elderly, public safety officials and others at significant risk. Is it necessary to observe this prioritisation program, or is it permissible to jump the queue by paying money and get vaccinated earlier?Answer 2: It is not permissible to violate the prioritization scheme if its mandated by the law of the land.Question 3: Some developing countries may not have the financial means to procure and make available vaccines for all their citizens. If doctors recommend taking the vaccine, and if private funds do not suffice to procure, distribute and administer the vaccines inside and outside the Jamaat, would His Eminence grant permission to use religious funds for this purpose?Answer 3: In cases where necessary there is no objection.Question 4: If a vaccine manufacturer appeals for volunteers to participate in trials for vaccine efficacy and safety, can mu’mineen join the trial if the manufacturer gives assurance of careful monitoring and caution for the safety of the volunteers, though there may be risk of unexpected side-effects, which in some cases could be lethal?Answer 4: If it has potentially lethal or extremely serious untreatable complications, then it’s not allowed; unless the risk is low and negligible.Question 5: In order to stabilize the vaccine, manufacturers use several additives. Sometimes this can include porcine gelatine. Is it sufficient to rely on the manufacturers’ non-declaration, or declaration of non-usage of such gelatine? If there is a possibility of chemical transformation during the manufacturing process, is it necessary to investigate? If the amount of gelatine is not negligible, would emergency use to prevent a potentially life-threatening infection, justify its inoculation?Answer 5: In all (the above) circumstances there is no legal Shar’i objection.Seal of the Office of Agha Sistani (may his life be lengthened), Najaf e Ashraf.Source: http://www.en.abna24.com/!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!', 'Apologies, but no results were found for your request. Perhaps searching will help you to find a related content.', 'Mosque of Kūfa (Arabic: مسجد الکوفة) is a great mosque in the Islamic world. For Shi\'as, it is the fourth important mosque after al-Masjid al-Haram, al-Masjid al-Nabi, and Masjid al-Aqsa. It is also the oldest and the most important visiting place in Kufa. According to some hadiths, the first person who founded the Mosque of Kufa was Prophet Adam (a). It was reconstructed by Prophet Noah (a) after the storm. In 17/638, when Muslims first entered Kufa in the period of Sa\'d b. Abi Waqqas, the mosque was rebuilt together with the governmental building (Dar al-\'Imara) at the suggestion of Salman al-Farsi. The mosque has witnessed many prophets (a), Prophet Muhammad (s), Amir al-Mu\'minin (a), Imam al-Hasan (a), and Imam al-Husayn (a), and some other Imams (a). In 36/656-7 when Amir al-Mu\'minin (a) attended the mosque, it became much more important. He frequently led congregational prayers in this mosque, delivered sermons on its minbar, fulfilled some governmental and judiciary tasks there, and was finally martyred in its mihrab. The mausoleum of Muslim b. \'Aqil, the mausoleum of Maytham al-Tammar, the house of Amir al-Mu\'minin (a), the governmental building of Kufa, the mausoleum of Hani b. \'Urwa and al-Mukhtar al-Thaqafi\'s grave are located near the Mosque of Kufa. The mosque has in it a number of positions, in many of which some spiritual practices of the mosque are performed. Just as travelers have the option to say their prayers fully or in a shortened form in al-Masjid al-Haram, the Holy Shrine of Imam al-Husayn (a), and al-Masjid al-Nabi, they have the same option in the Mosque of Kufa as well. There are many hadiths regarding the merits of this mosque. According to some hadiths, the Mosque of Kufa is a garden of the Heaven. If one enters the Mosque of Kufa, one will be forgiven. Kufa will be the center of Imam al-Mahdi\'s (a) government, and the Mosque of Kufa will be the headquarter of his command. Kufa is a city in Iraq located in the south of the country, ten kilometers on the northeastern side of Najaf. The city was built near Euphrates, it has a temperate climate, and has for long been green. Kufa was first known as ""Suristan"". In 17/638-9, months after the construction of Basra, Sa\'d b. Abi Waqqas built Kufa at the command of the Second Caliph as a residence for soldiers and military forces as well as their families during conquests. Soon did Kufa turn into an important Islamic city. It underwent many events. The great mosque of the city in which Imam \'Ali (a) was martyred was built in this period. One of the oldest and most important visiting places in Kufa is the great Mosque of Kufa. The mosque is one of the greatest mosques in the Islamic world, and the fourth important mosque for Shi\'as (after al-Masjid al-Haram, al-Masjid al-Nabi, and al-Aqsa mosque). The Mosque of Kufa is with 110 meters of length, 101 meters of width, and has an area of 11162 square meters. Its walls are ten meters hight. The open courtyard of the mosque is 5642 square meters, and the area of its Shabistans is 5520 square meters. The number of its pillars is 187, and it has four minarets each 30 meters tall. The mosque has five gates called: ""Bab al-Hujja"" (the main entrance), ""Bab al-Thu\'ban"", ""Bab al-Rahma"", ""Bab Muslim b. \'Aqil"", and ""Bab Hani b. \'Urwa"".[1] According to some hadiths, the construction of the mosque dates back to Prophet Adam (a).[2] It was later reconstructed by Prophet Noah (a) after the storm.[3] In 17/638, the Islamic army was in al-Mada\'in. Al-Mada\'in\'s weather was so terrible for soldiers from Hijaz that they became weak and thin. Thus, Hudhayfa b. Yaman wrote a letter to \'Umar b. al-Khattab and informed him about the situation. The Caliph wrote to Sa\'d b. Abi Waqqas to ""send Salman and Hudhayfa to find a convenient place [for soldiers]"". When they received the Caliph\'s letter, Salman and Hudhayfa departed from al-Mada\'in: Salman departed from the western bank of Euphrates and Hudhayfa departed from its eastern bank. They did not like any land until they arrived in Kufa. They both found the land appropriate as a residence for the army. They said two rak\'as of prayer and asked God to make the place peaceful and stable.[4] When Sa\'d b. Abi Waqqas and his army arrived in Kufa, he ordered the construction of a mosque before making any other constructions. Abu Hayja\' al-Asadi[5] stood in a place and threw arrows to all directions in order to specify the area of the Mosque of Kufa.[6] The Mosque of Kufa was, since its construction, a cultural center of the city. When Imam \'Ali (a) arrived in Kufa in 36/656, he first went to the Mosque of Kufa and delivered a speech for people there. After settling in Kufa, the Imam (a) taught the exegesis of the Qur\'an and other sciences in the mosque. Many people attended his lectures in this mosque, such as Kumayl b. Ziyad and \'Abd Allah b. \'Abbas.[7] Asbagh b. Nubata says: addressing people of Kufa, Amir al-Mu\'minin (a) referred to the Mosque of Kufa as ""the house of Adam (a), place of Noah (a), residence of Idris (a), worshiping place of Ibrahim (a) and my brother, Khidr (a)"" and ""one of the four mosques selected by God for His people"". The Imam (a) also predicted that the Black Stone (al-Hajar al-Aswad) will be installed in this mosque. There will be, he said, a time when the mosque will be the worshiping place of Imam al-Mahdi (a) and every believer.[8] There are places in this mosque which are attributed to prophets (a) or prominent religious figures. These are called ""Maqam"" (position). Some recommended prayers or practices are recommended for some of these positions. There are recommended practices for the Mosque of Kufa, including ziyara, prayers, and specific supplications mentioned in the practices of the Mosque of Kufa in Mafatih al-jinan. According to a number of hadiths, Kufa will be the center of the global government of Imam al-Mahdi (a). Mufaddal b. \'Umar asked Imam al-Sadiq (a) about where Imam al-Mahdi (a) will govern. He replied: the center of his government will be Kufa, his governmental building will be the Great Mosque of Kufa, and his treasury (and the place where booties of wars will be distributed) will be the al-Sahla Mosque.[30]', '']","The four holiest sites to Muslims are Mecca (Al-Haram Mosque), Medina (Al-Nabbawi Mosque), Jerusalem (Al-Aqsa Mosque), and Kufa (Kufa Mosque). In addition for Shias, the Imam Husayn Shrine, Al Abbas Mosque in Karbala, and Imam Ali Mosque in Najaf are also highly revered."
where did the term shooting brake come from,"['', '']","""Shooting-brake"" originated as an early 19th century British term for a vehicle used to carry shooting parties with their equipment and game. The etymology of the term brake is uncertain; initially a chassis used to break in horses, and subsequently used to describe a motorized vehicle. It is also possible, that the word' brake' has its origins in the Dutch word' brik' which means' cart' or' carriage'."
where did the tradition of carving pumpkins start,"['A Jack-o’-lantern is a carved pumpkin or similarly-sized gourd\xa0or turnip, associated chiefly with the holiday of Halloween, and was named after the phenomenon of strange light flickering over peat bogs, called will-o’-the-wisp or jack-o’-lantern. In a jack-o’-lantern, the top is cut off to form a lid, and the inside flesh is then scooped out; an image, usually a monstrous face, is carved out of the pumpkin’s rind to expose the hollow interior. To create the lantern effect, a light source is placed within before the lid is closed,\xa0traditionally a candle flame. It is common to see jack-o’-lanterns on doorsteps and otherwise used as decorations during Halloween. The term jack-o’-lantern is in origin a term for the visual phenomenon ignis fatuus (literally, “foolish fire”) known as a will-o’-the-wisp in English folklore. Used especially in East Anglia, its earliest known use dates to the 1660s.\xa0The term “will-o’-the-wisp” uses “wisp” (a bundle of sticks or paper sometimes used as a torch) and the proper name “Will”: thus, “Will-of-the-torch.” The term jack-o’-lantern is of the same construction: “Jack of [the] lantern.” The carving of root vegetables may appear to be a way of utilising usually unwanted oversized harvest but records of Man performing this task date back hundreds, if not thousands of years.\xa0Gourds were used to carve lanterns by the Maori over 700 years ago,\xa0with the Māori word for a gourd also used to describe a lampshade.\xa0There is a common belief that the custom of carving jack-o’-lanterns at Hallowe’en originated in Ireland, where turnips, mangelwurzel or beetroot\xa0were supposedly used. The carvings were said to represent spirits or goblins around the festival of Samhain. Conversely, other theories suggest they were simply ornate lanterns or even perhaps the representation of souls stuck in purgatory. Although study into Irish folklore has found no specific records of turnip lanterns, English accounts record something very similar, turnips being used to carve what was called a “Hoberdy’s Lantern” in Worcestershire at the end of the 18th century. These were placed randomly atop hedgerows to ward off ne’er-do-well travellers. More precise accounts are recorded from the early 1800s across Europe but in particular, the British Isles, Scandinavia, Germany, Italy and Spain. Irish tales speak of\xa0Stingy Jack, also known as Jack the Smith, Drunk Jack, and Jack of the Lantern, a character always associated with All Hallows Eve. It is common lore that the “jack-o’-lantern” is derived from the Jack of this legend. The most repeated account tells of a\xa0drunkard known as “Stingy Jack”, known throughout the land as a deceiver, manipulator and otherwise dreg of society. On a fateful night, the devil overheard the tale of Jack’s evil deeds and silver tongue. Unconvinced (and envious) of the rumours, the devil went to find out for himself whether or not Jack lived up to his vile reputation. Lo’, the inevitably drunken Jack staggered home one night and found\xa0a body on his cobblestone path. The body with an eerie grimace on its face turned out to be Satan. Jack realised this was his end; Satan had finally come to collect his malevolent soul. Jack made a last request: he asked Satan to let him drink ale\xa0before he departed to Hades. Finding no reason not to acquiesce the request, Satan took Jack to the local pub and supplied him with many alcoholic beverages. Upon quenching his thirst, Jack asked Satan to pay the tab on the ale, to Satan’s surprise. Jack convinced Satan to metamorphose into a silver coin with which to pay the bartender (impressed upon by Jack’s unyielding nefarious tactics). Shrewdly, Jack stuck the now transmogrified Satan (coin) into his pocket, which also contained a crucifix. The crucifix’s presence kept Satan from escaping his form. This coerced Satan to agree to Jack’s demand: in exchange for Satan’s freedom, he had to spare Jack’s soul for ten years. Ten years later to the date when Jack originally struck his deal, he found himself once again in Satan’s presence. Jack happened upon Satan in the same setting as before and seemingly accepted it was his time to go to Hades for good. As Satan prepared to take him to Hades, Jack asked if he could have one apple to feed his starving belly. Foolishly Satan once again agreed to this request. As Satan climbed up the branches of a nearby apple tree, Jack surrounded its base with crucifixes. Satan, frustrated at the fact that he been entrapped again, demanded his release. As Jack did before, he made a demand: that his soul never be taken by Satan into Hades. Satan agreed and was set free. Eventually, the drinking and unstable lifestyle took its toll on Jack; he died the way he lived. As Jack’s soul prepared to enter Heaven through the gates of St. Peter he was stopped. Jack was told by God that because of his sinful lifestyle of deceitfulness and drinking, he was not allowed into Heaven. The dreary Jack went before the Gates of Hades and begged for commission into the underworld. Satan, fulfilling his obligation to Jack, could not take his soul. To warn others, he gave Jack an ember, marking him a denizen of the netherworld. From that day on until eternity’s end, Jack is doomed to roam the world between the planes of good and evil, with only an ember inside a hollowed turnip (“turnip” actually referring to a large swede) to light his way. On a very basic level, Jack o’ lanterns were also a way of protecting your home against the undead. Superstitious people used them specifically to ward away vampires\xa0as\xa0it was said that the Jack-o-lantern’s light was a way of identifying the fiends\xa0and, once their identity was known, would give up their hunt for you. The American tradition of carving pumpkins (chosen because of their profusion and bright colour) is first recorded in 1837\xa0and was originally associated with harvest time in general, not becoming specifically associated with Halloween until later in the 19th century. The tradition of carving pumpkins is still largely associated with the USA and Americans have concocted many recipes to ensure masses of gigantic orange vegetables do not go to waste. As global trends spread, pumpkin carving is rapidly becoming a must around the world too… The carving of pumpkins has progressed from a craggy-toothed will-this-do effigy to a true art-form.\xa0Popular figures, symbols, and logos are now seen used on pumpkins, a\xa0variety of tools used to carve and hollow out the gourd, ranging from simple knives and spoons to specialised instruments. Candles are sometimes replaced with electric light of various colours to enhance the end result. So competitive has the pursuit become that pumpkins are sometimes grown into moulds so that usually impossible creations can be attempted. All US releases unless stated.', 'This is the time of year when the weather has started getting progressively worse, when the first of salvos the annual bombardment of Christmas adverts begin, and of course when people dress up as miscellaneous undead and carve Jack-o-lanterns for Halloween. In the liturgical calendar Halloween is a time to remember the dead, in particular the saints (the hallowed) and martyrs. This kind of festival is done all over the world. In Japan the day of the dead occurs on the 15th of August (or July), the bon\xa0festival where the spirits of the ancestors return to the world of the living. Often a candle is put outside the front door so that your forebears can find their way home. This is similar to the idea behind the jack-o-lantern which acts as the reverse of the Japanese tradition, it is used to ward away the evil spirits. The legend behind the jack-o-lantern tells the story of an Irishman called Stingy Jack, a drunk, deceiving and manipulating all-round dreg of society. Jack’s bad reputation became the envy of the Devil himself, who subsequently went out to see for himself if Jack was as bad as he had heard. One night Jack was stumbling through the countryside, typically drunk. At one point he came across a body on the cobblestone path, its face contorted in an eerie grimace. Jack eventually, and surprisingly soberly, realized that the corpse was, in fact, the Devil, come to collect his evil soul. Jack pleaded one last request, that he be allowed one last drink of ale. Seeing no reason to refuse the Devil took Jack to a nearby pub and ordered several rounds of ale which Jack duly consumed. Once Jack had slaked his thirst he told the Devil to pay the bill. Somewhat taken \xa0aback, and presumably lacking in money, the Devil decided that the best course of action was to turn himself into a silver coin for Jack to give to the bar keeper. Jack, however, put the silver coin into his pocket, which also contained a crucifix. Trapped by the power of the cross the devil could not turn himself back. Foiled by Jack’s cunning the Devil had no choice but to agree to Jack’s demand, namely to spare his soul for the next ten years. The bar man presumably was never paid. Ten years later to the day and the Devil returned to collect Jack’s soul. However, the Devil had clearly forgotten the cunning Irishman’s previous trick. Jack had another final request. He claimed that he was starving and asked if the Devil would pick him an apple from a nearby tree. Foolishly the Devil acquiesced and climbed up the tree. At this point Jack surrounded the base of the tree with crucifixes, thereby trapping the Devil yet again. This time, to bargain for his freedom, the Devil was forced into declaring that he would never lay claim to Jack’s soul ever again. That would seem to have been the end of the matter. However, soon after Jack’s binge drinking caught up with him and his soul appeared before St Peter at the Pearly Gates of Heaven. St Peter reminded Jack of his sinful life and that in view of the multitude of transgressions Jack would not be allowed into Heaven. Seeing no alternative Jack went to the Gates of Hell and begged the Devil to let him in. The Devil, true to his previous promise, also refused Jack entry. Jack was cursed to roam the world for eternity, and to warn others he was given an ember from Hell that never died. Jack placed this ember in a hollowed out turnip to use as a lantern to light his way, becoming known as Jack of the Lantern. The earliest account of this story comes from the 19th century and explains the name jack-o-lantern.The origin of the tradition of lantern carving is somewhat more uncertain. The practice of carving vegetables in this manner is virtually universal, it is likely that carving gourds has been happening for thousands of years. The Maori people even used to carve gourds to use as lanterns 700 years ago, the Maori word for gourd is also used to describe a lamp-shade. \xa0In Ireland, where the jack-o-lantern tradition is said to have originated, turnips and beetroots were carved into faces on All Saints’ Day (November 1st) to represent the people in purgatory, ward away evil spirits and to guide the guisers (trick-or-treaters). The tradition of a carved pumpkin came much later, at the end of the 19th century. Predictably it came from the United States where the pumpkin had long been a symbol of the harvest season. Originally the pumpkin had primarily been a thing reserved for Thanksgiving. An article from 1900 regarding Thanksgiving entertainment even suggested having a lit jack-o-lantern as part of the festivities. The first recorded use of a pumpkin as a jack-o-lantern with regards to Halloween was in 1866. Since then it has become the norm with sales of pumpkins booming in the days proceeding Halloween. Of course, today they are not only used to depict scary faces but also to display artistic talent (the most impressive that I have seen this year was a really detailed carving of King Kong’s face). Enter your email address to follow this blog and receive notifications of new posts by email. Notify me of new comments via email. Notify me of new posts via email. Enter your email address to follow this blog and receive notifications of new posts by email.', 'Adapt these activities to the age, interest, and skill levels of your group. Gourd crafting may be the perfect way for you to get creative while still connecting with the fruits of your garden harvest! Over the centuries, gourds have been adapted from simple utilitarian use to incredible works of art. As a result, gourd crafting has become important to cultures around the world especially in South America and Africa, and increasingly as a popular hobby in North America. Gourds provide a 3-dimensional canvas that is very versatile in its shape, size, and use. You can cut, carve, paint, and embellish them with natural materials such as stone, feathers, plants, etc. The end result can be both functional and ornamental.\xa0 There is a saying in the gourd craft world that “if the artist can ‘think it’, then the gourd can ‘be it’!” Have a question on specific gardening programs in your community? Find your local Cornell Cooperative Extension Office. Not from New York? Find your state’s extension office here. Our Master Gardener Program is part of a nationwide network of volunteers.\xa0 Learn more.']","The carving of vegetables has been a common practice in many parts of the world, and gourds were one of the earliest plant species domesticated by humans c. 10,000 years ago. For example, gourds were used to carve lanterns by the Maori over 700 years ago; the Māori word for a gourd also describes a lampshade."
what are the national archives in washington dc,"['Located north of the National Mall on Constitution Avenue, opened in 1935. It holds the original copies of the Declaration of Independence, the Constitution, and the Bill of Rights. It also hosts a copy of the 1297 Magna Carta confirmed by Edward I. These are displayed to the public in the Rotunda for the Charters of Freedom. The National Archives Building also exhibits other important American historical documents such as the Louisiana Purchase Treaty, the Emancipation Proclamation, and collections of photography and other historically and culturally significant American artifacts. And book your tour now. Don’t miss out on the best guides and prices. We welcome special requests. Contact Us now and we’ll answer your questions, offer personalized suggestions, and arrange your tour to fit your schedule and budget.', 'The National Archives and Records Administration is the nation’s record keeper. Many people know the National Archives as the custodian of the Declaration of Independence, the Constitution, and the Bill of Rights – the three main formative documents of the U.S. and its government. It is also the keeper of a copy of the Magna Carta, confirmed by Edward I in 1297. Other important historical documents maintained at the National Archives include the Louisiana Purchase Treaty, the Emancipation Proclamation, and collections of photography, art works, and other historically and culturally significant artifacts.\xa0 But they also maintain the public records about and for ordinary American citizens, such as textual and microfilm records relating to genealogy, census data, American Indians, the District of Columbia, maritime matters, charts, architectural and engineering drawings, and the records of the U.S. Congress and all Federal government agencies. Opened as its original headquarters in 1935, the U.S. National Archives and Records Administration Building is located approximately halfway between The White House and the U.S. Capitol Building, between 7th and 9th Streets at 700 Pennsylvania Avenue (MAP) in downtown D.C. Known informally as Archives I, the building has entrances on Pennsylvania Avenue and on Constitution Avenue just north of the National Mall. Designed by architect John Russell Pope, the National Archives and Records Administration building was intended to be on par with the other national monuments and symbols on the National Mall. The massive building covers two full city blocks, and is among the most impressive and architecturally striking buildings on the National Mall. During the cornerstone ceremony conducted in 1933, President Herbert Hoover stated, “This temple of our history will appropriately be one of the most beautiful buildings in America, an expression of the American soul.” The National Archives building is highly decorated with pediments, sculptures, medallions, and classical carvings. Imbedded in its size and beauty, the building has specific messages and symbolism in the inscriptions that encircle the building, and the sculptures that surround it. The inscriptions declare the building’s goals. On the west side of the building is inscribed, “The glory and romance of our history are here preserved in the chronicles of those who conceived and builded the structure of our nation.” The inscription on the east side of the building states, “This building holds in trust the records of our national life and symbolizes our faith in the permanency of our national institutions.” And the south side inscription reads, “The ties that bind the lives of our people in one indissoluble union are perpetuated in the archives of our government and to their custody this building is dedicated.” The four massive statues around the National Archives building were each was cut from a single block of limestone weighing 125 tons. Sculptor Robert I. Aitken’s statue “The Future” sits on the Pennsylvania Avenue side of the building to the left of the main entrance. The young woman appears to lift her eyes from the pages of an open book and gaze into the future. Its base is inscribed with a line inspired by Shakespeare’s play The Tempest: “What is Past is Prologue.” To the right of the main entrance is another sculpture by Aitken, entitled “The Past,” which depicts an aged figure with a scroll and closed book imparting the knowledge of past generations.”\xa0 The words on the base enjoin, “Study the Past.” To the rear of the building on Constitution Avenue sit “Heritage” and “Guardianship,” both sculpted by James Earle Fraser. Heritage is located to the right of the entrance, and depicts a woman who holds a child and a sheaf of wheat in her right hand as symbols of growth and hopefulness. In her left hand she protects an urn, symbolic of the ashes of past generations. The base is inscribed, “The Heritage of the Past is the Seed that Brings Forth the Harvest of the future.” And finally, “Guardianship,” to the left of the rear entrance, uses martial symbols, such as the helmet, sword, and lion skin to convey the need to protect the historical record for future generations. This sculpture is inscribed “Eternal Vigilance is the Price of Liberty.” A visit to the National Archives can be very productive in terms of research and information. But the building itself can make a visit worthwhile, even if you don’t go inside. Excellent post, full of good information.  Thanks very much. Notify me of new comments via email. Notify me of new posts via email. Enter your Email address to follow this blog and receive notifications of new posts.', ""7.0 hour ...s and visit the US Capitol Building and National Archives Building at the end of a guided sightseeing tour. Take a boat ... 2.0 hour Enjoy a 2-hour guided highlights tour of the National Archives, introducing you to the original pape... 5.0 hour Come face to face with history on this 5-hour combo highlights tour, mixing the best of the National... Take a stroll along Washington's Pennsylvania Avenue and discover the home of American presidents an... ... 2 to 2.5 hrs ... ... ... 5 to 5.5 hrs ... 5 to 5.5 hrs ... 8.5 hour Explore the best of Washington, DC on this small-group 8-hour tour including a reserved entrance to ... 4.5 hour Explore iconic landmarks with an expert guide on this 4.5-hour tour. Visit the Capitol Building, the... Enjoy a 90-minute panoramic trolley tour of Washington, DC with one stop.<br>The tour route will max... The National Archives preserves documents of national and historical importance such as the Declaration of Independence, the Constitution, the Bill of Rights, an original version of the 1297 Magna Carta, Articles of Confederation, the Louisiana Purchase Treaty, the Emancipation Proclamation, declassified top secret documents related to the Cold War, and collections of photography and other historically and culturally significant American artifacts. The National Archives preserves documents of national and historical importance such as the Declaration of Independence, the Constitution, the Bill of Rights, an original version of the 1297 Magna Carta, Articles of Confederation, the Louisiana Purchase Treaty, the Emancipation Proclamation, declassified top secret documents related to the Cold War, and collections of photography and other historically and culturally significant American artifacts. It is a must-visit for history buffs and political science enthusiasts.Start your visit from the Orientation Plaza which provides an introduction to the Archives. The ground floor also has the David M Rubenstein Gallery which houses the 'Records of Rights', a permanent exhibition that explores the rights and freedoms granted by the nation's founding documents and the evolution of constitutional rights of citizens. Its highlight is the Magna Carta.The upper level has the main Rotunda for the Charters of Freedom, which displays the Declaration of Independence housed in a hermetically sealed humidity-controlled encasement filled with inert argon. Also on display here are the United States Constitution, and the Bill of Rights. The Faulkner Murals on the walls, which depict fictional scenes of the presentation of the Declaration of Independence and the Constitution, are among the largest single-piece oil-on-canvas murals in the country. Around the Rotunda are the Public Vaults, home to historic original records of importance such as Abraham Lincoln’s telegrams to his generals, and the 1823 copperplate of the Declaration of Independence. The National Archives preserves documents of national and historical importance such as the Declaration of Independence, the Constitution, the Bill of Rights, an original version of the 1297 Magna Carta, Articles of Confederation, the Louisiana Purchase Treaty, the Emancipation Proclamation, declassified top secret documents related to the Cold War, and collections of photography and other historically and culturally significant American artifacts. It is a must-visit for history buffs and political science enthusiasts. Start your visit from the Orientation Plaza which provides an introduction to the Archives. The ground floor also has the David M Rubenstein Gallery which houses the 'Records of Rights', a permanent exhibition that explores the rights and freedoms granted by the nation's founding documents and the evolution of constitutional rights of citizens. Its highlight is the Magna Carta. The upper level has the main Rotunda for the Charters of Freedom, which displays the Declaration of Independence housed in a hermetically sealed humidity-controlled encasement filled with inert argon. Also on display here are the United States Constitution, and the Bill of Rights. The Faulkner Murals on the walls, which depict fictional scenes of the presentation of the Declaration of Independence and the Constitution, are among the largest single-piece oil-on-canvas murals in the country. Around the Rotunda are the Public Vaults, home to historic original records of importance such as Abraham Lincoln’s telegrams to his generals, and the 1823 copperplate of the Declaration of Independence. www.archives.gov Trip planning takes time. Create a new account or login to your existing account and save your trip details."", 'The United States National Archives and Records Administration (NARA) is an independent agency of the United States federal government charged with preserving and documenting government and historical records. It is also charged with increasing public access to those documents. NARA is officially responsible for maintaining and publishing the legally authentic and authoritative copies of acts of Congress, presidential proclamations and executive orders, and federal regulations. The chief administrator of NARA, the Archivist of the United States, not only maintains the official documentation of the passage of amendments to the U.S. Constitution by state legislatures, but has the authority to declare when the constitutional threshold for passage has been reached, and therefore when an act has become an amendment. NARA has been active in digitizing their holdings to make them easily accessible to the public. Since 2006, NARA collaborated with Google, Footnote, and CreateSpace to foster its digitization projects which include digitization of historical films and photos as well as documents. Originally, each branch and agency of the U.S. government was responsible for maintaining its own documents, which often resulted in the loss and destruction of records. Congress established the National Archives Establishment in 1934 to centralize federal record keeping, with the Archivist of the United States as its chief administrator. The National Archives was incorporated into the General Services Administration in 1949, but, in 1985, it was made an independent agency as NARA. Most of the documents in the care of NARA are in the public domain, as works of the federal government are excluded from copyright protection. However, some documents that have come into the care of NARA from other sources may still be protected by copyright or donor agreements.[1] NARA also stores classified documents and its Information Security Oversight Office monitors and sets policy for the U.S. government\'s security classification system. NARA\'s holdings are classified into ""record groups"" reflecting the governmental department or agency from which they originated. The records including paper records, microfilmed records, still pictures, motion pictures, and electronic media. Many of NARA\'s most requested records are frequently used for research in genealogy. This includes census records from 1790 to 1930, as well as ship passenger lists and naturalization records. As the nation’s record keeper, it is our vision that all Americans will understand the vital role records play in a democracy, and their own personal stake in the National Archives. Our holdings and diverse programs will be available to more people than ever before through modern technology and dynamic partnerships. The stories of our nation and our people are told in the records and artifacts cared for in NARA facilities around the country. We want all Americans to be inspired to explore the records of their country.[2] The National Archives and Records Administration serves American democracy by safeguarding and preserving the records of our Government, ensuring that the people can discover, use, and learn from this documentary heritage. We ensure continuing access to the essential documentation of the rights of American citizens and the actions of their government. We support democracy, promote civic education, and facilitate historical understanding of our national experience.[2] The National Archives Building, known informally as Archives I, located north of the National Mall on Constitution Avenue in Washington, DC, opened as its original headquarters in 1935. It holds the original copies of the three main formative documents of the United States and its government: the Declaration of Independence, the Constitution, and the Bill of Rights. It also hosts the Magna Carta confirmed by Edward I in 1297.[3] These are displayed to the public in the main chamber of the National Archives, which is called the Rotunda for the Charters of Freedom. Flash photography of the documents is prohibited, because the flashes can over time fade out the documents. There are no lines to see individual documents (although there is a line to reach the rotunda itself) at the National Archives, and visitors are allowed to walk from document to document as they wish. The National Archives Building also exhibits other important American historical documents such as the Louisiana Purchase and the Emancipation Proclamation, as well as collections of photography and other historically and culturally significant American artifacts. Due to space constraints, NARA opened a second facility, known informally as Archives II, in 1994 near the University of Maryland, College Park campus. The two institutions engage in multiple initiatives.[4] There are ten Affiliated Archives locations across the US which hold, by formal, written agreement with NARA,""[5] accessioned records. There are also fourteen Regional Archives facilities across the country with available research rooms and two major facilities in St. Louis, Missouri which comprise the National Personnel Records Center. However, the National Archives Building in downtown Washington still contains such record collections as all existing Federal Census records, Ship Passenger Lists, military unit records from the American Revolution up to the Philippine-American War, records of the Confederate Government, the Freedmen\'s Bureau records and pension/land records. NARA also maintains the Presidential Library system, a nationwide network of libraries for preserving and making available the documents of U.S. presidents since Herbert Hoover. The Presidential Libraries include: Libraries and museums have been established for other presidents, but they are not part of the NARA presidential library system, and are operated by private foundations, historical societies, or state governments, including the William McKinley, Rutherford Hayes, Calvin Coolidge, Abraham Lincoln and Woodrow Wilson libraries. For example, the Abraham Lincoln Presidential Library and Museum is owned and operated by the State of Illinois. The National Archives maintains a Nixon Presidential Materials Project at its Archives II facility in College Park, Maryland. The ""Nixon Project"" is currently (2007) transferring all of their materials to the newly-opened Richard Nixon Presidential Library & Museum in Yorba Linda, California. In March 2006, it was revealed by the Archivist of the United States in a public hearing that a memorandum of understanding between NARA and various government agencies existed to ""reclassify,"" i.e withdraw from public access, certain documents in the name of national security, and to do so in a manner such that researchers would not be likely to discover the process.[6] The National Archives aims to make its holdings more widely available and more easily accessible by entering into public-private partnerships. In 2006, NARA announced a joint-venture with Google to digitize and offer NARA video online. This pilot program represents an evolutionary step for the National Archives to achieve its goal of becoming an archives without walls, as explained in the NARA press release. This innovative partnership is just one step in a strategic plan which emphasizes the importance of providing access to records anytime, anywhere. This is one of many initiatives that NARA is launching to expand opportunities for the public to be able to view NARA\'s collections.[7] In early 2007, the National Archives and Footnote launched a pilot project to digitize historic documents. The NARA press release explained that this partnership will allow much greater access to approximately 4.5 million pages of important documents that are currently available only in their original format or on microfilm. No less important, the digitization of documents will also enhance NARA\'s efforts to preserve its original records.[8] In late 2007, the National Archives announced it would make thousands of historical films available for purchase through CreateSpace (an Amazon.com subsidiary) which specializes in on-demand distribution of DVDs, CDs and books. The NARA press release emphasized the potential benefits for the public-at-large and for the National Archives. At NARA facilities, the public can continue to view films and even copy them at no charge; this new program will make NARA\'s holdings much more accessible to those who cannot travel to the Washington, DC area. At the same time, the NARA-CreateSpace partnership will provide the National Archives with digital reference and preservation copies of the films as part of NARA\'s preservation program.[9] The Archivist of the United States is the chief official overseeing the operation of the National Archives and Records Administration. The first Archivist, R.D.W. Connor, began serving in 1934, when the National Archive was established by Congress. The Archivists served as subordinate officials in other government agencies until the National Archives and Records Administration became an independent agency on April 1, 1985. Allen Weinstein is now serving as the ninth Archivist, having been sworn in on February 16, 2005. The Archivist is responsible for safeguarding and making available for study all important public documents of the nation, including the actual Declaration of Independence, the Constitution and the Bill of Rights, which are displayed in the Archives\' main building in Washington, D.C.. Under Public Law No. 98-497, the Archivist also must maintain custody of state legislative ratifications of amendments to the United States Constitution and proclaim a particular amendment duly ratified and part of the Constitution, if the legislatures of at least three-quarters of the states approve the proposed amendment. Thomas Edison\'s Patent Application For an incandescent light bulb, 1880. Immigrants Landing at Ellis Island, 1990s. Last lifeboat arrived, filled with Titanic survivors. This photograph was taken by a passenger of the Carpathia, the ship that received the Titanic\'s distress signal and came to rescue the survivors. It shows the last lifeboat successfully launched from the Titanic, 1912. Caption from original: Helen Keller Christens a United States Emergency Fleet ship launched in the Los Angeles harbor. The newly completed ship was the twelfth boat launched by the Los Angeles Shipbuilding & Dry Dock Company. Central News Photo Service., ca. 1918. Declaration of Intention for Albert Einstein. Series: Petitions for Naturalization, 01/1931 - 11/1988. A few of the thousands of wedding rings the Germans removed from Holocaust Victims to salvage the gold. The U.S. troops found rings, watches, precious stones, eyeglasses, and gold fillings, near Buchenwald concentration camp, 1945. George and Barbara Bush with their first born child George W. Bush, while Bush was a student at Yale, ca. 1947 Apollo 11 Flight Plan, 1969. All links retrieved November 10, 2022. Note: Some restrictions may apply to use of individual images which are separately licensed.', '', 'Just Talking 7.info SEARCHING FOR SOLUTIONS, and identifying problems AMONG OURSELVES/ as we the people. Living, is a foundation dedicated to peace and harmony; as that is its price. Therefore the best, of all we can become, is based upon the lessons and realities of love, respect, value, and hope. Love gives each, the freedom of happiness, the essence of all that sharing and caring can be. Respect forms the basis of every foundation, every claim of a right, every justified relationship governed by the disciplines of order, that are balanced by the equality of me and you. Value is the framework or structure of a life building a home, shaped by the decisions which define who and what we are, or will become by the expressions of our own truth, validated by the consequences of what we choose. Hope stands on the balance of what we value, to ascend beyond time, as our relationship with life grows into the creation of our own thought achieves “home”; the values which ascend into soul, as our gift back to life. In the constant of human life, is the need for money to exchange our work and potential resource/ for what we need that somewhat else might provide. Without the gain of property possession, in this world as it is today:\xa0 there is no going to someplace new, because everything is essentially claimed by someone already there. That is the crisis of overpopulation. Therefore we must talk and consider what can be done to neutralize the competition of overpopulation, and gain control over the planet as one people, rather than a few rulers in charge of everything. To begin that discussion, requires us all to recognize the most critical liar in our world is “numbers”! Not because they can measure things that exist/ but because they can be used to create fantasies, which do not exist. Such as currency. The extreme delusion of American currency is one such example. We must examine history to conceive of what is the constant, that continues to go wrong under the direction and guidance of men? The answer is simple:\xa0 whenever resources are not plentiful/ whenever some men find themselves without, what they want/ whenever the cold or laziness or illness arise, and they just don’t want to work. They then attack the other men to take whatever it is, the other one had gained; whether women or money or property or whatever. That led to war, as populations rose. History then places governments to control the raiders, so larger armies of men must be gathered to take whatever war can bring. That requires a bribe, and money erupts as the value upon which men will risk their lives/ or build weapons; \xa0to capture a prize for someone else. The more money you can offer, the greater the army you will raise. In today’s world, N. Korea has a large army by force: “we will kill you”/ as is the constant of war on life. So the second critical question is how do we then destroy that threat/ thief (stealing lives)? The third development is more basic:\xa0 governments exist because of excess money; the wealthy exist, because the mass of humanity will confiscate and destroy every resource without mercy. Therefore the wealthy exist to control the resources, so that only a few can be horrific to the environment of this world. That means power over the people themselves MUST accompany any terms of change that will provide peace and harmony. We start with the obvious:\xa0 so many threats of extinction for us all exist that must be dealt with/ or nothing else matters whatsoever. Consequently look at my sites which begin with www.justtalking7.info to get a view of at least the worst. Then understand:\xa0 fix them NOW, or die, is our literal ONLY option. DISCARDING THAT, we assemble conclusions for the far less threat of economic chaos, and powerful governments by understanding: \xa0IT IS THE EXCESS MONEY, OR, an extreme need/ want; that makes people powerful enough to organize armies against the rest. Therefore by removing the excess money, we also remove the power to organize or maintain a major army. Fear is the placement of power over the rest by weapons and a desire to use them to kill/ maim/ or imprison. Without excess money, or the ability to control critical resources:\xa0 there is no real power, and participation under the terms of “together we decide” as in democracy occurs.\xa0 LIMITED CAPITALISM deters and destroys the excess money, and control over resources/ by limiting the ability to collect it again, through our own power as WE THE PEOPLE; through our vote. Three things make that possible:\xa0\xa0 we vote only for ourselves/ NOT, for someone to vote for me! That is simply the playground for “lies/ traitors/ thieves/ and tyranny”; it is NO real vote. We vote on the maximum income any individual can earn in a year/ and also the minimum income any worker shall be paid:\xa0 the law is divided into three variables:\xa0 the constitutional preamble (the right of law)/ first amendment redress of grievances (our right to demand a legal accounting, from our employees/ and eminent domain (nation first). \xa0We must vote periodically so as to protect ourselves, from the intellectual parasite. We must vote on the laws that govern our society ourselves, and make NOT more than one hundred “simple as possible” laws that do cover everything. The ten commandments is an example/ as are the constitutional amendments. OUR INDIVIDUAL VOTE on the power that controls our nation, then gives us OUR POWER, over those who rule. Because they are only citizens like us; and they are subject to our laws. WE ARE THE ARMY, ETC! therefore the substance of that truth is:\xa0 WE WILL decide for ourselves who has the power. OUR OWN LAWS, OUR OWN DECISIONS/ or those who want power, and threaten torture, poverty, and mayhem over us. BY CHOOSING limited capitalism we choose to control and limit the numbers of our society to conceive of what is true, for our reality. In that way we take over, and become our government as we the people! To accomplish that:\xa0 THERE MUST BE A TRUE ACCOUNTING, hidden from no one! THERE MUST BE a currency supply that is tied to the population count;\xa0 “so many numbers per citizen”. There must be an international currency that is tied to something real; such as gold. Being careful to prosecute those who allow, what is now counterfeiting gold & silver currency in public view; so as to remove their value and keep their fantasy of numbers/ they’re power control and enslave us, \xa0from view. IT IS AGAIN,\xa0 WORLD LAW, that provides the solution to destroy immense armies and their extreme weapons. By creating the laws as we the people of this world, OVER OUR LEADERS; simple and plain. We take their threat away, and define our world with our own version of justice and truth instead. World law means:\xa0 when we the people of this world gather as one and demand “our rulers” SHALL, OR SHALL NOT; be allowed to do these very things. We then have created the power of law over our world. To enforce that law, there must be an elite team of soldiers that are formed from every nation on earth into one army; so as to control the rulers themselves. That law will be limited to enforcement on rulers, and it will include the critical truths required to sustain and protect ALL life on earth. ONCE the world army is established:\xa0 they will bring any ruler that is deemed outside the law/ BACK to our courtroom, where the law we made will judge them. Death is not precluded/ and neither is assassination where it proves to difficult or dangerous to collect that leader from ANY NATION on earth. This army shall be located on ships, and as needed throughout the world/ but its numbers shall be limited; and there SHALL BE an entire repopulation of that army, leaders and all: \xa0not less than every twelve years. Munitions and the like, shall in fact be divided among nations, so that NO threat will emanate from our own army.\xa0 With this truth in place:\xa0 ALL WEAPONS OF MASS DESTRUCTION shall be surrendered, each proving it is so as “fair and disciplined prove it is so”. Failure to respect that ultimatum, will result in your torture, and death!\xa0 This method is the elimination of power over us/ by the laws which will control our world. We require governments, because the big things require all of us to participate with realistic equality. That means they won’t go away. But they need not, because justice doesn’t mean simple freedom! The only complete freedom ANY PERSON has, is to destroy yourself; without endangering excessively, the others! LIBERTY IS:\xa0 the right to define and accept as the rule of our law, the realities we must all live by; and that includes NOT destroying the future, or gambling with our lives. As to resources provided by this earth:\xa0 they are, as much yours as mine/ BUT IF YOUR RUIN THEM, you are assassinating every child, because we literally have none to spare. Due to the population explosion of humanity:\xa0 we must protect our world, and that means you CAN’T have anything or everything you want. The garbage dump is absolute proof! And neither can anyone else. So there will be rules, and laws to govern every resource properly, and with a clear decision to protect every child:\xa0 because without resources, we have only cannibalism, war, and death awaiting. With regard to how are these things done? The reality is very simple:\xa0 we take control over our government by creating our own law/ through our vote. \xa0REMOVING THEIR LAW, their collusion and conspiracy against us.\xa0 Assigning we the people as the power over OUR government. . Using the three documents that formed this nation: the constitution/ the bill of rights “Virginia edition”/ and the declaration of independence. We remove their currency/ and create our own:\xa0 or you fail! Because the numbers of dollars in circulation are so large: foreigners will own our land, and we will have the same fate as Palestine. To remove currency requires first amendment redress of grievances, and nothing less will initiate that process. So take control over your government as a democracy and enforce constitutional law; as is first amendment redress of grievances. By peaceful assembly!\xa0, we are the owners here, by law! A gun will only serve to destroy/ it will not build justice, unless it is absolutely necessary; and everybody knows it:\xa0 because you did everything else you could do, according to the law that is a constitutional guaranteed right.\xa0 The two constitutional redress cases I have provided 08-1339 & 11-100\xa0will help you sought out the details; more on www.justtalking2.info.\xa0 THEY ARE docketed cases:\xa0 WHICH LITERALLY DOES MEAN, “only a judge can now remove them”.\xa0 With treason apparent, the secretary of the court removed them:\xa0 because behind closed doors, “the law doesn’t count”. Even so, they still exist:\xa0 and legally can be enforced, and forced into the US supreme court.\xa0 To begin again, the process of what is true in this democracy and for life. TO sustain justice:\xa0 the courtroom must be opened and visible to all. The judge must be graded upon his or her acceptance and ruling based upon CONSTITUTIONAL RULES, not his or her opinion or betrayal. ALL PARTIES shall have a vote/ and all votes shall be tabulated to become a clear representation of what does in fact happen in this court. To poor a grade and the judge is evicted or imprisoned. The lawyers shall also be judged by the jury, and participants:\xa0 to poor a grade and they lose their license to practice law. NO person shall run for legal, or policing office, UNLESS they have been graded to assess and determine their value to this society. EVERY case shall be reviewed in the schools as a curriculum/ and by all who care to participate: to determine if something more must be done/ because incarceration, and penalty is no game. The religion of evolution shall be removed from government. The religion and cult of “university knows” shall be removed from government:\xa0 because they have threatened us with extermination. The reality of LAW shall be the government, and all participants not being required to be elected SHALL obtain their job by intermittent (no more than ten year) contract. Whereupon the people shall vote again, for you/ or someone else. That will be particularly true for the IRS. The rich man does not give you a job! He controls the resources, thereby he forces you to beg or work for what you need to survive. By controlling the resources as a nation, through our own vote: we begin the journey to what can be “a new world”.\xa0 That would include people hired by our vote, shall no longer be “lawmakers”/ they shall be law investigators, hired to insure what we the people have chosen for our society, IS IN FACT being done. There is no government anywhere in this world, apart from law. The enforcement of that law, and the means to do that enforcing comprise all that is government: NOT the people employed, as they are merely citizens like you and me. Therefore you must understand: in America the government is the constitution, because this is the foundation of ALL our laws. Those who deny it are traitors. Those who refuse to accept it as the government in our employment by oath;\xa0 are traitors. Those who refuse to enforce it through a courtroom or other, are an insurgency deliberately trying to overtake and destroy the constitution itself: by making it mute, or moot. So what matters to this future is: that we return to the laws and purposes of a constitution that was and is our agreement as people united in one nation/ that this is what we stand for. This is what we work for. This is what we fight for, and will not be denied any further. The values listed in constitutional documents;\xa0 particularly the three that matter most are the constitution itself/ bill of rights/ and declaration of independence. The reality of our situation in American life today is\xa0\xa0\xa0 CLEARLY IDENTIFIED in the trials that are provided as evidence:\xa0 by James Frank Osterbur. And most are established on these web sites linked to www.justtalking7.info OUR GOVERNMENT, is the law we allow or create for ourselves as we the people. The enforcement of that law is determined by our own decision to vote on the realities of law, that then determine our society and our future for ourselves. A vote for someone to vote for me: IS AS NOTHING/ you have no control.\xa0 Defining the law we live under/ work under/ protect each other with: is literally everything democracy can be.\xa0 Like the ten commandments, “a few short and clear words” can last a lifetime/ and need no further assistance;\xa0 although unless you get over 90% acceptance by vote; “you ain’t quite done”. Of the living that must be done; comes the truth of our situation: surrounded by human overpopulation/ our reality has changed. Universities have dealt with that by stealing/ lying/ cheating/ betrayal/ terrorism/ blind faith in fantasies/ complete delusion over reality/ and hidden agenda’s within imagination (we can do anything we want). None of it complies with truth. As a consequence of that: “the dead weight” of university is god; must be thrown off/ the epidemic of university knows, must be discarded without exception: to return only by truth is found/ the curse of the universities cult worshipers, must be disbanded. So that reality itself will return by the elemental truth of what will or removal of what will not provide: survival of life on earth. ONLY TRUTH SURVIVES, let that be your motto; or be extinct. To remove a cult: you must enlighten them, about faith in lies, and fantasies; will kill you dead/ or more simply with a court; you can convince some of them to return to truth. To remove an epidemic: you must investigate and examine the evidence without prior conviction; so that only the truth itself shall survive. That cannot occur outside a true and real courtroom: so that all the people, can convince themselves, we are not wrong anymore. To remove the dead from leadership, requires that you see the future: as being governed by law/ NOT leaders. As is the fundamental of all, democracy is or can be. That is governed by a vote on the laws which govern our lives: as we the people making these decisions for ourselves. Let those who put stumbling blocks in front of you be thrown into prison: don’t need the blight of fools or hatred in charge. We then come to the truth of our future as humanity on earth; and compile these functional forces as will be necessary to understand. Since female life (fight for your world) will not join me; I must construct the beginning values on my own. You must be logged in to post a comment.', 'A trip to the US East Coast offers an amazing range of learning and personal experiences. History buffs will adore Boston – the birthplace of the United States – and all students will come back home being able to relate to modern global politics after their time in Washington, DC. Travelbound understands the complexities of booking an international school trip and is here to make organising your experience as easy as possible. You can choose to stay in each city as long as you’d like and add as many stopovers as desired. Why not spend a few hours in Philadelphia on the iconic Rocky steps? As well as a range of meal and accommodation options, you can pre-book any number of excursions and guided tours. Or you’re free to explore on your own – whatever your budget, we can make an East Coast tour to match! This 2.5 mile walking tour through the compact city of Boston reveals the rich history of America’s Revolution – the events that led up to the historic break from Britain. It starts at Boston Common and takes in 16 historical sites, including King’s Chapel, the Benjamin Franklin statue, The Old State House, the site of the Boston Massacre, and USS Constitution. Sometimes referred to as ‘the Cradle of Liberty’, Faneuil Hall has been a marketplace and a meeting hall since 1742. It was the site of several speeches by Samuel Adams, James Otis and others, encouraging independence from Great Britain. The third floor contains the museum and armoury of the Ancient and Honorable Artillery Company of Massachusetts. A major educational resource, this aquarium a must-visit for students interested in marine life hosts more than 1.3m visitors a year. They can observe the behaviour of aquatic animals from green sea turtles to leafy seadragons and bonnethead sharks. Exhibits include the Giant Ocean Tank and the Simons IMAX Theatre – taller than a six-storey building. Take the Statue Cruise from Battery Park to the Statue of Liberty, one of the world’s most iconic structures and a symbol of freedom and democracy. Continue to Ellis Island and be inspired by the history and stories of the immigrants entering America between 1992-1954. This hop-on hop-off service allows you to explore at your leisure. When arriving in New York, a great way to appreciate the scale of the city and avoid crowds is to take a boat cruise. Students can see the famous skyline and get to know the layout of Manhattan with excellent photo opportunities. The Full Island Cruise takes in over 100 landmarks including the Statue of Liberty and Yankee Stadium. Built at the peak of the skyscraper craze in 1931, the 1250ft Empire State Building is an Art Deco symbol of NYC. A ride in the express lift to the observatory floors gives students an unrivalled view of the city with outdoor decks and restored original interiors. A handheld device acts as an audio and visual companion with engaging videos, image galleries, quizzes and maps. The memorial quadrant is a poignant reminder of the 9/11 devastation and an inspiring testimony by citizens to honour those who died. Twin reflecting pools and manmade waterfalls mark the spot where the Twin Towers stood, with the names of everyone lost inscribed into bronze panels around the outside. The maze of glass walkways and 110ft atrium lobby ensure this is a breathtaking experience from the get-go. The most influential modern art collection in the world has highlights like Monet’s\xa0Water Lilies\xa0and van Gogh’s\xa0Starry Night, with a recent face-lift by Yoshio Taniguchi creating space for huge contemporary installations and three movie theatres. The National Archives holds original copies of the three main formative documents of the United States and its government: the Declaration of Independence, the Constitution, and the Bill of Rights, plus a copy of the 1297 Magna Carta confirmed by Edward I. Tip:All filming, photographing, and videotaping is prohibited, so don’t get out your camera phones. The Smithsonian Institution – the world’s largest museum and research complex – includes 19 museums and galleries and a zoo. It’s dubbed ‘the nation’s attic’ for its eclectic holdings of 137m items. Take a museum tour or book activities from elephant baths at the zoo to tarantula feedings at Natural History or scavenger hunts at American Art. Visit some of the monuments that honour those who helped shape the US nation. The Washington Monument is a towering 555-feet high marble obelisk, The Lincoln Memorial is a symbol of freedom, the Martin Luther King Jnr Monument promotes love and tolerance, while monuments to the Vietnam War, the Korean War, World War II commemorate those that died. This military cemetery was established during the Civil War, and since then deceased veterans of America’s conflicts have been buried here, and their white headstones stretch out over 624 acres or rolling hills. A tour here can bring the military history of the United States to life. Don’t miss the elaborate Changing of the Guard Ceremony at the Tomb of the Unknown Soldier. Make a stop at Philadelphia, en-route from New York and Washington DC. The city of Brotherly Love was the epicentre of American Democracy and is the first city in the US to be awarded World Heritage status. See the Liberty Bell; an extraordinary symbol of freedom through the inspirational inscription it carries, and take a guided tour around Independence Hall where the US Constitution was shaped. Mural graffiti is a fundamental element of community art in New York, expressing peace and conflict, cultural shift and reflecting zeitgeist. The tour visits a number of major murals in the Lower Manhattan, Brooklyn, Bronx and Harlem districts, with knowledgeable guides to discuss the evolution of graffiti and elaborate on the storyboards and memorial walls. Students can take on a true Broadway experience. Enjoy a workshop led by Broadway stars located next to the audition studios of Matilda. Enter the world of theatre and discover the theory behind movement on stage. Vessel is a new landmark and the centre piece of \xa0Hudson Yards, a vibrant redeveloped neighborhood, located on the West Side of midtown Manhattan. The 154 interconnecting flights of stairs are an interactive art work comprising \xa0almost 2,500 individual steps and 80 landings. The ascent gives great views of the attraction itself , the city and river. Complement your visit to the Edge with REACH FOR THE SKY, a virtual STEM education Programme. Students take a behind-the-scenes look at amazing innovations of architecture and engineering and learn about the STEM, history, and social impact of this gravity-defying structure through digital resources and a Virtual Field Trip. This is a great educational city destination with so much for school trip groups to see and experience. All the flights and flight-inclusive holidays in this on this website are financially protected by the ATOL scheme. When you pay you will be supplied with an ATOL Certificate. Please ask for it and check to ensure that everything you booked (flights, hotels and other services) is listed on it. Please see our booking conditions for further information or for more information about financial protection and the ATOL Certificate go to: www.caa.co.uk The\u202fForeign, Commonwealth & Development Office (FCDO) and the NHS have up-to-date advice on staying safe and healthy abroad. For more on security, local laws, plus passport and visa information, please visit https://travelaware.campaign.gov.uk/. Keep informed of current travel health news by visiting www.fitfortravel.nhs.uk. Further information can be found at www.travelbound.co.uk/travel-aware. Advice can change so please check regularly for updates.']","It holds the original copies of the three main formative documents of the United States and its government: the Declaration of Independence, the Constitution, and the Bill of Rights. It also hosts an original version of the 1297 Magna Carta confirmed by Edward I. These are displayed to the public in the main chamber of the National Archives, which is called the Rotunda for the Charters of Freedom. The National Archives Building also exhibits other important American historical documents such as the Articles of Confederation, the Louisiana Purchase Treaty, the Emancipation Proclamation, and collections of photography and other historically and culturally significant American artifacts."
difference between an oak tree and a live oak tree,"['Message summary: Today the benefits of the tree of life are freely available to all of us in Jesus Christ. Many ignore His call, reject Him, or scorn His name but the Word of God declares: “Yet to all who received Him, to those who believed in His name, He gave the right to become children of God” (John 1:12,13). Due to travel we did not prepare a podcast for this message. We are enjoying our trip south and the warm temperatures. For the last several days we’ve been visiting my sister and brother-in-law, Genelle and Cesar Sankarsingh. Wherever we travel we enjoy the variety of trees along the highway. A species we do not see in our northern climate are the wide spread live oaks, which are abundant in the south. I first recall hearing about the live oak while touring many years ago the USS Constitution in Boston Harbor. This ship first launched in 1797 and is still a commissioned US Navy vessel. The tour guide explained that it was constructed with live oak, known for its durability and hardness. I have had oaks wherever I have lived and was puzzled by the designation “live” oak since the other oaks wherever I have lived were certainly also alive. The name live oak comes from the fact that evergreen oaks remain green and “live” throughout winter, when other oaks are dormant and leafless. The oldest live oaks in the country are estimated to be between several hundred to over a thousand years old. After the creation account one of the first notable trees in the Bible is the Oak of the Moreh, first mentioned in Genesis 12:6 which had a long and significant lifespan.* But today let us consider the “tree of life”. I enjoy relating to foresters and learned a great deal from several who attended the church I pastored in northern Pennsylvania years ago. Foresters work with trees which have the distinction of being referenced in the Bible from the first chapter (Genesis 1:11) right through to the last chapter with many references between. When Adam was banned from the garden the specific reason for this banishment was so that he could not “reach out\xa0 his\xa0 hand and take also from the tree of life and eat, and live forever” (Genesis 3:22). At the end of the Bible we again see several references to this tree of life. Apparently it will be a major attraction in our eternal home (Revelation 2:7; 22:14). As such it surely must be the longest living tree! One Bible version titles this chapter “Eden Restored”. The life-giving ministry of Jesus Christ fulfills for the believer the blessings of the tree of life. Fundamentally man has two great quests in life: One is for eternal life and Jesus meets this need. The Bible says, “For God so loved the world that He gave His one and only Son, that whoever believes in Him shall not perish but have eternal life” (John 3:16). Man’s second great quest is for abundant life (full and meaningful). Jesus meets this need as well. He said, “The thief comes only to steal and kill and destroy; I have come that they may have life, and have it to the full” (John 10:10). Today the benefits of the tree of life are freely available to all of us in Jesus Christ. Many ignore His call, reject Him, or scorn His name but the Word of God declares: “Yet to all who received Him, to those who believed in His name, He gave the right to become children of God” (John 1:12,13). Receive and share this merciful gift of life through Christ Jesus today! Daily prayer:\xa0 Jesus, Your sacrificial death on the cross became the tree of life for all who believe. It is the highest expression of love not only for those who bore the nails in your hands and shouted “Crucify, crucify” but it’s for all the generations who follow that were born under the sin curse. How grateful we are that You came from the glories of heaven to crush the head of the serpent, as You conquered death through Your miraculous resurrection so that we might be redeemed from the law of sin.\xa0 We will partake of the tree of life in heaven because You partook of the cross of death here on earth. All glory and praise is due Your name. Amen. A view of Saint Augustine from the top of the Saint Augustine lighthouse. We enjoyed a nice lunch at Columbia Restaurant in St. Petersburg with Genelle and Cesar. Enter your email address to subscribe to this blog and receive notifications of new posts by email.', 'Your kids are so cute!  I love the photo of your daughter sniffing the flower!I was wondering how this worked.  I have to check it out! @Joy Thanks! We are having so much fun with this. We learned a lot about GA by participating. @Stef Layton No problem. We have learned so much about our state and others! Extremely Fun. This is a fabulous post.  I had to cruise in from the field trip link up when I saw the word GA and ""Oak Trees!"" My extended family lives in Savannah. So, Oak trees and Moss remind me off home! I love oak tree especially the really big ones:) that provide lots of shade.  This looks like a fun link up unfortunately we live overseas at the moment:)  Thanks for linking up to the Field trip hop lots of great information here:) Thanks for stopping by! Please check the follow up box so you can receive my replies.', 'If you live anywhere in the United States, besides Alaska, chances are you’ll have to deal with termites. The greatest amount of termite activity is\xa0in the Southern and Western parts of the U.S. because\xa0termites thrive in warmer climates. Drywood termites their homes in dry, sturdy wood and as they\xa0burrow into wood as they carve out sections of it – leaving behind droppings or “frass.”\xa0They’re found along the East Coast, ranging from the Mid-Atlantic states to South Florida, also along the Gulf Coast, throughout the Southwest into California. There’s even one species in Hawaii. The Southeastern Drywood Termite is the most common –\xa0found in the South and Southeast. The West Indian Drywood Termite is common to the South and Southeast regions. It’s the only\xa0only drywood termite found in Hawaii. The Western Drywood Termite is found in the Western and Southwestern U.S. And occasionally in the Southeast. The Desert Drywood Termite\xa0favors Arizona and sections of southern California. Subterranean Termites live underground and are the most common and destructive group of termites in the U.S. \xa0As they burrow through wood they create a distinctive honeycomb pattern and \xa0are able to form tunnels within softer spring-wood. They usually leave external grain intact. With serious damage the wood breaks off easily to reveal mud or soil filled galleries. The Eastern Subterranean Termite is found in\xa0the Eastern half of the country. The Dark and Light Southeastern Subterranean Termites are found in the Eastern and Southeastern parts of the U.S. The Formosan Subterranean Termite is native to China. It’s the most destructive termite species found in most Southeastern states and southern California. This is the only subterranean termite species that’s found in Hawaii. The Western Subterranean Termite is found in the West, but have also been found as far east as Idaho and Nevada. The Arid Land Subterranean Termite is found in the prairie regions of the Rocky Mountain states. This is also the most common termite found in Arizona. The Desert Subterranean Termite\xa0lives\xa0mostly in southern Arizona and parts of California. Need help in Glendale? Visit Glendale Termite Control.', 'A fast-growing perennial deciduous shade tree native to Arizona & parts of Southwestern New Mexico. The “velvet” is a gray fuzz that covers the young twigs and leaves. Young trees are pyramidal, but the shape becomes more rounded and open as mature height is reached. Deciduous tree, up to 30 feet tall or more. The Bonita Ash is gaining popularity for its lush, broad canopy and flashy yellow/orange display of color in autumn. Once established, it is drought tolerant and requires minimal supplemental irrigation to sustain dense, green foliage through the summer months. It is a fast grower and withstands high winds. Originally cultivated in San Antonio for its smooth, glossy leaflets and increased tolerance to alkalinity. It makes an excellent shade tree for hot summer regions. It matures at about 35 feet with a spreading rounded canopy. It is a heat tolerant shade tree with a yellow fall color. Fan Tex is considered to be fast growing. This Ash is a fine-textured, deciduous tree which commonly grows to be 40 to 50 feet tall with a 25 foot spread in a landscape, opening into a full, rounded canopy with age. Young trees are somewhat upright or oval. The lustrous, dark green leaflets create a light shade beneath the tree The leaves turn various shades of red to purple before falling in autumn. This lofty, deciduous conifer grows 50-75 ft. or taller. It is slender and conical in youth, becoming flat-topped in very old age. Sage-green leaves resemble feathers and  turn copper-colored before falling. A tapering trunk is slightly buttressed at the swollen base. Knees develop mostly in poorly drained situations. Exfoliating bark is red-brown to silver. The Chinese pistache tree is a notable ornamental tree, especially during the fall season when the normally dark green foliage changes to a dramatic profusion of orange and red leaves. An excellent shade tree with a broad canopy, Chinese pistache can reach heights of between 30-60 feet.It fulfills a valuable niche for wildlife as birds love the berries. The cedar elm grows to a height of 50–70\' and a spread of 40–60\' at maturity. It grows at a medium rate, with height increases of 13–24"" per year. The cedar elm has been a favorite street tree for towns in the desert southwest due to its ability to survive in difficult soil types with little care. It is very drought-tolerant but can also grow in ground that is periodically saturated. This tree is considered both a shade tree and an ornamental tree. Lacebark elm is a medium-sized deciduous tree that typically grows to 30-50 feet. Due to its medium-fast growth rate, hardiness and visual qualities, it is often planted as a landscape tree. Leaves typically turn an dull yellow in fall and sometimes produce more interesting yellows or reddish-purples. This tree has mottled bark and once the tree matures the bark flakes to reveal patches of gray, cream, orange, brown and green.The bark resembles camouflage. If you are looking for a pine tree that grows fast with a straight trunk and attractive needles, the Loblolly pine may be your tree. It can grow more than 2 feet per year. It can grow to 90 feet but usually remains under 50 feet under landscape conditions. The loblolly is a tall attractive evergreen with yellow to dark-green needles up to 10 inches long. The columnar trunk of the loblolly is also very lovely, covered with reddish-brown plates of bark. Loblolly pine. A rapidly growing deciduous tree native to central and northeastern Mexico. It has very large, beautiful, maple-shaped bright green leaves, with soft-white, fuzzy undersides. The most stunning quality about this tree is its bark: a living work of art that gets more beautiful and intricate with age. It can get up to 80 feet tall in nature, but in most landscapes will only reach 50 feet, with a canopy of 30 feet wide. Usually wider than tall, this tree can exceed 100 ft. in height and width. The species name macrocarpa, refers to the golf ball sized acorns of this tree. The leaves of bur oak also are large, so they are easy to rake. Bur oak is drought resistant, long-lived and reasonably fast-growing for an oak. Tolerates limey soils better than other oaks. Resistant to oak wilt and a number of other problems. The chinquapin oak grows to a height of 40–50\' and a spread of 50–60\' at maturity. It features a spreading canopy capable of blocking sunlight and adds visual interest and beauty to landscaping. With its strong branches and interesting leaves, the chinquapin oak makes a beautiful statement.The magnificent oak also adds to the ambiance by drawing a variety of wildlife with its acorns. Leaves expand as a soft pink color, turning a handsome blue–green as they mature lending the plant an intriguing smoky air. The foliage is seldom bothered by insects or disease. Fall color varies from brown to yellow. Growth habit will vary with local environmental conditions, with the ultimate size ranging in most cultivated landscapes from 30\' to 35\' in height and spread. One of the best attributes of Lacey oak is it\'s picturesque irregularly rounded crown. The live oak tree is a southern symbol of strength. The name live oaks came from the fact that they remain green and ""alive"" throughout the winter when other oak trees are dormant and leafless. Once established a live oak will grow about 2-4 feet overall and 1 inch of caliper per year. It is the broadest spreading of the oaks producing an abundance of shade. Mexican white oak is a quickly growing tree, which means it can add more than 24 inches to its height in a single growing season. As oaks go, it is medium-size, a class that includes plants from 36 to 72 feet. It is capable of growing to a height of 80 feet and a width of 60 feet when fully mature. Because it is sensitive to its growing environment, Mexican white oak may grow taller and adapt better to warmer climates in addition to keeping its leaves. Quercus shumardii is a relatively fast-growing and adaptable oak. Shumard\'s oak is a pyramidal tree, growing 50-90 ft. and becoming more open at maturity. This species is quite drought resistant and also withstands short-term flooding. It is similar to the Texas or Spanish oak, but prefers deeper soils and tends to grow taller and straighter. Provides good fall foliage color. Named for Benjamin Franklin Shumard (1820-69), state geologist of Texas. Quercus Canbyi, a red oak, naturally grows in a pyramidal shape while it is young, developing a broader canopy after several years. This beautiful tree can grow in any area throughout Texas. Although it\'s classified as an evergreen, it will shed a majority of its leaves in the late winter much like Live or Mexican Oak. New foliage is red before turning a rich green color, turning red again in the fall. Leaves are up to three inches long, and resemble a holly leaf. Usually a medium-sized tree to 35 feet tall with one or more trunks 10"" in diameter, but can reach heights of 70 feet on fertile sites.Texas Red Oak is smaller and more drought tolerant than Shumard Red Oak. The foliage turns bright shades of vivid red and orange in autumn. Be aware that all red oak species are susceptible to oak wilt disease. This species was named for Samuel B. Buckley, (1809–1884) botanist and state geologist of Texas. latejanatreesales.com © All Rights Reserved', 'Ensure the page you are linking to exists in the correct folder. Check your file name for case sensitivity . Index.htm is not the same as index.htm! Temporarily disable any rewrite rules by renaming your .htaccess file if it exists.', 'Refer to the online version of The Mammals of Texas for additional details on the Hoary Bat.', '']","The name live oak comes from the fact that evergreen oaks remain green and ""live"" throughout winter, when other oaks are dormant and leafless. The name is used mainly in North America, where evergreen oaks are widespread in warmer areas along the Atlantic coast from southeast Virginia to Florida, west along the Gulf Coast to Louisiana and Mexico, and across the southwest to California."
what are some primary contributors to background radiation,"['', ""Carole Mitchell: I'm going to open our NF2 session with our keynote speaker, I like to say. Dr. John Golfinos, NYU. He's the Chairman of the Neurosurgical Department here at NYU. He is a Professor in Otolaryngology. He works very closely with Dr. Tom Roland. I apologize, Tom. He's not here. He's in Germany. Otherwise he would have been here with us today too. Without further ado, let me introduce Dr. Dr. John Golfinos, NYU. (Applause). Dr. John Golfinos, NYU: Let's just check a few things first. I'm a native New Yorker, born and raised, which means I'm going to speak really quickly probably. You let me know at any point if I'm going too fast. Dr. John Golfinos, NYU: Let's check the lighting. Can everyone see? The CART is coming up okay? Great. And then if there's any problem with the sound also, let me know. I will try and speak as close to these microphones as I can. Dr. John Golfinos, NYU: Okay. Here we are on the East River, it's going to be under water in another two days. I also put up my disclosure slide. I receive a honorarium/pittance from Medtronic. I'm an investor in a company called ViewRay. They're trying to provide a new type of radiation. I am a surgeon. I guess that's a conflict since I'll be discussing surgery. But I'll be talking about all treatments by modalities (factors and circumstances that cause symptoms). I forgot to put on here, I'm also a board member of the Children's Tumor Foundation which is a nice thing. I don't view it as a conflict, we're all in the same boat together. Everything I've done in the 17 years I've been at NYU has been made possible by all these people. Tom Roland, the Chairman of the ENT Department here at NYU. Jessica Schafrick, a Nurse Practitioner for 12 years now. At the end of the schedule, you'll meet all of them today. Carol has been instrumental in that in getting coordination for our patients. And Ashwatha Naryana and Bernadine Donahue are our Radiation Oncologists. First thing, make sure we're talking about the right thing. I put this up for my residents and I put this up for other doctors. Probably everyone in this room has learned, as you go through your medical care you'll find early on a lot of doctors have no idea what the difference is between the two. NF1 is in the room next door, the disease of optic gliomas, malignant peripheral nerve sheath tumors. NF1 is really a pediatric disease. These are children. But we're here to talk about NF2 which is a disease of bilateral, both sides, vestibular schwannoma, tumors on the balance nerves that come out of the brain cells. It's also a disease of the meningioma which we're going to talk about. People can have cafe au lait spots. They're not as common in NF1 but they do happen in NF2 as well. Frequently end up doing surgery and it's a disease of hearing problems. These are the diagnostic criteria for it. Manchester Criteria. I bet everybody in this room is familiar with these. Hallmark is a first line bilateral vestibular schwannoma. But any first degree relative that has NF2, unilateral vestibular schwannoma, that makes the diagnosis. You can see on the bottom line, anyone with multiple meningiomas, and any type of schwannoma and unilateral vestibular schwannoma, is diagnosed as having NF2. Why is that important? Here is a patient that we saw early on referred from elsewhere in New York City. This was sent to us as a patient with NF2. The patient had had surgery on the left side before. This is actually the bone of the skull is this black area. You can see it's missing here. The surgery was done on the left side. And there's this large tumor sitting next to the brain stem. So she was referred to us as she was going to lose her hearing. What can you do for it? If you look closely it's not a Schwannoma. It doesn't go out into the canal that the nerves travel into. This is a meningioma. This is a patient with multiple meningioma. Entirely different disease. This tumor was removed. We could preserve the hearing because it didn't involve the nerves coming out of the brain stem. What we should -- I put this slide up just to say it once. Age and diagnosis is the strongest predictor of diagnosis of NF2. But there are additional predictors. The presence of meningiomas in the skull. Type of treatment center you go to is an independent predictor, and the type of mutation that occurs. I put up this list, and we talk about some of these things today. Why is surgery so difficult in this disease? We already covered number one. If you think you're covering NF2 and you're not, it's making a wrong diagnosis. Number two, and it's a really important one, underestimating vestibular nerve tumors, and overestimating your ability to save the hearing. That's something that's changed in the last ten years in neurosurgery for NF2. Underestimating facial weakness or what happens. Underestimating the degree of involvement of the facial nerve. Facial neuromas are common with this disease. I think we realize now far more common than we thought. You see patients with bilateral facial palsy, and we try to avoid that. Not to be aware of other tumors that are part of the cell, especially the tumors on the lower cranial nerves, responsible for swallowing, keeping the air way open, for voice. Other problems: Not planning for the next operation. There's usually going to be a next operation in NF2. Not using MRI compatible things. Not leaving behind things that prevent the patient from having an MRI. That's a problem. We worry about the veins. When people think about blood in the brain, we think about blood getting into the brain. Everybody knows what a stroke is. Blood doesn't get into the brain. But we're more concerned in NF2 with the blood getting out of the brain. These meningiomas will affect the veins and sinuses. When I say sinuses, most people think about the air sinuses around your nose. I'm talking about big pools of blood as they come out of the brain and how they get out. The problem is that patients with NF2 will have multiple operations. When you do that if you're not careful you can reduce the size of the skull. When you reach adulthood you have a certain volume in the skull. After multiple operations it's possible to reduce that and that causes problems too. The lure of radiation. We'll speak about that. I think the last problem is one hopefully we're addressing today in this meeting which is a lack of comprehensive care. Not being able to get to an NF2 Center, having careful follow up, being able to connect with a clinical coordinator and communicate with your physician. So how do these vestibular schwannomas differ? We do about 60 vestibular schwannomas a year at NYU. The vast majority of those are in patients who do not have NF2. Those are relatively straightforward cases, tend to be smaller tumors, and tend to come out relatively nicely. NF2 is a different story. You can see on the slide, NF2, vestibular schwannoma presents at an earlier age. Remember these are tumors on the balance nerves. They tend to be larger in size. Usually patients with NF2 have worse hearing function before the surgery. And these tumors I can tell you in our experience are more adherent to nerves and we have a lower rate of getting the whole tumor out, especially when we're worried about that patient and we're trying to preserve their hearing. Therefore in NF2 we have worse hearing outcomes and greater rates of facial nerve injury. And because we're often leaving some tumor behind so we don't injure the facial nerve, that means the risk of tumor coming back is higher. There have been some studies, Gareth Evans did this paper looking at how else are these tumors particularly different than NF2, and what they found is the growth rates in NF2 can be highly variable. Meaning the tumors may not grow for some years and then suddenly take off. One of the good things that has come out of that is growth rates tend to decrease with increase in age. As patients get older, the growth rates tend to slow down. What we do in terms of hearing preservation, I can tell you now compared to when I started 17 years ago, our confidence in being able to save hearing with surgery alone with NF2 has gone down. We compensate for that by being better at picking patients. The ones we're really trying to save the hearing nowadays tend to be early on with very small tumors and we'll go for it on one side and attempt to get the tumor out and save the hearing. That's the first line you see there. But it's really a conversation with the patient and their family. Do you really want to take this risk? Do you want to go for it because you may lose your hearing on that side on the day of surgery. You may wake up and be unable to hear in that ear. Some of the other strategies that we tried is just doing a subtotal resection. We've had mixed results with that. I can tell you more and more now, especially in patients that have lost hearing on one side and only have (inaudible) hearing on the other, tend to go for conservative management, you'll hear about drug management until the hearing is lost on that side. What about the facial nerve? As I mentioned earlier on, bilateral facial palsy is difficult with our patients. We try in any way to repair that or improve it. That can mean at the time of surgery we know the nerve is lost, we'll do this on the upper and bottom. Remember when you're taking nerve grafts in NF2 you don't know if the nerve is completely (inaudible) not always so involved. You have to be careful with that. The best way to fix a facial nerve is to actually take the nerve that goes to the tongue, the 12th cranial nerve and to hook it into the nerves that go to the face. The brain reprograms itself. Patients think about moving their tongue and it moves their face and they generally learn to do that well. You get a good nerve supply into the face. But the difficulty again is this is NF2 and that 12th nerve may have a tumor on it as well. We have to be very careful of that. Dr. Samii was one of the surgeons with a large experience in Germany, similar to our own. A large number of patients. He was one of the people that pointed out that patient education is probably the most important determinant in this disease of outcome and patient satisfaction, which is what we're really aiming for as surgeons. We've sort of come to accept that we've gone against the idea of the surgeon causing hearing loss. It's not really acceptable to us anymore. We talk about facial nerves. For all these reasons we hope patients get to the NF2 Center early on. So we can have these talks and conversations. These are some typical problems that we see. Here is a patient who lost hearing on the left side and lost facial movement on the right. We're looking at an MRI scan. This is front, this is back. Radiologist did this to us so we're stuck with this being right, this being left so you're looking at it from the bottom. It's not the way a normal person would have done that but the radiologist did it that way because they're not so normal. What you see are the two big tumors of NF2. But there are other tumors around it. These little white spots are other tumors on other cranial nerves. This is after surgery on the left side. Large tumors taken out. Still the patient had hearing on the right. So we did the left side where the hearing was (inaudible). Then on the right side where there was facial nerve weakness we did that 12th nerve to 11th nerve, tongue nerve to the face graft. Because there was only hearing on this side we didn't operate again. You can see the tumor got larger and it got larger rapidly despite drug treatment. That left us only with the option of taking it out. This is the fat graft we took behind. You can see the tumor is gone off the brain stem. We removed that tumor. It was really two tumors, a tumor on the balance nerve and one on the facial nerve as well. This was an 18-year-old cheer leader referred up to us from Florida. Same idea we see with bilateral tumors. This is what's so difficult about NF2. The brain stem is caught between them. You can see tumors on the other cranial nerves around it. Again that's the same patient looking from the front now. These are all little tumors on the other nerves there. What is the right followup for patients? Currently we're recommending every six months getting an MRI scan of the brain, and and MRI scan of the spine. But I tell you those recommendations are still controversial. Depends on what health care system you're in. How many resources is the country going to devote to things like this? The reason we say every six months is we've seen tumors take off on a moment's notice. So we've had patients who have gone a year without an MRI scan and have come back with a large tumor. So we think that at least every six months is a reasonable thing to do.The United Kingdom, they do CAT scans only every two years. Involves a radiation dose. MRI scan of course involves no radiation. With this particular disease, vestibular schwannoma is most often first presenting the tumors. Our surgeries have gotten better. Our patients are living longer. The downside is it's given time for tumors on the other nerves to grow. So we deal more with problems with swallowing, voice, things like that. Let me say a few words about meningiomas, the other big tumor in this disease, and probably one of the more frustrating ones for us. As we said the defining tumor for this diagnosis. It comes to dominate the late phases of the disease. Meningiomas for this are very different than others. It's a very common brain tumor. You find it five times more in women than men. But with NF2 these are different meningiomas, just like the vestibular schwannomas are different. Presence of intracranial meningiomas is a predictor of how a person with NF2 will do. (Inaudible) This is a paper that was done by Harry Parry. I put it up here just to show that only 40 percent of these are called regular run of the mill meningiomas. 49 percent are atypical. 11 percent of the time they're taken out are anaplastic, which used to be called malignant. (Inaudible). These are the strategies we use. We're always thinking about the next surgery. We have to deal with the surgery we did before and the need for an MRI scan afterwords. Our strategies in terms of meningiomas were generally treating only the symptomatic ones. To me that means also radiologically symptomatic, if it looks like it's causing a lot of swelling on the MRI scan, that counts for the swelling and compression on the rest of the brain. We're always as I mentioned before always looking at the veins around this, are we going to damage the brain's ability to drain itself by taking this tumor out? That's a problem. We're always worried about making the skull too small afterwords. We're always trying to keep the skull in its original shape after the surgery. And of course, the first principle is don't do any harm if at all possible. What we have to consider, the skin incisions that we use, the flaps that we make. We're sure that we can do another surgery if we need to. We worry about spinal fluid getting trapped. We call that hydrocephalus. I mentioned the venous problem, the problem with the veins. So we're always particularly concerned about that. This is an example of a gentleman with NF2. You can see this large tumor in front. This is front, back, right, left. You can see it on this image. You can see there's other meningiomas in the brain. There's a large one here, another one back here. This is the same image. This is from looking further up, and from the side. This was that tumor that we were looking at before. Typical for NF2 we have to get past this tumor to get to this one. As you can see, this tumor is actually causing a deformity of the skull. This is a tumor that has percolated through the bone. Meningioma will do that, and it's caused swelling of the bone up here. This is a lump you could feel on the skull. This is what the veins look like. I know you're not familiar with regular angiograms. This is a picture of all the veins of the brain. If you look, it looks like varicose veins in the leg. That's exactly what happens in this disease. The reason is normally you have veins draining all the way over the top and going out the bottom of the skull. But because of the meningiomas along the top, the blood can't get out. So it has to find other ways out of the skull. And this one is coming down the skin. This is a before and after picture. Get in there and get that out. But more importantly, this is from the side. Again, getting past these tumors to get it out. When we recreate the skull, we restore the curvature to make sure the skull stays the same size. Just another example of getting there the right way. This is before and after. And again, look at the other tumors that are here. Again, this is another example of getting that big bone out but saving the curvature of the skull. If surgery is so difficult, why don't we just radiate everybody? There's a really good reason why you shouldn't in NF2. There's still some controversy about this but I don't think there should be, to be honest. There's probably at least a 14-fold increased risk of malignancy for radiated vs. Non-irradiated NF2 patients. Here is a study from Gareth Evans. These are other studies. This study from Rowe, a gamma knife study. Gamma knife is a type of radiation surgery that is giving radiation one big dose. They reported this because they thought their results were really good. They thought only half the patients had growth in their tumors at 8 years follow up. Yeah, but that means the other half did. Those are the people that we have to operate on after surgery. For us this is not good enough. Radiation doesn't do what you want it to do. They saw it as the glass is half full. We see it as half empty with radiation. There are several reports of rapid growth of radiated tumors. Here is one of them. Malignancy in a vestibular schwannoma. 8 reported cases in the literature, four had radiation, four did not in this review. Here is another review. Patients from the University of Toronto. In regular patients with vestibular schwannoma, regular sporadic everyday acoustic neuroma. It's very rare to see radiation caused malignancy. But the patients with malignancy were patients with NF2. 12 time higher rate than expected. And that includes not just a malignant acoustic neuromas, but malignancy (inaudible). Here is another review. 26 cases in the literature. 13 of those were in NF2 patients. This is why we think that radiation can have unpredictable results also even within the same patient. This is a patient who had gamma knife. Hopefully you're getting used to looking at these MRI's by now. This is right, left, front, back. You can see a big tumor on the left. A tiny one on the right that got radiated in 1988 when the patient was 19 years old. Lost hearing three months after the radiation on that side. (Inaudible) on the left side. And 5 years later was radiated on the left side. And two years after radiation lost the hearing on the left side. Didn't go for an MRI scan for nine years and then came back to us with a big tumor sitting on the brain here. This is the size of the tumor. Believe it or not this is a post operative scan. The thing was cemented to the brain stem. We didn't get the whole thing out. This is years later, the tumor is growing, two years later. Then you can see even after that it continued to grow, and the patient passed away from this tumor. This is a pathology report, it was called an atypical schwannoma. It's no longer a run of the mill vestibular schwannoma after radiation. We think that radiation causes poor hearing preservation rates, poor control rates. You heard earlier on that people who had a defect in the NF2 have difficulties stopping the bad effects of radiation. Then there are questions about patients, do you still put in the auditory brain stem implant, the cochlear implant? And in our cases at least, it's been harder to save the facial nerves in patients who have had radiation before when it comes time for surgery. What about patients with meningiomas? Not that useful. They tend to be thin things that cover the entire surface of the brain. This is looking from the front. Top, bottom, right, the ear lobe here, and left, the ear lobe here. This thin white thing is a meningioma covering the entire surface of the brain. Using radiosurgery doesn't seem to work. Just to finish up, I think obviously people have said this enough today. I want to say it one more time. Having a dedicated center enables clinical trials. It's probably the most important thing. There are as we heard before maybe 8,000 people with NF2 in the entire United States, in a population of 300 million. There are only 2,500 neurosurgeons in the United States. Hopefully people can get to places where they can share their knowledge and participate in clinical trials. That's our center here. You heard -- these are the people who get involved with our patients. Neurosurgery, both the head -- I don't even do the spine. We have spinal surgeons cover that, Neurotology, ear doctors like Dr. Roland, Rehab, medicine doctors, Orthopedics for some peripheral nerve tumors, Ophthalmologist, Neuropsychologist, Geneticist. A lot of different specialties. What's changed in the last five years? Surgery is less common but an intent to hearing preservation. Because we also recognize that when we do that, these patients recur. We think we take out tiny tumors, we still see them come back later. The risk of return is higher. And then our recognition that trying to save the hearing and take the tumor out at the same time is very difficult. We continue to use the Auditory Brain stem Implant and there has been some increased use of Cochlear Implant. The tumor is sitting there, just as a way to retain hearing for some time until the tumor finally has to come out. More attention to preserve the facial nerves. Probably the last and most controversial thing is drug management prior to surgery? It's a lot trickier than it sounds, believe it or not. Those chemotherapies, the drugs that we use, tend to shut down tumors. They also tend to shut down the cells that repair the skin. So you get wound infections. You can't operate on someone that has had a drug for six weeks. Timing it becomes tricky. We can see patients progress when they stop the drug and they have to wait six weeks, so the tumor can progress. The other problem is patients want to hold onto hearing. We understand that. But tumors can get really large and you're balancing saving the hearing against saving the facial nerve. For low amounts of hearing, you really have to have the discussion about what's our number one priority now? Follow up is everything in NF2. Multi-specialty management and surgery I think remains the optimal treatment but only done when necessary. I want to say one last thing. I'm looking out across this room and there are a lot of my patients in this room. That's about the most humbling thing you can expect as a surgeon. Thank you very much. (Applause). I'm on call for Bellevue Hospital, believe it or not, today. So. Carole Mitchell: We'll give you five minutes to ask Dr. Golfinos some questions. Dr. John Golfinos, NYU: Yes. FROM THE AUDIENCE: I have two questions. First, are there enough data on the effectiveness of Proton Radiation Therapy and its rate of malignant transformation? And second question, what more can you tell us about the use of Cochlear Implants without removing the vestibular schwannoma? Just piggybacking over the tumor? Dr. John Golfinos, NYU: I'll leave the Cochlear Implants for later on. Let me say something about Proton Beam. You understand all the forces involved here. To build a Proton Beam Center it costs over 100 million dollars in some cases. Proton Beam is another type of radiation. Normally when we radiate people we use photons, same thing in these lights, only really high energy photons. That's what we call radiation. Gamma radiation for the Gamma Knife. Creating photons that have really high energy. Plain old radiation. Protons are a little different. They're a slightly larger particle but there's still radiation. All radiation is radiation. It all works the same way, by damaging the genetics of the cell. By damaging the DNA. So it's hard to understand how there would be a different risk for causing malignancy. Probably the only difference is in patients who get either Radiosurgery, which is one dose one time, versus Fractionated Radiation, people are trying to do that as five doses. Down at Thomas Jefferson they do 33 doses. And the more doses you have of radiation, the higher risk of malignancy later on. But in patients with NF2, all radiation is radiation. Same type of damage. One last thing about that, the younger you are, the higher risk of radiation induced malignancy. For everybody in America, but especially patients with NF2. Dr. John Golfinos, NYU: We're going to talk about that today. Dr. John Golfinos, NYU: Ask me in 20 years. Hopefully that's what we're all here working on. That's what we're trying to do. We're trying to take care of the tumors in any way possible. I can tell you this, the good news is we're doing far better than even when I started 17 years ago. Hopefully that progress continues. Carole Mitchell: Thank you, Dr. Golfinos. (Applause). FROM THE AUDIENCE:  One more question. In Winthrop Hospital they are using a Carbon Dioxide Radiation treatment, what are your thoughts on that for treatments for people with NF2? Dr. John Golfinos, NYU: Probably not. All radiation is radiation. Doesn't matter which particle you use. Carbon nuclei are another type of radiation particle. Radiation all has its effect the same way by damaging the genes inside the cell. In NF2 there's an inability to repair that damage. Carole Mitchell: Thank you again."", 'Detects alpha, beta. These principles are used in several devices. Typical dead times are 0.1 to 1.0 milliseconds. It has many advantages. There is a lot of additional information commented out in the source of this document. Up to my Academic Projects Page. Up to my Home Page. This page is maintained by Ian Hickson (py8ieh@bath.ac.uk). Text last updated in March 1998. Document last updated in October 1998.', 'Fish And Ocean Radiation Testing In Hawaii –\xa0I am going to sample, test and check for nuclear radiation on fish and the local ocean beach.\xa0Since I live on the Big Island of Hawaii, I have been very concerned about the possible radiation leakage from the disaster in the Fukushima Nuclear Accident in Japan in 2011. I have had tens of emails over the years from subscribers wanting to know if Hawaii is safe to visit or live, or if is it toxic from the Fukushima Nuclear Disaster? The 7 year experiment is to see if the fish and local beach areas are toxic with high counts of nuclear fallout radiation. I will also sample test the ocean in the Hilo, Hawaii area, specifically testing and checking for nuclear radiation fallout from Japan or other radiation or physical pollution toxicities from the heavy rain of the tropical storm “Hurricane Lane” which dropped over 50 inches of rain in a few days to most of the big Island. I will use a very sensitive and accurate geiger counter/meter that can detect hot radioactive particles of both non-ionized and ionized radiation if they are present in the fish, or at the ocean beach I tested. We will also test the RF fields (Radio Frequency) or microwave wireless technology at the local beach. For the past 7 years I have been living full time on the Big Island of Hawaii. I have been “Radiation Testing” the ocean air and ocean weekly at my house 20 miles North of Hilo, Hawaii. I have also tested over 40 fish over 7 years for any type of hot ionizing particles of radiation that my inspector Geiger counter/meter could pick up from fish, directly caught from the local fisherman in Hilo. For several years I have heard stories from many sources that the radiation counts were high in the air, ocean and fish in Hawaii through the Pacific currents from the Fukushima radiation disaster. I have heard from the media and many other sources that Hawaii has been having much higher radiation counts other than the normal “Natural Background Radiation”, which is normally between 18-40 counts/min naturally from the Fukushima nuclear disaster in Japan. So, I bought several expensive meters and decided to keep an eye on the radiation counts myself to verify the information for myself. We are going to test two completely different species of fish. One being a “Pelagic” migratory species and the other is a more “Local” non migratory bottom species. Part 1 (24 min) – I will test the Yellowfin Tuna Pelagic, or migratory species, that can easily travel thousands of miles a year following the warm water currents, and the their constant need for their food supply throughout the Pacific oceans. Most Tuna usually consume at least their body weight daily just to survive. So, when the food source of the migratory tuna are swimming or feeding in contaminated toxic water with any nuclear fallout radiation, testing is very easy with an accurate meter for any radiation that usually is not there normally in healthy fish. If the fish are eating large quantities of other smaller toxic fish daily, the fish that are eaten will easily accumulate the radiation, chemicals or poisons in their flesh and organs. So, we can test them quite easily with the right testing equipment. Part 2 (45 min) – I will test another species which is a more deep water local fish, – a less migratory species called the “Amberjack”. This type of fish is usually caught in 100-200 ft deep water, and we will take a look at the radiation in deeper water fish that are local and grown up in these waters. I will also show you how I filet a fish correctly and test all of the internal organs including the gut, heart and internal flesh. Through all of the radioactive testing over the last 7 years of living in Hawaii, I have never found any radiation counts higher than the normal background radiation of approx. 18-35 CPM, or counts per minute, of detectable radiation. This radioactivity experiment is only a small sampling of the radioactive testing that I have done over the years of living here. I tested many locally caught fish, large and small, of many species, and checked the oceans at several beaches and rain water consistently, since we capture our water from the rain. I also checked many types of milk that is produced here locally for any significant radioactive activity, and found no rise other than the normal background radiation. So, for now I am not sure what all of the hype is about radioactivity in Hawaii, because I have not found any at all. I have several friends of mine that have the same accurate geiger counter, and they have not noticed any high radioactive counts other than the normal background radiation. Wikipedia definition: Background radiation is a measure of the ionizing radiation present in the environment at a particular location which is not due to deliberate introduction of radiation sources. Background radiation originates from a variety of sources, both natural and artificial. These include cosmic radiation and environmental radioactivity from such as naturally occurring radioactive materials including radon and radium, and man-made fallout from nuclear weapons testing and nuclear accidents. I did a Rethinking Reality video experiment called “Rethinking Reality: Food and Parasite Experiment with Pigs” with several types of vegetarian foods they eat daily, and the carcass of the spoiled dead fish flesh with the “Russian Boars” we have on the farm. Wait till you see the experiment results and what the pigs eat first, or what parasites are the strongest “Mind Controlling Parasites” that want to feed first. Watch the recommended videos we have below to get up to speed on the philosophy and power of\xa0Mind Controlling Parasites. Remember, they have a smorgasbord of good food to choose from. So, the question is: “What food will the piggies eat first?”, or like I already said “What mind controlling parasite is the most powerful to feed first?”. Recommended Courses and Categories:Rethinking Reality: Food and Parasite Experiment with Pigs, Parasites, Blood Free Diet and Mind Controlling Parasites. Recommended Products: IMI Inspector Alert V2 Geiger Counter,\xa0EMRSS Cornet RF Meter. Keep on enjoying the health, wealth and evolutionary journeys ahead. Dr. Robert To see the following Video(s) and Recipes you have to be an Earther Member. To become an Earther Member Click Here! or Login to see the Private Videos. Join our Free Informative Newsletter to receive future updates on our next WORLDWIDE ONLINE Life Transformation Group Guided Retreats, and get access to a Selection of Private Videos. You will also receive a coupon for 25% Discount Coupon for Earth Shift Products! The Earth Shift Discount Coupon is good for one-time use, and is valid for 25% off an order of $200+. This code includes free ground shipping within the 48 contiguous states. This code cannot be combined with other promo codes. You must be logged in to post a comment. This site uses Akismet to reduce spam. Learn how your comment data is processed. Copyright 2016 Earther AcademySite by selane.io The entire contents of this website are based upon the opinions of Dr. Robert Cassar and Earther Academy Research Institute, LLC. and/or Affiliates, unless otherwise noted. Individual articles are based upon the opinions of the respective author, who retains copyright as marked. The information on this website is not intended to replace a one-on-one relationship with a qualified health care professional and is not intended as medical advice. It is intended as a sharing of knowledge and information from the research and experience of Dr. Robert Cassar and Earther Academy Research Institute, LLC. Dr. Robert Cassar and Earther Academy Research Institute, LLC. and/or Affiliates encourages you to make your own health care decisions based upon your research and in partnership with a qualified health care professional.', 'Background radiation is the ionizing radiation present in the environment. Background radiation originates from a variety of sources, both natural and artificial. Sources include cosmic radiation, naturally occurring radioactive materials such as radon, and fallout from nuclear weapons testing and nuclear accidents. The term background radiation can have different meanings, depending whether we are considering an ambient radiation dose, or we wish to differentiate between an incidental background and a particular source of radiation of concern. For example, in considering radiation safety , background radiation is defined by the International Atomic Energy Agency as ""Dose or dose rate (or an observed measure related to the dose or dose rate) attributable to all sources other than the one(s) specified.[1] So a distinction is made between sources of dose which are incidentally in a location, which are defined here as being ""background"", and the dose due to a specified source. This is important where radiation measurements are taken of a specified radiation source, and the incidental background may affect this measurement. An example would be detection of radioactive contamination in a gamma ray background, which could increase the total reading above that expected from the contamination alone. However, if no specific radiation source is of concern, then the total radiation dose measurement taken at a location is generally called the background radiation , and this is usually the case where an ambient dose rate is measured for environmental purposes. Radioactive material is found throughout nature. Detectable amounts occur naturally in soil, rocks, water, air, and vegetation, from which it is inhaled and ingested into the body. In addition to this internal exposure, humans also receive external exposure from radioactive materials that remain outside the body and from cosmic radiation from space. The worldwide average natural dose to humans is about 2.4 millisievert (mSv) per year.[2] This is four times the worldwide average artificial radiation exposure, which in 2008 amounted to about 0.6\xa0mSv per year. In some rich countries, like the US and Japan, artificial exposure is, on average, greater than the natural exposure, due to greater access to medical imaging. In Europe, average natural background exposure by country ranges from under 2\xa0mSv annually in the United Kingdom to more than 7\xa0mSv annually for some groups of people in Finland.[5] The biggest source of natural background radiation is airborne radon, a radioactive gas that emanates from the ground. Radon and its isotopes, parent radionuclides, and decay products all contribute to an average inhaled dose of 1.26\xa0mSv/a (millisievert per year). Radon is unevenly distributed and varies with weather, such that much higher doses apply to many areas of the world, where it represents a significant health hazard. Concentrations over 500 times the world average have been found inside buildings in Scandinavia, the United States, Iran, and the Czech Republic.[7] Radon is a decay product of uranium, which is relatively common in the Earth\'s crust, but more concentrated in ore-bearing rocks scattered around the world. Radon seeps out of these ores into the atmosphere or into ground water or infiltrates into buildings. It can be inhaled into the lungs, along with its decay products, where they will reside for a period of time after exposure. Although radon is naturally occurring, exposure can be enhanced or diminished by human activity, notably house construction. A poorly sealed basement in an otherwise well insulated house can result in the accumulation of radon within the dwelling, exposing its residents to high concentrations. The widespread construction of well insulated and sealed homes in the northern industrialized world has led to radon becoming the primary source of background radiation in some localities in northern North America and Europe. Basement sealing and suction ventilation reduce exposure. Some building materials, for example lightweight concrete with alum shale, phosphogypsum and Italian tuff, may emanate radon if they contain radium and are porous to gas.[7] Radiation exposure from radon is indirect. Radon has a short half-life (4 days) and decays into other solid particulate radium-series radioactive nuclides. These radioactive particles are inhaled and remain lodged in the lungs, causing continued exposure. Radon is thus the second leading cause of lung cancer after smoking, and accounts for 15,000 to 22,000 cancer deaths per year in the US alone.[8] About 100,000\xa0Bq/m3 of radon was found in Stanley Watras\'s basement in 1984.[9][10] He and his neighbours in Boyertown, Pennsylvania, United States may hold the record for the most radioactive dwellings in the world. International radiation protection organizations estimate that a committed dose may be calculated by multiplying the equilibrium equivalent concentration (EEC) of radon by a factor of 8 to 9 nSv·m3/Bq·h and the EEC of thoron by a factor of 40 nSv·m3/Bq·h.[2] Most of the atmospheric background is caused by radon and its decay products. The gamma spectrum shows prominent peaks at 609, 1120, and 1764\xa0keV, belonging to bismuth-214, a radon decay product. The atmospheric background varies greatly with wind direction and meteorological conditions. Radon also can be released from the ground in bursts and then form ""radon clouds"" capable of traveling tens of kilometers.[11] The Earth and all living things on it are constantly bombarded by radiation from outer space. This radiation primarily consists of positively charged ions from protons to iron and larger nuclei derived sources outside our solar system. This radiation interacts with atoms in the atmosphere to create an air shower of secondary radiation, including X-rays, muons, protons, alpha particles, pions, electrons, and neutrons. The immediate dose from cosmic radiation is largely from muons, neutrons, and electrons, and this dose varies in different parts of the world based largely on the geomagnetic field and altitude. For example, the city of Denver in the United States (at 1650 meters elevation) receives a cosmic ray dose roughly twice that of a location at sea level.[12] This radiation is much more intense in the upper troposphere, around 10\xa0km altitude, and is thus of particular concern for airline crews and frequent passengers, who spend many hours per year in this environment. During their flights airline crews typically get an extra dose on the order of 2.2\xa0mSv (220 mrem) per year.[13] Similarly, cosmic rays cause higher background exposure in astronauts than in humans on the surface of Earth. Astronauts in low orbits, such as in the International Space Station or the Space Shuttle, are partially shielded by the magnetic field of the Earth, but also suffer from the Van Allen radiation belt which accumulates cosmic rays and results from the Earth\'s magnetic field. Outside low Earth orbit, as experienced by the Apollo astronauts who traveled to the Moon, this background radiation is much more intense, and represents a considerable obstacle to potential future long term human exploration of the moon or Mars. Cosmic rays also cause elemental transmutation in the atmosphere, in which secondary radiation generated by the cosmic rays combines with atomic nuclei in the atmosphere to generate different nuclides. Many so-called cosmogenic nuclides can be produced, but probably the most notable is carbon-14, which is produced by interactions with nitrogen atoms. These cosmogenic nuclides eventually reach the Earth\'s surface and can be incorporated into living organisms. The production of these nuclides varies slightly with short-term variations in solar cosmic ray flux, but is considered practically constant over long scales of thousands to millions of years. The constant production, incorporation into organisms and relatively short half-life of carbon-14 are the principles used in radiocarbon dating of ancient biological materials, such as wooden artifacts or human remains. The cosmic radiation at sea level usually manifests as 511\xa0keV gamma rays from annihilation of positrons created by nuclear reactions of high energy particles and gamma rays. At higher altitudes there is also the contribution of continuous bremsstrahlung spectrum.[11] Terrestrial radiation, for the purpose of the table above, only includes sources that remain external to the body. The major radionuclides of concern are potassium, uranium and thorium and their decay products, some of which, like radium and radon are intensely radioactive but occur in low concentrations. Most of these sources have been decreasing, due to radioactive decay since the formation of the Earth, because there is no significant amount currently transported to the Earth. Thus, the present activity on earth from uranium-238 is only half as much as it originally was because of its 4.5 billion year half-life, and potassium-40 (half-life 1.25 billion years) is only at about 8% of original activity. The effects on humans of the actual diminishment (due to decay) of these isotopes is, however, minimal. This is because humans evolved too recently for the difference in activity over a fraction of a half-life to be significant. Put another way, human history is so short in comparison to a half-life of a billion years, that the activity of these long-lived isotopes has been effectively constant throughout our time on this planet. In addition, many shorter half-life (and thus more intensely radioactive) isotopes have not decayed out of the terrestrial environment because of their on-going natural production. Examples of these are radium-226 (decay product of thorium-230 in decay chain of uranium-238) and radon-222 (a decay product of radium-226 in said chain). Thorium and uranium (and their daughters) primarily undergo alpha and beta decay, and aren\'t easily detectable. However, many of their daughter products are strong gamma emitters. Thorium-232 is detectable via a 239\xa0keV peak from lead-212, 511, 583 and 2614\xa0keV from thallium-208, and 911 and 969\xa0keV from actinium-228. Uranium-238 manifests as 609, 1120, and 1764\xa0keV peaks of bismuth-214 (cf. the same peak for atmospheric radon). Potassium-40 is detectable directly via its 1461\xa0keV gamma peak.[11] The level over the sea and other large bodies of water tends to be about a tenth of the terrestrial background. Conversely, coastal areas (and areas by the side of fresh water) may have an additional contribution from dispersed sediment.[11] Some areas have greater dosage than the country-wide averages.[17] In the world in general, exceptionally high natural background locales include Ramsar in Iran, Guarapari in Brazil, Karunagappalli in India,[18] Arkaroola in Australia [19] and Yangjiang in China.[20] The highest level of purely natural radiation ever recorded on the Earth\'s surface was 90\xa0µGy/h on a Brazilian black beach (areia preta in Portuguese) composed of monazite.[21] This rate would convert to 0.8 Gy/a for year-round continuous exposure, but in fact the levels vary seasonally and are much lower in the nearest residences. The record measurement has not been duplicated and is omitted from UNSCEAR\'s latest reports. Nearby tourist beaches in Guarapari and Cumuruxatiba were later evaluated at 14 and 15\xa0µGy/h.[22][23] The highest background radiation in an inhabited area is found in Ramsar, primarily due to the use of local naturally radioactive limestone as a building material. The 1000 most exposed residents receive an average external effective radiation dose of 6\xa0mSv per year, (0.6 rem/yr,) six times the ICRP recommended limit for exposure to the public from artificial sources.[24] They additionally receive a substantial internal dose from radon. Record radiation levels were found in a house where the effective dose due to ambient radiation fields was 131\xa0mSv/a, (13.1 rem/yr) and the internal committed dose from radon was 72\xa0mSv/a (7.2 rem/yr).[24] This unique case is over 80 times higher than the world average natural human exposure to radiation. Epidemiological studies are underway to identify health effects associated with the high radiation levels in Ramsar. It is much too early to draw statistically significant conclusions.[24] While so far support for beneficial effects of chronic radiation (like longer lifespan) has not been observed, a protective and adaptive effect is suggested by at least one study whose authors nonetheless caution that data from Ramsar are not yet sufficiently strong to relax existing regulatory dose limits.[25] Background radiation doses in the immediate vicinity of particles of high atomic number materials, within the human body, have a small enhancement due to the photoelectric effect.[26] Most of the natural neutron background is a product of cosmic rays interacting with the atmosphere. The neutron energy peaks at around 1\xa0MeV and rapidly drops above. At sea level, the production of neutrons is about 20 neutrons per second per kilogram of material interacting with the cosmic rays (or, about 100-300 neutrons per square meter per second). The flux is dependent on geomagnetic latitude, with a maximum at about 45 degrees. At solar minimums, due to lower solar magnetic field shielding, the flux is about twice as high vs the solar maximum. It also dramatically increases during solar flares. In the vicinity of larger heavier objects, e.g. buildings or ships, the neutron flux measures higher; this is known as ""cosmic ray induced neutron signature"", or ""ship effect"" as it was first detected with ships at sea.[11] The global average human exposure to artificial radiation is 0.6\xa0mSv/a, primarily from medical imaging. This medical component can range much higher, with an average of 3\xa0mSv per year across the USA population.[3] Other human contributors include smoking, air travel, radioactive building materials, historical nuclear weapons testing, nuclear power accidents and nuclear industry operation. A typical chest x-ray delivers 0.02\xa0mSv (2 mrem) of effective dose.[27] A dental x-ray delivers a dose of 5 to 10 µSv[28] The average American receives about 3\xa0mSv of diagnostic medical dose per year; countries with the lowest levels of health care receive almost none. Radiation treatment for various diseases also accounts for some dose, both in individuals and in those around them. Cigarettes contain polonium-210, originating from the decay products of radon, which stick to tobacco leaves. Heavy smoking results in a radiation dose of 160 mSv/year to localized spots at the bifurcations of segmental bronchi in the lungs from the decay of polonium-210. This dose is not readily comparable to the radiation protection limits, since the latter deal with whole body doses, while the dose from smoking is delivered to a very small portion of the body.[29] Air travel causes increased exposure to cosmic radiation. The average extra dose to flight personnel is 2.19 mSv/year.[30] Frequent above-ground nuclear explosions between the 1940s and 1960s scattered a substantial amount of radioactive contamination. Some of this contamination is local, rendering the immediate surroundings highly radioactive, while some of it is carried longer distances as nuclear fallout; some of this material is dispersed worldwide. The increase in background radiation due to these tests peaked in 1963 at about 0.15\xa0mSv per year worldwide, or about 7% of average background dose from all sources. The Limited Test Ban Treaty of 1963 prohibited above-ground tests, thus by the year 2000 the worldwide dose from these tests has decreased to only 0.005\xa0mSv per year.[34] The International Commission on Radiological Protection recommends limiting occupational radiation exposure to 50\xa0mSv (5 rem) per year, and 100\xa0mSv (10 rem) in 5 years.[35] However, background radiation for occupational doses includes radiation that is not measured by radiation dose instruments in potential occupational exposure conditions. This includes both offsite ""natural background radiation"" and any medical radiation doses. This value is not typically measured or known from surveys, such that variations in the total dose to individual workers is not known. This can be a significant confounding factor in assessing radiation exposure effects in a population of workers who may have significantly different natural background and medical radiation doses. This is most significant when the occupational doses are very low. At an IAEA conference in 2002, it was recommended that occupational doses below 1–2 mSv per year do not warrant regulatory scrutiny.[36] Under normal circumstances, nuclear reactors release small amounts of radioactive gases, which cause small radiation exposures to the public. Events classified on the International Nuclear Event Scale as incidents typically do not release any additional radioactive substances into the environment. Large releases of radioactivity from nuclear reactors are extremely rare. To the present day, there were two major civilian accidents - the Chernobyl accident and the Fukushima I nuclear accidents - which caused substantial contamination. The Chernobyl accident was the only one to cause immediate deaths. Total doses from the Chernobyl accident ranged from 10 to 50 mSv over 20 years for the inhabitants of the affected areas, with most of the dose received in the first years after the disaster, and over 100 mSv for liquidators. There were 28 deaths from acute radiation syndrome.[37] Total doses from the Fukushima I accidents were between 1 and 15 mSv for the inhabitants of the affected areas. Thyroid doses for children were below 50 mSv. 167 cleanup workers received doses above 100 mSv, with 6 of them receiving more than 250 mSv (the Japanese exposure limit for emergency response workers).[38] The average dose from the Three Mile Island accident was 0.01 mSv.[39] Non-civilian: In addition to the civilian accidents described above, several accidents at early nuclear weapons facilities - such as the Windscale fire, the contamination of the Techa River by the nuclear waste from the Mayak compound, and the Kyshtym disaster at the same compound - released substantial radioactivity into the environment. The Windscale fire resulted in thyroid doses of 5-20 mSv for adults and 10-60 mSv for children.[40] The doses from the accidents at Mayak are unknown. The Nuclear Regulatory Commission, the United States Environmental Protection Agency, and other U.S. and international agencies, require that licensees limit radiation exposure to individual members of the public to 1\xa0mSv (100 mrem) per year. Coal plants emit radiation in the form of radioactive fly ash which is inhaled and ingested by neighbours, and incorporated into crops. A 1978 paper from Oak Ridge National Laboratory estimated that coal-fired power plants of that time may contribute a whole-body committed dose of 19\xa0µSv/a to their immediate neighbours in a radius of 500 m.[41] The United Nations Scientific Committee on the Effects of Atomic Radiation\'s 1988 report estimated the committed dose 1\xa0km away to be 20\xa0µSv/a for older plants or 1\xa0µSv/a for newer plants with improved fly ash capture, but was unable to confirm these numbers by test.[42] When coal is burned, uranium, thorium and all the uranium daughters accumulated by disintegration\xa0— radium, radon, polonium\xa0— are released.[43] Radioactive materials previously buried underground in coal deposits are released as fly ash or, if fly ash is captured, may be incorporated into concrete manufactured with fly ash. In a radiation metrology laboratory, background radiation refers to the measured value from any incidental sources that affect an instrument when a specific radiation source sample is being measured. This background contribution, which is established as a stable value by multiple measurements, usually before and after sample measurement, is subtracted from the rate measured when the sample is being measured. This is in accordance with the International Atomic Energy Agency definition of background as being ""Dose or dose rate (or an observed measure related to the dose or dose rate) attributable to all sources other than the one(s) specified.[1] The same issue occurs with radiation protection instruments, where a reading from an instrument may be affected by the background radiation. An example of this is a scintillation detector used for surface contamination monitoring. In an elevated gamma background the scintillator material will be affected by the background gamma, which will add to the reading obtained from any contamination which is being monitored. In extreme cases it will make the instrument unusable as the background swamps the lower level of radiation from the contamination. In such instruments the background can be continually monitored in the ""Ready"" state, and subtracted from any reading obtained when being used in ""Measuring"" mode. Regular Radiation measurement is carried out at multiple levels.  Government agencies compile radiation readings as part of environmental monitoring mandates, often making the readings available to the public and sometimes in near-real-time.  Collaborative groups and private individuals may also make real-time readings available to the public.  Instruments used for radiation measurement include the Geiger–Müller tube and the Scintillation detector.  The former is usually more compact and affordable and reacts to several radiation types, while the latter is more complex and can detect specific radiation energies and types.  Readings indicate radiation levels from all sources including background, and real-time readings are in general unvalidated, but correlation between independent detectors increases confidence in measured levels.', ""The .gov means it’s official.Federal government websites often end in .gov or .mil. Before sharing sensitive information, make sure you're on a federal government site. The site is secure. The https:// ensures that you are connecting to the official website and that any information you provide is encrypted and transmitted securely. A1: A cabinet x-ray system is an x-ray system installed in an enclosure. The enclosure is intended to protect people from the x-rays generated and to exclude people from the enclosure’s interior. Cabinet x-ray systems are primarily used for security screening and industrial quality control. Security applications range from screening baggage at an airport to examining whole trucks at the border. Industrial quality control applications include the x-ray examination of foods, circuit boards, and tires. Some cabinet x-ray systems are also medical devices, such as a cabinet x-ray system used for analysis of tissue samples in a medical laboratory. A2: Other common names for cabinet x-ray systems are X-ray Inspection Systems, X-ray Screening Systems, X-ray Security Systems, and Baggage X-ray Systems. The words inspection, screening, security, and baggage might also be used interchangeably with or in addition to the description of a cabinet x-ray system. A3: The US Food and Drug Administration (FDA) has responsibility for assuring manufacturers produce cabinet x-ray systems that do not pose a radiation safety hazard. For most electronic products that emit radiation, safety regulation is divided between FDA and state regulatory agencies. Typically, FDA regulates the manufacture of the products and the states regulate the use of the products. For further information on FDA regulations that apply to manufacturers of electronic products that emit radiation; such as a cabinet x-ray system. Note: Manufacturers may be subject to additional FDA regulations if their cabinet x-ray system product is intended to be used in a medical application (e.g. specimen radiographs made in a medical laboratory) or in the inspection of foods (e.g. finding contamination in food such as metal fragments or bone chips found during manufacturing). These regulations do not address cabinet x-ray system radiation safety and their details are beyond the scope of this document. A4: The US Environmental Protection Agency (EPA) is responsible for issuing general radiation guidance to Federal Agencies. Additionally, basic information about radiation is available on the EPA web site (http://www.epa.gov). The US Occupational Health and Safety Administration (OSHA) has regulations on worker safety from radiation in the workplace (http://www.osha.gov). A5: Yes. Manufacturers are required to certify that their products meet the Federal radiation safety performance standard for cabinet x-ray systems. Specifically, the standard requires that the radiation emitted from a cabinet x-ray system not exceed an exposure of 0.5 milliroentgens in one hour at any point five centimeters from the external surface. Most cabinet x-ray systems emit less than this limit. In addition, the standard also requires safety features that include warning lights, warning labels, and interlocks. For comparison, the average person in the United States receives a dose of about 360 millirem of radiation per year from background radiation. (Note: 1 milliroentgen of exposure to x-rays will result in approximately 1 millirem of dose. These terms are defined later in this document.) Background radiation is radiation that is always present in the environment. Eighty percent of that exposure comes from natural sources: radon gas, the human body, outer space, rocks, and soil. The remaining 20 percent comes from man-made radiation sources, primarily medical x rays. For additional information on certification and labeling, see Title 21 Code of Federal Regulations (CFR) 1010. For the details of the cabinet x-ray performance standard see Title 21 CFR 1020.40. For further information on recommended limits of radiation exposure, we recommend the National Council on Radiation Protection and Measurements Report 116, Limitation of Exposure to Ionizing Radiation (1993). A6: Yes. The limit on radiation emission established by the performance standard is sufficiently restrictive that there is no additional hazard for specific populations such as children or pregnant women. For additional details please see the answer to question 5. A7: Personnel monitoring equipment is not required by Federal regulation for operators of cabinet x-ray systems. It is possible that some state regulations or the policies of the operators’ employer require use of personnel monitoring equipment. Personnel monitoring equipment means devices designed to be worn or carried by an individual for the purpose of measuring a radiation dose received (e.g. film badges, pocket dosimeters, film rings, etc.). For more information, please see the OSHA regulations found in Title 29 CFR 1910.1096(d) Precautionary procedures and personal monitoring and contact OSHA. The OSHA regulations are based on the amount of radiation that a worker can receive in a specific area from all radiation sources. The Federal limit on cabinet x-ray system emissions ensures the maximum possible exposure from cabinet x-ray systems in the workplace will always fall below the minimum threshold where personnel monitoring might be required. A8: There are no known adverse effects from eating food, drinking beverages, using medicine, or applying cosmetics that have been irradiated by a cabinet x ray system used for security screening. The radiation dose typically received by objects scanned by a cabinet x-ray system is 1 millirad or less. The average dose rate from background radiation is 360 millirad per year. The minimum dose used in food irradiation for food preservation or destruction of parasites or pathogens is 30,000 rad. For more detailed information on radiation used for food inspection or food treatment, see Title\xa021\xa0CFR\xa0179, www.FoodSafety.gov, contact FDA’s Center for Food Safety and Nutrition, or contact the United States Department of Agriculture Food Safety Inspection Service. A9: No, the x-ray dose received when a piece of electronic equipment is scanned by a cabinet x ray system used for security screening will not harm electronic equipment. A10: It is unlikely, but possible. Most cabinet x-ray systems used in the United States for security screening are built to be safe for all but the fastest film speeds (speeds below 1000). Multiple exposures of film to even film safe x-ray systems may eventually result in fogging or increased granularity. However, some systems, usually those scanning checked baggage, and some x-ray systems used in other parts of the world are not designed to be film safe. Manufacturers are not required by federal regulation to build their systems to be film safe. Your film manufacturer should be able to provide more specific recommendations about the storage and transport of exposed and unexposed film. A11: Exposure is a term defining the amount of ionizing radiation that strikes living or inanimate material. (This is a general definition. In health physics, exposure is specifically defined as a measure of ionization in air caused by x-ray or gamma radiation only.) Dose means the quantity of radiation or energy absorbed. Dose may refer to the following: Roentgen (R) is a unit of exposure of ionizing radiation and indicates the strength of the ionizing radiation. One Roentgen is the amount of x-ray needed to produce ions carrying 1 electrostatic unit of electrical charge in 1 cubic centimeter of dry air under standard conditions.Roentgen absorbed dose (rad) is the basic unit of absorbed radiation dose. A dose of 1 rad to an object means each gram of the object received 100 ergs of energy or 1 rad = 100 ergs/gram.Roentgen Equivalent Man (rem) is the basic unit of equivalent dose, and relates the absorbed dose in human tissue to the biological effect of the radiation. Not all radiation has the same biological effect, even for the same amount of absorbed dose."", 'Javascript is required for this site. Radiation occurs naturally and comes from sources all around us, including our own bodies. Radiation is often misunderstood, but helps to save lives and cure disease. Radiation is natural and found everywhere – it comes from outer space, the air we breathe, and the earth we tread. It’s even in our bodies; naturally occurring radioactive elements in our bones irradiate us on average 5000 times per second. Sleeping next to someone gives us a much higher radiation dose than living close to a nuclear power station – both of which are harmless. Life itself emerged at a time when the planet was much more radioactive than it is today, and all living organisms have evolved in ways to be able to coexist with radiation. Many find radiation scary, especially when it is associated with a nuclear power station, despite the fact that there is no difference between natural radiation and ‘man-made’ radiation. After an incident involving radiation, many become anxious because they cannot see, touch or smell it. Because we cannot sense radiation, we rely on different interpretations and portrayals of it to try and understand it – popular culture has played a significant role in shaping the way many of us relate to radiation. On average, we all receive between 2 and 3 millisieverts (mSv) of radiation every year, but this varies considerably around the world due to factors such as altitude and the composition of the ground. For instance, the radiation dose in Shanghai, which sits at sea level, is lower than in Denver, which sits at an elevation of 1610m. This is due to the fact that the atmosphere reduces the amount of radiation from space that we are exposed to. Denver, sitting at a higher altitude, receives more radiation due to a thinner atmosphere. Equally, flying exposes you to higher doses of radiation as the atmosphere is considerably thinner at 12,000 metres above the sea. Bedrock geology can also play a major role in background radiation levels. Many areas of the world, such as Kerala (India), Yangjiang (China), and Guarapari (Brazil), have background radiation levels 10-20 times higher than the global average. In Ramsar (Iran), residents can receive doses of up to 260 mSv per year, about 100 times the global average, due to naturally occurring radioactive elements.\xa0 However, there is no evidence of any adverse health effects in these areas. Many of these areas actually have higher radiation levels than many parts of the evacuation zones around Chernobyl and Fukushima. In fact, most areas of the Chernobyl and Fukushima evacuation zones have radiation levels no higher than natural background levels. A person’s background dose is also dependent on individual lifestyle (e.g. number of flights or medical procedures). Cancer patients often receive extremely high radiation doses – in some cases 40-60 Sievert over a period of a few weeks – to treat their disease. Cancer treatments focus on a specifically-targeted part of the body – which the body can cope with – whereas an identical dose over the whole body would be fatal. Building materials can also emit radiation. Many buildings made out of granite are radioactive, due to the fact that granite contains uranium. If \xa0the US Capitol Building in Washington, D.C. were a nuclear facility, it would not have been licensed due to the radiation levels the buildings gives off. The main negative health effect that people often associate with radiation exposure is cancer. Whilst many believe that all it takes is a single exposure to radiation for cancer to develop, this is not true. Because we are constantly surrounded by radiation, our bodies have developed sophisticated protection mechanisms against its effects. The health impacts of radiation is well understood and studied. The relationship between radiation exposure and cancer has been researched extensively for more than 100 years and it has been proven that radiation is only a weak carcinogen – in other words, it takes a very large amount of radiation to increase the risk of cancer only slightly. Exposure to radiation is the principal public concern in the event of a nuclear accident. The worst nuclear accident in history, which took place at Chernobyl, caused the death of 28 nuclear plant and emergency workers who were exposed to lethal amounts of radiation. Many of them received doses above 10 Sievert (10,000 mSv) within minutes or hours. Since the accident in 1986, Chernobyl also resulted in about 6500 thyroid cases – which would have been prevented if the authorities had stopped contaminated foodstuffs from entering the food chain. These cases have, to date, resulted in 15 deaths. In comparison, air pollution from the use of coal kills about 80 people - every hour - in China alone. Neither of the accidents at Three Mile Island nor Fukushima Daiichi – the only other civil nuclear power plants that have suffered accidents resulting in a noteworthy release of radioactive material into the environment – resulted in any radiation-induced health effects. Every year, nuclear medicine helps doctors diagnose and treat tens of millions of people. Using radiation, such as X-rays, doctors can make quick, non-intrusive and accurate diagnoses of a patient’s organs. Radioisotopes, which can be produced by commercial power reactors, are used as ’tracers’ in PET scans, which have proven to be the most accurate means of detecting and evaluating most cancers. Radiation can also be used as a non-invasive alternative to brain surgery. Radiation can also cure cancer and other life-threatening conditions. There are numerous different treatment options, either using external or internal radiation, with the aim to control or eliminate the cancer by irradiating the area containing it. One example is brachytherapy, where small radiation sources are placed inside the body, either inside or nearby the area that requires treatment. It is used to treat many different types of cancer, including breast, prostate and lung.']","Background radiation is the ionizing radiation present in the environment. Background radiation originates from a variety of sources, both natural and artificial. Sources include cosmic radiation, and environmental radioactivity from such as naturally occurring radioactive materials including radon and radium, and fallout from nuclear weapons testing and nuclear accidents."
how many mg in 1 unit of alcohol,"['Cannabis remains one of the most universally abused recreational drugs. Cannabis abuse can have several cardiovascular adverse effects and an overdose can lead to cardiac arrest. Binge alcohol drinking and subsequent withdrawal in the background of cannabis overdose can lead to convulsion and QT prolongation leading to malignant arrhythmia. We report two cases of ventricular fibrillation complicated with seizure precipitated by cannabis overdose and alcohol withdrawal. Such serious clinical presentation complicated with cardiac arrest does not necessarily lead to a fatal outcome if timely medical attention and care are provided. Timely aggressive resuscitative measures combined with intensive care can lead to a successful outcome. Later on, psychiatric counseling and occupational and behavioral therapies can help them to live longer. Cannabis remains one of the most universally abused recreational drugs worldwide and its popularity has increased considerably due to the recent legalization and medicinal use [1-5]. Sometimes, cannabis overuse can lead to malignant arrhythmia leading to cardiac arrest [5,6]. Alcohol withdrawal following binge drinking combined with cannabis abuse can lead to malignant arrhythmia, seizure, and at times culminating in cardiac arrest [2,5,6]. We report two cases of ventricular fibrillation (VF) complicated with seizure caused by cannabis overdose and alcohol withdrawal following binge drinking. Cannabis abuse can also lead to serious cardiac dysrhythmia complicated with seizure and ultimately cardiac arrest. If timely and proper resuscitative efforts are instituted, these patients can have a successful outcome. The patients’ consents were obtained. © 2018 The Author(s). This is an open-access article distributed under the terms of the Creative Commons Attribution 4.0 International License (CC-BY). The article is now accepted for publication. I accept the revised manuscript for publication. 109 E. 17th St. Suite #5366Cheyenne, WY 82001United States contact@scitemed.com We use cookies to ensure that we give you the best experience on our website. If you continue without changing your browser settings we will assume that you are happy to receive all cookies on the SciTeMed Publishing Group website. Privacy Policy|Cookies', 'This is a term related to Alcohol by Volume which is abbreviated as ABV or alc/vol. It is a common measure of the amount of alcohol present in any given volume of alcoholic drink and is expressed in alcohol percentage. It shows how much alcohol (ethanol – chemical compound) content there is in a beverage. A Unit of alcohol is used to indicate the actual alcohol quantity within a volume of alcoholic substance and to provide information on total alcohol consumption. One unit of alcohol contains 10 milliliters or 8 grams of pure alcohol. Typical servings of drinks usually contain 1-3 units of alcohol. Gravity in alcoholic beverages refers to specific gravity or relative density of the substance (wort or must) compared to the density of reference substance usually water. Gravity is measured by hydrometer. The density of a wort or must is influenced by their sugar content. The amplitude between the original (gravity before fermentation) and final gravity (measured when fermentation completes) indicates how much sugar has changed into alcohol and hence the bigger the difference, the more alcohol content present and the stronger the drink. Oxygen exposure to wine improves its taste because it softens the acerbic tannins and releases the fruit and floral aromas. So this is why wine is poured into decanters and wide wine glasses. The Units utilized for wine volume are the same as some standard volume units such as ounces, liters, milliliters. The names of the containers are also used for units for wine volumes such as glass and bottle.', 'Main was a station on the Chicago Transit Authority\'s Niles Center branch, now known as the Yellow Line. The station was located at Main Street and Skokie Boulevard in Skokie, Illinois. Main was situated south of Dempster and north of Oakton. Main opened on March 28, 1925, and closed on March 27, 1948, upon the closing of the Niles Center branch. Unité is a mobile network operator in Moldova. Working in CDMA,  UMTS and LTE   standards. Communication standard: Unité has a license to work in CDMA standard on frequency of 450\xa0MHz as well as in UMTS standard on frequencies of 2100\xa0MHz and 900\xa0MHz. Unité began its activity on March 1, 2007 as CDMA operator. On April 1, 2010 Unité launched its own 3.5G network. Unité offers mobile internet services via CDMA standard under the brand of ""Connect"" with speeds up to 2.4 Mbit/s and via 3.5G under the brand of ""3G Connect"" with speeds up to 14.4 Mbit/s Moldtelecom is 100% shareholder of the operator. Units of alcohol are used in the United Kingdom (UK) as a measure to quantify the actual alcoholic content within a given volume of an alcoholic beverage, in order to provide guidance on total alcohol consumption. A number of other countries (including Australia, Canada, New Zealand, and the US) use the concept of a ""standard drink"", the definition of which varies from country to country, for the same purpose.  ""Standard drinks"" were referred to in the first UK guidelines (1984) that published ""safe limits"" for drinking, but these were replaced by references to ""alcohol units"" in the 1987 guidelines and the latter term has been used in all subsequent UK guidance. One unit of alcohol (UK) is defined as 10 millilitres (8 grams) of pure alcohol.  Typical drinks (i.e. typical quantities or servings of common alcoholic beverages) may contain 1–3 units of alcohol. Containers of alcoholic beverages sold directly to UK consumers are normally labelled to indicate the number of units of alcohol in a typical serving of the beverage (optional) and in the full container (can or bottle), as well as information about responsible drinking.  Additionally, the advent of smartphones has led to the creation of apps which report the number of units contained in an alcoholic drink. Military organization or military organisation is the structuring of the armed forces of a state so as to offer military capability required by the national defense policy. In some countries paramilitary forces are included in a nation\'s armed forces, though not considered military. Armed forces that are not a part of military or paramilitary organizations, such as insurgent forces, often mimic military organizations, or use ad hoc structures. Military organization is hierarchical. The use of formalized ranks in a hierarchical structure came into widespread use with the Roman Army. In modern times, executive control, management and administration of military organization is typically undertaken by the government through a government department within the structure of public administration, often known as a Ministry of Defense, Department of Defense, or Department of War. These in turn manage Armed Services that themselves command combat, combat support and service support formations and units.', '', 'It looks like nothing was found at this location. Maybe try searching? Let us help you find a program that fits your needs, budget, and location. Call us anytime, our helpline is 100% free. Our proven process can help you find the right rehab for you or your loved one. We are here to help you every step of the way. We are not a government website, and display advertisements.\xa0GENERAL DISCLAIMER: QuitAlcohol.com is designed for educational purposes only and is not engaged in rendering medical advice. The information provided through QuitAlcohol.com should not be used for diagnosing or treating a health problem or disease. It is not a substitute for professional care. If you have or suspect you may have a health problem, you should consult your health care provider. The authors, editors, producers, sponsors, and contributors shall have no liability, obligation, or responsibility to any person or entity for any loss, damage, or adverse consequences alleged to have happened directly or indirectly as a consequence of material on this website. If you believe you have a medical emergency, you should immediately call 911. Our helpline is available 24 hours a day, 7 days a week at no cost to you and with no obligation for you to enter into treatment. In some cases, Quit Alcohol charges our verified partner a modest cost per call, which helps us cover the costs of building and maintaining our website. We do not receive any commission or fee that is dependent upon which treatment provider a visitor ultimately selects.', 'Enter your email address to join the network and receive notifications of new activity by email. The high calorific content of alcohol will be the latest focus of the Government’s drive on Britain’s drinking culture. The hope is that by showing that the average wine drinker consumes an extra 2,000 calories a month – over a year this would be the equivalent of eating 184 bags of crisps – people will cut down on their alcohol. Britain is one of the fattest nations in Europe and is also classed as being home to the biggest drinkers. In England two thirds of adults and one third of children are either overweight or obese. Few middle class drinkers realise that a couple sharing a bottle of red wine a night are both consuming the equivalent of a Snickers chocolate bar in alcohol. This means a woman would consume eight days’ worth of calories in a week. Over a year this would mean putting more than two stone in fat unless those extra calories were burned off in exercise or food intake was reduced to compensate. A man drinking five pints of lager a week would consume 44,200 calories in alcohol a year, the equivalent to 221 doughnuts, and put on 12 pounds of fat unless he cut his diet elsewhere. A YouGov poll found that the average wine drinker admits to consuming around a bottle of wine per week, a spokesman for the Department of Health said. A survey conducted by the Know Your Limits campaign found that one in three drinkers say they order crisps, nuts or pork scratching with their alcohol, piling on more calories and a fifth would grab a burger or takeaway when drinking more than two pints of beer or two glasses of wine. A person needs to consume 500 more calories a day than they burn off for a week, or 3,500 calories in total, to put on between one and two pounds of fat, a spokesman for the Medical Research Council’s Human Nutrition Research centre in Cambridge said. Government guidelines say women should drink no more than two to three units a day and men no more than three to four. There is eight grams of alcohol and seven calories in a UK unit of alcohol. Heather Caswell, spokesperson for the British Nutrition Foundation added: “Many women don’t know that two large glasses of white wine not only puts them over the recommended daily limit for alcohol consumption, but also provides them with nearly 20 per cent of their daily calorie allowance, at approximately 370kcals in total. “Most people would baulk at consuming a full glass of single cream, but wouldn’t think twice about a couple of pints. But the calorie content is similar and, over time, excess alcohol intake is likely to lead to weight gain. “Sticking to sensible drinking habits and keeping to the recommended units will not only help keep off those extra pounds but will also help decrease your risk of serious health problems, such as some types of cancer and liver disease.” Don Shenker, Chief Executive of Alcohol Concern, said: “The challenge faced by this country of rising obesity and alcohol health problems go hand in hand. “Weight gain is only one of the harms caused by excessive drinking and there’s little understanding of the calorie content of alcohol. “It’s remarkable that there’s more dietary information on a can of cola than on a bottle of wine. The government needs to urgently press ahead with mandatory labelling to ensure people know exactly what they’re drinking.” Health Minister, Phil Hope said: “Regularly drinking more than our recommended daily limits can have a knock on effect on our health – including an expanding waistline. “It’s not only the calories in the drinks themselves that can help to pile on the pounds, we’re also more likely to eat fatty foods when we’ve had one too many. To avoid piling on the pounds we should try to drink within the recommended limits, eat a healthy diet and exercise regularly.” Large glass (250ml) of average strength red wine = 214 calories = one bag of Cheesy Wotsits. A bottle of average strength red wine = 644 calories = 14 jaffa cakes or McDonald’s Cheeseburger and medium fries. Large glass of medium dry white wine = 190 calories = two and a half digestive biscuits. Bottle of medium dry white wine = 570 calories = chicken with cashew nuts and egg fried rice. source: Human Nutrition Research and weightlossresources.co.uk Hello, how’s it going with your fitness routines/programmes? Hope all well. I am happy to report I came third in the pedometer walking challenge at work last week and looking forward to my prize – guessing it won’t be chocolate. Does anyone regularly wear a pedometer or other fitness device like a fitbit? I want to buy one (or get hubs to lol) and would really appreciate recommendations if poss. I have started the UK NHS Couch to 5K http://www.nhs.uk/Livewell/c25k/Pages/couch-to-5k.aspx and enjoying it; finding with the intervals of walking and running I can push myself to run faster, rather than trying to maintain a sludgy, stumbly jog, red faced and in pain… Food wise I have got into a routine of 400 calorie ish sandwich am and pm, some fruit and coffees. This routine with the exercise led me to losing 6lbs last week. I’ve managed to knock the sugary rubbish on the head but not thinking ‘banned’ as this immediately makes me want it. I have dropped pasta and potatoes for the moment, cheese and yogurt. Brown rice rather than white. My previously bloated, windy and sore tummy is saying thank you. As with alcohol, the word ‘banned’ makes certain foods instantly desirable to me…nope, am saying to myself ‘choose not to’ and this works much better in my head. I am pretty much convinced making this change in thinking/wording is the key to overcoming any addiction. It certainly worked with alcohol to change from ‘can’t’ to ‘choose not to’. The next thing I need to tackle, for me personally, is over eating at night. I still come in at night feeling wired and use a big yummy meal to wind down and feel better. Which is fine for maintaining weight, but not for losing it. To lose the pounds I need to be eating smaller at night, and then once the job is done, relax a bit. I am finding setting a series of goals and actions associated with these goals is really helpful to me, rather than trying to do ‘everything’ all at once and ‘it’ becomes a big mush in my head. Routine and predictable patterns are working for me. – cut out/right down white bread, pasta, potatoes, rice, cheese, yogurt (always get medical advice for your own situation, this is not expert advice!).\xa0 These dietary changes have helped my poorly, sore, bloated tum massively. I have also found that nuts made me sore, and I feel better when not eating them.I am mentally better and sleeping more deeply, too. \xa0 As I say, get advice before making changes to your own normal diet. 22 lbs to go.', '']","One unit of alcohol (UK) is defined as 10 millilitres (8 grams) of pure alcohol. Typical drinks (i.e., typical quantities or servings of common alcoholic beverages) may contain 1 -- 3 units of alcohol."
where are bobcats located in the united states,"['.. everything you want to know about animals is so close..', '', '']","The bobcat is an adaptable animal. It prefers woodlands -- deciduous, coniferous, or mixed -- but unlike the other Lynx species, it does not depend exclusively on the deep forest. It ranges from the humid swamps of Florida to desert lands of Texas or rugged mountain areas. It makes its home near agricultural areas, if rocky ledges, swamps, or forested tracts are present; its spotted coat serves as camouflage. The population of the bobcat depends primarily on the population of its prey; other principal factors in the selection of habitat type include protection from severe weather, availability of resting and den sites, dense cover for hunting and escape, and freedom from disturbance."
what is the standardized coefficient in a regression,"['One of the outputs of a Species Distribution Modelling experiment is the Variable Importance Plots (VIP), which can assist in understanding the contribution of environmental predictor variables to the model outputs. Our colleagues Assoc Prof Sama Low-Choy and Dr John Xie at Griffith University have written a special R function (VIPplot) for us to incorporate into the BCCVL to generate these plots. The plots are based on algorithm-specific outputs, and are currently available for the following algorithms: CTA, GAM, Maxent, GLM, GBM, RF and ANN. Depending on what is appropriate for each algorithm, the variable importance plots differ in assessment method. This plot is only included for the GLM algorithm. The effect size measures the variable importance in terms of goodness-of-fit, and is here defined as the absolute values of the standardised regression coefficients (also referred to as the beta weights). Standardised coefficients refer to how many standard deviations the response variable will change per a standard deviation increase in the predictor variable. This reflects the rank ordering of the predictor variables with respect to the role they play in accounting for variability on the response variable. A negative effect size indicates that an increase in the value of the predictor (e.g. an increased temperature) results in a lower probability of occurrence, whereas a positive effect size indicates that an increase in the predictor variable results in an increased probability of occurrence. The graph represents the confidence interval of the effect size per predictor variable. If the confidence interval crosses the zero line, then the association is considered non-significant. Thus, only predictor variables with a confidence interval below or above zero are considered to be of significant importance. The variable with either the highest or lowest effect size is the most important variable. The effect size plot below indicates that B12 is the most important predictor variable, and B17 the least important, but all predictor variables have a significant effect on the response variable. It is important to note that the effect size assessment relies on the condition that all of the predictor variables are independent of another. Correlation among predictor variables makes it difficult to determine how much variability in the response variable can be accounted for by any single predictor variable. This is why the VIP output also includes a correlation matrix (see below). This plot is included for the GLM and GAM algorithms. The AIC method measures the prediction performance in terms of information loss if a predictor variable would be excluded from the fitted model. It uses the Kullback-Leibler (K-L) information, which is a unique overall measure of discrepancies between a fitted model and the true model which generates the observed data. AIC is derived by minimizing the relative K-L information. For the machine learning algorithms ANN and GBM, the AIC approach is not applicable because there is no model log-likelihood information available. Therefore, we have included the variable importance function that is implemented in the biomod2 package. This function uses a machine-learning approach once the models are trained to randomize one of the variables in each permutation and calculate a correlation score between the standard prediction and the new prediction. This score is considered to give an estimation of the variable importance in the model. The higher the value, the more importance the predictor variable has on the model. A value of 0 assumes no influence of that predictor. Note that this method does not account for interactions between variables and should be considered more as an information tool for each model independently. For tree-based models, the variable importance is measured by the total decrease in node impurities from splitting on the variable, averaged over all trees. For classification trees, this impurity is measured by the Gini index. The VIP output for the Classification Tree algorithm in the BCCVL includes the tree plot as well as the variable importance score plot. This matrix is currently only included for the GLM and Maxent algorithms. This matrix shows the linear correlation among predictor variables included in the model. This can be used to ensure that the included variables in the model are not too highly correlated which might bias the model outputs. For each combination of predictor variables the correlation is indicated as being either strongly negative (dark green), weakly negative (light green), weakly positive (light pink) or strongly positive (dark pink). The diagonal of the matrix represents the relationship of each variable with itself which is obviously always 1.', ""Sorry, we couldn't find the page you are looking for.Please use the search box in the upper right corner or contact us. ERIM is the joint research institute of Rotterdam School of Management, Erasmus University and the  Erasmus School of Economics, Erasmus University Rotterdam."", ""Click through the PLOS taxonomy to find articles in your field. * E-mail: guendalina.graffigna@unicatt.it http://orcid.org/0000-0002-8514-2563 Increasing bodies of scientific research today examines the factors and interventions affecting patients’ ability to self-manage and adhere to treatment. Patient activation is considered the most reliable indicator of patients’ ability to manage health autonomously. Only a few studies have tried to assess the role of psychosocial factors in promoting patient activation. A more systematic modeling of the psychosocial factors explaining the variance of patient activation is needed. To test the hypothesized effect of patient activation on medication adherence; to test the the hypothesized effects of positive emotions and of the quality of the patient/doctor relationship on patient activation; and to test the hypothesized mediating effect of Patient Health Engagement (PHE-model) in this pathway. This cross-sectional study involved 352 Italian-speaking adult chronic patients. The survey included measures of i) patient activation (Patient Activation Measure 13 –short form); ii) Patient Health Engagement model (Patient Health Engagement Scale); iii) patient adherence (4 item-Morinsky Medication Adherence Scale); iv) the quality of the patients’ emotional feelings (Manikin Self Assessment Scale); v) the quality of the patient/doctor relationship (Health Care Climate Questionnaire). Structural equation modeling was used to test the hypotheses proposed. According to the theoretical model we hypothesized, research results confirmed that patients’ activation significantly affects their reported medication adherence. Moreover, psychosocial factors, such as the patients’ quality of the emotional feelings and the quality of the patient/doctor relationship were demonstrated to be factors affecting the level of patient activation. Finally, the mediation effect of the Patient Health Engagement model was confirmed by the analysis. Consistently with the results of previous studies, these findings demonstrate that the Patient Health Engagement Model is a critical factor in enhancing the quality of care. The Patient Health Engagement Model might acts as a mechanism to increase patient activation and adherence. Copyright:  © 2017 Graffigna et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. Data Availability: All relevant data are within the paper. Funding: The authors received no specific funding for this work. Competing interests:  The authors have declared that no competing interests exist. An increasing body of scientific research today examines the factors and interventions affecting patients’ ability to self-manage and adhere to treatment.[1,2] Patient activation is considered to be the most reliable indicator of the willingness and ability to manage health and care autonomously.[3–5] The patient activation theory has been developed by Hibbard and Mahoney.[2] It describes an incremental process, which patients undergo when becoming protagonists of their care management. Specifically, this theory is rooted in the concepts of self-efficacy [6,7] and locus of control, [8,9] and in the transtheoretical model of change.[10] It refers to “the individual’s knowledge, skill and confidence in managing his/her own health and care”[11]. Drawing on this theory, Hibbard and Mahoney [2] developed the Patient Activation Measure (PAM-13), which is a 13-item Likert self-reported questionnaire. The PAM-13 is widely used to measure the level of empowerment and self-management of chronic care patients. [5] The scale features four levels of patient activation describing different levels of patients’ readiness to assume an active role in their care management. Previous studies have shown the role of patients’ activation in influencing their adherence to treatment prescriptions. [12,13] Moreover, studies have found that patients actively involved in their care plans are also more likely to trust their clinicians [14] and less likely to experience adverse clinical events and hospital readmissions.[15] Furthermore, making patients active in their healthcare is also recognized as a key strategy with which to make healthcare more sustainable by reducing healthcare-related costs.[16] Numerous studies have demonstrated empirically that patients more activated in their care are also more likely to enact preventive behavior such as having regular check-ups, screenings, and immunizations.[17–20] More highly activated people are also significantly more likely to enact healthy behaviors such as following a healthy diet and taking regular exercise. [21] Moreover, those who are more activated are more likely to avoid health-damaging behaviors like smoking and substance abuse.[22] In general, studies have demonstrated the association of a high level of patient activation with positive clinical outcomes in several populations across chronic conditions [23–27]. This has generated the hypothesis that the patient activation process, its antecedents, and its consequences on patient care, are disease-transcending instead of disease-specific. [28] A great deal of effort is being devoted to implementing programs and initiatives intended to improve patients’ activation as a crucial predictor of medication adherence and better healthcare utilization. But they often prove not to be effective.[28] The reason for this ineffectiveness is often attributed to the lack of personalization of patient activation interventions.[29] A further reason may relate to the lack of agreement on the factors associated with patient activation and which may promote it.[30] The variance empirically explained regarding the level of activation in patients with chronic illness is still low,[31] so that it is difficult to design interventions effective in promoting self-management. In particular, the vast majority of studies exploring the variables that may impact on patient activation are primarily related to extrinsic factors related to the patient condition. In this domain, studies have demonstrated the association between patient activation and socio-cultural characteristics of the individual patient such as gender, age, level of education[28,32] and level of income [12,33]. Other studies have demonstrated the association between patients’ activation and their clinical condition: such as type and year of diagnosis [28], type of treatment regimen [34], level of health literacy[35–37], and psychiatric and cognitive condition of the patient[38]. However, the results are often partial and contrasting, which impedes final consensus on the factors, which predict the patient activation level. Only few studies have sought to assess the role of psychological factors in influencing patient activation[24,35,39,40], although the level of patient activation may not be ascribable solely to external, contextual causes. In this regard, some studies have verified that patients’ health locus of control[41,42]–defined as the individual’s set of beliefs and motivation concerning self-determination of his/her health–is associated with patients’ level of activation.[13,40] Similarly, the perceived level of social support received from informal caregivers or the patient’s peers has been demonstrated to be a predictor of patient activation.[31] Other studies have argued that the emotional state of patients in a specific life moment may influence their ability to assume a proactive role in their care management [43]. These studies have shown that a higher level of patient activation is associated with lower depressive symptoms, although they have not demonstrated the causal relationship (and its direction) between these two variables (patient activation and depressive symptoms). Finally, some studies have explored the role of the perceived quality of the patient/doctor relationship in determining patients’ activation: in particular, a reference healthcare professional perceived as open to dialogue, emotionally supportive, and easily accessible has been demonstrated to be associated with a higher level of patient activation.[14,44] This preliminary scientific evidence on the psychological factors associated with patient activation is promising. They suggest that more personalized interventions aimed at improving patients’ self-management and adherence can be devised. However, only few of the studies currently available in the scientific arena have explored the causal relationship between these different factors and patient activation.[39,45,46] A more systematic modeling of the psychosocial factors causing patient activation is therefore needed. Furthermore, the concept of patient activation often overlaps with the one of patient engagement. However, systematic reviews of the scientific literature demonstrated that the two concepts are diverse and linked to different phenomena. Basing on previous studies, patients’ engagement refers to the ability of patients to give sense and to adjust to their disease and their actual care condition. It may play an important mediating role in the activation process and in patient adherence to treatment. In previous studies, we have explored how the experience of patient engagement emotionally develops in the care journey as a consequence of a complex sense-making process related to patients’ health status and perceived role in the healthcare journey. We have described this process in its four evolving phases (blackout, arousal, adhesion, eudaimonic project) and termed it the Patient Health Engagement Model (PHE-model).[44,47–50] This model highlights how patients emotionally elaborate and give sense their illness status and patients’ identity, and it may be considered a crucial precursor of their ability and willingness to play a more active role in self-management. A previous study has highlighted how PHE-model plays a mediating role in the activation of type-2 diabetes patients.[44] Based on these premises, we claim that the ability of the healthcare professional to legitimize the proactive role of patients in their healthcare might affect their reported adherence to medical treatments. This variable might also predict the level of patient activation. Furthermore, the quality of the emotional feelings experienced by patients in relation to their illness might impact on patient activation levels. Finally, we assume that the PHE-model—due to its ability to capture the psychological journey of patient engagement–may be a mediator of the impact of the quality of emotional feelings and of the perceived quality of the relationship with the healthcare professional on patient activation and on patient adherence (Fig 1). This is a path diagram describing the hypothesized effects of positive emotions and of the ability of the healthcare professionals to support patients’ autonomy on patient activation and medication adherence; it also describes the hypothesized mediating effect of patient engagement in this pathway. Unidirectional straight arrows indicate the predicted direction of the hypothesized effect. Note: HCCQ: Health Care Climate Questionnaire, PHE-s: Patient Health Engagement Scale, SAM: Self-Assessment Manikin Scale, PAM-13: Patient Activation Measure-short form, MMAS-4: 4 item-Morinsky Medication Adherence Scale. This is a path diagram describing the hypothesized effects of positive emotions and of the ability of the healthcare professionals to support patients’ autonomy on patient activation and medication adherence; it also describes the hypothesized mediating effect of patient engagement in this pathway. Unidirectional straight arrows indicate the predicted direction of the hypothesized effect. Note: HCCQ: Health Care Climate Questionnaire, PHE-s: Patient Health Engagement Scale, SAM: Self-Assessment Manikin Scale, PAM-13: Patient Activation Measure-short form, MMAS-4: 4 item-Morinsky Medication Adherence Scale. https://doi.org/10.1371/journal.pone.0179865.g001 The research was conducted on a sample of 352 Italian-speaking chronic patients randomly selected from the Research Now Panel (http://www.researchnow.com/en-US.aspx). The entire Research Now Panel covers a wide range of chronic diseases and comprises more than 6.5 million registered subjects worldwide. The panel provider screens subjects belonging to the Research Now Panel for their authenticity via digital fingerprint and geo-IP-validation. All Research Now’s panelists are profiled on the basis of their socio-demographic, clinical and lifestyle characteristics. To ensure data reliability, the Research Now Panel is certified to be statistically representative of all the populations covered. For the specific purposes of this research, we randomly selected a sample of patients enrolled by the Research Now panel, according to the following pre-defined inclusion criteria: patients included in our study sample had to be Italian-speaking, affected by a chronic condition, aged over 18 years old, and of each gender. Patients with dementia, cognitive impairments, active psychiatric disorders, blindness, deafness, or insufficient Italian language skills to answer the questions meaningfully, or without informed consent, were excluded from this study. In order to be certain regarding our sample patients’ characteristics we asked them to confirm—before completing the study’s survey—previously collected by the Research Now Panel such as their demographics (i.e. gender, date and place of birth, ethnicity, nationality, educational level, place of residence) and clinical diagnosis. The sample included in our study is not a stratified and fully representative of the Italian chronic population but it was randomly selected in order to guarantee its probabilistic feature. However, in this study we did not seek a descriptive estimation of the variables under examination, rather we were interested in their associative relationship. Thus, we did not consider the full representativeness of the sample necessarily required. All participants provided written informed consent before being enrolled in the research. Initially, we randomly selected and enrolled a convenience sample of 500 patients according to the inclusion criteria established for this study. Only 352 returned the completed survey. Patients who did not complete the entire survey did not differ from the ones who provided all responses in terms of socio-demographic characteristics (Table 1). https://doi.org/10.1371/journal.pone.0179865.t001 The survey was based on a structured self-administered online questionnaire (powered by the QUALTRICS online platform, https://www.qualtrics.com/). The Research Now Panel provider mailed the online link to the survey to the enrolled participants. The questionnaire developed by the Authors of this study included validated measures and ad hoc items. Following, a detailed description of the included measures: Data analysis was conducted in five steps. In the first step descriptive analyses were conducted, with particular reference to socio-demographic characteristics of the sample. In a second step of the analysis, the psychometric properties of the instruments were assessed in terms of reliability by using Cronbach’s Alpha for metric variables or Ordinal Alpha via Empirical Copula for ordinal variables [44]. A Cronbach’s or Ordinal Alpha via Empirical Copula, which was higher than 0.7 was considered acceptable. An evaluation of floor and ceiling effects for each items and a measure of skewness and kurtosis for the total scores of each scale were also performed in order to test Gaussian assumptions of next analyses. In a third step of analysis, Gender, Education, Age, Employment and Marital Status Differences on outcome variables (PAM-13 and MMAS-4) were investigated. For gender and age factors a t-test was conducted; for other factors a univariate Anova. In a fourth step of analysis, correlations between all the considered variables were calculated. Since every instrument produced a metric score, the linear correlation coefficient r was calculated and evaluated with a significance test. In the last step, a Structural Equation Model with observed variables using ML estimation method was implemented [45] in order to evaluate the relationships between the considered variables and to explore the theoretical model hypothesized (see the hypotheses stated above). Structural equation analysis was conducted to test the hypothesized relationships among variables, which are based on a theoretical model previously developed (Fig 1). In the model we considered HCCQ and SAM as exogenous variables, and mediator (PHE-S) and dependent variables (PAM-13, MMAS-4) as endogenous ones. The Goodness-of-fit indexes were examined through Chi square test, RMSEA, CFI and SRMR. Models with acceptable fit presented non-significant Chi square value, RMSEA < .08 CFI > .90 and SRMR < .08 [46]. The normed fit index (NFI), relative fit index (RFI), incremental fit index (IFI) and Tucker-Lewis index (TLI) were used as incremental fit measures. An incremental fit measure value > 0.9 indicated a `good' fit for the model. Parsimonious normed-of-fit index (PNFI) and parsimonious comparative fit index (PCFI) were used as parsimonious fit measures. A value > 0.05 was considered reasonable for a good model fit. To improve the goodness-of-fit, modification indices were considered. Analysis was conducted with IBM SPSS 24.0 and AMOS 23.0. The study received approval from the Università Cattolica del Sacro Cuore Ethics Committee. Patients consented to participate in the study, and they were allowed to withdraw from the study whenever they wanted. The data were collected anonymously and analyzed in aggregated form. Overall, 500 patients were invited to participate in the study and completely answered the questionnaire for the analysis. 352 patients (159 female) completed the survey, mean age 53.1 (±15.1), and years with mean disease duration of almost 12 years. Table 1 lists the socio-demographic, clinical and psychometric characteristics of the sample. Mean, standard deviation (unless otherwise indicated) and a suitable reliability index (Cronbach Alpha or Ordinal Alpha via Empirical Copula) are reported for all the psychometric measures considered. All the psychometric measures presented a good or excellent reliability, with a Cronbach or Ordinal Alpha ranging from .77 to .93. No floor and ceiling effects were detected. Asymmetry and Kurtosis indices were in the acceptable limits [-1; + 1]. A t-test was performed to determine whether there were significant differences by gender and age (under or over 65 years) related to the outcome variables PAM-13 and MMAS-4. An univariate Anova was performed to investigate differences related to the outcome variables for educational, employment and marital status. The results are reported in Table 2. Socio-demo characteristics did not impact on PAM-13 scores, while age and employment status had a significant effect on MMAS-4. In particular, older and retired subjects presented a lower level of treatment adherence. https://doi.org/10.1371/journal.pone.0179865.t002 Table 3 reports linear correlation coefficients between the psychometric variables considered. https://doi.org/10.1371/journal.pone.0179865.t003 HCCQ presented a significant correlation with all the measures except SAM: a positive correlation with PHE-S and PAM-13 and a negative correlation with MMAS-4 were detected. SAM had a significant positive correlation with MMAS-4, and a negative correlation with PHE-S and PAM-13. PHE-S showed a significant direct correlation with HCCQ and PAM-13, and a negative correlation with SAM and with MMAS-4. PAM-13 had a significant direct correlation with all the measures except SAM and MMAS-4. Considering the hypotheses to be tested in the study and the correlations between the psychometric measures detected, a Structural Equation Model was implemented to verify associations and relationship between the variables. Relationships among patients' perceptions of the ability of the healthcare professionals to support their autonomy (HCCQ), negative patients’ emotions (SAM), patients’ engagement (PHE-S), patients’ activation (PAM-13) and medication adherence (MMAS-4) were tested. Fig 2 shows the explanatory model of the hypotheses that we wanted to verify. Circles indicate unobserved latent variables, while rectangles represent observed variables. Significant paths with their estimated parameter are shown by solid lines. Standardized path coefficients are presented at the midpoint of the unidirectional arrow paths. Not significant paths are shown by dashed lines. Circles indicate unobserved latent variables, while rectangles represent observed variables. Significant paths with their estimated parameter are shown by solid lines. Standardized path coefficients are presented at the midpoint of the unidirectional arrow paths. Not significant paths are shown by dashed lines. https://doi.org/10.1371/journal.pone.0179865.g002 The hypotheses were verified. Evaluation of the modification indexes did not suggest any change to the structure of the model. The model presented an acceptable goodness-of-fit. Chi square test was not significant (χ2(1) = 1.9, p = .17). All goodness of fit indexes were satisfactory (RMSEA = 0.052, CFI = 0.996, SRMR = 0.040). The estimated paths were significant (p < .001). The Adjusted Goodness-of-fit (AGFI) was superior to .90 (AGFI = 0.967). NFI = 0.984, RFI = 0.940, IFI = 0.992, TLI = 0.960 as incremental fit measures, and PNFI = 0.099, PCFI = 0.100 as parsimonious fit measures confirmed the adequacy and consistency of the model. Some path coefficients have not been significant. Table 4 reports all standardized path coefficients, standard errors, 95% confidence intervals (via percentile bootstrap method) and p-value. https://doi.org/10.1371/journal.pone.0179865.t004 In addition to overall model fit, path coefficients also provide information regarding the direct and indirect effects. The direction of the arrow in Fig 2 implies the flow of the causal effect and the impact of one variable on another. Standardized path coefficients (i.e., the direct effect of a variable on the other) varied between-1 and +1 and could be interpreted in the same way as standardized multiple regression coefficients, indicating the amount of standard deviations a dependent variable will change, per standard deviation increase in the predictor Variable. Table 5 shows the standardized total, direct and indirect effects of each variable (estimates and standard errors) on the dependent variable MMAS-4. https://doi.org/10.1371/journal.pone.0179865.t005 The purpose of the analysis reported by this study was to contribute to the scholarly debate on the determinants of patient activation. In particular, given the crucial role that the level of patient activation plays in promoting the better quality and effectiveness of healthcare, the first objective was to verify the association between PAM-13 level and patients’ reported adherence to treatment. Consistently with other previous studies [64,65], our results confirmed this relationship by demonstrating that patients’ activation is associated to their reported treatment adherence. This result is relevant to clinical practice because it confirms the importance of allocating time and effort to promoting patients’ empowerment and activation in order to assure their ability to self-manage and effectively adhere to treatment. In this study we verified the theoretical hypothesis and the hypnotized relationships among the variables included in our conceptual model. Structural equation analysis allows testing hypotesized relationships among variables, which are based on a theoretical model previously developed. Further research should be conducted in order to increase evidences about the direction of the hypotesized relationships among the variables. Indeed, reverse causality could be possible and should be tested by conducting longitudinal research design. For instance, further studies could be aimed at exploring the hypothesis that being empowered in their medical care cause patient to feel more positive in general and to experience higher quality patient-doctor relationships. Furthermore, the analysis sought to disentangle the roles of psychosocial variables, such as positive emotion and perceived quality of the doctor/patient relationship, in determining the level of patients’ activation. We claimed that not only extrinsic factors such as patients’ demographic characteristics and their disease conditions might influence their level of activation. In this framework, we primarily explored the role of positive emotional feelings in affecting patient activation, on the assumption that the psychological wellness of patients and their ability to adapt positively to their illness may be an antecedent of their ability to self-manage and assume an active role in the healthcare journey. This relationship was verified by confirming the role of the patients’ positive emotional state in affecting patient activation. Furthermore, we explored the predictor role of the perceived quality of the patient/doctor relationship in sustaining patient activation. Also this relationship was verified, thus confirming the findings of previous studies [44,66–68]. In particular, the ability of healthcare professionals to motivate patients towards self-management and treatment adherence is important in this process; but especially so are their recognition and acceptance of the patients’ active role in the care journey. This study has demonstrated that the healthcare professional’s ability to make the patient autonomous in the care journey predicts the ability of patients to adopt a proactive role in the healthcare experience and to adhere to treatment [66,67,69]. This result suggests interesting further investigation on how the role of healthcare professionals and their attitudes to engagement are crucial assets with which to achieve activation.[70–75,68,67] Attitudes not given for granted since the concept of patient activation and engagement put into question the need of revisiting traditional power dynamics in the doctor-patients relationships [76,77]. A further purpose of our analysis was to explore the role of PHE-model in explaining patient activation. Particularly we proposed to consider Patient Health Engagement such as the patients’ psychological elaboration of their healthcare experience. In this study we explored the role of PHE-model in mediating the impact of positive emotions and the perceived quality of the doctor-patient relationship on the level of patient activation and medication adherence. Also this relationship was verified, confirming that PHE-model is a crucial factor in their ability to assume an active role in self-management and treatment adherence. In previous studies, we argued that PHE-model must be conceived as a complex psychological process of adjustment to illness, which evolves in time and which is a function of several contextual factors [47]. In particular, engaging in the healthcare journey means becoming able not only to accept the diagnosis and its consequences for one’s health condition and lifestyle but also to understand one’s potential (starring) role in the care process. As a consequence, also the patient’s ability to become proactive in self-management and treatment adherence, thus improving his/her level of activation, is the result of a complex psychological elaboration and adjustment to the disease (and to the new”role patient”). Activation, therefore, may not be conceived as an ‘on/off’ state; it is determined by the developmental change in the patient’s identity on a complex journey of engagement. At the beginning of the care pathway, in fact, patients may be too overwhelmed and shocked (the ‘blackout’ phase in the PHE Model [50,78–80] to be able to assume an active role in the care process. In this phase patients tend to be passive and to delegate all decisions and actions concerning their care to the reference healthcare professionals. Activation or promotion of patient empowerment may be difficult and even counterproductive in this phase because the patient would reject medical attempts to make him or her autonomous. With time, clinical support and education, the patient may then evolve in his/her adjustment to the disease and the care management. S/he moves to the state of psychological ‘alert’: here the patient is over-sensitized and worried about his/her ill body, and hyper-vigilant on signs and symptoms that may occur. In this phase, the patient is disorganized in his/her activation in a way likely to be dysfunctional for the clinical relationship and the care management. In this phase the patient is ‘disease centered’ because his/her psychological energy and cognitive resources are all focused on the disease, but s/he may be disorganized and over-demanding in his/her navigation of the healthcare system. As their psychological adjustment evolves, patients acquire better mastery of their illness condition and improved awareness of their important role in determining the effectiveness of their care (‘adhesion’ phase). In this psychological phase, patients become ‘good patients’, with an acceptable literacy about their disease and its treatment and able to comply with the medical prescriptions. Although they are activated, they are not autonomous in self-management because they are still very reliant on their reference healthcare professional, whom they tend to over-consult upon even minimum changes in their everyday and care routines. Patients in this state tend to be still rather unsure about their role in self-determining the care journey and still reluctant to be autonomous in self-management. A phase of full engagement then follows. Patients are completely aware of their health and care conditions, and also able to make satisfactory life plans despite the disease. According to the PHE-Model these patients are in a state of Eudaimonic Project. They have fully mastered their patient identity and agreed to play an active and fulfilling role in the care journey. But they have also become able to perceive themselves as persons, and not just as patients afflicted by a disease and by medical treatments. These patients have determined that ‘they are not their disease’, and this new psychological awareness foster energy, positive emotions and self-confidence in them. Patients in this phase are fully aware that they are co-authors of their health. They accept that the effectiveness of care is also dependent on their motivation and determination to fight the disease and improve their quality of life. These fully engaged patients are well able to navigate the healthcare system and adhere to the medical prescription. They are also able to enact effective shared decision–making. [66,67,81,82]. Moreover, they become apostles of engagement practices, providing crucial testimony for other patients affected by the same disease but at the beginning of their engagement journey. These patients are fully activated and empowered towards their medical journey. Concerning this study’s limitations, the heterogeneity of the diseases suffered by the patients in our sample may be regarded as a weakness. Furthermore, although the sample analyzed by our research was not stratified and fully representative of the Italian chronic population, it was randomly selected in order to guarantee its probabilistic nature. We used it only to explore the relationships among the variables under analysis (i.e. for associative purposes, not for descriptive estimation of their dimensions): given these considerations, full representativeness was not necessarily required. Moreover, in this study we explored formal mediation among the included variables. This is basically an observational study with no experimental manipulation of the independent variables involved in the conceptual model under investigation. Indeed, it is possible that several of the relationships between the variables included in the analysis are actually operating in a reverse manner from the hypothesized relationships (i.e., perhaps adherence increases patient activation through feeling the positive benefits of treatment) and the cross-sectional nature of the data preclude determining this. For these reasons, further longitudinal studies should be conducted to verify a causal relationship among the variables. Furthermore, although the sample included in our study is not a stratified and fully representative of the Italian chronic population, it was randomly selected in order to guarantee its probabilistic feature. We used it only to explore the relationships of the variables under analysis (i.e. for associative purposes and not for a descriptive estimation of their dimensions): based on these considerations full representativeness is not necessarily required [83]. The PHE-model, measured in this study with the PHE-scale, casts light on possible psychological roots of patient motivation to self-management. The role the PHE-model in determining patient activation appears to us particularly promising for future research and clinical practice. PHE-model may be considered as lever to foster patients’ activation and—thus—patients’ adherence to treatments [84,85]. Our data suggest a cluster of factors associated with patient activation: mainly the level of patients’ elaboration of their disease, but also the quality of the patient/doctor relationship and positive emotional attitudes towards the health conditions [86]. If effective interventions to improve patient activation are to be developed, those targeting patients with lower levels of PHE-model should be prioritized [87]. Thanks for your feedback. Thanks for your feedback. Thanks for your feedback. Thanks for your feedback. Thanks for your feedback. Thanks for your feedback. Thanks for your feedback. Thanks for your feedback."", '', 'When one looks at the plots of the various Juckes proxies against gridcell temperature, the possibility of spurious regression must come to mind. “Spurious regression” has been discussed on this blog from time to time and tries to provide a statistical framework for seemingly high correlations between unrelated series – things like Honduran births and Australian wine exports.  The original article on the topic by Yule in 1928 observed a correlation of something like 0.97 between alcoholism and Church of England marriages. A prominent econometrician (Hendry) observed in the early 1980s that rainfall provided an excellent statistical explanation of inflation in an interesting article “Econometrics – Alchemy or Science?” (url). The same question – Alchemy or Science? – is surely applicable to proxymetrics. In 1974, Granger and Newbold, the former a Nobel Prize winning economist, wrote an influential article on Spurious Regression, posted up here, which I discussed last year here. Granger and Newbold observed that, although the classic spurious regressions (see Spurious #1) had very high correlation (r2 statistics), they had very low (under 1.5) Durbin-Watson (DW) statistics. (The DW statistic measures autocorrelation in the residuals.) It is very common to see reported in applied econometric literature time series regression equations with an apparently high degree of fit, as measured by the coefficient of multiple correlation R2 or the corrected coefficient R2, but with an extremely low value for the Durbin-Watson statistic. We find it very curious that whereas virtually every textbook on econometric methodology contains explicit warnings of the dangers of autocorrelated errors, this phenomenon crops up so frequently in well-respected applied work. Numerous examples could be cited, but doubtless the reader has met sufficient cases to accept our point. It would, for example, be easy to quote published equations for which R2 = 0.997 and the Durbin-Watson statistic (d) is 0.53. The most extreme example we have met is an equation for which R2 = 0.99 and d = 0.093.,, Granger and Newbold found that regressions between random walks consistently had “statistically significant” F-statistics (or equivalent statistically significant correlation r statistics) – they didn’t mention whether they were “99.98% significant”, but some would have been. Granger and Newbold suggested that the Durbin-Watson (DW) statistic did a good job of identifying problems. They didn’t argue that a failed DW statistic was a necessary condition of a spurious condition, but they certainly argued that a failed DW statistic was sufficient for a failed model. It has been well known for some time now that if one performs a regression and finds the residual series is strongly autocorrelated, then there are serious problems in interpreting the coefficients of the equation. Despite this, many papers still appear with equations having such symptoms and these equations are presented as though they have some worth. It is possible that earlier warnings have been stated insufficiently strongly. From our own studies we would conclude that if a regression equation relating economic variables is found to have strongly autocorrelated residuals, equivalent to a low Durbin-Watson value, the only conclusion that can be reached is that the equation is mis-specified, whatever the value of R^2 observed. … It is not our intention in this paper to go deeply into the problem of how one should estimate equations in econometrics, but rather to point out the difficulties involved. In our opinion the econometrician can no longer ignore the time series properties of the variables with which he is concerned – except at his peril. The fact that many economic “\x8bÅ\x93levels’ are near random walks or integrated processes means that considerable care has to be taken in specifying one’s equations… One cannot propose universal rules about how to analyse a group of time series as it is virtually always possible to find examples that could occur for which the rule would not apply. Let us now visit the residuals of Juckes’ Union reconstruction. Here is a plot of residuals between the Union reconstruction and the archived instrumental temperature. Figure 1. Residuals from Juckes “Union” reconstruction and archived instrumental temperature. Plotting of residuals is a standard operation in applied statistics. A simple inspection of the plot strongly suggests the possibility of autocorrelated errors. A Durbin-Watson test (which is a very elementary test) returns a value of 1.09 far below the required minimum of 1.5. The p-value for autocorrelated residuals is 1.018e-07 – less than one in a millll-yun. It is difficult (rather impossible) to contemplate an undergraduate econometrics student presenting a univariate relationship between two variables, with correlation between the only statistical test being performed. It is impossible to contemplate a student failing to carry out a Durbin-Watson (or equivalent) test.  It is hard to imagine the response of statistical reviewers to a team of professors presenting an econometrics paper based on a single univariate equation with a Durbin-Watson statistic of 1.09. (It is taking all my will-power to avoid making a snarky comment.) Now think about the reviewing by paleoclimatologists at Climates of the Past. No one has raised this topic. I suppose that either I or someone else will wander over to CPD and make this and other observations – but it would be nice to see some adequate reviewing within the discipline. Simply writing down an “economic theory”, manipulating it to a condensed form and “calibrating” the resulting parameters using a pseudo-sophisticated estimator based on poor data which the model does not adequately describe constitutes a recipe for disaster, not for simulating gold. It’s only link with alchemy is self-deception. I had been meaning to ask Jukes whether Union and temperature cointegrated as a basic test that they hadn’t shown a spurious relationship. Looking at these residuals I think the answer is clear. The two series are not cointegrated because the residuals look to be strongly I(1). (Precisely, it looks like you can not reject H0 that the residuals are I(1) using an ADF or similar test). It is a basic point that you can make with reference to lots of econometric literature without worrying about the potential ambiguity of a DW statistic (although the DW statistic tells you essentially the same thing, the formal DF tests aren’t structured around the DW statistic). The simple point is – temperature is I(1) (I’m assuming this from inspection), Union is I(1) (similarly by inspection), unless the residuals are I(0) there is no basis for claiming a meaningful relationship between the two. John S, thank you for your most puzzling post above. Questions: w. I(1) and I(0) refer to order of integraion. (See this brief Wikipedia link for a sketch of the idea – also called having a unit root.) The term shares an etymology with the mathematical concept of integration. The easiest way to make an integrated series (I(1)) is to sum up or integrate another (stationary) series. An I(0) process is a stationary process. An I(1) process is stationary once you difference it (delta X=X(t)-X(t-1)). An I(2) process would require you to difference it twice for it to be stationary, and so on. For example, a random walk or an AR process with an autoregressive parameter of 1 is I(1). For example, the rate of economic growth is I(0) while the level of GDP is I(1). I(2) series are relatively rare in economics but there are some people who believe that the price level is I(2) while inflation is I(1) – most people believe that the price level is I(1) and inflation is I(0) although it may have mean shifts or breaks. Other less economic data: population is I(1). An ADF test is an Augmented Dickey Fuller test. The whole econometric literature on spurious regressions boils down to dealing with integrated series properly. If you have two trending series (I(1) series) then you will get high r-squareds and the like even though there is no real relationship. In order to test whether there is the possibility of a meaningful relationship you require that the trends in the two series are actually common across the series. This is known as testing for cointegration – that is, two integrated series actually share the same stochastic trend. I think I used the abbreviations and whatnot without explanation because explaining it if you don’t already know the terms is the work of a good statistics or econometrics course – which I wouldn’t presume to be able to provide. A Primer on Co-integration by Dickey et al. My impression is that statisticians working in climate science often seem wedded to frequency domain time-series methods, and I was curious if anyone had any thoughts about that. #7. I agree with your comment about frequency-domain.  At the NAS panel, both Bloomfield and Nychka were frequency-domain guys, #5. The whole econometric literature on spurious regressions boils down to dealing with integrated series properly. John S, my impression is that there are other animals in the spurious regression zoo besides two I(1) processes – although this is the type case. You can get spurious regression between fractionally-differenced processes. In any case, the Team should have carried out a pretty nuanced statistical analysis, as opposed to merely providing one statistic. all the references are interesting, but I am a bit confused by this contribution. As far as I understand it, CVM  is not a regression method in which regression coeeficients are estimated through minimization of some funtion, so I am not sure whether the DW test finds application here. I would agree that the variance matching step could be affected by the co-integrated nature of the series, but this is a different question. After taking the average of the scaled proxies, the re-scaling procedure can be shown to be a constrained regression in which the variance of the estimator is constrained to be equal to the variance of the target. However, quite independently of this, many techniques for analyzing statistical significance transpose quite readily. Just saying that something is “CVM” rather than “regression” doesn’t negate the responsibility to analyse the residuals. BTW Eduardo, I wasn’t able to replicate the exact Union reconstruction from archived proxies anyway – perhaps there’s something in the Python code but the code is so poorly documented that it would take a long time to sort out – and the sd of the archived instrumental target for 1856-1980 doesn’t quite match the sd of the Union reconstruction. DO you have any hints? There are other animals at the zoo – but the initial motivation and driving force was integrated series, which economics has so many of. Along the way techniques for a much wider class of pathologies were undoubtedly covered. So perhaps you could rephrase my comment somewhat for perfect accuracy but I think the gist is still accurate. But more generally, what do you mean by ‘regression’? There are many estimators available and you need to test their outputs regardless of the methods used to obtain them. Thus, minimising the squared deviations of residuals is one very popular technique for constructing linear estimators, but it has no special status (at least because of that). You can also maximise the likelihood function, match the moments (GMM rather than just variance matching) or any other variation you care to speak of. OLS is popular because it has a number of nice properties – being the best linear unbiased estimator is a major part of that. #10 Steve, I have never programmed in python and I do not have the proxy data, so unfortunately I cannot help you in this. I have not located the link to the data archive you mention in other post. In my comment I was trying to clarify things, mostly for myself. I was not stating that the analysis of the residuals is not important. For instance, if the spectrum of the residuals is clearly red, the CVM estimation should  have wider confidence intervals. #11 John, perhaps my previous post was unclear, sorry for that. I was not trying to mix  the concepts of regression and co-integration. I agree that the estimation of the variance ratio may be affected if the two series are integrated processes. This seems to me quite clear, although one should be able to guess how strongly thzey are affected in this case.  More interesting would be perhaps how the confidence intervals for this ratio would look like. Assuming simple AR1 processes, Montecarlo experiemnts do indicate that these confidence intervals widen.  On the other hand, I am only  aware of one application to climatic timeseries of the concepts of cointegration (Kaufmann and Stern, Nature 97).  My (honest) question to the econometricians here would be if 100 samples are enough to distinguish between an integrated process or just stationary ARMA process, and even if they could apply such a test to the NHT timeseries. I mentioned ‘regression’ before, because it was not clear to me whether CVM is a regression method in the sense of minimizing some function to estimate the parameters, as you wrote. In that case, it was not clear to me whether the DW test can be applied to the residuals of CVM. #12. Eduardo, in Appendix 1, Juckes provides the following “statistical model” for his CVM composite: That’s a regression model.  So a Durbin-Watson test can be applied directly to this model in any event. The rescaling should only be a linear transformation and the autocorrelation properties of the residuals would remain unchanged through re-scaling, also leaving the DW value unchanged. BTW on the “correction” of the estimate by inflation – this methodology was discussed in von Storch [1999] which sharply criticized this procedure. You really should include some discussion of why you think von Storch [1999] no longer applies. You can never have enough data. I am not aware of exact statistics but the closer to 1 is your AR parameter, the more data you need to separate the two hypotheses. But the amount of data available to you is typically larger than that available to macro econometricians and with 100 observations or more that would normally be considered ‘enough’ to conduct meaningful inference using these tests. You will see the paper by Kaufmann, Kauppi and Stock that finds temperature to be an I(1) process. At this stage it appears to be a working paper but it may be submitted for publication somewhere – regardless, there is nothing wrong with their test of the properties of the temperature series and they obtain significant results. Having reread the Kaufmann et al paper now and spurred by Steve’s presentation of the residuals I think the basic point to be made is pretty simple. Temperature is non-stationary (Kaufmann, Kauppi and Stock – on further checking it is forthcoming in Climatic Change). Any proxy series that purports to reflect temperature must likewise be non-stationary. Thus, standard statistical techniques that assume stationarity can not be used. A basic requirement for such a proxy series to have any forecasting (actually hindcasting I suppose) ability is that it cointegrate with temperature over the instrumental period. In economic journals it is a basic test whose failure would lead to almost certain rejection. (If you can tap dance like Gregory Hines there might be arguments you can make to get over it – but they need to be really good.) That would be a huge leap, and I’m not sure there is any reason to take it. While it is true that the climate system exhibits long-term excursions from the mean — ice ages; sea level changes that last for millennia; centuries-long periods of drought — it also seems to revisit the same “regimes” again and again.  That is how stationary long-memory processes behave; it is not evidence of nonstationarity. To illustrate the point, you might try generating and looking at synthetic time series — say 1000 years each — from stationary FARIMA (start with (ar=0,d=0.4,ma=0)) and non-stationary ARIMA (say (0,1,0)) models. You will find that you can produce remarkably realistic temperature records using stationary LTP (e.g. FARIMA) or ARMA(ar=0.95,ma=-0.95) models. At the risk of repetition, I once again recommend taking a  look at Koutsoyiannis’s work on long-memory processes (see here). From a statistical point of view it is not a huge leap. It is generally better to treat near-integrated series using the cointegration techniques to ensure that your inference is not flawed. While the leap may be large philosophically it is still a valid statistical aproach. But regardless. If you believe that human emissions are leading to global warming and that such warming could be catastrophic you implicitly believe that temperature is non-stationary. Furthermore, as discussed in the Kaufmann et al paper, human emissions are non-stationary as they derive from economic activity which is non-stationary. Surely, the degree of timeseries analysis in climate research has probably not the level of sophistication as in econometrics. You can have a look into “Science” this week and you will see estimating trends and their significance without looking into the residuals whatsoever. ok, CVM being a simple linear re-scaling it can be re-stated as regression with inflation. At the end, the variances should match, and since there is only one free parameter, this parameter should be the same within both ‘views’. I am not sure if the nuisance is important here. I tend to see the CVM method simply a brute-force calibration, and within this “model” the autocorrelation of the residuals would only matter for the estimation of the variance. But I cave in that you can see it in the other way.  Anyway, ideally the residuals should be white and trendless, this latter point seems to me to be more important than the autocorrelation. Simple extrapolation would indicate that residuals were larger (negative)  in the past, i.e. that the true NHT was cooler than estimated. This is also what one gets with the pseudo-proxies. I am a bit confused by this contribution. As far as I understand it, CVM is not a regression method in which regression coeeficients are estimated through minimization of some funtion, so I am not sure whether the DW test finds application here. Eduardo, with all the respect, you are not the only one. Most (all?) of these multiproxy reconstructions are in a terrible confusion of two statistical disiplines: estimation theory and regression analysis. Let me quote the relevant definitions (from Wikipedia): Estimation theory is a branch of statistics and signal processing that deals with estimating the values of parameters based on measured/empirical data. The parameters describe the physical scenario or object that answers a question posed by the estimator. In statistics, regression analysis is used to model relationships between variables and determine the magnitude of those relationships. The models can be used to make predictions. [The following is a very crude explenation, so sorry for all those who are very careful about exact details.] So in the problem setting in question, your goal is to estimate/predict the temperature of the NH from the indirect measurements (proxies). So the problem itself can be thought as an estimation problem or as a regression problem. If you want to think it as an estimation problem, then you think temperature as a random field over NH and you are estimating its mean. If you want to think it as a regression problem, then the (NH) temperature can be thought either as a random process whose particular sample you try to predict or as a determistic variable. Now the crucial difference comes from the fact how you handle the known (instrumental) temperature data. In the estimation problem setting,  you can not basicly use it once you have defined your model (for proxies). An estimator is a function of your observations (proxies in this case) alone. Thus treating the problem as an estimating problem, you only use your knowledge of the instrumental series to improve your model, but you do not incorporate the instrumental series (a particular sample) into your model. Once you have defined your model, you now define your function of proxies alone (an estimator) that should give you the thing of the interest, an estimate of the temperature given a particular realization of proxies. Now it is easy to check your performance as you can compare your estimate directly to the measured instrumental series. On the other hand, in the regression problem setting, you define your model to describe the relationship between the temperature and the proxies.  Once you have done that you then (use estimation theory to) estimate the parameters of that model with the known values of all variables. Then you use the same model, with estimated parameters, to predict the (out of sample) values of the temperature variable (i.e., the “non-instrumental” part). Now it is crucial to understand that the same values you used for estimating your parameters can not be any more used to check how well your model is behaving. You already fitted you values best you can during that period! Your model may be worthless, but you can still find nice parameters to fit your model and get the error in the instrumental time very low, in essence your are then overfitting/-learning. The simplest way to guard against this is to have a verification period. If the verification period stats are bad while calibration period stats are good, this is usually a clear sign of overfitting happening. Now all of these multiproxy studies I’ve seen (excluding Mann, he has invented his own terminology), the papers are mainly using estimation theory language, although they clearly use regression analysis setting (and (rather simple) methods). This is a confusion which should be cleared away before anymore spaghetti graphs. What comes to CVM, it is not an estimation method (so you can safely categorize it as a regression method). The reason is that in CVM you match your reconstruction variance to that of the instrumental series. That is not so “innocent” as it first appears, because you have already “standardised” your proxies to have the same sample variance (and mean) in the very same period. If your proxies were uncorrelated, you could equivalently describe CVM such that you first match the variance (and mean) of the proxies in the calibration period to that of the instrumental series and then take the mean. Anyhow, CVM is not a function of proxies alone as it uses the instrumental series also, and it is not therefore an estimator. I can think of ways of solving this problem within the estimation theory setting. However, assuming the linear proxy response, I think the solution comes easiest way with the regression methods. In fact, it took me about an hour to derive the “correct” regression model and find its optimal (unbiased) solution from the linearity assumption. However, as I have stated many times earlier, I do not believe in that linearity assumption, so it’s not worth going into details. If you are interested in knowing more (and even if not), I suggest that you have a careful reading of the book I have mentioned here a few times: It contains pretty much everything you need to know about linear models. As some clarification of my suggestion that it doesn’t matter whether the temperature process is truly non-stationary or whether one merely needs to treat it as such for the purposes of statistical testing I provide a quote from the conclusion of Stephen R. Blough (1992) “The Relationship Between Power and Level for Generic Unit Root Tests in Finite Samples”, Journal of Applied Econometrics, Vol. 7, No. 3. (Jul. – Sep., 1992), pp. 295-308. Finite sample continuity between unit root and stationary process implies that researchers seeking to discover whether conventional inference is justified are not literally concerned with the existence of unit roots. Unit root tests cannot literally distinuish between unit root and stationary processes, but this is also not the distinction which matters for subsequent inference. Limited Monte Carlo experimentation suggests that probabilities of spurious regression match up quite well with the rejection probabilities of the low-order Said-Dickey test, but much work remains to be done along this line. So, perhaps I mis-spoke, it is not necessary that temperature be non-stationary, rather, temperature should be treated as if it is non-stationary. How does the variance matching of CVM compare with the Generalised Method of Moments (GMM)? I have not used GMM myself but was wondering if there was a correspondance there and thought you might be well on top of that sort of thing. #18. Eduardo, can you explain something that has totally baffled Jean S and myself.  You say that the autocorrelation of the residuals only matters for the estimation of the variance.  MBH99 does something along these lines, inflating the confidence intervals because of autocorrelated residuals.  We have both tried diligently to replicate how this increase is supposed to be estimated and have been completely baffled. It’s not a procedure (as far as I know) known to econometrics, which takes the position that the appropriate diagnosis is that the model is mis-specified and confidence intervals cannot be estimated. MBH99 did not provide a reference for this method;  I take it that there is some trade technique for the inflation of confidence intervals that has eluded us. Can you give us a reference?  Cheers, Steve Then this is not then even generalized MM, simply MM. I was talking only about simple CVM of two processes, and about the confidence intervals for the estimation of the variance ratio, and not on the confidence intervals  for the prediction. perhaps this is the source of confusion (?). re #23: Eduardo, you are on the right track. When you do your regression in this case, you think temperature as determistic and the rest is stochastic. Then your optimal solution depends from the (auto)correlation structure of your noise. This is the reason why I have been here (in vain) few weeks trying to get the answer from your lead author about the assumed noise structure in your paper. Then there is only one more additional thing to know: (the out of sample) prediction depends additionally only from the correlation structure between the noise in the sample time and the noise in the out-of-sample time (this is a result due Goldberg (1962) if I recall right, don’t have any references here at home). This gives you the final correction term needed for the optimal (unbiased) solution. Of course, if you finally obtain anything reasonable depends if the assumptions you make for your noise are (physically) plausible. But these are all explained much better in the book I referred. Since the errors in any practical case will be unknown the test must be based on the residuals from the calculated regression. Consequently the ordinary tests of independence cannot be used as they stand, since the residuals are necessarily correlated whether the errors are dependent or not . I know that the above refers to OLS, but I think it is a good start before going to CVM. Quotes from: Durbin and Watson (1950) Testing for Serial Correlation in Least Squares Regression: I, Biometrika, Vol. 37, No 3/4, pp. 409-428 There are relatively well known adjustments for the variance estimates in OLS that are robust to general forms of heteroskedasticity or autocorrelation. See White, H (1980) “A Heteroskedasticity Consistent Covaraince Matrix Estimator and a Diret Test for Heteroskedasticity”, Econometrica, Vol. 48, No. 4, 817-838. Whitney K. Newey, Kenneth D. West (1987), “A Simple, Positive Semi-Definite, Heteroskedasticity and Autocorrelation Consistent Covariance Matrix “, Econometrica, Vol. 55, No. 3 (May, 1987), pp. 703-708. If you are really worried about it you can do FGLS but for the most part OLS with robust standard errors is generally considered sufficient. There are relatively well known adjustments for the variance estimates in OLS that are robust to general forms of heteroskedasticity or autocorrelation. Yes, that is true. If we know the covariance matrix of noise. Juckes’ reply is now online at CPD.  I’ll post up on this separately. In the mean time, here is what I said in my review about this topic and the response of Juckes et al.  I commented: Para 6: The Durbin-Watson test does not test for spurious correlations. Wow. Juckes should have Googled that one before replying. These people can only be described as aggressively stupid. #31 and #32:  SteveM has it right and  Juckes is wrong when it comes to the substance of SteveM’s comment, but Juckes does have a point about the Durbin-Watson test.  It is usually used to test for autocorrelation in regression residuals rather than for spurious correlation. I’m not aware of a standard test for spurious correlation. I’m not aware of a standard test for spurious correlation. I suppose there’s a technical definition of spurious correlation which would allow a test, but basically the concept shouldn’t allow a test.  I.e. if something passes the tests for correlation but can’t have a true correlation for logical reasons, then it must be a spurious correlation. I think usually when we have what is called spurious correlation we assume that it will disappear when later data comes in.  This would imply that you could divide up the available data and look to see if the correlation disappears when hidden data is examined.  Except that that would require no cherry-picking.  If the data is cherry-picked all you can do is wait for new data. TAC,  is he trying to make a distinction between spurious regression and spurious correlation?  My goodness. I agree that the DW test is “usually” used to test for autocorrelation of residuals, but the interest in autocorrelated residuals was prompted in part by Granger and Newbold 1974, Spurious Regression in Econometrics – linked to a url above – in which the DW test was suggested as a test for spurious regression. If Juckes is trying to say that the test would apply to a regression, but not to a correlation, then you have to reflect on the underlying geometry. The correlation coefficient is the angle between the vectors in N-space. The regression coefficient between two normalized vectors is equal to the correlation coefficient. Any apparatus from one applies to the other. Also, as noted in a post above, the variance-matching procedure of CVM is mathematically equivalent to a constrained regression in which the norm of the estimator is equal to the norm of the target. This is very simple mathematics, which does not cease to apply, merely because Juckes ignores it. That’s how I read it.  Sure, it’s irrelevant and unresponsive, but, strictly speaking, it’s not entirely wrong.  😉 Sure, it’s irrelevant and unresponsive, but, strictly speaking, it’s not entirely wrong. I’ve read most all of the responses now (not very hard since they’re quite short.)  Your remark above about irrelevant and unresponsive is a good summary of all of them.  Actually I was tempted to post something even snarkier, but I think I’ll leave it to Steve (or Willis when he’s back and up to speed) if they desire.  Let’s just say that it was quite obvious that there is no attempt to actually address the questions put before Dr. Junkes.  BTW, I wonder if Dr. Junkes himself actually composed the responses.  When he was here he was fairly responsive, if a bit pompous.  I wonder if there was a mini-IPCC meeting to make sure that this summary for policy-makers will match the individual positions to be given out later. This problem was recognized almost 80 years ago by Yule (1926) and has been ex-tensively analysed in areas, such as econometrics, where trend time series are the rule. The present manuscript by Bürger and Cubasch is focused on the problem of attaching physical significance to statistical relationships derived from non-stationary timeseries. This problem was recognized almost 80 years ago by Yule (1926) and has been extensively analysed in areas, such as econometrics, where trend time series are the rule. Spurious regression, or nonsense correlation as they were originally called, have a long history in statistics, dating back at least to Yule (1926).Textbooks and the literature of statistics and econometrics abound with interesting examples, many of them quite humorous. One is the high correlation between the number of ordained ministers and the rate of alcoholism in Britain in the nineteenth century. Another is that of Yule (1926), reporting a correlation of 0.95 between the proportion of Church of England marriages to all marriages and the mortality rate of the period 1866-1911. Yet another is the econometric example of alchemy reported by Henry(1980) between the price level and cumulative rainfall in the UK. The latter relation proved resilient to many econometric diagnostic test and was humorously advanced by its author as a new theory of inflation. With so many well known examples like these, the pitfalls of regression and correlation studies are now common knowledge even to nonspecialists. The situation is especially difficult in cases where the data are trending- as indeed they are in the examples above- because third factors that drive the trends come into play in the behavior of the regression, although these factors may not be at all evident in the data. Phillips (1998). This strikes me as one of the most useful threads on the site. Many thanks for all the citations and ULs. BTW, I wonder if Dr. Junkes himself actually composed the responses. When he was here he was fairly responsive, if a bit pompous. I don’t think he was responsive then or now. DaveD (#37):  I just re-read SteveM’s comment and Juckes’s (non) replies. I agree with you that in most cases Juckes presents Under the circumstances, it is curious that he decided to respond at all.', 'Cardiac magnetic resonance imaging (CMR) with adenosine-stress myocardial perfusion is gaining importance for the detection and quantification of coronary artery disease (CAD). However, there is little knowledge about patients with CMR-detected ischemia, but having no relevant stenosis as seen on coronary angiography (CA). The aims of our study were to characterize these patients by CMR and CA and evaluate correlations and potential reasons for the ischemic findings. 73 patients with an indication for CA were first scanned on a 1.5T whole-body CMR-scanner including adenosine-stress first-pass perfusion. The images were analyzed by two independent investigators for myocardial perfusion which was classified as subendocardial ischemia (n = 22), no perfusion deficit (n = 27, control 1), or more than subendocardial ischemia (n = 24, control 2). All patients underwent CA, and a highly significant correlation between the classification of CMR perfusion deficit and the degree of coronary luminal narrowing was found. For quantification of coronary blood flow, corrected Thrombolysis in Myocardial Infarction (TIMI) frame count (TFC) was evaluated for the left anterior descending (LAD), circumflex (LCX) and right coronary artery (RCA). The main result was that corrected TFC in all coronaries was significantly increased in study patients compared to both control 1 and to control 2 patients. Study patients had hypertension or diabetes more often than control 1 patients. In conclusion, patients with CMR detected subendocardial ischemia have prolonged coronary blood flow. In connection with normal resting flow values in CAD, this supports the hypothesis of underlying coronary microvascular impairment. CMR stress perfusion differentiates non-invasively between this entity and relevant CAD. The assessment of myocardial ischemia is an essential component for the further diagnostic and therapeutic decision making in patients presenting with angina and suspected coronary artery disease (CAD). However, 10–30% of these patients with diagnosed ischemia show no pathological findings in coronary angiograms [1, 2]. Most studies suggested coronary microangiopathy to be the cause for angina in this patient collective [3–5]. The use of cardiac magnetic resonance (CMR) including pharmacologically induced stress perfusion as an emerging non-invasive method for the imaging of myocardial ischemia is supported by rapidly growing evidence of its accuracy in predicting relevant coronary stenosis [6–11]. However, knowledge on its proposed capability for also detecting subendocardial perfusion deficit consistent with small vessel disease [12] is limited. As angiographic correlate in these patients, studies have suggested microvascular perfusion deficit [3, 5, 13]. For the quantification of coronary blood flow, Thrombolysis in Myocardial Infarction (TIMI) frame count (TFC) [14, 15] proved to be a simple, reproducible and objective index [5, 16–19]. The aims of our study were 1. to correlate CMR detected subendocardial perfusion deficit proposed for coronary small vessel disease with angiographically determined coronary blood flow by corrected TFC 2. and to compare these findings with CAD. During a three month period, we prospectively enrolled consecutive patients scheduled for coronary x-ray angiography (CA) who had previously undergone adenosine stress CMR examination and shown subendocardial perfusion deficit. Patients without perfusion deficit and patients with more than subendocardial perfusion deficit in CMR were enrolled in equal proportions to serve as control groups. The exclusion criteria were an internal pacemaker or defibrillator, contraindications for adenosine infusion, or inability to give written informed consent. Written informed consent was obtained from all patients. Patients with a history of myocardial infarction or in whom Late Gadolinium Enhancement (LGE) could be visualized were excluded from the study. All anti anginal medication and caffein containing beverages were stopped at least 24 hours before CMR examination. A 12-lead surface ECG was obtained for each patient. All patients were examined clinically and cardiovascular risk factors such as hypertension, diabetes mellitus, hypercholesterolemia, smoking and family disposition for CAD were assessed. In case of claustrophobia mild sedation with midazolame was offered. All CMR studies were performed with a 1.5T magnetic resonance system (Signa Excite®, GE Medical Systems, Milwaukee, USA) using an 8-element phased array surface coil (Cardiac coil, GE Medical Systems). Left ventricular (LV) parameters were measured using long-axis (two-chamber and four-chamber-views) functional steady-state free precession (SSFP) sequence images as part of our clinical routine protocol. After infusion of adenosine at a constant rate of 140 μg/kg per minute over three minutes (Spectris MR injector, Medrad, Indianola, USA) first-pass kinetic of a gadolinium-based contrast agent (Omniscan®, GE Healthcare Buchler, Germany; 0.1 mmol/kg) was measured in 4 contiguous short axis orientations at every heart beat using a hybrid gradient echo/echo-planar pulse sequence (echo time 1.2 ms, flip angle 25°, slice thickness 8 mm, field of view 32–34 × 24–25.5 cm, matrix 128 × 96) as previously described [7, 20]. Echo time was reduced to 1.2 ms for reducing susceptibility artifact as sometimes seen in gradient echo sequences [21]. Ten minutes after stress perfusion a second perfusion study with the same orientation and with the same setting was performed at rest without adenosine infusion. Ten minutes after this second bolus, LGE images were acquired by using an inversion-recovery prepared gated fast-gradient echo-pulse sequence (repetition time 6.7 ms; echo time 3.3 ms; flip 20°; inversion time individually adjusted; slice thickness 8 mm; rectangular field of view 30 to 34 cm; matrix 256 × 160). Again, three long axes, 4–5 short axes as planned in the perfusion study as well as contiguous short axes views using a 3D 20 slice sequence were acquired. Two experienced investigators evaluated all CMR studies in consensus. If consensus could not be achieved, a third opinion was included. Image analysis was performed with the standard software provided by the CMR system manufacturer (Advantage Workstation, GE Medical System). Image analysis was performed visually for reducing the rate of false positive results due to rim artifacts as previously reported [22]. Secondly, we compared stress to rest perfusion to reduce the potential rate of artifacts. If a deficit was equally present at stress and rest, if it did not follow the subendocardial border, if ghosting artifacts could be seen or if it ""blinked"" bright and dark it was not regarded as an evident hypoperfusion, but a potential artifact. Such cases were not included into the study. Segments were classified according to AHA recommendations [23] and evaluated for inducible hypoperfusion during the stress first-pass sequence and classified as ""no hypoperfusion"", ""subendocardial hypoperfusion"" [12] or ""relevant hypoperfusion"" indicative of relevant coronary artery stenosis [6, 7] in comparison to rest perfusion images according to following criteria: - Patients were classified as having small vessel disease, if diffuse subendocardial hypoperfusion [12] (affecting ≤ 1/3 of myocardial wall thickness and myocardial areas supplied at least by two different coronary arteries or circumferential perfusion deficit) and lasting for maximum five heart beats after maximal signal peak intensity in the LV cavity [24]. Patients with a lesser degree of hypoperfusion (such as ≤ 1/3 of myocardial wall thickness in only one territory) were not included. - Patients with regional perfusion deficit of > 1/3 wall thickness and lasting for more than five heart beats were classified as having CAD with ≥ 70% luminal narrowing [7]. Patients with a lesser degree of regional hypoperfusion (such < 5 beats of stress perfusion defect regardless of affected myocardial wall thickness or ≥ 5 beats but ≤ 1/3 of myocardial wall thickness in one territory) were not included. See figure 1 for examples of our patients groups. Adenosine-stress CMR perfusion images. With (A) no perfusion deficit, (B) diffuse circumferential subendocardial perfusion deficit and (C) perfusion deficit affecting more than subendocardial layers in the LAD perfusion territory. Patients with small vessel disease were analyzed as study patients, patients with no perfusion deficit as ""control 1"" and patients with perfusion deficit consistent with CAD as ""control 2"". Classification was performed before CA. All patients underwent CA within 48 hours after CMR examination. Angiographic case study data were collected and analyzed for affected coronary arteries and degree of luminal reduction. Afterwards stored angiograms were assessed for corrected TFC for each coronary vessel [14]. TFC analysis was performed by the physician in charge with CA evaluation before CMR data disclosure. The corrected TFC is the number of cine frames required for contrast to first reach standardized distal coronary landmarks [14, 15]. In our patients, CA was performed by hand injection of contrast medium via 5 French catheters and filmed at 12.5 frames/s. Since the original TFC is described for a cinefilm speed of 30 frames/sec, an adaptation was performed as previously reported [15]. Therefore, frame counts were multiplied by 2.4 (correction factor). TFC for coronary arteries with normal flow is different in the left anterior descending (LAD) compared to the left circumflex (LCX) and right coronary artery (RCA) because of the larger vessel length. To adapt those differences and to provide comparable results of TIMI frame count for the different vessels, TIMI frame count of the LAD was divided through a correction factor of 1.7 [15]. Data are reported as mean ± standard deviation. Continuous variables between groups were compared by t-test for unpaired observations. Nominal data were compared by Fisher\'s exact test. Categorial data were compared by Wilcoxon signed rank test for matched pairs. Correlation was assessed by means of correlation coefficient κ and regression coefficient R2. In all cases, a p value < 0.05 was considered statistically significant. 95% confidence intervals (CI 95%) are given. Analyses were performed with commercially available statistic software (StatView 5). Twenty-two patients out of a total of 265 adenosine stress CMR examinations fulfilled the entry criteria and were enrolled to the study. Mean age was 66.0 ± 12.5 years, 14 (64%) patients were male and 8 (36%) female. 9/22 study patients had previous stress testing (8 bicycle ergometry, 1 dobutamine stress echocardiography), all with pathological findings. The remainder had been referred for stress CMR without previous stress testing. Fifty-one patients formed the control groups. Patients\' characteristics are given in table 1. CMR examination was performed in all 73 patients without relevant complications or adverse events. Image quality was sufficient for further analysis in all patients with primary investigators consensus in 71/73 cases and inclusion of a third opinion in two cases. Subendocardial perfusion deficit during stress perfusion in comparison to rest perfusion was found in 22 (30%) patients, who formed the study group. In 27 (37%) patients no perfusion deficit could be observed (control 1), a relevant perfusion deficit was visualized in 24 (33%) patients (control 2). Patient groups did not differ significantly in age or gender (see table 1). CMR-derived LV parameters in study patients compared to controls were as follows: LV mass (g) 135 ± 36 (control 1: 119 ± 31, p: 0.17; control 2: 129 ± 36, p: 0.65), LV ejection fraction (%) 60.3 ± 8.8 (control 1: 61.7 ± 8.1, p: 0.60; control 2: 60.5 ± 7.2, p: 0.92), LV wall stress (N/m2x1000) 43.3 ± 8.8 (control 1: 40.0 ± 7.8, p: 0.25; control 2: 41.3 ± 8.6 g, p: 0.46). Perfusion deficits in control 2 patients were detected in the LAD perfusion territory in 13 [54%], in the LCX territory in 15 [63%] and in the RCA perfusion territory in 12 [50%] cases, respectively. CA was performed in all patients without relevant complications. Coronary one-vessel disease (≥ 70% luminal narrowing) was observed in 15 [21%], two-vessel disease in 9 [12%] and three-vessel disease in 6 [8%]. Mean corrected TFC for the LAD was 21.5 ± 4.6 frames, for the LCX 33.0 ± 7.3 and for the RCA 25.9 ± 4.9. In our study patients (only subendocardial perfusion deficit on CMR exam) no coronary stenosis ≥ 70% could be shown. In contrast, all control 2 patients (relevant perfusion deficit in CMR) had coronary stenoses as visualized by CA. A highly significant correlation between classification of CMR perfusion deficit and degree of coronary luminal narrowing was found (see table 2). Corrected TFC in all coronary arteries was significantly increased in study patients compared to both controls groups: Study patients vs. control 1 (no perfusion deficit): 25.1 ± 4.9 frames vs. 20.9 ± 4.2 frames in the LAD, p = 0.002; 39.1 ± 7.7 vs. 30.1 ± 6.1 in the LCX, p < 0.0001; 29.1 ± 5.5 vs. 24.4 ± 3.8 in the RCA, p = 0.001) and vs. control 2 (relevant myocardial ischemia): 18.7 ± 2.0 in the LAD, p < 0.0001; 30.7 ± 4.5 in the LCX, p < 0.0001; 24.6 ± 4.5 in the RCA, p = 0.004 (figure 2). Prolonged corrected TFC (values above mean of control 1) were present in all 22 study group patients (per vessel analysis: in 60/66 (91%)), in contrast to control 2 patients (per vessel analysis: in 12/72 (17%)). A good correlation between corrected TFC in LAD and LCX was found in our study patients (κ = 0.87; 95% CI [0.72–0.95]; p < 0.0001). Corrected TFC in control 1 and control 2 patients showed a lower correlation for LAD and LCX (κ = 0.71; 95% CI [0.45–0.86]; p < 0.0001 and κ = 0.50; 95% CI [0.11–0.75]; p = 0.01), respectively (figure 3). No correlation between LAD and RCA or LCX and RCA TIMI frame count was observed, respectively. Comparison of corrected TIMI frame count. Between study patients and controls for LAD, LCX and RCA. Significantly increased frame count in study patients compared to both control groups. Regression graphs with 95% confidence interval. For correlation of LAD and LCX corrected TIMI frame count in our study group and in controls including regression coefficients. Study patients had more often hypertension (15 [68%] versus 10 [37%], p = 0.03) and diabetes (9 [41%] versus 4 [15%], p = 0.04) than control 1 patients. Control 2 patients also had more commonly hypertension (16 [67%], p = 0.03) and diabetes (11 [46%], p = 0.02) than control 1 patients. Patient groups did not differ for hypercholesterolemia or smoking nor did study and control 2 patients differ for the above mentioned cardiovascular risk factors. Patients presenting with angina pectoris, but having normal coronary arteries with normal ventricular function and without coronary spasm have been described previously [3, 4]. Coronary microangiopathy causing increased resistance in prearteriolar coronary vessels, consequently lowering myocardial perfusion and thus leading to impaired coronary flow reserve has been suggested to be the underlying pathophysiology [4, 25]. Although having a good long-term prognosis [26], quality of life is significantly impaired in patients with small vessel disease, such as seen in syndrome X, mainly because of persistent angina and decreased exercise tolerance [27]. In addition, diagnostic clarification presently requires invasive angiography. In the attempt for non-invasive diagnosis, the results of our study confirm that this patients\' group can be diagnosed by adenosine-stress CMR examination as first described by Panting et al. [12]. Their study showed patients with syndrome X to have subendocardial diffuse perfusion deficit patterns as seen by adenosine-stress CMR in contrast to patients with a relevant coronary artery stenosis. We used their CMR criteria for our study patient classification with following specification: We added a perfusion deficit lasting five heart beats or less after maximum signal intensity peak in the LV cavity as another inclusion criterion. This is based on the study of Lauerma et al. [24] who showed patients with perfusion deficits lasting more than five heart beats to have relevant CAD. Furthermore, our study extends the protocol of Panting et al. [12] in the following aspects: First, a close time relationship between CMR and angiography (≤ 48 hours in contrast to a mean interval of 18 months [12]); second, use of CMR for patient classification and subsequent angiographic analysis for validation; third, inclusion of two control groups (patients without and patients having relevant perfusion deficit). Most important of all, we focused on the correlation between CMR findings and corrected TFC in these patients. The main finding of our study was that pure subendocardial perfusion deficit as seen by CMR highly correlates with slowed coronary artery flow as determined by corrected TFC compared to both control patient groups with or without coronary artery stenosis. This finding is consistent with data from a recent study showing patients with small vessel disease to have reduced total coronary blush score [13]. Hence, this correlation between subendocardial ischemia, angina pectoris and reduced coronary artery flow in the absence of coronary artery stenoses strengthens the criteria used for CMR stress perfusion as noninvasive diagnostic imaging modality in the assessment of small vessel disease. Since subendocardial ischemia is a potential source of false positive CMR interpretation of CAD yielding in a lower specificity [11], establishing criteria for detection of small vessel disease may improve specificity and thus, the accuracy of adenosine-stress CMR. Standard LV parameters such as LV mass, ejection fraction and wall stress were less discriminatory than stress perfusion. In addition, other stress tests yielding findings compatible with myocardial ischemia in the study group were incapable of differentiating from CAD, at least in the subset of patients referred with previous stress tests. Remarkably, mean resting corrected TFC was normal in our CAD group. TFC measurement during stress was not part of our protocol. Methodologically, it is primarily TFC during stress (""hyperemic TFC"") which has been shown to yield decreased values in stenosed arteries, with significant improvement after successful angioplasty with stent placement [16]. In this context, further studies correlating both resting and hyperemic corrected TFC with QCA determined degree of stenosis in CAD are recommended. Another finding of our study is that in small vessel disease corrected TFC in the LAD correlates very well to that in LCX. This is in concordance with findings of another recent study in patients with microvascular dysfunction and angina pectoris [5]. Furthermore, our results support the concept that systemic hypertension and diabetes mellitus are not only risk factors for CAD in epicardial vessels, but also for small vessel disease. Our data strengthen the hypothesis of microvascular functional impairment in patients with small vessel disease: The slowed coronary artery flow under rest causing detectable pure subendocardial ischemia under stress conditions in the absence of coronary artery stenoses suggests microvascular disease as the cause of anginal symptoms. The causes of microvascular dysfunction are probably multiple in these patients. Structural abnormalities like myocardial medial hypertrophy and/or fibrosis of arteriolar vessels have been described in a small patient cohort [28]. Regarding higher TFC in microvascular disease compared to CAD patients with the same risk factors, we can only hypothesize that microvascular disease and CAD, although sharing diabetes and hypertension as risk factors, form two distinct and not necessarily concurrent disease manifestations. The following limitations need to be mentioned for our study. First, we did not directly measure coronary flow velocity using a flow wire and have used instead corrected TFC as a surrogate. This approach may be questioned in view of the results of Chug et al [29], who found no significant correlation between coronary flow velocity reserve and corrected TFC in patients undergoing coronary intervention. On the other hand, several studies have shown the validity of such angiographic grading of coronary blood flow by comparing it to reference methods such as Doppler flow wire during baseline [30] and hyperemia [16], flow velocity measured by magnetic resonance [19] or, most recently, by Doppler echo [31]. Flow quantified by TFC is related to the risk of adverse outcomes in acute coronary syndromes [32] or in heart transplant coronary vasculopathy [33], and corrected TFC has been used as endpoint in interventional trials on early recanalization of the infarct-related artery [34–36]. Thus, although use of TFC in our study seems feasible, TFC disaffirmation in the study of Chug et al cannot be disregarded and therefore the use of this non-invasive surrogate parameter is contradictory. In view of this contradiction, studies directly comparing our CMR-based criteria for diagnosis of small vessel disease with invasive coronary flow velocity measurements by flow wire are required for definitive confirmation of our results. In this context, Muehling et al have shown a significant correlation between invasive measurement of coronary flow reserve and noninvasive evaluation by CMR perfusion imaging in heart transplant arteriopathy [37]. In CAD patients, three recent studies have found a good correlation between CMR adenosine stress perfusion results and the invasively measured coronary fractional flow reserve [38–40]. Secondly, we did not perform (semi-)quantitative analysis of CMR perfusion images. Finally, while our study group patients were included consecutively and prospectively, the two control groups were enrolled to achieve equal proportions. Thus, the groups do not reflect the incidence of the three conditions studied. Although the very strict CMR classification criteria should ensure homogenous groups for evaluation, it precludes neither referral nor selection bias. Thus, while syndrome X patients are predominantly females [12], the unexpected high proportion of males in our study cohort was most likely due to referral bias. In conclusion, subendocardial perfusion deficit as seen by CMR highly correlates to slowed coronary artery flow. Given normal resting flow values in our patients with coronary macroangiopathy, this finding is most likely due to coronary small vessel disease. CMR allows non-invasive detection of these patients. Proudfit WL, Shirey EK, Sones FM: Selective cine coronary angiography: correlation with clinical findings in 1000 patients. Circulation. 1966, 33: 901-10. Kemp HG, Kronmal RA, Vliestra RE, Frye RL: Seven year survival of patients with normal or near normal coronary arteriograms: a CASS registry study. J Am Coll Cardiol. 1986, 7: 479-89. Cannon RO, Epstein SE: ""Microvascular angina"" as a cause of chest pain with angiographically normal coronary arteries. Am J Cardiol. 1988, 61: 1338-43. 10.1016/0002-9149(88)91180-0. Maseri A, Crea F, Kaski JC, Crake T: Mechanisms of angina pectoris in syndrome X. J Am Coll Cardiol. 1991, 17: 499-506. Sun H, Fukumoto Y, Ito A, Shimokawa H, Sunagawa K: Coronary microvascular dysfunction in patients with microvascular angina. J Cardiovasc Pharmacol. 2005, 46: 622-26. 10.1097/01.fjc.0000181291.96086.ae. Schwitter J, Nanz D, Kneifel S, Bertschinger K, Buchi M, Knusel PR, Marincek B, Luscher TF, von Schulthess GK: Perfusion in coronary artery disease by magnetic resonance: a comparison with positron emission tomography and coronary angiography. Circulation. 2001, 103: 2230-35. Bernhardt P, Engels T, Levenson B, Haase K, Albrecht A, Strohm O: Prediction of necessity for coronary artery revascularization by adenosine contrast-enhanced magnetic resonance imaging. Int J Cardiol. 2006, 112: 184-90. 10.1016/j.ijcard.2005.08.050. Ingkanisorn WP, Kwong RY, Bohme NS, Geller NL, Rhoads KL, Dyke CK, Paterson DI, Syed MA, Aletras AH, Arai AE: Prognosis of negative adenosine stress magnetic resonance in patients presenting to an emergency department with chest pain. J Am Coll Cardiol. 2006, 47: 1427-32. 10.1016/j.jacc.2005.11.059. Klem I, Heitner JF, Shah DJ, Sketch MH, Behar V, Weinsaft J, Cawley P, Parker M, Elliott M, Judd RM, Kim RJ: Improved detection of coronary artery disease by stress perfusion cardiovascular magnetic resonance with the use of delayed enhancement infarction imaging. J Am Coll Cardiol. 2006, 47: 1630-38. 10.1016/j.jacc.2005.10.074. Cury RC, Cattani CAM, Gabure LAG, Racy DJ, de Gois JM, Siebert U, Lima SS, Brady TJ: Diagnostic performance of stress perfusion and delayed-enhancement MR imaging in patients with coronary artery disease. Radiology. 2006, 240: 39-45. 10.1148/radiol.2401051161. Pilz G, Bernhardt P, Klos M, Ali E, Wild M, Höfling B: Clinical implication of adenosine-stress cardiac magnetic resonance imaging as potential gatekeeper prior to invasive examination in patients with AHA/ACC class II indication for coronary angiography. Clin Res Cardiol. 2006, 95: 531-38. 10.1007/s00392-006-0422-7. Panting JR, Gatehouse PD, Yang GZ, Grothues F, Firmin DN, Collins P, Pennell DJ: Abnormal subendocardial perfusion in cardiac syndrome X detected by cardiovascular magnetic resonance imaging. N Engl J Med. 2002, 346: 1948-53. 10.1056/NEJMoa012369. Atmaca Y, Ozdemir AO, Ozdol C, Oguz D, Gulec S, Kumbasar D, Erol C: Angiographic evaluation of myocardial perfusion in patients with syndrome X. Am J Cardiol. 2005, 96: 803-05. 10.1016/j.amjcard.2005.05.024. Gibson CM, Cannon CP, Daley WL, Dodeg JT, Alexander B, Marble SJ, MacCabe CH, Raymond L, Fortin T, Poole WK, Braunwald E: TIMI frame count: a quantitative method of assessing coronary artery flow. Circulation. 1996, 93: 879-88. Gibson CM, Murphy SA, Rizzo MJ, Ryan KA, Marble SJ, McCabe CH, Cannon CP, Van de Werf F, Braunwald E, for the Thrombolysis In Myocardial Infarction (TIMI) Study Group: Relationship between TIMI frame count and clinical outcomes after thrombolytic administration. Circulation. 1999, 99: 1945-50. Manginas A, Gatzov P, Chasikidis C, Voudris V, Pavlides G, Cokkinos DV: Estimation of coronary flow reserve using the thrombolysis in myocardial infarction (TIMI) frame count method. Am J Cardiol. 1999, 83: 1562-65. 10.1016/S0002-9149(99)00149-6. Bickel C, Rupprecht HJ, Maimaitiming A, Welk I, Blankenberg S, Krummenauer F, Meyer J: The superiority of TIMI frame count in detecting coronary flow changes after coronary stenting compared to TIMI flow classification. J Invasive Cardiol. 2002, 14: 590-96. Senen K, Yetkin E, Turhan H, Atak R, Sivri N, Battaloglu B, Tandogan I, Ileri M, Kosar K, Ozdemir R, Cehreli S: Increased thrombolysis in myocardial infarction frame counts in patients with isolated coronary artery ectasia. Heart Vessels. 2004, 19: 23-26. 10.1007/s00380-003-0722-z. Mavrogeni SI, Manginas A, Papadakis E, Douskou M, Cokkinos D, Katsiva V, Foussas S, Voudris V, Giakoumelos A, Seimenis I, Baras P, Cokkinos DV: Coronary flow evaluation by TIMI frame count and magnetic resonance flow velocity in patients with coronary artery ectasia. J Cardiovasc Magn Reson. 2005, 7: 545-50. 10.1081/JCMR-200060641. Bernhardt P, Steffens M, Kleinertz K, Morell R, Budde R, Leischik R, Krämer A, Overhoff U, Strohm O: Safety of adenosine stress magnetic resonance using a mobile cardiac magnetic resonance system. J Cardiovasc Magn Reson. 2006, 8: 475-78. 10.1080/10976640600575270. Neimatallah MA, Chenevert TL, Carlos RC, Londy FJ, Dong Q, Prince MR, Kim HM: Subclavian MR arteriography: reduction of susceptibility artifact with short echo time and dilute gadopentetate dimeglumine. Radiology. 2000, 217: 581-86. Di Bella EVT, Parker DL, Sinusas AJ: On the dark rim artifact in dynamic contrast-enhanced MRI myocardial perfusion studies. Magn Reson Med. 2005, 54: 1295-99. 10.1002/mrm.20666. Cerqueria MD, Weissmann NJ, Dilsizian V, Jacobs AK, Kaul S, Laskey WK, Pennell DJ, Rumberger JA, Ryan T, Verani MS, American Heart Association Writing Group on Myocardial Segmentation and Registration for Cardiac Imaging: Standardized myocardial segmentation and nomenclature for tomographic imaging of the heart: a statement for healthcare professionals from the Cardiac Imaging Committee of the Council on Clinical Cardiology of the American Heart Association. Circulation. 2002, 105: 539-42. 10.1161/hc0402.102975. Lauerma K, Virtanen KS, Sipila LM, Hekali P, Aronen HJ: Multislice MRI in assessment of myocardial perfusion in patients with single-vessel proximal left anterior descending coronary artery disease before and after revascularization. Circulation. 1997, 96: 2859-67. Meeder JG, Blanksma PK, Crijns HJ, Anthonio RI, Pruim J, Brouwer J, de Jong RM, van der Wall EE, Vaalburg W, Lie KI: Mechanisms of angina pectoris in syndrome X assessed by myocardial perfusion dynamic and heart rate variability. Eur Heart J. 1995, 16: 1571-77. Opherk D, Shuler G, Wetterauer K, Manthey J, Schwarz K, Kubler W: Four-year follow-up study in patients with angina pectoris and normal coronary arteriograms („Syndrome X""). Circulation. 1989, 80: 1610-16. Atienza F, Velasco JA, Brown S, Ridocci F, Kaski JC: Assessment of quality of life in patients with chest pain and normal coronary arteriogram (syndrome X) using a specific questionaire. Clin Cardiol. 1999, 22: 283-90. Crea F, Lanza GA: Angina pectoris and normal coronary arteries: cardiac syndrome X. Heart. 2004, 90: 457-63. 10.1136/hrt.2003.020594. Chugh SK, Koppel J, Scott M, Shewchuk L, Goodhart D, Bonan R, Tardif JC, Worthley SG, DiMario C, Curtis MJ, Meredith IT, Anderson TJ: Coronary flow velocity reserve does not correlate with TIMI frame count in patients undergoing non-emergency percutaneous coronary intervention. J Am Coll Cardiol. 2004, 44: 778-82. 10.1016/j.jacc.2004.05.048. Kern MJ, Moore JA, Aguirre FV, Bach RG, Caracciolo EA, Wolford T, Khoury AF, Mechem C, Donohue TJ: Determination of angiographic (TIMI grade) blood flow by intracoronary Doppler flow velocity during acute myocardial infarction. Circulation. 1996, 94: 1545-52. Erdogan D, Caliskan M, Gullu H, Sezgin AT, Yildirir A, Muderrisoglu H: Coronary flow reserve is impaired in patients with slow coronary flow. Atherosclerosis. 2007, 191: 168-74. 10.1016/j.atherosclerosis.2006.03.016. Amos DJ, French JK, Andrews J, Ashton NG, Williams BF, Whitlock RML, Manda SOM, White HD: Corrected TIMI frame counts correlate with stenosis severity and infarct zone wall motion after thrombolytic therapy. Am Heart J. 2001, 141: 586-91. 10.1067/mhj.2001.113393. Baris N, Sipahi I, Kapadia SR, Nicholls SJ, Erinc K, Gulel O, Crowe TD, Hobbs R, Yamani MH, Taylor DO, Smedira N, Starling RC, Nissen SE, Tuzcu EM: Coronary angiography for follow-up of heart transplant recipients: insights from TIMI frame count and TIMI myocardial perfusion grade. J Heart Lung Transplant. 2007, 26: 593-97. 10.1016/j.healun.2007.03.016. Petronio AS, Rovai D, Musumeci G, Baglini R, Nardi C, Limbruno U, Palagi C, Volterrani D, Mariani M: Effects of abciximab on microvascular integrity and left ventricular functional recovery in patients with acute infarction treated by primary coronary angioplasty. Eur Heart J. 2003, 24: 67-76. 10.1016/S0195-668X(02)00324-1. Gyöngyösi M, Domanovits H, Benzer W, Haugk M, Heinisch B, Sodeck G, Hödl R, Gaul G, Bonner G, Wojta J, Laggner A, Glogar D, Huber K, for the ReoPro-BRIDGING Study Group: Use of abciximab prior to primary angioplasty in STEMI results in early recanalization of the infarct-related artery and improved myocardial tissue reperfusion – results of the Austrian multi-centre randomized ReoPro-BRIDGING Study. Eur Heart J. 2004, 25: 2125-33. 10.1016/j.ehj.2004.09.018. Ozdemir R, Sezgin AT, Barutcu I, Topal E, Gullu H, Acikgoz N: Comparison of direct stenting versus conventional stent implantation on blood flow in patients with ST-segment elevation myocardial infarction. Angiology. 2006, 57: 453-58. 10.1177/0003319706290620. Muehling OM, Wilke NM, Panse P, Jerosch-Herold M, Wilson BV, Wilson RF, Miller LW: Reduced myocardial perfusion reserve and transmural perfusion gradient in heart transplant arteriopathy assessed by magnetic resonance imaging. J Am Coll Cardiol. 2003, 42: 1054-60. 10.1016/S0735-1097(03)00924-0. Rieber J, Huber A, Erhard I, Mueller S, Schweyer M, Koenig A, Schiele TM, Theisen K, Siebert U, Schoenberg SO, Reiser M, Klauss V: Cardiac magnetic resonance perfusion imaging for the functional assessment of coronary artery disease: a comparison with coronary angiography and fractional flow reserve. Eur Heart J. 2006, 27: 1465-71. 10.1093/eurheartj/ehl039. Kühl HP, Katoh M, Buhra C, Krombach GA, Hoffmann R, Rassaf T, Neizel M, Buecker A, Kelm M: Comparison of magnetic resonance perfusion imaging versus invasive fractional flow reserve for assessment of the hemodynamic significance of epicardial coronary artery stenosis. Am J Cardiol. 2007, 99: 1090-95. 10.1016/j.amjcard.2006.11.061. Futamatsu H, Wilke N, Klassen C, Shoemaker S, Angiolillo DJ, Siuciak A, Morikawa-Futamatsu K, Suzuki N, von Ziegler F, Bass TA, Costa MA: Evaluation of cardiac magnetic resonance imaging parameters to detect anatomically and hemodynamically significant coronary artery disease. Am Heart J. 2007, 154: 298-305. 10.1016/j.ahj.2007.04.024. Below are the links to the authors’ original submitted files for images. This article is published under license to BioMed Central Ltd. This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/2.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. DOI: https://doi.org/10.1186/1532-429X-10-8 Sorry, a shareable link is not currently available for this article.', 'Global climate change impacts on human and natural systems are predicted to be severe, far reaching, and to affect the most physically and economically vulnerable disproportionately. Society can respond to these threats through two strategies: mitigation and adaptation. Industry, commerce, and government play indispensable roles in these actions but so do individuals, if they are receptive to behavior change. We explored whether the health frame can be used as a context to motivate behavioral reductions of greenhouse gas emissions and adaptation measures. In 2008, we conducted a cross-sectional survey in the United States using random digit dialing. Personal relevance of climate change from health threats was explored with the Health Belief Model (HBM) as a conceptual frame and analyzed through logistic regressions and path analysis. Of 771 individuals surveyed, 81% (n = 622) acknowledged that climate change was occurring, and were aware of the associated ecologic and human health risks. Respondents reported reduced energy consumption if they believed climate change could affect their way of life (perceived susceptibility), Odds Ratio (OR) = 2.4 (95% Confidence Interval (CI): 1.4 - 4.0), endanger their life (perceived severity), OR = 1.9 (95% CI: 1.1 - 3.1), or saw serious barriers to protecting themselves from climate change, OR = 2.1 (95% CI: 1.2 - 3.5). Perceived susceptibility had the strongest effect on reduced energy consumption, either directly or indirectly via perceived severity. Those that reported having the necessary information to prepare for climate change impacts were more likely to have an emergency kit OR = 2.1 (95% CI: 1.4 - 3.1) or plan, OR = 2.2 (95% CI: 1.5 -3.2) for their household, but also saw serious barriers to protecting themselves from climate change or climate variability, either by having an emergency kit OR = 1.6 (95% CI: 1.1 - 2.4) or an emergency plan OR = 1.5 (95%CI: 1.0 - 2.2). Motivation for voluntary mitigation is mostly dependent on perceived susceptibility to threats and severity of climate change or climate variability impacts, whereas adaptation is largely dependent on the availability of information relevant to climate change. Thus, the climate change discourse could be framed from a health perspective to motivate behaviour change. Humans are now unequivocally implicated in contributing to global climate change [1, 2]. Strategic action is required both from individuals and the private/public sector to prevent harmful corollaries from climate change to individuals and society at large. Climate change will alter the probability of extreme weather events, which have been associated with adverse health outcomes, such as heat-related mortality and morbidity during heat waves [3, 4]; injuries from extreme weather events [5]; injuries and death from flooding [6]; re- and emerging communicable diseases such as hantavirus associated hemorrhagic fever, West Nile fever, or Lyme disease [7]. Dramatic episodes, such as the European heat wave of 2003 or hurricane Katrina in 2005 can be seen in isolation or as part of a probability function of events with increasing frequency, duration, and intensity. Thus, the difficulty in building understanding of climate change lies in the fact that many climate change-related events such as natural disasters or disease outbreaks cannot be directly attributed to climate change making it less intuitive and thus difficult to communicate. In order to gauge the motivation of individuals to take precautionary steps to reduce climate risks we explored options for mitigation and adaptation. Mitigation entails reductions in greenhouse gas emissions and augmentation in greenhouse gas sinks intended to minimize the extent of global warming [8]. These steps include energy conservation by increasing the fuel efficiency of vehicles; switching to cleaner energy sources by changing business practices; or carbon sequestration through tropical reforestation. However, these practices have proven to be remarkably slow and difficult to implement at best. Even if so, their impact on global climate change will not be noticed in decades to come due to the longevity of greenhouse gases in the atmosphere [2]. Thus, adaptation to climate change impacts becomes a necessity both on an individual and communal level [9, 10]. Adaptation entails adjustments of environmental or social settings in response to past, current or anticipated climatic events and their impacts in order to moderate their consequences [2]. Autonomous (or spontaneous) adaptation is typically defined as responding to climate-driven changes in natural systems that occur naturally by private actors without intervention of public institutions [8]. It is usually the result of reactive responses to current climate impacts, rather than preventive measures. In contrast, anticipatory (proactive or planned) adaptation is initiated prior to climate change impacts are observed. It is based on scientific information about projected impacts and is usually executed by government agencies [2, 11]. Climate change has traditionally been framed as an environmental, rather than a health issue. Concerns of ecologic, environmental, social, or economic climate change impacts are certainly important drivers of behaviour change but may have contributed to the recent ""climate fatigue"" [12]. Meanwhile, it is known that personal perception of risk is the strongest motivator of health behaviour change based on the health promotion literature [13]. Potentially then, the health aspects of climate change should resonate well across wide segments of the American public [14]. Thus, health could be a strong motivating factor for individuals to reduce greenhouse gas emissions and to adopt adaptation measures to reduce health risks. However, it is not clear if the health frame would suffice to engage the pubic in adaptation and mitigation steps, since they hinge on public appreciation of the health threats of these climatic processes. Besides, media coverage has been rather polarized and not constructively educated the public about potential health threats [15]. Very little research has been published to date on public perception of adverse health effects from climate change but some studies that have touched on this issue have not found the public to be very knowledgeable [16–18]. The goal of this study was to assess the health context as a motivating factor for adaptation and mitigation behavior. We had previously tested the transtheoretical model (stages of change model) to explain barriers to behaviour change for mitigation [19]. We also considered theory of reasoned action and social learning theory to elucidate underlying drivers of behaviour change [20, 21]. In order to test the hypothesis whether health is an appropriate frame for behaviour change in response to climate change risks we applied the health belief model (HBM) to gauge respondents\' willingness to engage in voluntary mitigation and adaptation efforts based on their attitudes and beliefs [22]. The HBM had originally been developed to explain the likelihood of health-related behavior from an individual perspective. The HBM has been widely used to understand preventive health behaviors as well as mitigation behavior to reduce environmental pollution that has human health impacts [23–25]. The components of the HBM are perception of susceptibility, severity, benefits, and barriers to action, as well as cues to action and self-efficacy. Perceived susceptibility and perceived barriers have been shown to be associated with preventive behavior while perceived severity, perceived benefits, and perceived barriers have been most strongly associated with treatment of a condition. We hypothesized that if climate change is perceived as a health threat, then the components of the HBM might be able to predict mitigation and adaptation behavior. We probed whether respondents considered themselves to be susceptible to the threats of climate change/variability and whether this health risk was deemed severe. We explored whether or not the HBM could explain respondents\' propensity for autonomous adaptation behavior, and whether or not they had engaged in voluntary energy reduction to counteract global climate change (mitigation behavior). The time-frame for mitigation is long-range while adaptation is more immediate but both actions are important and complementary, and are not mutually exclusive [26]. Thus, these findings are important if public health agencies are to reach the public with behavior change messages through social marketing or communication campaigns using the health context as a frame. Attitudes about climate change/variability impacts, mitigation and adaptation were assessed through random-digit dial telephone surveys from a U.S. sample between September and October, 2008 (table 1). The surveys were conducted in both Spanish and English at Portland State University\'s Survey Research Laboratory (SRL) which has been described elsewhere [19]. The SRL is outfitted with a state-of the-art Computer Assisted Telephone Interviewing (CATI) system with 20 phone interviewing booths. The survey questions appeared on a monitor and were read by the interviewer in a preset order. The survey was designed with complex contingency patterns of questions, where sub-questions were automatically branched off to produce skip patterns. Invalid responses were recognized by the CATI system which enhanced data quality. Furthermore, the need for subsequent data entry was omitted since the data were typed directly into the database. Quality control was assured by a centralized facility that monitored the interviews. The original sample of phone numbers was selected based on the census distribution of population density across all U.S. states in order to assure a geographically representative study population. The optimum time for calling was established through call-back procedures (three call-backs per number) and interview scheduling. On average an interview took 17 minutes and the survey was administered over the course of 33 days. Participants were screened for age (> 18 years), comprehension, zip codes (to assure geographic specificity of respondents) and knowledge of global climate change. Respondents denying climate change as a phenomenon were censured (15%), because all questions pertained to different aspects of climate change [16]. The survey instrument and study protocol was approved by PSU\'s Human Subjects Research Review Committee (HSRRC Proposal #04157). The ranking of respondents per U.S. state in our study population correlated highly with the ranking of the U.S. census population density by state (Spearman correlation: r = 0.897; p < 0.001); thus the study sample was reasonably representative of the geographic distribution of the U.S. population. The demographic profile of the sample (table 1) was also reasonably representative of the US population at large (according to population data from the 2000 census) with respect to gender (Census female 50.9%, analysis sample 56.8%) and race (Census white 75.1%, analysis sample 81.4%), although there was a certain sampling bias towards the age, educational qualifications and household income, since our sample reflected the populations that were more likely to be home during the day, a common occurrence in phone surveys [27–29]. In order to further explain and predict health behaviors related to climate change/variability we drew on the HBM, a psychological model that focuses on attitudes and beliefs of individuals [30]. Survey questions were designed to capture predictors of mitigation and autonomous adaptation behavior through the lens of the HBM components: perception of susceptibility, severity, benefits, and barriers to action, as well as cues to action and self-efficacy. Categorical demographic variables were dichotomized due to sample size constraints (table 1). Responses to open ended questions were subjected to content analysis. We first estimated three parallel logistic regression equations within a single model in order to obtain estimates of the association between all the predictors (demographics and HMB related variables) with the three outcomes (mitigation: reduced energy consumption; autonomous adaptation: emergency kit and emergency plan). The causal structure implied by the HBM was not imposed on the data, but the correlation between the three dependent variables was taken into account which were jointly modeled. We employed the robust maximum likelihood (MLR) estimator with Gauss-Hermite integration. In the second stage of the analysis we employed a path analytic approach to estimate the parameters representing the causal structure which is implied by the HBM (see figure 1). For example the effect of perceived susceptibility to the three outcomes is mediated by perceived severity and therefore an indirect effect is implied. Path analysis allows the formal estimation of indirect effects and their associated standard errors, which is not possible with the standard regression approach we used in the first analytic stage, since with this the effect of all the variables in the model is simply adjusted for the presence of all the other covariates [31]. Conceptual path diagram of the Health Belief Model. In the presence of binary or ordinal mediators or endogenous variables (perceived severity for example) it has been suggested that the product of standardized probit coefficients is the most reliable estimate of the indirect effect [32]. The probit model assumes that a latent continuum underlies the observed binary or ordinal variables. The standardised probit regression coefficients can therefore be interpreted as the probability of a one standard deviation change in the underlying continuous variable attributable to a one standard deviation change in the predictor. The path analysis was estimated with the Weighted Least Squares, mean and variance adjusted (WLSMV) estimator, in the Mplus 5.21 software [33]. Due to the complexity of the model and the nature of our sample we report significance tests derived by bootstrapped standard errors with 10,000 replications. Of the 771 individuals surveyed 3% (n = 23) had never heard of climate change before and 15% (n = 112) did not believe climate change was in fact occurring. However, the majority of Americans (n = 622; 81%) in our survey were aware of climate change and believed that it was certainly taking place. Study participants, when prompted, attributed a number of environmental phenomena to climate change, most noticeably average temperature increases and the melting of permafrost in the Arctic region (table 2). Heat waves, more frequent storms, water shortages, sea-level rise, flooding, and loss of wildlife habitat were mentioned by four out of five respondents that knew about climate change. Misconceptions about climate change impacts were revealed in 10% of comments provided to open-ended questions (n = 135), such as earthquakes, depletion of the ozone layer, vitamin depletion in food, etc. Perceived health risks to the American public are listed in table 3. Respondents were concerned about both air and water quality impacts and about heat stroke and respiratory problems. The most common health concern in the open ended comments related to food shortages (21% of n = 126). Perceived susceptibility was further explored by asking respondents if climate change could affect their way of life or lifestyle; 78% of respondents recognized a certain level of susceptibility (table 4). Of the respondents, 69% reported that climate change could potentially endanger their lives and pose adverse personal effects. However, 62% were under the impression that personal preparation could save their life. Only a minority of study participants (31%) saw any obstacles or barriers to protecting themselves from negative consequences of climate change. They included lack of money or resources (65%), lack of help from others (56%), lack of knowledge (53%), lack of personal energy or motivation (43%), or lack of time (34%) (table 5). The majority (56%) of respondents felt that they both had the necessary information to prepare for climate change impacts as well as the confidence and ability to protect themselves from health impacts of climate change. Based on these findings we explored whether the respondents were ready for behavioural change and to take mitigation or adaptation actions. The majority of respondents (77%) reported having reduced their energy consumption based on what they have heard about global climate change. Reported energy conservation steps (N = 479) are listed in table 6. Virtually everybody claimed to have reduced their home energy consumption and their gasoline use. Energy intensive commodities such as water and food were also considered by four out of five respondents. Among those that did not report any energy conservation efforts (18%; n = 118) cited inconvenience and lack of conviction as reasons (table 7). The vast majority of study participants affirmed autonomous adaptive behavior during an extremely hot weather period. These steps included cooling off in a room with air-conditioning (89%) or with a fan (79%), staying out of the sun (96%), drinking plenty of water (99%), and dressing lightly (88%), reduced exercise (60%). For other types of climatic events, 52% individuals reported having an emergency kit that included such items as a first aid kit, thermometers, flashlight and batteries, food that won\'t spoil, sufficient drinking water, and other essential items in the event of a disaster or emergency. Among those that reported not having one (n = 298) 23% admitted never having thought about it and 3% did not expect to need one; procrastination and laziness were some of the other reasons for not having one. Of those that provided open ended comments (n = 82) 35% reported having some of the items but not all and were planning to reassemble them into a kit in the near future. Qualitative comments described some of the circumstances: ""Usually we get tornados, and when there is a tornado there is no time to get the kit when the emergency is happening."" and ""We are not in a flood plain and once in a while we have had a tornado, but it is so rare. I keep some of the stuff on the shelf but not in a specific kit."" Respondents were also asked whether their household currently had a plan for what to do to protect themselves and their family in the event of a disaster or emergency, such as how to evacuate the home, or how to stay in contact with other family members; 57% claimed having such a plan. Of those that did not have an emergency plan (n = 115) 59% never considered it and 5% did not get around to it. With respect to the predictive power of the HBM constructs as independent variables, in table 8 we present the odd ratios from the three parallel logistic regression models. We observed a positive association between perceived severity and mitigation (OR = 1.874, p < 0.001), perceived susceptibility and mitigation (OR = 2.364, p < 0.001), as well as perceived barriers and mitigation (OR = 2.052, p < 0.001). Furthermore, gender was associated with mitigation (OR = 1.885, p < 0.001), with women being 1.88 times more likely to take voluntary mitigation actions. Having an emergency kit was positively associated with perceived barriers (OR = 1.608, p < 0.001) and cues to action (OR = 2.098, p < 0.001), whereas perceived susceptibility (OR = 1.614, p < 0.001), perceived barriers (OR = 1.476, p < 0.05) and cues to action (OR = 2.161, p < 0.001), were all positively associated with having an emergency plan. Finally gender was negatively associated with having an emergency kit (OR = 0.577, p < 0.001) and an emergency plan (OR = 0.883, p < 0.001), with women being less likely to engage in any of the two autonomous adaptation actions. In table 9 we present the standardized probit regression coefficients derived from the path analytic model, in order to estimate the influence of each pathway implied by the HBM. We did not observe any significant effect of the demographic characteristics and SEP status of the participants in the endogenous variables -mediators (perceived threat, perceived benefits and perceived barriers) of the HBM. Consequently none of the indirect effects of the demographic and SEP indicators on the three outcomes was significant. On the contrary we observed a strong positive association between perceived severity and mitigation, β = 0.479, p < 0.001. Similarly we observed a strong indirect effect of perceived susceptibility on mitigation via perceived severity, β = 0.349, p < 0.001, which was dominated by the very strong association between perceived susceptibility and perceived severity, β = 0.728, p < 0.001. Perceived benefits had a positive association with mitigation, β = 0.204, p < 0.001, as did perceived barriers, β = 0.322, p < 0.001. We did not observe any other significant association between the HBM variables and mitigation. With respect to the two autonomous adaptation actions, we observed a positive association between perceived susceptibility and having an emergency kit, β = 0.100, p < 0.01, as well as an indirect effect of perceived susceptibility via perceived severity, β = 0.108, p < 0.01. Perceived benefits had also a significant association with having an emergency kit, β = 0.108, p < 0.01, as did perceived barriers, β = 0.213, p < 0.001. We did not observe any other significant association between the HBM variables and having an emergency kit. Finally, perceived barriers had a positive association with having an emergency plan, β = 0.160, p < 0.001. We did not observe any other significant associations between the HBM variables and having a plan. Based on the results of both analytic approaches (parallel logistic regressions and path analysis) we estimated a refined path analytic model adding direct effects from cues to action and gender to the three outcomes. The added results are presented as underlined parameters in table 9. As expected from the logistic regression results cues to action were positively associated with having an emergency kit and an emergency plan, whereas gender was positively associated with mitigation and negatively with both autonomous adaptation actions. In the present study we explored perception of climate change risks among those who were not dismissive of climate change [16]. We tested the predictive power of the HBM with respect to respondents\' propensity for autonomous adaptation behavior and mitigation behavior. We employed two statistical modeling approaches in order to test this: i) three parallel logistic regressions to obtain fully adjusted parameters for all the HBM constructs as well as demographics and socio-economic predictors; ii) a path analysis, where the causal structure implied by the HBM (see figure 1) was taken into account in the estimation of the model. This allowed us to estimate the indirect effects of perceived susceptibility, cues to action and demographic characteristics - all via perceived severity - on the three outcomes. Our findings on environmental impacts from climate change are very similar to recent surveys conducted in the U.S., Canada and Malta with 60-80% of respondents anticipating environmental threats [16]. Climate change or climate variability is perceived as posing a risk which sets the stage for behaviour change. Almost 8 in 10 respondents who had heard about global climate change reported having reduced their energy consumption; this self-reported mitigation effort was associated with a sense of susceptibility as well as the severity of climate change, with the effect of susceptibility being both direct as well as mediated by severity, thus making it the strongest predictor of mitigation effort. Furthermore, while respondents felt that there were certain barriers to protecting themselves from the negative consequences of climate change they also felt that their mitigation actions had co-benefits, such as reduced energy bills. Intentional reduction in energy consumption by individuals hinges on their state of awareness and concern about climate change, their willingness to act and their ability to change [34, 35]. Thus, it is important to portray voluntary mitigation as necessary and achievable [36]. Low impact energy conservation was acted upon but not on high energy savings: curtailment (home energy conservation such as switching off lights; driving less; etc) was readily embraced (or at least reported) in contrast to efficiency improvements (switching to a fuel-efficient car or appliance) which was not, despite the fact, that later would deliver higher energy savings. Other high energy savings activities such as flying less or walking more were comparatively underreported in our survey which has also been reported elsewhere [37]. It is important to note that respondents were prompted about these different activities and might as a result have overstated their true motivation for these actions [38]. While interviewers specifically asked about climate change-related behavior change other factors (such as utility bills and gasoline prices) could also have contributed to behavior change. In addition, we did not attempt to quantify the extent of energy reduction based on these self-reported mitigation activities. These data should be considered an indication that the respondents would be willing to tackle mitigation steps but not necessarily being actively engaged in climate change mitigation. The majority of respondents also reported having taken steps towards autonomous adaptation to extreme weather events attributable to climate variability or climate change. Study participants that were aware of climate change attributed a number of environmental impacts to climate change such as average temperature increase, heat waves, drought conditions or water shortage. Heat stroke or heat exhaustion, stress or anxieties were listed as major health concerns from these environmental impacts. In the context of the climate change interview, over half of respondents (52%) asserted having prepared an emergency kit with essential items needed in the event of a disaster or emergency and 57% claimed having a household emergency plan to protect themselves and their family in the event of a disaster or emergency. Both of these autonomous adaptation actions were positively influenced by cues to action, a finding which indicates that respondents felt they had the necessary information to prepare for the impacts of climate change. Similarly, both autonomous adaptation actions were influenced by perceived barriers, indicating that without removing those barriers the necessary information (cues to action) may not result in the desired behavioural change which is needed for successful adaptation. The majority of these barriers could be overcome with financial or practical support. There are a number of other autonomous adaptation actions or reactive responses to current climate impacts not covered in our survey. They could be supported with tax incentives and technical solutions and government agencies should work with communities to address their needs. From the other predictors only gender was associated with either autonomous adaptation action, with women appearing to be less adaptive. The majority of study participants had adapted to extreme weather conditions by cooling off in air conditioned places, reducing physical exertion or using a fan. These autonomous adaptation actions are reactive in nature, more so than proactive and thus does not capture anticipatory (proactive or planned) adaptive intentions. The survey instrument was initially designed to capture anticipatory adaptation as well by asking respondents if they adapted their home to climate change. For example: have you installed an A/C, insulation, insect screens, eliminated mosquitoes breeding sites, etc. However, due to low frequency responses these questions were eliminated from the analysis; thus the results apply to autonomous adaptation only and not to long-term impacts. Other studies that did not specifically examine the psychological constructs of the HBM have shown that adaptive behaviour to climate change may be more strongly linked to factors such as, environmental attitudes, political affiliation and attitudes towards scientists [39–41]. The relative differences in predictors of our mitigation and adaptation outcomes might in part be due to the wording of the survey questions. Nevertheless, health as a communication frame can be used to complement other strategies to augment the public response [42]. Attitudes and public perception of global climate change has also been examined in other surveys in the U.S. [19, 23, 40, 41, 43–47]. A recent study of US local public health department directors found that health directors are not actively responding to climate change in part due to their belief that the public does not have knowledge about the impact of climate change and therefore would be unwilling to support mitigation and adaptation activities [48]. Our study indicates that the majority of the public report awareness of environmental and health risks associated with climate change and that they consider themselves to be susceptible to being affected by it. Individuals with concerns about climate change hazards have been shown to be more engaged in personal actions [49, 50]. Our survey examined more specifically vulnerability and risk perception of climate change/vulnerability and indicates that the majority of the respondents would like to be part of climate solutions, which is consistent with other studies [51–54]. These findings indicate that the motivation for voluntary mitigation is mostly dependent on the perceived susceptibility to and severity of climate change, and autonomous adaptation is largely dependent on the availability of information relevant to climate change and its impact. Furthermore, our findings suggest an extension of the classic HBM as a predictive causal structure of mitigation and autonomous adaptation strategies, by adding direct effects of cues to action and gender to the these outcomes. Media advocacy campaigns should embrace the health context as a frame and aim at increasing general understanding of climate change and encourage active participation in mitigation and adaptation. Our findings indicate that proximal climate threats against which individuals feel highly susceptible, such as heat waves, droughts, or forest fires, are acted upon, especially when having the necessary information and if the threat is perceived as endangering their way of life. However, climate change is a multiplier of existing vulnerabilities for susceptible populations, underrepresented in our survey, who are at increased risk from such events. Vulnerable populations of low socio-economic status tend not to respond equally well to health promotion campaigns compared to the general population [55]. Thus, traditional media messages might not be able to persuade these populations to change behaviour and concerted efforts need to be put in place to reach these individuals both through more effective communication frames and community organizing [10, 56]. This study indicates how climate change can be framed from a health perspective to advance population health. Air Conditioning. UNFCCC: Framework Convention on Climate Change. Article 1: Definitions. IPCC: Fourth Assessment Report, Synthesis Report. Fourth Assessment Report, Synthesis Report. 2007 Semenza JC, Rubin HC, Falter KH, Selanikio JD, Flanders DW, Wilhelm JL: Risk factors for heat-related mortality during the July 1995 heat wave in Chicago. New Eng J Med. 1996, 335: 84-90. 10.1056/NEJM199607113350203. Semenza JC, McCullough J, Flanders DW, McGeehin MA, Lumpkin JR: Excess hospital admissions during the 1995 heat wave in Chicago. Am J Prev Med. 1999, 16: 269-277. 10.1016/S0749-3797(99)00025-2. Broder JMA, Tintinalli J: Injuries from the 2002 North Carolina ice storm, and strategies for prevention. Injury. 2005, 36: 21-26. 10.1016/j.injury.2004.08.007. Hajat SEK, Kovats S, Menne B, Edwards S, Haines A: The human health consequences of flooding in Europe and the Implications for public health: a review of the literature. Applied Environmental and Science Public Health. 2003, 1: 13-21. Semenza JC, Menne B: Climate Change and Infectious Diseases in Europe. Lancet ID. 2009, 9: 365-375. 10.1016/S1473-3099(09)70104-5. McCarthy JJCO, Leary NA, Dokken DJ, White KS, (Ed.): Climate change 2001: Imacts, Adaptation, and Vulnerability. 2001, Cambridge Cambridge University Press Haines AKR, Campbell-Lendrum D, Corvalan C: Climate change and human health: impacts, vulnerability, and mitigation. Lancet. 2006, 367: 2101-2109. 10.1016/S0140-6736(06)68933-2. Ebi KL, Semenza JC: Community-based adaptation to the health impacts of climate change. Am J Prev Med. 2008, 35: 501-507. 10.1016/j.amepre.2008.08.018. McCarthy JOF, Canziani NL, Dokken DJ, White KS, (eds) (Ed.): Climate Change 2001, Impacts, Adaptation, and Vulnerability 2001: Impacts, Adaptation and Vulnerability: Contribution of Working Group II to the Third Assessment Report of the Intergovernmental Panel on Climate Change. 2001, Cambridge, UK and New York.: Cambridge University Pres Kerr RA: Amid worrisome signs of warming, ""climate fatigue"" sets in. Science. 2009, 326: 926-928. 10.1126/science.326.5955.926. Hale J, Dillard J, (Eds.): Fear appeals in health promotion campaigns: Too much, too little, or just right?. 1995, Thousand Oaks, CA: Sage Publications Nisbet MC: Communicating climate change: Why frames matter for public engagement. Environment. 2009, 51: 514-518. Campbell-Lendrum DBR: Science, media and public perception: Implications for climate and health policies. Bulletin of the World Health Organization. 2010, 88: 242-242. 10.2471/BLT.10.077362. Akerlof KDR, Berry P, Leiserowitz A, Roser-Renouf C, Clarke KL, Rogaeva A, Nisbet MC, Weathers MR, Maibach EW: Public perceptions of climate change as a human health risk: surveys of the United States, Canada and Malta. Int J Environ Res Public Health. 2010, 7: 2559-2606. 10.3390/ijerph7062559. Gallup: Americans\' Global Warming Concerns Continue to Drop. Book Americans\' Global Warming Concerns Continue to Drop. 2010 Leiserowitz AA: Climate change risk perception and policy preferences: The role of affect, imagery and values. Climatic Change. 2006, 77: 45-72. 10.1007/s10584-006-9059-9. Semenza JCHD, Wilson DJ, Bontempo BD, Sailor DJ, George LA: Public perception of climate change voluntary mitigation and barriers to behavior change. Am J Prev Med. 2008, 35: 479-487. 10.1016/j.amepre.2008.08.020. Fishbein MAI, (Ed.): Belief, attitude, intention and behaviour. 1975, New York: Addison-Wesley Bandura A, (Ed.): Social learning theory. 1977, NJ: Prentice-Hall Rosenstock IM, (Ed.): The health belief model:explaning health behaviour through expectancies. 1900, San Francisco: Jossey-Bass Brody SDZS, Vedlitz A, Grover H: Examining the relationship between physical vulnerability and public perceptions of global climate change in the United States. Environment and Behavior. 2008, 40: 72-95. Lichtenberg EZR: Adverse health experiences, environmental attitudes, and pesticide usage behavior of farm operators. Risk Analysis. 1999, 19: 283-294. Skov TCT, Jensen LK, Saugman P, Schmidt K, Theilade P: Modifications of health behaviour in response to air pollution notifications in Copenhagen. Social Science and Medicine. 1991, 33: 621-626. 10.1016/0277-9536(91)90220-7. Biesbroek GRSR, Knaap GM van der: The mitigation-adaptation dichotomy and the role of spatial planning. Habitat International. 2008, 33: 230-237. Steeh CKN, Cannon B, DeWitt J: Are they really as bad as they seem? Nonresponse rates at the end of the twentieth century. Journal of Official Statistics. 2001, 17: 227-247. Groves RMCM, (Ed.): Nonresponse in household surveys. 1998, New York: Wiley Link MWKM: The future of random-digit-dial surveys for injury prevention and violence research. Am J Prev Med. 2006, 31: 444-450. 10.1016/j.amepre.2006.07.017. Rosenstock IM, Strecher VJ, Becker MH: Social Learning Theory and the Health Belief Model. Health Education & Behavior. 1988, 15: 175-183. 10.1177/109019818801500203. De Stavola BL, Nitsch D, Silva ID, McCormack V, Hardy R, Mann V, Cole TJ, Morton S, Leon DA: Statistical issues in life course epidemiology. American Journal of Epidemiology. 2006, 163: 84-96. MacKinnon DPLC, Brown Wang WCH, Hoffman JM: The intermediate endpoint effect in logistic and probit regression. Clinical Trials. 2007, 4: 499-513. 10.1177/1740774507083434. Muthen LK, Muthen BO: Mplus User\'s Guide. Fourth Edition. 1998, Los Angeles, CA Stern PCDT, Abel T, Guagnano GA, Kalof L: A Value-Belief-Norm Theory of Support for Social Movements: The Case of Environmentalism. Human Ecology Review. 1999, 6: 81-97. Stern PC: Towards a coherent theory of environmentally significant behavior. Jouranl of Social Issues. 2000, 56: 407-424. 10.1111/0022-4537.00175. Lorenzoni IN-CS, Whitmarsh L: Barriers perceived to engagning with climate change among the UK public and their policy implications. Global Environmental Change. 2007, 17: 445-459. 10.1016/j.gloenvcha.2007.01.004. Attari SZDM, Davidson CI, Bruine de Bruin W: Public perceptions of energy consumption and savings. Proc Natl Acad Sci USA. 2010, 107: 16054-16059. 10.1073/pnas.1001509107. Whitmarsh L: Behavioural responses to climate change: Asymmetry of intentions and impacts. J Environ Psychology. 2009, 29: 13-23. 10.1016/j.jenvp.2008.05.003. Whitmarsh L: Are flood victims more concerned about climate change than other people? the role of direct experience in risk perception and behavioural response. Journal of Risk Research. 2008, 11: 351-374. 10.1080/13669870701552235. Malka AKJ, Langer G: The association of knowledge with concern about global warming: Trusted information sources shape public thinking. Risk Analysis. 2009, 29: 633-647. 10.1111/j.1539-6924.2009.01220.x. Kellstedt PMZS, Vedlitz A: Personal efficacy, the information environment, and attitudes toward global warming and climate change in the United States. Risk Analysis. 2008, 28: 113-126. 10.1111/j.1539-6924.2008.01010.x. Maibach EWNM, Baldwin P, Akerlof K, Diao G: Reframing climate change as a public health issue: an exploratory study of public reactions. BMC Public Health. 2010, 10: 299-10.1186/1471-2458-10-299. Reiner DMCT, De Figueiredo MA, Herzog HJ, Ansolabehere SD, Itaoka K, Johnsson F, Odenberger M: American exceptionalism? Similarities and differences in national attitudes toward energy policy and global warming. Environ Sci Technol. 2006, 40: 2093-2098. 10.1021/es052010b. Bord RJFA, O\'Connor RE: Public perceptions of global warming: United States and international perspectives. Climate Research. 1998, 11: 75-84. Brechin SR: Comparative public opinion and knowledge on global climatic change and the Kyoto protocol: The US vs the rest of the world?. International Journal of Sociology and Social Policy. 2003, 23: 106-134. 10.1108/01443330310790318. Kempton W: How the public views climate change. Environment. 1997, 39: 12-21. Semenza JCWD, Parra J, Bontempo BD, Hart M, Sailor DJ, George LA: Public perception and behavior change in relationship to hot weather and air pollution. Environ Res. 2008, 107: 401-411. 10.1016/j.envres.2008.03.005. Maibach EWCA, McBride D, Chuk M, Ebi KL, Balbus J: Climate change and local public health in the United States: Preparedness, programs and perceptions of local public health department directors. PLoS ONE. 2008, 3: e2838-10.1371/journal.pone.0002838. World Health Organization G: Protecting Health from Climate change: Connecting Science, Policy and People. Book Protecting Health from Climate change: Connecting Science, Policy and People. 2009, City, (Editor ed.^eds.). Wilkinson PSK, Davies M, Adair H, Armstrong BG, Barrett M, Bruce N, Haines A, Hamilton I, Oreszczyn T, Ridley I, Tonne C, Chalabi Z: Public health benefits of strategies to reduce greenhouse-gas emissions: household energy. Lancet. 2009, 374: 1917-1929. 10.1016/S0140-6736(09)61713-X. Zahran S, Brody SD, Grover H, Vedlitz A: Climate change vulnerability and policy support. Society and Natural Resources. 2006, 19: 771-789. 10.1080/08941920600835528. Leiserowitz AA: American risk perceptions: Is climate change dangerous?. Risk Analysis. 2005, 25: 1433-1442. 10.1111/j.1540-6261.2005.00690.x. Krosnick JAHA, Lowe L, Visser PS: The Origins and consequences of democratic citizens\' policy agendas: A study of popular concern about global warming. Climatic Change. 2006, 7-43. Slimak MWDT: Personal values, beliefs, and ecological risk perception. Risk Analysis. 2006, 26: 1689-1705. 10.1111/j.1539-6924.2006.00832.x. Semenza JC: Strategies to intervene on social determinants of infectious diseases. Euro Surveill. 2010, 15: 32-39. Spence APN: Framing and communicating climate change: The effects of distance and outcome frame manipulations. Global Environmental Change. 2010, The authors would like to thank Amber Johnson, Debi Elliott and the survey team from the Survey Research Laboratory Portland State University for their diligent work on this project. We would like to thank Drs Kristie Ebi, John Balbus, George Luber, Jeremy Hess, Michele Bernardi, Tek-Ang Lim and Jonathan Suk for critical feedback on the paper. This work was supported by the National Science Foundation under Grant No. 0410103. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation. The authors declare that they have no competing interests. JCS designed the study, developed the questionnaire, supervised the survey, analyzed the data and wrote the paper. GBP conducted the parallel logistic regressions, path analysis and contributed to the writing. LAG contributed to the questionnaire development, survey, and writing of the paper. All authors read and approved the final manuscript Below are the links to the authors’ original submitted files for images. This article is published under license to BioMed Central Ltd. This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/2.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. DOI: https://doi.org/10.1186/1476-069X-10-46 Sorry, a shareable link is not currently available for this article.']","In statistics, standardized coefficients or beta coefficients are the estimates resulting from a regression analysis that have been standardized so that the variances of dependent and independent variables are 1. Therefore, standardized coefficients refer to how many standard deviations a dependent variable will change, per standard deviation increase in the predictor variable. For univariate regression, the absolute value of the standardized coefficient equals the correlation coefficient. Standardization of the coefficient is usually done to answer the question of which of the independent variables have a greater effect on the dependent variable in a multiple regression analysis, when the variables are measured in different units of measurement (for example, income measured in dollars and family size measured in number of individuals)."
the most abundant dissolved salt in ocean water is,"['my.chemeurope.com With an accout for my.chemeurope.com you can always see everything at a glance – and you can configure your own website and individual newsletter. To use all functions of this page, please activate cookies in your browser. Seawater is water from a sea or ocean.  On average, seawater in the world\'s oceans has a salinity of ~3.5%, or 35 parts per thousand. This means that every 1 kg of seawater has approximately 35 grams of dissolved salts (mostly, but not entirely, the ions of sodium chloride: Na+, Cl-). The average density of seawater at the surface of the ocean is 1.025 g/mL; seawater is denser than fresh water (which reaches a maximum density of 1.000 g/mL at a temperature of 4°C) because of the added weight of the salts and electrostriction.[1] The freezing point of sea water decreases with increasing salinity and is about  -2°C (28.4°F) at 35 parts per thousand. [2] Although the vast majority of seawater has a salinity of between 3.1% and 3.8%, seawater is not uniformly saline throughout the world. Where mixing occurs with fresh water runoff from river mouths or near melting glaciers, seawater can be substantially less saline. The most saline open sea is the Red Sea, where high rates of evaporation, low precipitation and river inflow, and confined circulation result in the formation of unusually salty seawater. The salinity in isolated seas and salt-water lakes (for example, the Dead Sea) can be considerably greater. The density of surface seawater ranges from about 1020 to 1029\xa0kg·m-3, depending on the temperature and salinity.  Deep in the ocean, under high pressure, seawater can reach a density of 1050\xa0kg·m-3 or higher.  Seawater pH is limited to the range 7.5 to 8.4.  The speed of sound in seawater is about 1500 m·s-1, and varies with water temperature and pressure. Seawater is more enriched in dissolved ions of all types than fresh water.[3]  However, the ratios of various solutes differ dramatically.  For instance, although seawater is ~2.8 times more enriched with bicarbonate than river water based on molarity, the  percentage of bicarbonate in seawater as a ratio of all dissolved ions is far lower than in river water; bicarbonate ions constitute 48% of river water solutes, but only 0.41% of all seawater ions.[3][4]  Differences like these are due to the varying residence times of seawater solutes;  sodium and chlorine have very long residence times, while calcium (vital for carbonate formation) tends to precipitate out much more quickly.[4] Scientific theories behind the origins of sea salt started with Sir Edmond Halley in 1715, who proposed that salt and other minerals were carried into the sea by rivers, having been leached out of the ground by rainfall runoff. Upon reaching the ocean, these salts would be retained and concentrated as the process of evaporation (see Hydrologic cycle) removed the water. Halley noted that of the small number of lakes in the world without ocean outlets (such as the Dead Sea and the Caspian Sea, see endorheic basin), most have high salt content. Halley termed this process ""continental weathering"". Halley\'s theory is partly correct. In addition, sodium was leached out of the ocean floor when the oceans first formed. The presence of the other dominant ion of salt, chloride, results from ""outgassing"" of chloride (as hydrochloric acid) with other gases from Earth\'s interior via volcanos and hydrothermal vents. The sodium and chloride ions subsequently became the most abundant constituents of sea salt. Ocean salinity has been stable for billions of years, most likely as a consequence of a chemical/tectonic system which removes as much salt as is deposited; for instance, sodium and chloride sinks include evaporite deposits, pore water burial, and reactions with seafloor basalts[6] Since the ocean\'s creation, sodium is no longer leached out of the ocean floor, but instead is captured in sedimentary layers covering the bed of the ocean. One theory is that plate tectonics result in salt being forced under the continental land masses, where it is again slowly leached to the surface. Even on a ship or island in the middle of the ocean, there can be a ""shortage of water"" meaning a shortage of fresh water. This is described famously by a line from Samuel Taylor Coleridge\'s The Rime of the Ancient Mariner: Seawater can be turned into drinkable (potable) water by one of a number of desalination processes, or by diluting it with fresh water to reduce the salinity.  Almost all large ocean-going vessels create fresh water from seawater using vacuum evaporators, flash evaporators or by the use of reverse osmosis. Otherwise, seawater should not be drunk because of its high salt content.  In the long run, more water must be expended to eliminate the salt (through excretion in urine) than the amount of water that is gained from drinking the seawater itself. [7] Accidentally consuming small quantities of seawater is not harmful. However some people cling to a persistent and incorrect belief that humans can survive at sea by drinking only seawater. This misconception probably originated from questionable reports claiming that the French physician Alain Bombard survived an ocean crossing using only seawater and other provisions harvested from the ocean. The amount of sodium chloride in human blood and in urine is always kept within a very narrow range of 9 g per L (0.9% by weight). Drinking seawater (which contains about 3.5% ions of dissolved sodium chloride) temporarily increases the concentration of sodium chloride in the blood, so the only way to excrete the excess sodium chloride in the urine is by sacrificing internal water from cells.  The cells eventually give so much water to try to dilute the salt that they die from dehydration, quickly followed by organs and eventually the organism. Read what you need to know about our industry portal chemeurope.com. Find out more about the company LUMITOS and our team. Find out how LUMITOS supports you with online marketing. https://www.chemeurope.com/en/encyclopedia/Seawater.html', 'Seawater, or salt water, is water from a sea or ocean. On average, seawater in the world\'s oceans has a salinity of about 3.5% (35\xa0g/L, or 0.600 M) This means that every kilogram (roughly one litre by volume) of seawater has approximately 35 grams (1.2\xa0oz) of dissolved salts (predominantly sodium (Na+) and chloride (Cl−) ions). Average density at the surface is 1.025\xa0kg/l. Seawater is denser than both fresh water and pure water (density 1.0\xa0kg/l at 4\xa0°C (39\xa0°F)) because the dissolved salts increase the mass by a larger proportion than the volume. The freezing point of seawater decreases as salt concentration increases. At typical salinity, it freezes at about −2\xa0°C (28\xa0°F).[1] The coldest seawater ever recorded (in a liquid state) was in 2010, in a stream under an Antarctic glacier, and measured −2.6\xa0°C (27.3\xa0°F).[2] Seawater pH is typically limited to a range between 7.5 and 8.4.[3] However, there is no universally accepted reference pH-scale for seawater and the difference between measurements based on different reference scales may be up to 0.14 units.[4] Although the vast majority of seawater has a salinity of between 3.1% and 3.8%, seawater is not uniformly saline throughout the world. Where mixing occurs with fresh water runoff from river mouths or near melting glaciers, seawater can be substantially less saline. The most saline open sea is the Red Sea, where high rates of evaporation, low precipitation and river inflow, and confined circulation result in unusually salty water. The salinity in isolated bodies of water (for example, the Dead Sea) can be considerably greater still. The density of surface seawater ranges from about 1020 to 1029\xa0kg/m3, depending on the temperature and salinity. Deep in the ocean, under high pressure, seawater can reach a density of 1050\xa0kg/m3 or higher. Seawater pH is limited to the range 7.5 to 8.4. The speed of sound in seawater is about 1,500\xa0m/s, and varies with water temperature, salinity, and pressure. Seawater contains more dissolved ions than all types of freshwater.[8] However, the ratios of solutes differ dramatically. For instance, although seawater contains about 2.8 times more bicarbonate than river water based on molarity, the percentage of bicarbonate in seawater as a ratio of all dissolved ions is far lower than in river water. Bicarbonate ions also constitute 48% of river water solutes but only 0.14% of all seawater ions.[8][9] Differences like these are due to the varying residence times of seawater solutes; sodium and chlorine have very long residence times, while calcium (vital for carbonate formation) tends to precipitate much more quickly.[9] The most abundant dissolved ions in seawater are sodium, chloride, magnesium, sulfate and calcium.[10] Its osmolarity is about 1000 mOsm/l.[11] Small amounts of other substances are found including amino acids at concentrations up to 2 micrograms of Nitrogen atoms per liter,[12] which are thought to have played a key role in the origin of life. Research in 1957 by the Scripps Institution of Oceanography sampled water in both pelagic and neritic locations in the Pacific Ocean. Direct microscopic counts and cultures were used, the direct counts in some cases showing up to 10 000 times that obtained from cultures. These differences were attributed to the occurrence of bacteria in aggregates, selective effects of the culture media, and the presence of inactive cells. A marked reduction in bacterial culture numbers was noted below the thermocline, but not by direct microscopic observation. Large numbers of spirilli-like forms were seen by microscope but not under cultivation. The disparity in numbers obtained by the two methods is well known in this and other fields.[13] In the 1990s, improved techniques of detection and identification of microbes by probing just small snippets of DNA, enabled researchers taking part in the Census of Marine Life to identify thousands of previously unknown microbes usually present only in small numbers. This revealed a far greater diversity than previously suspected, so that a litre of seawater may hold more than 20,000 species. Dr. Mitchell Sogin from the Marine Biological Laboratory feels that ""the number of different kinds of bacteria in the oceans could eclipse five to 10 million.""[14] Bacteria are found at all depths in the water column, as well as in the sediments, some being aerobic, others anaerobic. Most are free-swimming, but some exist as symbionts within other organisms – examples of these being bioluminescent bacteria. Cyanobacteria played an important role in the evolution of ocean processes, enabling the development of stromatolites and oxygen in the atmosphere. Some bacteria interact with diatoms, and form a critical link in the cycling of silicon in the ocean. One anaerobic species, Thiomargarita namibiensis, plays an important part in the breakdown of hydrogen sulphide eruptions from diatomaceous sediments off the Namibian coast, and generated by high rates of phytoplankton growth in the Benguela Current upwelling zone, eventually falling to the seafloor. Bacteria-like Archaea surprised marine microbiologists by their survival and thriving in extreme environments, such as the hydrothermal vents on the ocean floor. Alkalotolerant marine bacteria such as Pseudomonas and Vibrio spp. survive in a pH range of 7.3 to 10.6, while some species will grow only at pH 10 to 10.6.[15] Archaea also exist in pelagic waters and may constitute as much as half the ocean\'s biomass, clearly playing an important part in oceanic processes.[16] In 2000 sediments from the ocean floor revealed a species of Archaea that breaks down methane, an important greenhouse gas and a major contributor to atmospheric warming.[17] Some bacteria break down the rocks of the sea floor, influencing seawater chemistry. Oil spills, and runoff containing human sewage and chemical pollutants have a marked effect on microbial life in the vicinity, as well as harbouring pathogens and toxins affecting all forms of marine life. The protist dinoflagellates may at certain times undergo population explosions called blooms or red tides, often after human-caused pollution. The process may produce metabolites known as biotoxins, which move along the ocean food chain, tainting higher-order animal consumers. Pandoravirus salinus, a species of very large virus, with a genome much larger than that of any other virus species, was discovered in 2013. Like the other very large viruses Mimivirus and Megavirus, Pandoravirus infects amoebas, but its genome, containing 1.9 to 2.5 megabases of DNA, is twice as large as that of Megavirus, and it differs greatly from the other large viruses in appearance and in genome structure. In 2013 researchers from Aberdeen University announced that they were starting a hunt for undiscovered chemicals in organisms that have evolved in deep sea trenches, hoping to find ""the next generation"" of antibiotics, anticipating an ""antibiotic apocalypse"" with a dearth of new infection-fighting drugs. The EU-funded research will start in the Atacama Trench and then move on to search trenches off New Zealand and Antarctica.[18] Scientific theories behind the origins of sea salt started with Sir Edmond Halley in 1715, who proposed that salt and other minerals were carried into the sea by rivers after rainfall washed it out of the ground. Upon reaching the ocean, these salts concentrated as more salt arrived over time (see Hydrologic cycle.) Halley noted that most lakes that don\'t have ocean outlets (such as the Dead Sea and the Caspian Sea, see endorheic basin), have high salt content. Halley termed this process ""continental weathering"". Halley\'s theory was partly correct. In addition, sodium leached out of the ocean floor when the ocean formed. The presence of salt\'s other dominant ion, chloride, results from outgassing of chloride (as hydrochloric acid) with other gases from Earth\'s interior via volcanos and hydrothermal vents. The sodium and chloride ions subsequently became the most abundant constituents of sea salt. Ocean salinity has been stable for billions of years, most likely as a consequence of a chemical/tectonic system which removes as much salt as is deposited; for instance, sodium and chloride sinks include evaporite deposits, pure water burial, and reactions with seafloor basalts.[9]:133 Climate change, rising atmospheric carbon dioxide, excess nutrients, and pollution in many forms are altering global oceanic geochemistry. Rates of change for some aspects greatly exceed those in the historical and recent geological record. Major trends include an increasing acidity, reduced subsurface oxygen in both near-shore and pelagic waters, rising coastal nitrogen levels, and widespread increases in mercury and persistent organic pollutants. Most of these perturbations are tied either directly or indirectly to human fossil fuel combustion, fertilizer, and industrial activity. Concentrations are projected to grow in coming decades, with negative impacts on ocean biota and other marine resources.[22] Accidentally consuming small quantities of clean seawater is not harmful, especially if the seawater is taken along with a larger quantity of fresh water. However, drinking seawater to maintain hydration is counterproductive; more water must be excreted to eliminate the salt (via urine) than the amount of water obtained from the seawater itself.[23] The renal system actively regulates sodium chloride in the blood within a very narrow range around 9 g/L (0.9% by weight). In most open waters concentrations vary somewhat around typical values of about 3.5%, far higher than the body can tolerate and most beyond what the kidney can process. A point frequently overlooked , in claims that the kidney can excrete NaCl in Baltic concentrations (2%), is that the gut cannot absorb water at such concentrations, so that there is no benefit in drinking such water. Drinking seawater temporarily increases blood\'s NaCl concentration. This signals the kidney to excrete sodium, but seawater\'s sodium concentration is above the kidney\'s maximum concentrating ability. Eventually the blood\'s sodium concentration rises to toxic levels, removing water from cells and interfering with nerve conduction, ultimately producing fatal seizure and cardiac arrhythmia. Survival manuals consistently advise against drinking seawater.[24] A summary of 163 life raft voyages estimated the risk of death at 39% for those who drank seawater, compared to 3% for those who did not. The effect of seawater intake on rats confirmed the negative effects of drinking seawater when dehydrated.[25] The temptation to drink seawater was greatest for sailors who had expended their supply of fresh water, and were unable to capture enough rainwater for drinking. This frustration was described famously by a line from Samuel Taylor Coleridge\'s The Rime of the Ancient Mariner: Although humans cannot survive on seawater, some people claim that up to two cups a day, mixed with fresh water in a 2:3 ratio, produces no ill effect. The French physician Alain Bombard survived an ocean crossing in a small Zodiak rubber boat using mainly raw fish meat, which contains about 40 percent water (like most living tissues), as well as small amounts of seawater and other provisions harvested from the ocean. His findings were challenged, but an alternative explanation was not given. In his 1948 book, Kon-Tiki, Thor Heyerdahl reported drinking seawater mixed with fresh in a 2:3 ratio during the 1947 expedition.[26] A few years later, another adventurer, William Willis, claimed to have drunk two cups of seawater and one cup of fresh per day for 70 days without ill effect when he lost part of his water supply.[27] During the 18th Century, Richard Russell advocated the practice\'s medical use in the UK, and René Quinton expanded the advocation of the practice other countries, notably France, in the 20th century. Currently, the practice is widely used in Nicaragua and other countries, supposedly taking advantage of the latest medical discoveries. ASTM International has an international standard for artificial seawater: ASTM D1141-98 (Original Standard ASTM D1141-52). It is used in many research testing labs as a reproducible solution for seawater such as tests on corrosion, oil contamination, and detergency evaluation.[29]', '', 'I watched quite a few of their videos a very long time ago, but since then I haven’t really been following along. I happened to stumble across the channel on Friday evening, and this meant there was a lot of catching up to do. I’ve added some of the videos I really enjoyed, but I couldn’t include all of them – there is a lot of good chemistry-related stuff in that channel, and a lot of interesting details about ‘how stuff works’ and/or ‘how we know something’. Even videos about obscure elements you didn’t even know existed may contain fascinating details that turn out to be really quite relevant to your every-day life; did you for example know that due to the material properties of niobium, by adding perhaps 200 grams of this material to a car, a car manufacturer might save in the order of 100 kilograms of steel? Well, I didn’t. Does Mendeleev get too much credit? An interesting ‘walk through the archives’. I agree with the overall assessment; other people came close/had similar ideas, but it’s quite natural for Mendeleev to be associated strongly with the Table; he pushed the idea very hard, and he was not afraid to make detailed predictions which might turn out to be wrong. As noted in (one of) Scerri’s book(/s) on the topic, “it has been estimated that within one hundred years of the introduction of Mendeleev’s famous table of 1869, approximately 700 different versions of the periodic table had been published” – so although the video seems to cover a lot of different versions, it’s really only scratching the surface. I read this book quite some time ago, but back when I did I never blogged it; instead I just added a brief review on goodreads. I remember that the main reason why I decided against blogging it shortly after I’d read it was that the coverage overlapped a great deal with Mladenov’s marine biology text, which I had at that time just read and actually did blog in some detail. I figured if I wanted to blog this book as well I would be well-advised to wait a while, so that I’d at least have forget some of the stuff first – that way blogging the book might end up serving as a review of stuff I’d forgot, rather than as a review of stuff that would still be fresh in my memory and so wouldn’t really be worth reviewing anyway. So now here we are a few months later, and I have come to think it might be a good idea to blog the book. Below I have added some quotes from the first half of the book and some links to topics/people/etc. covered. “Several methods now exist for calculating the rate of plate motion. Most reliable for present-day plate movement are direct observations made using satellites and laser technology. These show that the Atlantic Ocean is growing wider at a rate of between 2 and 4 centimetres per year (about the rate at which fingernails grow), the Indian Ocean is attempting to grow at a similar rate but is being severely hampered by surrounding plate collisions, while the fastest spreading centre is the East Pacific Rise along which ocean crust is being created at rates of around 17 centimetres per year (the rate at which hair grows). […] The Nazca plate has been plunging beneath South America for at least 200 million years – the imposing Andes, the longest mountain chain on Earth, is the result. […] By around 120 million years ago, South America and Africa began to drift apart and the South Atlantic was born. […] sea levels rose higher than at any time during the past billion years, perhaps as much as 350 metres higher than today. Only 18 per cent of the globe was dry land — 82 per cent was under water. These excessively high sea levels were the result of increased spreading activity — new oceans, new ridges, and faster spreading rates all meant that the mid-ocean ridge systems collectively displaced a greater volume of water than ever before. Global warming was far more extreme than today. Temperatures in the ocean rose to around 30°C at the equator and as much as 14°C at the poles. Ocean circulation was very sluggish.” “The land–ocean boundary is known as the shoreline. Seaward of this, all continents are surrounded by a broad, flat continental shelf, typically 10–100 kilometres wide, which slopes very gently (less than one-tenth of a degree) to the shelf edge at a water depth of around 100 metres. Beyond this the continental slope plunges to the deep-ocean floor. The slope is from tens to a few hundred kilometres wide and with a mostly gentle gradient of 3–8 degrees, but locally steeper where it is affected by faulting. The base of slope abuts the abyssal plain — flat, almost featureless expanses between 4 and 6 kilometres deep. The oceans are compartmentalized into abyssal basins separated by submarine mountain ranges and plateaus, which are the result of submarine volcanic outpourings. Those parts of the Earth that are formed of ocean crust are relatively lower, because they are made up of denser rocks — basalts. Those formed of less dense rocks (granites) of the continental crust are relatively higher. Seawater fills in the deeper parts, the ocean basins, to an average depth of around 4 kilometres. In fact, some parts are shallower because the ocean crust is new and still warm — these are the mid-ocean ridges at around 2.5 kilometres — whereas older, cooler crust drags the seafloor down to a depth of over 6 kilometres. […] The seafloor is almost entirely covered with sediment. In places, such as on the flanks of mid-ocean ridges, it is no more than a thin veneer. Elsewhere, along stable continental margins or beneath major deltas where deposition has persisted for millions of years, the accumulated thickness can exceed 15 kilometres. These areas are known as sedimentary basins“. “The super-efficiency of water as a solvent is due to an asymmetrical bonding between hydrogen and oxygen atoms. The resultant water molecule has an angular or kinked shape with weakly charged positive and negative ends, rather like magnetic poles. This polar structure is especially significant when water comes into contact with substances whose elements are held together by the attraction of opposite electrical charges. Such ionic bonding is typical of many salts, such as sodium chloride (common salt) in which a positive sodium ion is attracted to a negative chloride ion. Water molecules infiltrate the solid compound, the positive hydrogen end being attracted to the chloride and the negative oxygen end to the sodium, surrounding and then isolating the individual ions, thereby disaggregating the solid [I should mention that if you’re interested in knowing (much) more this topic, and closely related topics, this book covers these things in great detail – US]. An apparently simple process, but extremely effective. […] Water is a super-solvent, absorbing gases from the atmosphere and extracting salts from the land. About 3 billion tonnes of dissolved chemicals are delivered by rivers to the oceans each year, yet their concentration in seawater has remained much the same for at least several hundreds of millions of years. Some elements remain in seawater for 100 million years, others for only a few hundred, but all are eventually cycled through the rocks. The oceans act as a chemical filter and buffer for planet Earth, control the distribution of temperature, and moderate climate. Inestimable numbers of calories of heat energy are transferred every second from the equator to the poles in ocean currents. But, the ocean configuration also insulates Antarctica and allows the build-up of over 4000 metres of ice and snow above the South Pole. […] Over many aeons, the oceans slowly accumulated dissolved chemical ions (and complex ions) of almost every element present in the crust and atmosphere. Outgassing from the mantle from volcanoes and vents along the mid-ocean ridges contributed a variety of other elements […]\xa0The composition of the first seas was mostly one of freshwater together with some dissolved gases. Today, however, the world ocean contains over 5 trillion tonnes of dissolved salts, and nearly 100 different chemical elements […] If the oceans’ water evaporated completely, the dried residue of salts would be equivalent to a 45-metre-thick layer over the entire planet.” “The average time a single molecule of water remains in any one reservoir varies enormously. It may survive only one night as dew, up to a week in the atmosphere or as part of an organism, two weeks in rivers, and up to a year or more in soils and wetlands. Residence times in the oceans are generally over 4000 years, and water may remain in ice caps for tens of thousands of years. Although the ocean appears to be in a steady state, in which both the relative proportion and amounts of dissolved elements per unit volume are nearly constant, this is achieved by a process of chemical cycles and sinks. The input of elements from mantle outgassing and continental runoff must be exactly balanced by their removal from the oceans into temporary or permanent sinks. The principal sink is the sediment and the principal agent removing ions from solution is biological. […] The residence times of different elements vary enormously from tens of millions of years for chloride and sodium, to a few hundred years only for manganese, aluminium, and iron. […] individual water molecules have cycled through the atmosphere (or mantle) and returned to the seas more than a million times since the world ocean formed.” “Because of its polar structure and hydrogen bonding between individual molecules, water has both a high capacity for storing large amounts of heat and one of the highest specific heat values of all known substances. This means that water can absorb (or release) large amounts of heat energy while changing relatively little in temperature. Beach sand, by contrast, has a specific heat five times lower than water, which explains why, on sunny days, beaches soon become too hot to stand on with bare feet while the sea remains pleasantly cool. Solar radiation is the dominant source of heat energy for the ocean and for the Earth as a whole. The differential in solar input with latitude is the main driver for atmospheric winds and ocean currents. Both winds and especially currents are the prime means of mitigating the polar–tropical heat imbalance, so that the polar oceans do not freeze solid, nor the equatorial oceans gently simmer. For example, the Gulf Stream transports some 550 trillion calories from the Caribbean Sea across the North Atlantic each second, and so moderates the climate of north-western Europe.” “[W]hy is [the sea] mostly blue? The sunlight incident on the sea has a full spectrum of wavelengths, including the rainbow of colours that make up the visible spectrum […] The longer wavelengths (red) and very short (ultraviolet) are preferentially absorbed by water, rapidly leaving near-monochromatic blue light to penetrate furthest before it too is absorbed. The dominant hue that is backscattered, therefore, is blue. In coastal waters, suspended sediment and dissolved organic debris absorb additional short wavelengths (blue) resulting in a greener hue. […] The speed of sound in seawater is about 1500 metres per second, almost five times that in air. It is even faster where the water is denser, warmer, or more salty and shows a slow but steady increase with depth (related to increasing water pressure).” “From top to bottom, the ocean is organized into layers, in which the physical and chemical properties of the ocean – salinity, temperature, density, and light penetration – show strong vertical segregation. […] Almost all properties of the ocean vary in some way with depth. Light penetration is attenuated by absorption and scattering, giving an upper photic and lower aphotic zone, with a more or less well-defined twilight region in between. Absorption of incoming solar energy also preferentially heats the surface waters, although with marked variations between latitudes and seasons. This results in a warm surface layer, a transition layer (the thermocline) through which the temperature decreases rapidly with depth, and a cold deep homogeneous zone reaching to the ocean floor. Exactly the same broad three-fold layering is true for salinity, except that salinity increases with depth — through the halocline. The density of seawater is controlled by its temperature, salinity, and pressure, such that colder, saltier, and deeper waters are all more dense. A rapid density change, known as the pycnocline, is therefore found at approximately the same depth as the thermocline and halocline. This varies from about 10 to 500 metres, and is often completely absent at the highest latitudes. Winds and waves thoroughly stir and mix the upper layers of the ocean, even destroying the layered structure during major storms, but barely touch the more stable, deep waters.” Below I have added some quotes from the chapters of the book I did not cover in my first post, as well as some supplementary links. “Haemoglobin is of crucial biological importance; it is also easy to obtain safely in large quantities from donated blood. These properties have resulted in its becoming the most studied protein in human history. Haemoglobin played a key role in the history of our understanding of all proteins, and indeed the science of biochemistry itself. […] Oxygen transport defines the primary biological function of blood. […] Oxygen gas consists of two atoms of oxygen bound together to form a symmetrical molecule. However, oxygen cannot be transported in the plasma alone. This is because water is very poor at dissolving oxygen. Haemoglobin’s primary function is to increase this solubility; it does this by binding the oxygen gas on to the iron in its haem group. Every haem can bind one oxygen molecule, increasing the amount of oxygen able to dissolve in the blood.” “An iron atom can exist in a number of different forms depending on how many electrons it has in its atomic orbitals. In its ferrous (iron II) state iron can bind oxygen readily. The haemoglobin protein has therefore evolved to stabilize its haem iron cofactor in this ferrous state. The result is that over fifty times as much oxygen is stored inside the confines of the red blood cell compared to outside in the watery plasma. However, using iron to bind oxygen comes at a cost. Iron (II) can readily lose one of its electrons to the bound oxygen, a process called ‘oxidation’. So the same form of iron that can bind oxygen avidly (ferrous) also readily reacts with that same oxygen forming an unreactive iron III state, called ‘ferric’. […] The complex structure of the protein haemoglobin is required to protect the ferrous iron from oxidizing. The haem iron is held in a precise configuration within the protein. Specific amino acids are ideally positioned to stabilize the iron–oxygen bond and prevent it from oxidizing. […] the iron stays ferrous despite the presence of the nearby oxygen. Having evolved over many hundreds of millions of years, this stability is very difficult for chemists to mimic in the laboratory. This is one reason why, desirable as it might be in terms of cost and convenience, it is not currently possible to replace blood transfusions with a simple small chemical iron oxygen carrier.” “Given the success of the haem iron and globin combination in haemoglobin, it is no surprise that organisms have used this basic biochemical architecture for a variety of purposes throughout evolution, not just oxygen transport in blood. One example is the protein myoglobin. This protein resides inside animal cells; in the human it is found in the heart and skeletal muscle. […] Myoglobin has multiple functions. Its primary role is as an aid to oxygen diffusion. Whereas haemoglobin transports oxygen from the lung to the cell, myoglobin transports it once it is inside the cell. As oxygen is so poorly soluble in water, having a chain of molecules inside the cell that can bind and release oxygen rapidly significantly decreases the time it takes the gas to get from the blood capillary to the part of the cell—the mitochondria—where it is needed. […] Myoglobin can also act as an emergency oxygen backup store. In humans this is trivial and of questionable importance. Not so in diving mammals such as whales and dolphins that have as much as thirty times the myoglobin content of the terrestrial equivalent; indeed those mammals that dive for the longest duration have the most myoglobin. […] The third known function of myoglobin is to protect the muscle cells from damage by nitric oxide gas.” “The heart is the organ that pumps blood around the body. If the heart stops functioning, blood does not flow. The driving force for this flow is the pressure difference between the arterial blood leaving the heart and the returning venous blood. The decreasing pressure in the venous side explains the need for unidirectional valves within veins to prevent the blood flowing in the wrong direction. Without them the return of the blood through the veins to the heart would be too slow, especially when standing up, when the venous pressure struggles to overcome gravity. […] normal [blood pressure] ranges rise slowly with age. […] high resistance in the arterial circulation at higher blood pressures [places] additional strain on the left ventricle. If the heart is weak, it may fail to achieve the extra force required to pump against this resistance, resulting in heart failure. […] in everyday life, a low blood pressure is rarely of concern. Indeed, it can be a sign of fitness as elite athletes have a much lower resting blood pressure than the rest of the population. […] the effect of exercise training is to thicken the muscles in the walls of the heart and enlarge the chambers. This enables more blood to be pumped per beat during intense exercise. The consequence of this extra efficiency is that when an athlete is resting—and therefore needs no more oxygen than a more sedentary person—the heart rate and blood pressure are lower than average. Most people’s experience of hypotension will be reflected by dizzy spells and lack of balance, especially when moving quickly to an upright position. This is because more blood pools in the legs when you stand up, meaning there is less blood for the heart to pump. The immediate effect should be for the heart to beat faster to restore the pressure. If there is a delay, the decrease in pressure can decrease the blood flow to the brain and cause dizziness; in extreme cases this can lead to fainting.” “If hypertension is persistent, patients are most likely to be treated with drugs that target specific pathways that the body uses to control blood pressure. For example angiotensin is a protein that can trigger secretion of the hormone aldosterone from the adrenal gland. In its active form angiotensin can directly constrict blood vessels, while aldosterone enhances salt and water retention, so raising blood volume. Both these effects increase blood pressure. Angiotensin is converted into its active form by an enzyme called ‘Angiotensin Converting Enzyme’ (ACE). An ACE inhibitor drug prevents this activity, keeping angiotensin in its inactive form; this will therefore drop the patient’s blood pressure. […] The metal calcium controls many processes in the body. Its entry into muscle cells triggers muscle contraction. Preventing this entry can therefore reduce the force of contraction of the heart and the ability of arteries to constrict. Both of these will have the effect of decreasing blood pressure. Calcium enters muscle cells via specific protein-based channels. Drugs that block these channels (calcium channel blockers) are therefore highly effective at treating hypertension.” “Autoregulation is a homeostatic process designed to ensure that blood flow remains constant [in settings where constancy is desirable]. However, there are many occasions when an organism actively requires a change in blood flow. It is relatively easy to imagine what these are. In the short term, blood supplies oxygen and nutrients. When these are used up rapidly, or their supply becomes limited, the response will be to increase blood flow. The most obvious example is the twenty-fold increase in oxygen and glucose consumption that occurs in skeletal muscle during exercise when compared to rest. If there were no accompanying increase in blood flow to the muscle the oxygen supply would soon run out. […] There are hundreds of molecules known that have the ability to increase or decrease blood flow […] The surface of all blood vessels is lined by a thin layer of cells, the ‘endothelium’. Endothelial cells form a barrier between the blood and the surrounding tissue, controlling access of materials into and out of the blood. For example white blood cells can enter or leave the circulation via interacting with the endothelium; this is the route by which neutrophils migrate from the blood to the site of tissue damage or bacterial/viral attack as part of the innate immune response. However, the endothelium is not just a selective barrier. It also plays an active role in blood physiology and biochemistry.” “Two major issues [related to blood transfusions] remained at the end of the 19th century: the problem of clotting, which all were aware of; and the problem of blood group incompatbility, which no one had the slightest idea even existed. […] For blood transfusions to ever make a recovery the key issues of blood clotting and adverse side effects needed to be resolved. In 1875 the Swedish biochemist Olof Hammarsten showed that adding calcium accelerated the rate of blood clotting (we now know the mechanism for this is that key enzymes in blood platelets that catalyse fibrin formation require calcium for their function). It therefore made sense to use chemicals that bind calcium to try to prevent clotting. Calcium ions are positively charged; adding negatively charged ions such as oxalate and citrate neutralized the calcium, preventing its clot-promoting action. […] At the same time as anticoagulants were being discovered, the reason why some blood transfusions failed even when there were no clots was becoming clear. It had been shown that animal blood given to humans tended to clump together or agglutinate, eventually bursting and releasing free haemoglobin and causing kidney damage. In the early 1900s, working in Vienna, Karl Landsteiner showed the same effect could occur with human-to-human transfusion. The trick was the ability to separate blood cells from serum. This enabled mixing blood cells from a variety of donors with plasma from a variety of participants. Using his laboratory staff as subjects, Landsteiner showed that only some combinations caused the agglutination reaction. Some donor cells (now known as type O) never clumped. Others clumped depending on the nature of the plasma in a reproducible manner. A careful study of Landsteiner’s results revealed the ABO blood type distinctions […]. Versions of these agglutination tests still form the basis of checking transfused blood today.” “No blood product can be made completely sterile, no matter how carefully it is processed. The best that can be done is to ensure that no new bacteria or viruses are added during the purification, storage, and transportation processes. Nothing can be done to inactivate any viruses that are already present in the donor’s blood, for the harsh treatments necessary to do this would inevitably damage the viability of the product or be prohibitively expensive to implement on the industrial scale that the blood market has become. […] In the 1980s over half the US haemophiliac population was HIV positive.” “Three fundamentally different ways have been attempted to replace red blood cell transfusions. The first uses a completely chemical approach and makes use of perfluorocarbons, inert chemicals that, in liquid form, can dissolve gasses without reacting with them. […] Perfluorocarbons can dissolve oxygen much more effectively than water. […] The problem with their use as a blood substitute is that the amount of oxygen dissolved in these solutions is linear with increasing pressure. This means that the solution lacks the advantages of the sigmoidal binding curve of haemoglobin, which has evolved to maximize the amount of oxygen captured from the limited fraction found in air (20 per cent oxygen). However, to deliver the same amount of oxygen as haemoglobin, patients using the less efficient perfluorocarbons in their blood need to breathe gas that is almost 100 per cent pure oxygen […]; this restricts the use of these compounds. […] The second type of blood substitute makes use of haemoglobin biology. Initial attempts used purified haemoglobin itself. […] there is no haemoglobin-based blood substitute in general use today […] The problem for the lack of uptake is not that blood substitutes cannot replace red blood cell function. A variety of products have been shown to stay in the vasculature for several days, provide volume support, and deliver oxygen. However, they have suffered due to adverse side effects, most notably cardiac complications. […] In nature the plasma proteins haptoglobin and haemopexin bind and detoxify any free haemoglobin and haem released from red blood cells. The challenge for blood substitute research is to mimic these effects in a product that can still deliver oxygen. […] Despite ongoing research, these problems may prove to be insurmountable. There is therefore interest in a third approach. This is to grow artificial red blood cells using stem cell technology.” “[P]roteins are the most abundant molecules in the body except for water. […] Proteins make up half the dry weight of a cell whereas DNA and RNA make up only 3 per cent and 20 per cent respectively. […] The approximately 20,000 protein-coding genes in the human genome can, by alternative splicing, multiple translation starts, and post-translational modifications, produce over 1,000,000 different proteins, collectively called ‘the proteome‘. It is the size of the proteome and not the genome that defines the complexity of an organism. […] For simple organisms, such as viruses, all the proteins coded by their genome can be deduced from its sequence and these comprise the viral proteome. However for higher organisms the complete proteome is far larger than the genome […] For these organisms not all the proteins coded by the genome are found in any one tissue at any one time and therefore a partial proteome is usually studied. What are of interest are those proteins that are expressed in specific cell types under defined conditions.” “Enzymes are proteins that catalyze or alter the rate of chemical reactions […] Enzymes can speed up reactions […] but they can also slow some reactions down. Proteins play a number of other critical roles. They are involved in maintaining cell shape and providing structural support to connective tissues like cartilage and bone. Specialized proteins such as actin and myosin are required [for] muscular movement. Other proteins act as ‘messengers’ relaying signals to regulate and coordinate various cell processes, e.g. the hormone insulin. Yet another class of protein is the antibodies, produced in response to foreign agents such as bacteria, fungi, and viruses.” “Proteins are composed of amino acids. Amino acids are organic compounds with […] an amino group […] and a carboxyl group […] In addition, amino acids carry various side chains that give them their individual functions. The twenty-two amino acids found in proteins are called proteinogenic […] but other amino acids exist that are non-protein functioning. […] A peptide bond is formed between two amino acids by the removal of a water molecule. […] each individual unit in a peptide or protein is known as an amino acid residue. […] Chains of less than 50-70 amino acid residues are known as peptides or polypeptides and >50-70 as proteins, although many proteins are composed of more than one polypeptide chain. […] Proteins are macromolecules consisting of one or more strings of amino acids folded into highly specific 3D-structures. Each amino acid has a different size and carries a different side group. It is the nature of the different side groups that facilitates the correct folding of a polypeptide chain into a functional tertiary protein structure.” “Atoms scatter the waves of X-rays mainly through their electrons, thus forming secondary or reflected waves. The pattern of X-rays diffracted by the atoms in the protein can be captured on a photographic plate or an image sensor such as a charge coupled device placed behind the crystal. The pattern and relative intensity of the spots on the diffraction image are then used to calculate the arrangement of atoms in the original protein. Complex data processing is required to convert the series of 2D diffraction or scatter patterns into a 3D image of the protein. […] The continued success and significance of this technique for molecular biology is witnessed by the fact that almost 100,000 structures of biological molecules have been determined this way, of which most are proteins.” “The number of proteins in higher organisms far exceeds the number of known coding genes. The fact that many proteins carry out multiple functions but in a regulated manner is one way a complex proteome arises without increasing the number of genes. Proteins that performed a single role in the ancestral organism have acquired extra and often disparate functions through evolution. […] The active site of an enzyme employed in catalysis is only a small part of the protein, leaving spare capacity for acquiring a second function. […] The glycolytic pathway is involved in the breakdown of sugars such as glucose to release energy. Many of the highly conserved and ancient enzymes from this pathway have developed secondary or ‘moonlighting’ functions. Proteins often change their location in the cell in order to perform a ‘second job’. […] The limited size of the genome may not be the only evolutionary pressure for proteins to moonlight. Combining two functions in one protein can have the advantage of coordinating multiple activities in a cell, enabling it to respond quickly to changes in the environment without the need for lengthy transcription and translational processes.” “Post-translational modifications (PTMs) […] is [a] process that can modify the role of a protein by addition of chemical groups to amino acids in the peptide chain after translation. Addition of phosphate groups (phosphorylation), for example, is a common mechanism for activating or deactivating an enzyme. Other common PTMs include addition of acetyl groups (acetylation), glucose (glucosylation), or methyl groups (methylation). […] Some additions are reversible, facilitating the switching between active and inactive states, and others are irreversible such as marking a protein for destruction by ubiquitin. [The difference between reversible and irreversible modifications can be quite important in pharmacology, and if you’re curious to know more about these topics Coleman’s drug metabolism text provide great coverage of related topics – US.] Diseases caused by malfunction of these modifications highlight the importance of PTMs. […] in diabetes [h]igh blood glucose lead to unwanted glocosylation of proteins. At the high glucose concentrations associated with diabetes, an unwanted irreversible chemical reaction binds the gllucose to amino acid residues such as lysines exposed on the protein surface. The glucosylated proteins then behave badly, cross-linking themselves to the extracellular matrix. This is particularly dangerous in the kidney where it decreases function and can lead to renal failure.” “Twenty thousand protein-coding genes make up the human genome but for any given cell only about half of these are expressed. […] Many genes get switched off during differentiation and a major mechanism for this is epigenetics. […] an epigenetic trait […] is ‘a stably heritable phenotype resulting from changes in the chromosome without alterations in the DNA sequence’. Epigenetics involves the chemical alteration of DNA by methyl or other small molecular groups to affect the accessibility of a gene by the transcription machinery […] Epigenetics can […] act on gene expression without affecting the stability of the genetic code by modifying the DNA, the histones in chromatin, or a whole chromosome. […] Epigenetic signatures are not only passed on to somatic daughter cells but they can also be transferred through the germline to the offspring. […] At first the evidence appeared circumstantial but more recent studies have provided direct proof of epigenetic changes involving gene methylation being inherited. Rodent models have provided mechanistic evidence. […] the importance of epigenetics in development is highlighted by the fact that low dietary folate, a nutrient essential for methylation, has been linked to higher risk of birth defects in the offspring.” […on the other hand, well…] “The cell cycle is divided into phases […] Transition from G1 into S phase commits the cell to division and is therefore a very tightly controlled restriction point. Withdrawal of growth factors, insufficient nucleotides, or energy to complete DNA replication, or even a damaged template DNA, would compromise the process. Problems are therefore detected and the cell cycle halted by cell cycle inhibitors before the cell has committed to DNA duplication. […] The cell cycle inhibitors inactive the kinases that promote transition through the phases, thus halting the cell cycle. […] The cell cycle can also be paused in S phase to allow time for DNA repairs to be carried out before cell division. The consequences of uncontrolled cell division are so catastrophic that evolution has provided complex checks and balances to maintain fidelity. The price of failure is apoptosis […] 50 to 70 billion cells die every day in a human adult by the controlled molecular process of apoptosis.” “There are many diseases that arise because a particular protein is either absent or a faulty protein is produced. Administering a correct version of that protein can treat these patients. The first commercially available recombinant protein to be produced for medical use was human insulin to treat diabetes mellitus. […] (FDA) approved the recombinant insulin for clinical use in 1982. Since then over 300 protein-based recombinant pharmaceuticals have been licensed by the FDA and the European Medicines Agency (EMA) […], and many more are undergoing clinical trials. Therapeutic proteins can be produced in bacterial cells but more often mammalian cells such as the Chinese hamster ovary cell line and human fibroblasts are used as these hosts are better able to produce fully functional human protein. However, using mammalian cells is extremely expensive and an alternative is to use live animals or plants. This is called molecular pharming and is an innovative way of producing large amounts of protein relatively cheaply. […] In plant pharming, tobacco, rice, maize, potato, carrots, and tomatoes have all been used to produce therapeutic proteins. […] [One] class of proteins that can be engineered using gene-cloning technology is therapeutic antibodies. […] Therapeutic antibodies are designed to be monoclonal, that is, they are engineered so that they are specific for a particular antigen to which they bind, to block the antigen’s harmful effects. […] Monoclonal antibodies are at the forefront of biological therapeutics as they are highly specific and tend not to induce major side effects.” “In gene therapy the aim is to restore the function of a faulty gene by introducing a correct version of that gene. […] a cloned gene is transferred into the cells of a patient. Once inside the cell, the protein encoded by the gene is produced and the defect is corrected. […] there are major hurdles to be overcome for gene therapy to be effective. One is the gene construct has to be delivered to the diseased cells or tissues. This can often be difficult […] Mammalian cells […] have complex mechanisms that have evolved to prevent unwanted material such as foreign DNA getting in. Second, introduction of any genetic construct is likely to trigger the patient’s immune response, which can be fatal […] once delivered, expression of the gene product has to be sustained to be effective. One approach to delivering genes to the cells is to use genetically engineered viruses constructed so that most of the viral genome is deleted […] Once inside the cell, some viral vectors such as the retroviruses integrate into the host genome […]. This is an advantage as it provides long-lasting expression of the gene product. However, it also poses a safety risk, as there is little control over where the viral vector will insert into the patient’s genome. If the insertion occurs within a coding gene, this may inactivate gene function. If it integrates close to transcriptional start sites, where promoters and enhancer sequences are located, inappropriate gene expression can occur. This was observed in early gene therapy trials [where some patients who got this type of treatment developed cancer as a result of it. A few more details here – US] […] Adeno-associated viruses (AAVs) […] are often used in gene therapy applications as they are non-infectious, induce only a minimal immune response, and can be engineered to integrate into the host genome […] However, AAVs can only carry a small gene insert and so are limited to use with genes that are of a small size. […] An alternative delivery system to viruses is to package the DNA into liposomes that are then taken up by the cells. This is safer than using viruses as liposomes do not integrate into the host genome and are not very immunogenic. However, liposome uptake by the cells can be less efficient, resulting in lower expression of the gene.” “This is a great publication, considering the format. These authors in my opinion managed to get quite close to what I’d consider to be ‘the ideal level of coverage’ for books of this nature.” The above was what I wrote in my short goodreads review of the book. In this post I’ve added some quotes from the first chapters of the book and some links to topics covered. “Once the base-pairing double helical structure of DNA was understood it became apparent that by holding and preserving the genetic code DNA is the source of heredity. The heritable material must also be capable of faithful duplication every time a cell divides. The DNA molecule is ideal for this. […] The effort then concentrated on how the instructions held by the DNA were translated into the choice of the twenty different amino acids that make up proteins. […] George Gamov [yes, that George Gamov! – US] made the suggestion that information held in the four bases of DNA (A, T, C, G) must be read as triplets, called codons. Each codon, made up of three nucleotides, codes for one amino acid or a ‘start’ or ‘stop’ signal. This information, which determines an organism’s biochemical makeup, is known as the genetic code. An encryption based on three nucleotides means that there are sixty-four possible three-letter combinations. But there are only twenty amino acids that are universal. […] some amino acids can be coded for by more than one codon.” “The mechanism of gene expression whereby DNA transfers its information into proteins was determined in the early 1960s by Sydney Brenner, Francois Jacob, and Matthew Meselson. […] Francis Crick proposed in 1958 that information flowed in one direction only: from DNA to RNA to protein. This was called the ‘Central Dogma‘ and describes how DNA is transcribed into RNA, which then acts as a messenger carrying the information to be translated into proteins. Thus the flow of information goes from DNA to RNA to proteins and information can never be transferred back from protein to nucleic acid. DNA can be copied into more DNA (replication) or into RNA (transcription) but only the information in mRNA [messenger RNA] can be translated into protein”. “The genome is the entire DNA contained within the forty-six chromosomes located in the nucleus of each human somatic (body) cell. […] The complete human genome is composed of over 3 billion bases and contain approximately 20,000 genes that code for proteins. This is much lower than earlier estimates of 80,000 to 140,000 and astonished the scientific community when revealed through human genome sequencing. Equally surprising was the finding that genomes of much simpler organisms sequenced at the same time contained a higher number of protein-coding genes than humans. […] It is now clear that the size of the genome does not correspond with the number of protein-coding genes, and these do not determine the complexity of an organism. Protein-coding genes can be viewed as ‘transcription units’. These are made up of sequences called exons that code for amino acids, and separated by by non-coding sequences called introns. Associated with these are additional sequences termed promoters and enhancers that control the expression of that gene.” “Some sections of the human genome code for RNA molecules that do not have the capacity to produce proteins. […] it is now becoming apparent that many play a role in controlling gene expression. Despite the importance of proteins, less than 1.5 per cent of the genome is made up of exon sequences. A recent estimate is that about 80 per cent of the genome is transcribed or involved in regulatory functions with the rest mainly composed of repetitive sequences. […] Satellite DNA […] is a short sequence repeated many thousands of times in tandem […] A second type of repetitive DNA is the telomere sequence. […] Their role is to prevent chromosomes from shortening during DNA replication […] Repetitive sequences can also be found distributed or interspersed throughout the genome. These repeats have the ability to move around the genome and are referred to as mobile or transposable DNA. […] Such movements can be harmful sometimes as gene sequences can be disrupted causing disease. […] The vast majority of transposable sequences are no longer able to move around and are considered to be ‘silent’. However, these movements have contributed, over evolutionary time, to the organization and evolution of the genome, by creating new or modified genes leading to the production of proteins with novel functions.” “A very important property of DNA is that it can make an accurate copy of itself. This is necessary since cells die during the normal wear and tear of tissues and need to be replenished. […] DNA replication is a highly accurate process with an error occurring every 10,000 to 1 million bases in human DNA. This low frequency is because the DNA polymerases carry a proofreading function. If an incorrect nucleotide is incorporated during DNA synthesis, the polymerase detects the error and excises the incorrect base. Following excision, the polymerase reinserts the correct base and replication continues. Any errors that are not corrected through proofreading are repaired by an alternative mismatch repair mechanism. In some instances, proofreading and repair mechanisms fail to correct errors. These become permanent mutations after the next cell division cycle as they are no longer recognized as errors and are therefore propagated each time the DNA replicates.” “DNA sequencing identifies the precise linear order of the nucleotide bases A, C, G, T, in a DNA fragment. It is possible to sequence individual genes, segments of a genome, or whole genomes. Sequencing information is fundamental in helping us understand how our genome is structured and how it functions. […] The Human Genome Project, which used Sanger sequencing, took ten years to sequence and cost 3 billion US dollars. Using high-throughput sequencing, the entire human genome can now be sequenced in a few days at a cost of 3,000 US dollars. These costs are continuing to fall, making it more feasible to sequence whole genomes. The human genome sequence published in 2003 was built from DNA pooled from a number of donors to generate a ‘reference’ or composite genome. However, the genome of each individual is unique and so in 2005 the Personal Genome Project was launched in the USA aiming to sequence and analyse the genomes of 100,000 volunteers across the world. Soon after, similar projects followed in Canada and Korea and, in 2013, in the UK. […] To store and analyze the huge amounts of data, computational systems have developed in parallel. This branch of biology, called bioinformatics, has become an extremely important collaborative research area for molecular biologists drawing on the expertise of computer scientists, mathematicians, and statisticians.” “[T]he structure of RNA differs from DNA in three fundamental ways. First, the sugar is a ribose, whereas in DNA it is a deoxyribose. Secondly, in RNA the nucleotide bases are A, G, C, and U (uracil) instead of A, G, C, and T. […] Thirdly, RNA is a single-stranded molecule unlike double-stranded DNA. It is not helical in shape but can fold to form a hairpin or stem-loop structure by base-pairing between complementary regions within the same RNA molecule. These two-dimensional secondary structures can further fold to form complex three-dimensional, tertiary structures. An RNA molecule is able to interact not only with itself, but also with other RNAs, with DNA, and with proteins. These interactions, and the variety of conformations that RNAs can adopt, enables them to carry out a wide range of functions. […] RNAs can influence many normal cellular and disease processes by regulating gene expression. RNA interference […] is one of the main ways in which gene expression is regulated.” “Translation of the mRNA to a protein takes place in the cell cytoplasm on ribosomes. Ribosomes are cellular structures made up primarily of rRNA and proteins. At the ribosomes, the mRNA is decoded to produce a specific protein according to the rules defined by the genetic code. The correct amino acids are brought to the mRNA at the ribosomes by molecules called transfer RNAs (tRNAs). […] At the start of translation, a tRNA binds to the mRNA at the start codon AUG. This is followed by the binding of a second tRNA matching the adjacent mRNA codon. The two neighbouring amino acids linked to the tRNAs are joined together by a chemical bond called the peptide bond. Once the peptide bond forms, the first tRNA detaches leaving its amino acid behind. The ribosome then moves one codon along the mRNA and a third tRNA binds. In this way, tRNAs sequentially bind to the mRNA as the ribosome moves from codon to codon. Each time a tRNA molecule binds, the linked amino acid is transferred to the growing amino acid chain. Thus the mRNA sequence is translated into a chain of amino acids connected by peptide bonds to produce a polypeptide chain. Translation is terminated when the ribosome encounters a stop codon […]. After translation, the chain is folded and very often modified by the addition of sugar or other molecules to produce fully functional proteins.” “The naturally occurring RNAi pathway is now extensively exploited in the laboratory to study the function of genes. It is possible to design synthetic siRNA molecules with a sequence complementary to the gene under study. These double-stranded RNA molecules are then introduced into the cell by special techniques to temporarily knock down the expression of that gene. By studying the phenotypic effects of this severe reduction of gene expression, the function of that gene can be identified. Synthetic siRNA molecules also have the potential to be used to treat diseases. If a disease is caused or enhanced by a particular gene product, then siRNAs can be designed against that gene to silence its expression. This prevents the protein which drives the disease from being produced. […] One of the major challenges to the use of RNAi as therapy is directing siRNA to the specific cells in which gene silencing is required. If released directly into the bloodstream, enzymes in the bloodstream degrade siRNAs. […] Other problems are that siRNAs can stimulate the body’s immune response and can produce off-target effects by silencing RNA molecules other than those against which they were specifically designed. […] considerable attention is currently focused on designing carrier molecules that can transport siRNA through the bloodstream to the diseased cell.” “Both Northern blotting and RT-PCR enable the expression of one or a few genes to be measured simultaneously. In contrast, the technique of microarrays allows gene expression to be measured across the full genome of an organism in a single step. This massive scale genome analysis technique is very useful when comparing gene expression profiles between two samples. […] This can identify gene subsets that are under- or over-expressed in one sample relative to the second sample to which it is compared.” “[C]oral reefs occupy a very small proportion of the planet’s surface – about 284,000 square kilometres – roughly equivalent to the size of Italy [yet they] are home to an incredibly diversity of marine organisms – about a quarter of all marine species […]. Coral reef systems provide food for hundreds of millions of people, with about 10 per cent of all fish consumed globally caught on coral reefs. […] Reef-building corals thrive best at sea temperatures above about 23°C and few exist where sea temperatures fall below 18°C for significant periods of time. Thus coral reefs are absent at tropical latitudes where upwelling of cold seawater occurs, such as the west coasts of South America and Africa. […] they are generally restricted to areas of clear water less than about 50 metres deep. Reef-building corals are very intolerant of any freshening of seawater […] and so do not occur in areas exposed to intermittent influxes of freshwater, such as near the mouths of rivers, or in areas where there are high amounts of rainfall run-off. This is why coral reefs are absent along much of the tropical Atlantic coast of South America, which is exposed to freshwater discharge from the Amazon and Orinoco Rivers. Finally, reef-building corals flourish best in areas with moderate to high wave action, which keeps the seawater well aerated […]. Spectacular and productive coral reef systems have developed in those parts of the Global Ocean where this special combination of physical conditions converges […] Each colony consists of thousands of individual animals called polyps […] all reef-building corals have entered into an intimate relationship with plant cells. The tissues lining the inside of the tentacles and stomach cavity of the polyps are packed with photosynthetic cells called zooxanthellae, which are photosynthetic dinoflagellates […] Depending on the species, corals receive anything from about 50 per cent to 95 per cent of their food from their zooxanthellae. […] Healthy coral reefs are very productive marine systems. This is in stark contrast to the nutrient-poor and unproductive tropical waters adjacent to reefs. Coral reefs are, in general, roughly one hundred times more productive than the surrounding environment”. “Overfishing constitutes a significant threat to coral reefs at this time. About an eighth of the world’s population – roughly 875 million people – live within 100 kilometres of a coral reef. Most of the people live in developing countries and island nations and depend greatly on fish obtained from coral reefs as a food source. […] Some of the fishing practices are very harmful. Once the large fish are removed from a coral reef, it becomes increasingly more difficult to make a living harvesting the more elusive and lower-value smaller fish that remain. Fishers thus resort to more destructive techniques such as dynamiting parts of the reef and scooping up the dead and stunned fish that float to the surface. People capturing fish for the tropical aquarium trade will often poison parts of the reef with sodium cyanide which paralyses the fish, making them easier to catch. An unfortunate side effect of this practice is that the poison kills corals. […] Coral reefs have only been seriously studied since the 1970s, which in most cases was well after human impacts had commenced. This makes it difficult to define what might actually constitute a ‘natural’ and healthy coral reef system, as would have existed prior to extensive human impacts.” “Mangrove is a collective term applied to a diverse group of trees and scrubs that colonize protected muddy intertidal areas in tropical and subtropical regions, creating mangrove forests […] Mangroves are of great importance from a human perspective. The sheltered waters of a mangrove forest provide important nursery areas for juvenile fish, crabs, and shrimp. Many commercial fisheries depend on the existence of healthy mangrove forests, including blue crab, shrimp, spiny lobster, and mullet fisheries. Mangrove forests also stabilize the foreshore and protect the adjacent land from erosion, particularly from the effects of large storms and tsunamis. They also act as biological filters by removing excess nutrients and trapping sediment from land run-off before it enters the coastal environment, thereby protecting other habitats such as seagrass meadows and coral reefs. […] [However] mangrove forests are disappearing rapidly. In a twenty-year period between 1980 and 2000 the area of mangrove forest globally declined from around 20 million hectares to below 15 million hectares. In some specific regions the rate of mangrove loss is truly alarming. For example, Puerto Rico lost about 89 per cent of its mangrove forests between 1930 and 1985, while the southern part of India lost about 96 per cent of its mangroves between 1911 and 1989.” “[A]bout 80 per cent of the entire volume of the Global Ocean, or roughly one billion cubic kilometres, consists of seawater with depths greater than 1,000 metres […] The deep ocean is a permanently dark environment devoid of sunlight, the last remnants of which cannot penetrate much beyond 200 metres in most parts of the Global Ocean, and no further than 800 metres or so in even the clearest oceanic waters. The only light present in the deep ocean is of biological origin […] Except in a few very isolated places, the deep ocean is a permanently cold environment, with sea temperatures ranging from about 2° to 4°C. […] Since there is no sunlight, there is no plant life, and thus no primary production of organic matter by photosynthesis. The base of the food chain in the deep ocean consists mostly of a ‘rain’ of small particles of organic material sinking down through the water column from the sunlit surface waters of the ocean. This reasonably constant rain of organic material is supplemented by the bodies of large fish and marine mammals that sink more rapidly to the bottom following death, and which provide sporadic feasts for deep-ocean bottom dwellers. […] Since food is a scarce commodity for deep-ocean fish, full advantage must be taken of every meal encountered. This has resulted in a number of interesting adaptations. Compared to fish in the shallow ocean, many deep-ocean fish have very large mouths capable of opening very wide, and often equipped with numerous long, sharp, inward-pointing teeth. […] These fish can capture and swallow whole prey larger than themselves so as not to pass up a rare meal simply because of its size. These fish also have greatly extensible stomachs to accommodate such meals.” “In the pelagic environment of the deep ocean, animals must be able to keep themselves within an appropriate depth range without using up energy in their food-poor habitat. This is often achieved by reducing the overall density of the animal to that of seawater so that it is neutrally buoyant. Thus the tissues and bones of deep-sea fish are often rather soft and watery. […]\xa0There is evidence that deep-ocean organisms have developed biochemical adaptations to maintain the functionality of their cell membranes under pressure, including adjusting the kinds of lipid molecules present in membranes to retain membrane fluidity under high pressure. High pressures also affect protein molecules, often preventing them from folding up into the correct shapes for them to function as efficient metabolic enzymes. There is evidence that deep-ocean animals have evolved pressure-resistant variants of common enzymes that mitigate this problem. […] The pattern of species diversity of the deep-ocean benthos appears to differ from that of other marine communities, which are typically dominated by a small number of abundant and highly visible species which overshadow the presence of a large number of rarer and less obvious species which are also present. In the deep-ocean benthic community, in contrast, no one group of species tends to dominate, and the community consists of a high number of different species all occurring in low abundance. […] In general, species diversity increases with the size of a habitat – the larger the area of a habitat, the more species that have developed ways to successfully live in that habitat. Since the deep-ocean bottom is the largest single habitat on the planet, it follows that species diversity would be expected to be high.” “Seamounts represent a special kind of biological hotspot in the deep ocean. […] In contrast to the surrounding flat, soft-bottomed abyssal plains, seamounts provide a complex rocky platform that supports an abundance of organisms that are distinct from the surrounding deep-ocean benthos. […] Seamounts support a great diversity of fish species […] This [has] triggered the creation of new deep-ocean fisheries focused on seamounts. […] [However these species are generally] very slow-growing and long-lived and mature at a late age, and thus have a low reproductive potential. […] Seamount fisheries have often been described as mining operations rather than sustainable fisheries. They typically collapse within a few years of the start of fishing and the trawlers then move on to other unexplored seamounts to maintain the fishery. The recovery of localized fisheries will inevitably be very slow, if achievable at all, because of the low reproductive potential of these deep-ocean fish species. […] Comparisons of ‘fished’ and ‘unfished’ seamounts have clearly shown the extent of habitat damage and loss of species diversity brought about by trawl fishing, with the dense coral habitats reduced to rubble over much of the area investigated. […] Unfortunately, most seamounts exist in areas beyond national jurisdiction, which makes it very difficult to regulate fishing activities on them, although some efforts are underway to establish international treaties to better manage and protect seamount ecosystems.” “Hydrothermal vents are unstable and ephemeral features of the deep ocean. […] The lifespan of a typical vent is likely in the order of tens of years. Thus the rich communities surrounding vents have a very limited lifespan. Since many vent animals can live only near vents, and the distance between vent systems can be hundreds to thousands of kilometres, it is a puzzle as to how vent animals escape a dying vent and colonize other distant vents or newly created vents. […] Hydrothermal vents are [however] not the only source of chemical-laden fluids supporting unique chemosynthetic-based communities in the deep ocean. Hydrogen sulphide and methane also ooze from the ocean buttom at some locations at temperatures similar to the surrounding seawater. These so-called ‘cold seeps‘ are often found along continental margins […] The communities associated with cold seeps are similar to hydrothermal vent communities […] Cold seeps appear to be more permanent sources of fluid compared to the ephemeral nature of hot water vents.” “Seepage of crude oil into the marine environment occurs naturally from oil-containing geological formations below the seabed. It is estimated that around 600,000 tonnes of crude oil seeps into the marine environment each year, which represents almost half of all the crude oil entering the oceans. […] The human activities associated with exploring for and producing oil result in the release on average of an estimated 38,000 tonnes of crude oil into the oceans each year, which is about 6 per cent of the total anthropogenic input of oil into the oceans worldwide. Although small in comparison to natural seepage, crude oil pollution from this source can cause serious damage to coastal ecosystems because it is released near the coast and sometimes in very large, concentrated amounts. […] The transport of oil and oil products around the globe in tankers results in the release of about 150,000 tonnes of oil worldwide each year on average, or about 22 per cent of the total anthropogenic input. […] About 480,000 tonnes of oil make their way into the marine environment each year worldwide from leakage associated with the consumption of oil-derived products in cars and trucks, and to a lesser extent in boats. Oil lost from the operation of cars and trucks collects on paved urban areas from where it is washed off into streams and rivers, and from there into the oceans. Surprisingly, this represents the most significant source of human-derived oil pollution into the marine environment – about 72 per cent of the total. Because it is a very diffuse source of pollution, it is the most difficult to control.” “Today it has been estimated that virtually all of the marine food resources in the Mediterranean sea have been reduced to less than 50 per cent of their original abundance […] The greatest impact has been on the larger predatory fish, which were the first to be targeted by fishers. […] It is estimated that, collectively, the European fish stocks of today are just one-tenth of their size in 1900. […] In 1950 the total global catch of marine seafood was just less than twenty million tonnes fresh weight. This increased steadily and rapidly until by the late 1980s more than eighty million tonnes were being taken each year […] Starting in the early 1990s, however, yields began to show signs of levelling off. […] By far the most heavily exploited marine fishery in the world is the Peruvian anchoveta (Engraulis ringens) fishery, which can account for 10 per cent or more of the global marine catch of seafood in any particular year. […] The anchoveta is a very oily fish, which makes it less desirable for direct consumption by humans. However, the high oil content makes it ideal for the production of fish meal and fish oil […] the demand for fish meal and fish oil is huge and about a third of the entire global catch of fish is converted into these products rather than consumed directly by humans. Feeding so much fish protein to livestock comes with a considerable loss of potential food energy (around 25 per cent) compared to if it was eaten directly by humans. This could be viewed as a potential waste of available energy for a rapidly growing human population […] around 90 per cent of the fish used to produce fish meal and oil is presently unpalatable to most people and thus unmarketable in large quantities as a human food”. “On heavily fished areas of the continental shelves, the same parts of the sea floor can be repeatedly trawled many times per year. Such intensive bottom trawling causes great cumulative damage to seabed habitats. The trawls scrape and pulverize rich and complex bottom habitats built up over centuries by living organisms such as tube worms, cold-water corals, and oysters. These habitats are eventually reduced to uniform stretches of rubble and sand. For all intents and purposes these areas are permanently altered and become occupied by a much changed and much less rich community adapted to frequent disturbance.” “The eighty million tonnes or so of marine seafood caught each year globally equates to about eleven kilograms of wild-caught marine seafood per person on the planet. […] What is perfectly clear […] on the basis of theory backed up by real data on marine fish catches, is that marine fisheries are now fully exploited and that there is little if any headroom for increasing the amount of wild-caught fish humans can extract from the oceans to feed a burgeoning human population. […] This conclusion is solidly supported by the increasingly precarious state of global marine fishery resources. The most recent information from the Food and Agriculture Organization of the United Nations (The State of World Fisheries and Aquaculture 2010) shows that over half (53 per cent of all fish stocks are fully exploited – their current catches are at or close to their maximum sustainable levels of production and there is no scope for further expansion. Another 32 per cent are overexploited and in decline. Of the remaining 15 per cent of stocks, 12 per cent are considered moderately exploited and only 3 per cent underexploited. […] in the mid 1970s 40 per cent of all fish stocks were in [the moderately exploited or unexploited] category as opposed to around 15 per cent now. […] the real question is not so much whether we can get more fish from the sea but whether we can sustain the amount of fish we are harvesting at present”. This book was ‘okay’. Some quotes and links related to the first half of the book below. “The Global Ocean has come to be divided into five regional oceans – the Pacific, Atlantic, Indian, Arctic, and Southern Oceans […] These oceans are large, seawater-filled basins that share characteristic structural features […] The edge of each basin consists of a shallow, gently sloping extension of the adjacent continental land mass and is term the continental shelf or continental margin. Continental shelves typically extend off-shore to depths of a couple of hundred metres and vary from several kilometres to hundreds of kilometres in width. […] At the outer edge of the continental shelf, the seafloor drops off abruptly and steeply to form the continental slope, which extends down to depths of 2–3 kilometres. The continental slope then flattens out and gives way to a vast expanse of flat, soft, ocean bottom — the abyssal plain — which extends over depths of about 3–5 kilometres and accounts for about 76 per cent of the Global Ocean floor. The abyssal plains are transected by extensive mid-ocean ridges—underwater mountain chains […]. Mid-ocean ridges form a continuous chain of mountains that extend linearly for 65,000 kilometres across the floor of the Global Ocean basins […]. In some places along the edges of the abyssal plains the ocean bottom is cut by narrow, oceanic trenches or canyons which plunge to extraordinary depths — 3–4 kilometres below the surrounding seafloor — and are thousands of kilometres long but only tens of kilometres wide. […] Seamounts are another distinctive and dramatic feature of ocean basins. Seamounts are typically extinct volcanoes that rise 1,000 or more metres above the surrounding ocean but do not reach the surface of the ocean. […] Seamounts generally occur in chains or clusters in association with mid-ocean ridges […] The Global Ocean contains an estimated 100,000 or so seamounts that rise more than 1,000 metres above the surrounding deep-ocean floor. […] on a planetary scale, the surface of the Global Ocean is moving in a series of enormous, roughly circular, wind-driven current systems, or gyres […] These gyres transport enormous volumes of water and heat energy from one part of an ocean basin to another “We now know that the oceans are literally teeming with life. Viruses […] are astoundingly abundant – there are around ten million viruses per millilitre of seawater. Bacteria and other microorganisms occur at concentrations of around 1 million per millilitre” “The water in the oceans is in the form of seawater, a dilute brew of dissolved ions, or salts […] Chloride and sodium ions are the predominant salts in seawater, along with smaller amounts of other ions such as sulphate, magnesium, calcium, and potassium […] The total amount of dissolved salts in seawater is termed its salinity. Seawater typically has a salinity of roughly 35 – equivalent to about 35 grams of salts in one kilogram of seawater. […] Most marine organisms are exposed to seawater that, compared to the temperature extremes characteristic of terrestrial environments, ranges within a reasonably moderate range. Surface waters in tropical parts of ocean basins are consistently warm throughout the year, ranging from about 20–27°C […]. On the other hand, surface seawater in polar parts of ocean basins can get as cold as −1.9°C. Sea temperatures typically decrease with depth, but not in a uniform fashion. A distinct zone of rapid temperature transition is often present that separates warm seawater at the surface from cooler deeper seawater. This zone is called the thermocline layer […]. In tropical ocean waters the thermocline layer is a strong, well-defined and permanent feature. It may start at around 100 metres and be a hundred or so metres thick. Sea temperatures above the thermocline can be a tropical 25°C or more, but only 6–7°C just below the thermocline. From there the temperature drops very gradually with increasing depth. Thermoclines in temperate ocean regions are a more seasonal phenomenon, becoming well established in the summer as the sun heats up the surface waters, and then breaking down in the autumn and winter. Thermoclines are generally absent in the polar regions of the Global Ocean. […] As a rule of thumb, in the clearest ocean waters some light will penetrate to depths of 150-200 metres, with red light being absorbed within the first few metres and green and blue light penetrating the deepest. At certain times of the year in temperate coastal seas light may penetrate only a few tens of metres […] In the oceans, pressure increases by an additional atmosphere every 10 metres […] Thus, an organism living at a depth of 100 metres on the continental shelf experiences a pressure ten times greater than an organism living at sea level; a creature living at 5 kilometres depth on an abyssal plain experiences pressures some 500 times greater than at the surface”. “With very few exceptions, dissolved oxygen is reasonably abundant throughout all parts of the Global Ocean. However, the amount of oxygen in seawater is much less than in air — seawater at 20°C contains about 5.4 millilitres of oxygen per litre of seawater, whereas air at this temperature contains about 210 millilitres of oxygen per litre. The colder the seawater, the more oxygen it contains […]. Oxygen is not distributed evenly with depth in the oceans. Oxygen levels are typically high in a thin surface layer 10–20 metres deep. Here oxygen from the atmosphere can freely diffuse into the seawater […] Oxygen concentration then decreases rapidly with depth and reaches very low levels, sometimes close to zero, at depths of around 200–1,000 metres. This region is referred to as the oxygen minimum zone […] This zone is created by the low rates of replenishment of oxygen diffusing down from the surface layer of the ocean, combined with the high rates of depletion of oxygen by decaying particulate organic matter that sinks from the surface and accumulates at these depths. Beneath the oxygen minimum zone, oxygen content increases again with depth such that the deep oceans contain quite high levels of oxygen, though not generally as high as in the surface layer. […] In contrast to oxygen, carbon dioxide (CO2) dissolves readily in seawater. Some of it is then converted into carbonic acid (H2CO3), bicarbonate ion (HCO3-), and carbonate ion (CO32-), with all four compounds existing in equilibrium with one another […] The pH of seawater is inversely proportional to the amount of carbon dioxide dissolved in it. […] the warmer the seawater, the less carbon dioxide it can absorb. […] Seawater is naturally slightly alkaline, with a pH ranging from about 7.5 to 8.5, and marine organisms have become well adapted to life within this stable pH range. […] In the oceans, carbon is never a limiting factor to marine plant photosynthesis and growth, as it is for terrestrial plants.” “Since the beginning of the industrial revolution, the average pH of the Global Ocean has dropped by about 0.1 pH unit, making it 30 per cent more acidic than in pre-industrial times. […] As a result, more and more parts of the oceans are falling below a pH of 7.5 for longer periods of time. This trend, termed ocean acidification, is having profound impacts on marine organisms and the overall functioning of the marine ecosystem. For example, many types of marine organisms such as corals, clams, oysters, sea urchins, and starfish manufacture external shells or internal skeletons containing calcium carbonate. When the pH of seawater drops below about 7.5, calcium carbonate starts to dissolve, and thus the shells and skeletons of these organisms begin to erode and weaken, with obvious impacts on the health of the animal. Also, these organisms produce their calcium carbonate structures by combining calcium dissolved in seawater with carbonate ion. As the pH decreases, more of the carbonate ions in seawater become bound up with the increasing numbers of hydrogen ions, making fewer carbonate ions available to the organisms for shell-forming purposes. It thus becomes more difficult for these organisms to secrete their calcium carbonate structures and grow.” “Roughly half of the planet’s primary production — the synthesis of organic compounds by chlorophyll-bearing organisms using energy from the sun—is produced within the Global Ocean. On land the primary producers are large, obvious, and comparatively long-lived — the trees, shrubs, and grasses characteristic of the terrestrial landscape. The situation is quite different in the oceans where, for the most part, the primary producers are minute, short-lived microorganisms suspended in the sunlit surface layer of the oceans. These energy-fixing microorganisms — the oceans’ invisible forest — are responsible for almost all of the primary production in the oceans. […] A large amount, perhaps 30-50 per cent, of marine primary production is produced by bacterioplankton comprising tiny marine photosynthetic bacteria ranging from about 0.5 to 2\xa0μm in size. […] light availability and the strength of vertical mixing are important factors limiting primary production in the oceans. Nutrient availability is the other main factor limiting the growth of primary producers. One important nutrient is nitrogen […] nitrogen is a key component of amino acids, which are the building blocks of proteins. […] Photosynthetic marine organisms also need phosphorus, which is a requirement for many important biological functions, including the synthesis of nucleic acids, a key component of DNA. Phosphorus in the oceans comes naturally from the erosion of rocks and soils on land, and is transported into the oceans by rivers, much of it in the form of dissolved phosphate (PO43−), which can be readily absorbed by marine photosynthetic organisms. […] Inorganic nitrogen and phosphorus compounds are abundant in deep-ocean waters. […] In practice, inorganic nitrogen and phosphorus compounds are not used up at exactly the same rate. Thus one will be depleted before the other and becomes the limiting nutrient at the time, preventing further photosynthesis and growth of marine primary producers until it is replenished. Nitrogen is often considered to be the rate-limiting nutrient in most oceanic environments, particularly in the open ocean. However, in coastal waters phosphorus is often the rate-limiting nutrient.” “The overall pattern of primary production in the Global Ocean depends greatly on latitude […] In polar oceans primary production is a boom-and-bust affair driven by light availability. Here the oceans are well mixed throughout the year so nutrients are rarely limiting. However, during the polar winter there is no light, and thus no primary production is taking place. […] Although limited to a short seasonal pulse, the total amount of primary production can be quite high, especially in the polar Southern Ocean […] In tropical open oceans, primary production occurs at a low level throughout the year. Here light is never limiting but the permanent tropical thermocline prevents the mixing of deep, nutrient-rich seawater with the surface waters. […] open-ocean tropical waters are often referred to as ‘marine deserts’, with productivity […] comparable to a terrestrial desert. In temperate open-ocean regions, primary productivity is linked closely to seasonal events. […] Although occurring in a number of pulses, primary productivity in temperate oceans [is] similar to [that of] a temperate forest or grassland. […] Some of the most productive marine environments occur in coastal ocean above the continental shelves. This is the result of a phenomenon known as coastal upwelling which brings deep, cold, nutrient-rich seawater to the ocean surface, creating ideal conditions for primary productivity […], comparable to a terrestrial rainforest or cultivated farmland. These hotspots of marine productivity are created by wind acting in concert with the planet’s rotation. […] Coastal upwelling can occur when prevailing winds move in a direction roughly parallel to the edge of a continent so as to create offshore Ekman transport. Coastal upwelling is particularly prevalent along the west coasts of continents. […] Since coastal upwelling is dependent on favourable winds, it tends to be a seasonal or intermittent phenomenon and the strength of upwelling will depend on the strength of the winds. […] Important coastal upwelling zones around the world include the coasts of California, Oregon, northwest Africa, and western India in the northern hemisphere; and the coasts of Chile, Peru, and southwest Africa in the southern hemisphere. These regions are amongst the most productive marine ecosystems on the planet.” “Considering the Global Ocean as a whole, it is estimated that total marine primary production is about 50 billion tonnes of carbon per year. In comparison, the total production of land plants, which can also be estimated using satellite data, is estimated at around 52 billion tonnes per year. […] Primary production in the oceans is spread out over a much larger surface area and so the average productivity per unit of surface area is much smaller than on land. […]\xa0the energy of primary production in the oceans flows to higher trophic levels through several different pathways of various lengths […]. Some energy is lost along each step of the pathway — on average the efficiency of energy transfer from one trophic level to the next is about 10 per cent. Hence, shorter pathways are more efficient. Via these pathways, energy ultimately gets transferred to large marine consumers such as large fish, marine mammals, marine turtles, and seabirds.” “…it has been estimated that in the 17th century, somewhere between fifty million and a hundred million green turtles inhabited the Caribbean Sea, but numbers are now down to about 300,000. Since their numbers are now so low, their impact on seagrass communities is currently small, but in the past, green turtles would have been extraordinarily abundant grazers of seagrasses. It appears that in the past, green turtles thinned out seagrass beds, thereby reducing direct competition among different species of seagrass and allowing several species of seagrass to coexist. Without green turtles in the system, seagrass beds are generally overgrown monocultures of one dominant species. […] Seagrasses are of considerable importance to human society. […] It is therefore of great concern that seagrass meadows are in serious decline globally. In 2003 it was estimated that 15 per cent of the planet’s existing seagrass beds had disappeared in the preceding ten years. Much of this is the result of increasing levels of coastal development and dredging of the seabed, activities which release excessive amounts of sediment into coastal waters which smother seagrasses. […] The number of marine dead zones in the Global Ocean has roughly doubled every decade since the 1960s”. “Sea ice is habitable because, unlike solid freshwater ice, it is a very porous substance. As sea ice forms, tiny spaces between the ice crystals become filled with a highly saline brine solution resistant to freezing. Through this process a three-dimensional network of brine channels and spaces, ranging from microscopic to several centimetres in size, is created within the sea ice. These channels are physically connected to the seawater beneath the ice and become colonized by a great variety of marine organisms. A significant amount of the primary production in the Arctic Ocean, perhaps up to 50 per cent in those areas permanently covered by sea ice, takes place in the ice. […] Large numbers of zooplanktonic organisms […] swarm about on the under surface of the ice, grazing on the ice community at the ice-seawater interface, and sheltering in the brine channels. […] These under-ice organisms provide the link to higher trophic levels in the Arctic food web […] They are an important food source for fish such as Arctic cod and glacial cod that graze along the bottom of the ice. These fish are in turn fed on by squid, seals, and whales.” “[T]he Antarctic marine system consists of a ring of ocean about 10° of latitude wide – roughly 1,000 km. […] The Arctic and Antarctic marine systems can be considered geographic opposites. In contrast to the largely landlocked Arctic Ocean, the Southern Ocean surrounds the Antarctic continental land mass and is in open contact with the Atlantic, Indian, and Pacific Oceans. Whereas the Arctic Ocean is strongly influenced by river inputs, the Antarctic continent has no rivers, and so hard-bottomed seabed is common in the Southern Ocean, and there is no low-saline surface layer, as in the Arctic Ocean. Also, in contrast to the Arctic Ocean with its shallow, broad continental shelves, the Antarctic continental shelf is very narrow and steep. […] Antarctic waters are extremely nutrient rich, fertilized by a permanent upwelling of seawater that has its origins at the other end of the planet. […] This continuous upwelling of cold, nutrient-rich seawater, in combination with the long Antarctic summer day length, creates ideal conditions for phytoplankton growth, which drives the productivity of the Antarctic marine system. As in the Arctic, a well-developed sea-ice community is present. Antarctic ice algae are even more abundant and productive than in the Arctic Ocean because the sea ice is thinner, and there is thus more available light for photosynthesis. […] Antarctica’s most important marine species [is] the Antarctic krill […] Krill are very adept at surviving many months under starvation conditions — in the laboratory they can endure more than 200 days without food. During the winter months they lower their metabolic rate, shrink in body size, and revert back to a juvenile state. When food once again becomes abundant in the spring, they grow rapidly […] As the sea ice breaks up they leave the ice and begin feeding directly on the huge blooms of free-living diatoms […]. With so much food available they grow and reproduce quickly, and start to swarm in large numbers, often at densities in excess of 10,000 individuals per cubic metre — dense enough to colour the seawater a reddish-brown. Krill swarms are patchy and vary greatly in size […] Because the Antarctic marine system covers a large area, krill numbers are enormous, estimated at about 600 billion animals on average, or 500 million tonnes of krill. This makes Antarctic krill one of the most abundant animal species on the planet […] Antarctic krill are the main food source for many of Antarctica’s large marine animals, and a key link in a very short and efficient food chain […]. Krill comprise the staple diet of icefish, squid, baleen whales, leopard seals, fur seals, crabeater seals, penguins, and seabirds, including albatross. Thus, a very simple and efficient three-step food chain is in operation — diatoms eaten by krill in turn eaten by a suite of large consumers — which supports the large numbers of large marine animals living in the Southern Ocean.” “The need to maintain a steady state ensuring homeostasis is an essential concern in nature while negative feedback loop is the fundamental way to ensure that this goal is met. The regulatory system determines the interdependences between individual cells and the organism, subordinating the former to the latter. In trying to maintain homeostasis, the organism may temporarily upset the steady state conditions of its component cells, forcing them to perform work for the benefit of the organism.  […] On a cellular level signals are usually transmitted via changes in concentrations of reaction substrates and products. This simple mechanism is made possible due to limited volume of each cell. Such signaling plays a key role in maintaining homeostasis and ensuring cellular activity. On the level of the organism signal transmission is performed by hormones and the nervous system. […] Most intracellular signal pathways work by altering the concentrations of selected substances inside the cell. Signals are registered by forming reversible complexes consisting of a ligand (reaction product) and an allosteric receptor complex. When coupled to the ligand, the receptor inhibits the activity of its corresponding effector, which in turn shuts down the production of the controlled substance ensuring the steady state of the system. Signals coming from outside the cell are usually treated as commands (covalent modifications), forcing the cell to adjust its internal processes […] Such commands can arrive in the form of hormones, produced by the organism to coordinate specialized cell functions in support of general homeostasis (in the organism). These signals act upon cell receptors and are usually amplified before they reach their final destination (the effector).” “Each concentration-mediated signal must first be registered by a detector. […] Intracellular detectors are typically based on allosteric proteins. Allosteric proteins exhibit a special property: they have two stable structural conformations and can shift from one form to the other as a result of changes in ligand concentrations. […] The concentration of a product (or substrate) which triggers structural realignment in the allosteric protein (such as a regulatory enzyme) depends on the genetically-determined affinity of the active site to its ligand. Low affinity results in high target concentration of the controlled substance while high affinity translates into lower concentration […]. In other words, high concentration of the product is necessary to trigger a low-affinity receptor (and vice versa). Most intracellular regulatory mechanisms rely on noncovalent interactions. Covalent bonding is usually associated with extracellular signals, generated by the organism and capable of overriding the cell’s own regulatory mechanisms by modifying the sensitivity of receptors […]. Noncovalent interactions may be compared to requests while covalent signals are treated as commands. Signals which do not originate in the receptor’s own feedback loop but modify its affinity are known as steering signals […] Hormones which act upon cells are, by their nature, steering signals […] Noncovalent interactions — dependent on substance concentrations — impose spatial restrictions on regulatory mechanisms. Any increase in cell volume requires synthesis of additional products in order to maintain stable concentrations. The volume of a spherical cell is given as V = 4/3 π ∗ r3, where r indicates cell radius. Clearly, even a slight increase in r translates into a significant increase in cell volume, diluting any products dispersed in the cytoplasm. This implies that cells cannot expand without incurring great energy costs. It should also be noted that cell expansion reduces the efficiency of intracellular regulatory mechanisms because signals and substrates need to be transported over longer distances. Thus, cells are universally small, regardless of whether they make up a mouse or an elephant.” “An effector is an element of a regulatory loop which counteracts changes in the regulated quantity […] Synthesis and degradation of biological compounds often involves numerous enzymes acting in sequence. The product of one enzyme is a substrate for another enzyme. With the exception of the initial enzyme, each step of this cascade is controlled by the availability of the supplied substrate […] The effector consists of a chain of enzymes, each of which depends on the activity of the initial regulatory enzyme […] as well as on the activity of its immediate predecessor which supplies it with substrates. The function of all enzymes in the effector chain is indirectly dependent on the initial enzyme […]. This coupling between the receptor and the first link in the effector chain is a universal phenomenon. It can therefore be said that the initial enzyme in the effector chain is, in fact, a regulatory enzyme. […] Most cell functions depend on enzymatic activity. […] It seems that a set of enzymes associated with a specific process which involves a negative feedback loop is the most typical form of an intracellular regulatory effector. Such effectors can be controlled through activation or inhibition of their associated enzymes.” “Strong signal amplification carries an important drawback: it tends to “overshoot” its target activity level, causing wild fluctuations in the process it controls. […] Nature has evolved several means of signal attenuation. The most typical mechanism superimposes two regulatory loops which affect the same parameter but act in opposite directions. An example is the stabilization of blood glucose levels by two contradictory hormones: glucagon and insulin. Similar strategies are exploited in body temperature control and many other biological processes. […] The coercive properties of signals coming from the organism carry risks associated with the possibility of overloading cells. The regulatory loop of an autonomous cell must therefore include an “off switch”, controlled by the cell. An autonomous cell may protect itself against excessive involvement in processes triggered by external signals (which usually incur significant energy expenses). […] The action of such mechanisms is usually timer-based, meaning that they inactivate signals following a set amount of time. […] The ability to interrupt signals protects cells from exhaustion. Uncontrolled hormone-induced activity may have detrimental effects upon the organism as a whole. This is observed e.g. in the case of the vibrio cholerae toxin which causes prolonged activation of intestinal epithelial cells by locking protein G in its active state (resulting in severe diarrhea which can dehydrate the organism).” “Biological systems in which information transfer is affected by high entropy of the information source and ambiguity of the signal itself must include discriminatory mechanisms. These mechanisms usually work by eliminating weak signals (which are less specific and therefore introduce ambiguities). They create additional obstacles (thresholds) which the signals must overcome. A good example is the mechanism which eliminates the ability of weak, random antigens to activate lymphatic cells. It works by inhibiting blastic transformation of lymphocytes until a so-called receptor cap has accumulated on the surface of the cell […]. Only under such conditions can the activation signal ultimately reach the cell nucleus […] and initiate gene transcription. […] weak, reversible nonspecific interactions do not permit sufficient aggregation to take place. This phenomenon can be described as a form of discrimination against weak signals. […] Discrimination may also be linked to effector activity. […] Cell division is counterbalanced by programmed cell death. The most typical example of this process is apoptosis […] Each cell is prepared to undergo controlled death if required by the organism, however apoptosis is subject to tight control. Cells protect themselves against accidental triggering of the process via IAP proteins. Only strong proapoptotic signals may overcome this threshold and initiate cellular suicide”. “Without regulation biological processes would become progressively more and more chaotic. In living cells the primary source of information is genetic material. Studying the role of information in biology involves signaling (i.e. spatial and temporal transfer of information) and storage (preservation of information). Regarding the role of the genome we can distinguish three specific aspects of biological processes: steady-state genetics, which ensure cell-level and body homeostasis; genetics of development, which controls cell differentiation and genesis of the organism; and evolutionary genetics, which drives speciation. […] The ever growing demand for information, coupled with limited storage capacities, has resulted in a number of strategies for minimizing the quantity of the encoded information that must be preserved by living cells. In addition to combinatorial approaches based on noncontiguous genes structure, self-organization plays an important role in cellular machinery. Nonspecific interactions with the environment give rise to coherent structures despite the lack of any overt information store. These mechanisms, honed by evolution and ubiquitous in living organisms, reduce the need to directly encode large quantities of data by adopting a systemic approach to information management.” “Information is commonly understood as a transferable description of an event or object. Information transfer can be either spatial (communication, messaging or signaling) or temporal (implying storage). […] The larger the set of choices, the lower the likelihood [of] making the correct choice by accident and — correspondingly — the more information is needed to choose correctly. We can therefore state that an increase in the cardinality of a set (the number of its elements) corresponds to an increase in selection indeterminacy. This indeterminacy can be understood as a measure of “a priori ignorance”. […] Entropy determines the uncertainty inherent in a given system and therefore represents the relative difficulty of making the correct choice. For a set of possible events it reaches its maximum value if the relative probabilities of each event are equal. Any information input reduces entropy — we can therefore say that changes in entropy are a quantitative measure of information.  […] Physical entropy is highest in a state of equilibrium, i.e. lack of spontaneity (∆G = 0,0) which effectively terminates the given reaction. Regulatory processes which counteract the tendency of physical systems to reach equilibrium must therefore oppose increases in entropy. It can be said that a steady inflow of information is a prerequisite of continued function in any organism. As selections are typically made at the entry point of a regulatory process, the concept of entropy may also be applied to information sources. This approach is useful in explaining the structure of regulatory systems which must be “designed” in a specific way, reducing uncertainty and enabling accurate, error-free decisions.” “The fire ant exudes a pheromone which enables it to mark sources of food and trace its own path back to the colony. In this way, the ant conveys pathing information to other ants. The intensity of the chemical signal is proportional to the abundance of the source. Other ants can sense the pheromone from a distance of several (up to a dozen) centimeters and thus locate the source themselves. […] As can be expected, an increase in the entropy of the information source (i.e. the measure of ignorance) results in further development of regulatory systems — in this case, receptors capable of receiving signals and processing them to enable accurate decisions. Over time, the evolution of regulatory mechanisms increases their performance and precision. The purpose of various structures involved in such mechanisms can be explained on the grounds of information theory. The primary goal is to select the correct input signal, preserve its content and avoid or eliminate any errors.” “The magnitude of effort involved in replication of genetic code can be visualized by comparing the DNA chain to a zipper […]. Assuming that the zipper consists of three pairs of interlocking teeth per centimeter (300 per meter) and that the human genome is made up of 3 billion […] base pairs, the total length of our uncoiled DNA in “zipper form” would be equal to […] 10,000 km […] If we were to unfasten the zipper at a rate of 1 m per second, the entire unzipping process would take approximately 3 months […]. This comparison should impress upon the reader the length of the DNA chain and the precision with which individual nucleotides must be picked to ensure that the resulting code is an exact copy of the source. It should also be noted that for each base pair the polymerase enzyme needs to select an appropriate matching nucleotide from among four types of nucleotides present in the solution, and attach it to the chain (clearly, no such problem occurs in zippers). The reliability of an average enzyme is on the order of 10-3–10-4, meaning that one error occurs for every 1,000–10,000 interactions between the enzyme and its substrate. Given this figure, replication of 3*109 base pairs would introduce approximately 3 million errors (mutations) per genome, resulting in a highly inaccurate copy. Since the observed reliability of replication is far higher, we may assume that some corrective mechanisms are involved. Really, the remarkable precision of genetic replication is ensured by DNA repair processes, and in particular by the corrective properties of polymerase itself.” “Many mutations are caused by the inherent chemical instability of nucleic acids: for example, cytosine may spontaneously convert to uracil. In the human genome such an event occurs approximately 100 times per day; however uracil is not normally encountered in DNA and its presence alerts defensive mechanisms which correct the error. Another type of mutation is spontaneous depurination, which also triggers its own, dedicated error correction procedure. Cells employ a large number of corrective mechanisms […] DNA repair mechanisms may be treated as an “immune system” which protects the genome from loss or corruption of genetic information. The unavoidable mutations which sometimes occur despite the presence of error correction-mechanisms can be masked due to doubled presentation (alleles) of genetic information. Thus, most mutations are recessive and not expressed in the phenotype. As the length of the DNA chain increases, mutations become more probable. It should be noted that the number of nucleotides in DNA is greater than the relative number of aminoacids participating in polypeptide chains. This is due to the fact that each aminoacid is encoded by exactly three nucleotides — a general principle which applies to all living organisms. […] Fidelity is, of course, fundamentally important in DNA replication as any harmful mutations introduced in its course are automatically passed on to all successive generations of cells. In contrast, transcription and translation processes can be more error-prone as their end products are relatively short-lived. Of note is the fact that faulty transcripts appear in relatively low quantities and usually do not affect cell functions, since regulatory processes ensure continued synthesis of the required substances until a suitable level of activity is reached. Nevertheless, it seems that reliable transcription of genetic material is sufficiently significant for cells to have developed appropriate proofreading mechanisms, similar to those which assist replication. […] the entire information pathway — starting with DNA and ending with active proteins — is protected against errors. We can conclude that fallibility is an inherent property of genetic information channels, and that in order to perform their intended function, these channels require error correction mechanisms.” “The discrete nature of genetic material is an important property which distinguishes prokaryotes from eukaryotes. […] The ability to select individual nucleotide fragments and construct sequences from predetermined “building blocks” results in high adaptability to environmental stimuli and is a fundamental aspect of evolution. The discontinuous nature of genes is evidenced by the presence of fragments which do not convey structural information (introns), as opposed to structure-encoding fragments (exons). The initial transcript (pre-mRNA) contains introns as well as exons. In order to provide a template for protein synthesis, it must undergo further processing (also known as splicing): introns must be cleaved and exon fragments attached to one another. […] Recognition of intron-exon boundaries is usually very precise, while the reattachment of adjacent exons is subject to some variability. Under certain conditions, alternative splicing may occur, where the ordering of the final product does not reflect the order in which exon sequences appear in the source chain. This greatly increases the number of potential mRNA combinations and thus the variety of resulting proteins. […] While access to energy sources is not a major problem, sources of information are usually far more difficult to manage — hence the universal tendency to limit the scope of direct (genetic) information storage. Reducing the length of genetic code enables efficient packing and enhances the efficiency of operations while at the same time decreasing the likelihood of errors. […] The number of genes identified in the human genome is lower than the number of distinct proteins by a factor of 4; a difference which can be attributed to alternative splicing. […] This mechanism increases the variety of protein structures without affecting core information storage, i.e. DNA sequences. […] Primitive organisms often possess nearly as many genes as humans, despite the essential differences between both groups. Interspecies diversity is primarily due to the properties of regulatory sequences.” “The discontinuous nature of genes is evolutionarily advantageous but comes at the expense of having to maintain a nucleus where such splicing processes can be safely conducted, in addition to efficient transport channels allowing transcripts to penetrate the nuclear membrane. While it is believed that at early stages of evolution RNA was the primary repository of genetic information, its present function can best be described as an information carrier. Since unguided proteins cannot ensure sufficient specificity of interaction with nucleic acids, protein-RNA complexes are used often in cases where specific fragments of genetic information need to be read. […] The use of RNA in protein complexes is common across all domains of the living world as it bridges the gap between discrete and continuous storage of genetic information.” “Epigenetic differentiation mechanisms are particularly important in embryonic development. […] Unlike the function of mature organisms, embryonic programming refers to structures which do not yet exist but which need to be created through cell proliferation and differentiation. […] Differentiation of cells results in phenotypic changes. This phenomenon is the primary difference between development genetics and steady-state genetics. Functional differences are not, however, associated with genomic changes: instead they are mediated by the transcriptome where certain genes are preferentially selected for transcription while others are suppressed. […] In a mature, specialized cell only a small portion of the transcribable genome is actually expressed. The remainder of the cell’s genetic material is said to be silenced. Gene silencing is a permanent condition. Under normal circumstances mature cells never alter their function, although such changes may be forced in a laboratory setting […] Cells which make up the embryo at a very early stage of development are pluripotent, meaning that their purpose can be freely determined and that all of their genetic information can potentially be expressed (under certain conditions). […] At each stage of the development process the scope of pluripotency is reduced until, ultimately, the cell becomes monopotent. Monopotency implies that the final function of the cell has already been determined, although the cell itself may still be immature. […] functional dissimilarities between specialized cells are not associated with genetic mutations but rather with selective silencing of genes. […] Most genes which determine biological functions have a biallelic representation (i.e. a representation consisting of two alleles). The remainder (approximately 10 % of genes) is inherited from one specific parent, as a result of partial or complete silencing of their sister alleles (called paternal or maternal imprinting) which occurs during gametogenesis. The suppression of a single copy of the X chromosome is a special case of this phenomenon.” This book is really dense and is somewhat tough for me to blog. One significant problem is that: “The authors assume that the reader is already familiar with the material covered in a classic biochemistry course.” I know enough biochem to follow most of the stuff in this book, and I was definitely quite happy to have recently read John Finney’s book on the biochemical properties of water and Christopher Hall’s introduction to materials science, as both of those books’ coverage turned out to be highly relevant (these are far from the only relevant books I’ve read semi-recently – Atkins introduction to thermodynamics is another book that springs to mind) – but even so, what do you leave out when writing a post like this? I decided to leave out a lot. Posts covering books like this one are hard to write because it’s so easy for them to blow up in your face because you have to include so many details for the material included in the post to even start to make sense to people who didn’t read the original text. And if you leave out all the details, what’s really left? It’s difficult.. Anyway, some observations from the first chapters of the book below. “[T]he biological world consists of self-managing and self-organizing systems which owe their existence to a steady supply of energy and information. Thermodynamics introduces a distinction between open and closed systems. Reversible processes occurring in closed systems (i.e. independent of their environment) automatically gravitate toward a state of equilibrium which is reached once the velocity of a given reaction in both directions becomes equal. When this balance is achieved, we can say that the reaction has effectively ceased. In a living cell, a similar condition occurs upon death. Life relies on certain spontaneous processes acting to unbalance the equilibrium. Such processes can only take place when substrates and products of reactions are traded with the environment, i.e. they are only possible in open systems. In turn, achieving a stable level of activity in an open system calls for regulatory mechanisms. When the reaction consumes or produces resources that are exchanged with the outside world at an uneven rate, the stability criterion can only be satisfied via a negative feedback loop […] cells and living organisms are thermodynamically open systems […] all structures which play a role in balanced biological activity may be treated as components of a feedback loop. This observation enables us to link and integrate seemingly unrelated biological processes. […] the biological structures most directly involved in the functions and mechanisms of life can be divided into receptors, effectors, information conduits and elements subject to regulation (reaction products and action results). Exchanging these elements with the environment requires an inflow of energy. Thus, living cells are — by their nature — open systems, requiring an energy source […] A thermodynamically open system lacking equilibrium due to a steady inflow of energy in the presence of automatic regulation is […] a good theoretical model of a living organism. […] Pursuing growth and adapting to changing environmental conditions calls for specialization which comes at the expense of reduced universality. A specialized cell is no longer self-sufficient. As a consequence, a need for higher forms of intercellular organization emerges. The structure which provides cells with suitable protection and ensures continued homeostasis is called an organism.” “In biology, structure and function are tightly interwoven. This phenomenon is closely associated with the principles of evolution. Evolutionary development has produced structures which enable organisms to develop and maintain its architecture, perform actions and store the resources needed to survive. For this reason we introduce a distinction between support structures (which are akin to construction materials), function-related structures (fulfilling the role of tools and machines), and storage structures (needed to store important substances, achieving a compromise between tight packing and ease of access). […] Biology makes extensive use of small-molecule structures and polymers. The physical properties of polymer chains make them a key building block in biological structures. There are several reasons as to why polymers are indispensable in nature […] Sequestration of resources is subject to two seemingly contradictory criteria: 1. Maximize storage density; 2. Perform sequestration in such a way as to allow easy access to resources. […]\xa0In most biological systems, storage applies to energy and information. Other types of resources are only occasionally stored […]. Energy is stored primarily in the form of saccharides and lipids. Saccharides are derivatives of glucose, rendered insoluble (and thus easy to store) via polymerization.Their polymerized forms, stabilized with α-glycosidic bonds, include glycogen (in animals) and starch (in plantlife). […] It should be noted that the somewhat loose packing of polysaccharides […] makes them unsuitable for storing large amounts of energy. In a typical human organism only ca. 600 kcal of energy is stored in the form of glycogen, while (under normal conditions) more than 100,000 kcal exists as lipids. Lipids deposit usually assume the form of triglycerides (triacylglycerols). Their properties can be traced to the similarities between fatty acids and hydrocarbons. Storage efficiency (i.e. the amount of energy stored per unit of mass) is twice that of polysaccharides, while access remains adequate owing to the relatively large surface area and high volume of lipids in the organism.” “Most living organisms store information in the form of tightly-packed DNA strands. […] It should be noted that only a small percentage of DNA (about few %) conveys biologically relevant information. The purpose of the remaining ballast is to enable suitable packing and exposure of these important fragments. If all of DNA were to consist of useful code, it would be nearly impossible to devise a packing strategy guaranteeing access to all of the stored information.” “The seemingly endless diversity of biological functions frustrates all but the most persistent attempts at classification. For the purpose of this handbook we assume that each function can be associated either with a single cell or with a living organism. In both cases, biological functions are strictly subordinate to automatic regulation, based — in a stable state — on negative feedback loops, and in processes associated with change (for instance in embryonic development) — on automatic execution of predetermined biological programs. Individual components of a cell cannot perform regulatory functions on their own […]. Thus, each element involved in the biological activity of a cell or organism must necessarily participate in a regulatory loop based on processing information.” “Proteins are among the most basic active biological structures. Most of the well-known proteins studied thus far perform effector functions: this group includes enzymes, transport proteins, certain immune system components (complement factors) and myofibrils. Their purpose is to maintain biological systems in a steady state. Our knowledge of receptor structures is somewhat poorer […] Simple structures, including individual enzymes and components of multienzyme systems, can be treated as “tools” available to the cell, while advanced systems, consisting of many mechanically-linked tools, resemble machines. […] Machinelike mechanisms are readily encountered in living cells. A classic example is fatty acid synthesis, performed by dedicated machines called synthases. […] Multiunit structures acting as machines can be encountered wherever complex biochemical processes need to be performed in an efficient manner. […] If the purpose of a machine is to generate motion then a thermally powered machine can accurately be called a motor. This type of action is observed e.g. in myocytes, where transmission involves reordering of protein structures using the energy generated by hydrolysis of high-energy bonds.” “In biology, function is generally understood as specific physiochemical action, almost universally mediated by proteins. Most such actions are reversible which means that a single protein molecule may perform its function many times. […] Since spontaneous noncovalent surface interactions are very infrequent, the shape and structure of active sites — with high concentrations of hydrophobic residues — makes them the preferred area of interaction between functional proteins and their ligands. They alone provide the appropriate conditions for the formation of hydrogen bonds; moreover, their structure may determine the specific nature of interaction. The functional bond between a protein and a ligand is usually noncovalent and therefore reversible.” “In general terms, we can state that enzymes accelerate reactions by lowering activation energies for processes which would otherwise occur very slowly or not at all. […] The activity of enzymes goes beyond synthesizing a specific protein-ligand complex (as in the case of antibodies or receptors) and involves an independent catalytic attack on a selected bond within the ligand, precipitating its conversion into the final product. The relative independence of both processes (binding of the ligand in the active site and catalysis) is evidenced by the phenomenon of noncompetitive inhibition […] Kinetic studies of enzymes have provided valuable insight into the properties of enzymatic inhibitors — an important field of study in medicine and drug research. Some inhibitors, particularly competitive ones (i.e. inhibitors which outcompete substrates for access to the enzyme), are now commonly used as drugs. […]  Physical and chemical processes may only occur spontaneously if they generate energy, or non-spontaneously if they consume it. However, all processes occurring in a cell must have a spontaneous character because only these processes may be catalyzed by enzymes. Enzymes merely accelerate reactions; they do not provide energy. […] The change in enthalpy associated with a chemical process may be calculated as a net difference in the sum of molecular binding energies prior to and following the reaction. Entropy is a measure of the likelihood that a physical system will enter a given state. Since chaotic distribution of elements is considered the most probable, physical systems exhibit a general tendency to gravitate towards chaos. Any form of ordering is thermodynamically disadvantageous.” “Photosynthesis is a process which — from the point of view of electron transfer — can be treated as a counterpart of the respiratory chain. In heterotrophic organisms, mitochondria transport electrons from hydrogenated compounds (sugars, lipids, proteins) onto oxygen molecules, synthesizing water in the process, whereas in the course of photosynthesis electrons released by breaking down water molecules are used as a means of reducing oxydised carbon compounds […]. In heterotrophic organisms the respiratory chain has a spontaneous quality (owing to its oxidative properties); however any reverse process requires energy to occur. In the case of photosynthesis this energy is provided by sunlight […] Hydrogen combustion and photosynthesis are the basic sources of energy in the living world. […]\xa0For an energy source to become useful, non-spontaneous reactions must be coupled to its operation, resulting in a thermodynamically unified system. Such coupling can be achieved by creating a coherent framework in which the spontaneous and non-spontaneous processes are linked, either physically or chemically, using a bridging component which affects them both. If the properties of both reactions are different, the bridging component must also enable suitable adaptation and mediation. […] Direct exploitation of the energy released via the hydrolysis of ATP is possible usually by introducing an active binding carrier mediating the energy transfer. […] Carriers are considered active as long as their concentration ensures a sufficient release of energy to synthesize a new chemical bond by way of a non-spontaneous process. Active carriers are relatively short-lived […] Any active carrier which performs its function outside of the active site must be sufficiently stable to avoid breaking up prior to participating in the synthesis reaction. Such mobile carriers are usually produced when the required synthesis consists of several stages or cannot be conducted in the active site of the enzyme for sterical reasons. Contrary to ATP, active energy carriers are usually reaction-specific. […] Mobile energy carriers are usually formed as a result of hydrolysis of two high-energy ATP bonds. In many cases this is the minimum amount of energy required to power a reaction which synthesizes a single chemical bond. […] Expelling a mobile or unstable reaction component in order to increase the spontaneity of active energy carrier synthesis is a process which occurs in many biological mechanisms […] The action of active energy carriers may be compared to a ball rolling down a hill. The descending snowball gains sufficient energy to traverse another, smaller mound, adjacent to its starting point. In our case, the smaller hill represents the final synthesis reaction […] Understanding the role of active carriers is essential for the study of metabolic processes.” “A second category of processes, directly dependent on energy sources, involves structural reconfiguration of proteins, which can be further differentiated into low and high-energy reconfiguration. Low-energy reconfiguration occurs in proteins which form weak, easily reversible bonds with ligands. In such cases, structural changes are powered by the energy released in the creation of the complex. […] Important low-energy reconfiguration processes may occur in proteins which consist of subunits. Structural changes resulting from relative motion of subunits typically do not involve significant expenditures of energy. Of particular note are the so-called allosteric proteins […] whose rearrangement is driven by a weak and reversible bond between the protein and an oxygen molecule. Allosteric proteins are genetically conditioned to possess two stable structural configurations, easily swapped as a result of binding or releasing ligands. Thus, they tend to have two comparable energy minima (separated by a low threshold), each of which may be treated as a global minimum corresponding to the native form of the protein. Given such properties, even a weakly interacting ligand may trigger significant structural reconfiguration. This phenomenon is of critical importance to a variety of regulatory proteins. In many cases, however, the second potential minimum in which the protein may achieve relative stability is separated from the global minimum by a high threshold requiring a significant expenditure of energy to overcome. […] Contrary to low-energy reconfigurations, the relative difference in ligand concentrations is insufficient to cover the cost of a difficult structural change. Such processes are therefore coupled to highly exergonic reactions such as ATP hydrolysis. […]\xa0 The link between a biological process and an energy source does not have to be immediate. Indirect coupling occurs when the process is driven by relative changes in the concentration of reaction components. […] In general, high-energy reconfigurations exploit direct coupling mechanisms while indirect coupling is more typical of low-energy processes”. “Muscle action requires a major expenditure of energy. There is a nonlinear dependence between the degree of physical exertion and the corresponding energy requirements. […] Training may improve the power and endurance of muscle tissue. Muscle fibers subjected to regular exertion may improve their glycogen storage capacity, ATP production rate, oxidative metabolism and the use of fatty acids as fuel.“ (I have had some computer issues over the last couple of weeks, which was the explanation for my brief blogging hiatus, but they should be resolved by now and as I’m already starting to fall quite a bit behind in terms of my intended coverage of the books I’ve read this year I hope to get rid of some of the backlog in the days to come.) I have added some more observations from the second half of the book, as well as some related links, below. “[R]ecycling of old plant material is especially important in lakes, and one way to appreciate its significance is to measure the concentration of CO2, an end product of decomposition, in the surface waters. This value is often above, sometimes well above, the value to be expected from equilibration of this gas with the overlying air, meaning that many lakes are net producers of CO2 and that they emit this greenhouse gas to the atmosphere. How can that be? […] Lakes are not sealed microcosms that function as stand-alone entities; on the contrary, they are embedded in a landscape and are intimately coupled to their terrestrial surroundings. Organic materials are produced within the lake by the phytoplankton, photosynthetic cells that are suspended in the water and that fix CO2, release oxygen (O2), and produce biomass at the base of the aquatic food web. Photosynthesis also takes place by attached algae (the periphyton) and submerged water plants (aquatic macrophytes) that occur at the edge of the lake where enough sunlight reaches the bottom to allow their growth. But additionally, lakes are the downstream recipients of terrestrial runoff from their catchments […]. These continuous inputs include not only water, but also subsidies of plant and soil organic carbon that are washed into the lake via streams, rivers, groundwater, and overland flows. […] The organic carbon entering lakes from the catchment is referred to as ‘allochthonous’, meaning coming from the outside, and it tends to be relatively old […] In contrast, much younger organic carbon is available […] as a result of recent photosynthesis by the phytoplankton and littoral communities; this carbon is called ‘autochthonous’, meaning that it is produced within the lake.” “It used to be thought that most of the dissolved organic matter (DOM) entering lakes, especially the coloured fraction, was unreactive and that it would transit the lake to ultimately leave unchanged at the outflow. However, many experiments and field observations have shown that this coloured material can be partially broken down by sunlight. These photochemical reactions result in the production of CO2, and also the degradation of some of the organic polymers into smaller organic molecules; these in turn are used by bacteria and decomposed to CO2. […]\xa0Most of the bacterial species in lakes are decomposers that convert organic matter into mineral end products […] This sunlight-driven chemistry begins in the rivers, and continues in the surface waters of the lake. Additional chemical and microbial reactions in the soil also break down organic materials and release CO2 into the runoff and ground waters, further contributing to the high concentrations in lake water and its emission to the atmosphere. In algal-rich ‘eutrophic’ lakes there may be sufficient photosynthesis to cause the drawdown of CO2 to concentrations below equilibrium with the air, resulting in the reverse flux of this gas, from the atmosphere into the surface waters.” “There is a precarious balance in lakes between oxygen gains and losses, despite the seemingly limitless quantities in the overlying atmosphere. This balance can sometimes tip to deficits that send a lake into oxygen bankruptcy, with the O2 mostly or even completely consumed. Waters that have O2 concentrations below 2mg/L are referred to as ‘hypoxic’, and will be avoided by most fish species, while waters in which there is a complete absence of oxygen are called ‘anoxic’ and are mostly the domain for specialized, hardy microbes. […] In many temperate lakes, mixing in spring and again in autumn are the critical periods of re-oxygenation from the overlying atmosphere. In summer, however, the thermocline greatly slows down that oxygen transfer from air to deep water, and in cooler climates, winter ice-cover acts as another barrier to oxygenation. In both of these seasons, the oxygen absorbed into the water during earlier periods of mixing may be rapidly consumed, leading to anoxic conditions. Part of the reason that lakes are continuously on the brink of anoxia is that only limited quantities of oxygen can be stored in water because of its low solubility. The concentration of oxygen in the air is 209 millilitres per litre […], but cold water in equilibrium with the atmosphere contains only 9ml/L […]. This scarcity of oxygen worsens with increasing temperature (from 4°C to 30°C the solubility of oxygen falls by 43 per cent), and it is compounded by faster rates of bacterial decomposition in warmer waters and thus a higher respiratory demand for oxygen.” “Lake microbiomes play multiple roles in food webs as producers, parasites, and consumers, and as steps into the animal food chain […]. These diverse communities of microbes additionally hold centre stage in the vital recycling of elements within the lake ecosystem […]. These biogeochemical processes are not simply of academic interest; they totally alter the nutritional value, mobility, and even toxicity of elements. For example, sulfate is the most oxidized and also most abundant form of sulfur in natural waters, and it is the ion taken up by phytoplankton and aquatic plants to meet their biochemical needs for this element. These photosynthetic organisms reduce the sulfate to organic sulfur compounds, and once they die and decompose, bacteria convert these compounds to the rotten-egg smelling gas, H2S, which is toxic to most aquatic life. In anoxic waters and sediments, this effect is amplified by bacterial sulfate reducers that directly convert sulfate to H2S. Fortunately another group of bacteria, sulfur oxidizers, can use H2S as a chemical energy source, and in oxygenated waters they convert this reduced sulfur back to its benign, oxidized, sulfate form. […] [The] acid neutralizing capacity (or ‘alkalinity’) varies greatly among lakes. Many lakes in Europe, North America, and Asia have been dangerously shifted towards a low pH because they lacked sufficient carbonate to buffer the continuous input of acid rain that resulted from industrial pollution of the atmosphere. The acid conditions have negative effects on aquatic animals, including by causing a shift in aluminium to its more soluble and toxic form Al3+. Fortunately, these industrial emissions have been regulated and reduced in most of the developed world, although there are still legacy effects of acid rain that have resulted in a long-term depletion of carbonates and associated calcium in certain watersheds.” “Rotifers, cladocerans, and copepods are all planktonic, that is their distribution is strongly affected by currents and mixing processes in the lake. However, they are also swimmers, and can regulate their depth in the water. For the smallest such as rotifers and copepods, this swimming ability is limited, but the larger zooplankton are able to swim over an impressive depth range during the twenty-four-hour ‘diel’ (i.e. light–dark) cycle. […] the cladocerans in Lake Geneva reside in the thermocline region and deep epilimnion during the day, and swim upwards by about 10m during the night, while cyclopoid copepods swim up by 60m, returning to the deep, dark, cold waters of the profundal zone during the day. Even greater distances up and down the water column are achieved by larger animals. The opossum shrimp, Mysis (up to 25mm in length) lives on the bottom of lakes during the day and in Lake Tahoe it swims hundreds of metres up into the surface waters, although not on moon-lit nights. In Lake Baikal, one of the main zooplankton species is the endemic amphipod, Macrohectopus branickii, which grows up to 38mm in size. It can form dense swarms at 100–200m depth during the day, but the populations then disperse and rise to the upper waters during the night. These nocturnal migrations connect the pelagic surface waters with the profundal zone in lake ecosystems, and are thought to be an adaptation towards avoiding visual predators, especially pelagic fish, during the day, while accessing food in the surface waters under the cover of nightfall. […]\xa0Although certain fish species remain within specific zones of the lake, there are others that swim among zones and access multiple habitats. […] This type of fish migration means that the different parts of the lake ecosystem are ecologically connected. For many fish species, moving between habitats extends all the way to the ocean. Anadromous fish migrate out of the lake and swim to the sea each year, and although this movement comes at considerable energetic cost, it has the advantage of access to rich marine food sources, while allowing the young to be raised in the freshwater environment with less exposure to predators. […] With the converse migration pattern, catadromous fish live in freshwater and spawn in the sea.” “Invasive species that are the most successful and do the most damage once they enter a lake have a number of features in common: fast growth rates, broad tolerances, the capacity to thrive under high population densities, and an ability to disperse and colonize that is enhanced by human activities. Zebra mussels (Dreissena polymorpha) get top marks in each of these categories, and they have proven to be a troublesome invader in many parts of the world. […] A single Zebra mussel can produce up to one million eggs over the course of a spawning season, and these hatch into readily dispersed larvae (‘veligers’), that are free-swimming for up to a month. The adults can achieve densities up to hundreds of thousands per square metre, and their prolific growth within water pipes has been a serious problem for the cooling systems of nuclear and thermal power stations, and for the intake pipes of drinking water plants. A single Zebra mussel can filter a litre a day, and they have the capacity to completely strip the water of bacteria and protists. In Lake Erie, the water clarity doubled and diatoms declined by 80–90 per cent soon after the invasion of Zebra mussels, with a concomitant decline in zooplankton, and potential impacts on planktivorous fish. The invasion of this species can shift a lake from dominance of the pelagic to the benthic food web, but at the expense of native unionid clams on the bottom that can become smothered in Zebra mussels. Their efficient filtering capacity may also cause a regime shift in primary producers, from turbid waters with high concentrations of phytoplankton to a clearer lake ecosystem state in which benthic water plants dominate.” “One of the many distinguishing features of H2O is its unusually high dielectric constant, meaning that it is a strongly polar solvent with positive and negative charges that can stabilize ions brought into solution. This dielectric property results from the asymmetrical electron cloud over the molecule […] and it gives liquid water the ability to leach minerals from rocks and soils as it passes through the ground, and to maintain these salts in solution, even at high concentrations. Collectively, these dissolved minerals produce the salinity of the water […] Sea water is around 35ppt, and its salinity is mainly due to the positively charged ions sodium (Na+), potassium (K+), magnesium (Mg2+), and calcium (Ca2+), and the negatively charged ions chloride (Cl–), sulfate (SO42-), and carbonate CO32-). These solutes, collectively called the ‘major ions’, conduct electrons, and therefore a simple way to track salinity is to measure the electrical conductance of the water between two electrodes set a known distance apart. Lake and ocean scientists now routinely take profiles of salinity and temperature with a CTD: a submersible instrument that records conductance, temperature, and depth many times per second as it is lowered on a rope or wire down the water column. Conductance is measured in Siemens (or microSiemens (µS), given the low salt concentrations in freshwater lakes), and adjusted to a standard temperature of 25°C to give specific conductivity in µS/cm. All freshwater lakes contain dissolved minerals, with specific conductivities in the range 50–500µS/cm, while salt water lakes have values that can exceed sea water (about 50,000µS/cm), and are the habitats for extreme microbes”. “The World Register of Dams currently lists 58,519 ‘large dams’, defined as those with a dam wall of 15m or higher; these collectively store 16,120km3 of water, equivalent to 213 years of flow of Niagara Falls on the USA–Canada border.\xa0[…]\xa0Around a hundred large dam projects are in advanced planning or construction in Africa […]. More than 300 dams are planned or under construction in the Amazon Basin of South America […]. Reservoirs have a number of distinguishing features relative to natural lakes. First, the shape (‘morphometry’) of their basins is rarely circular or oval, but instead is often dendritic, with a tree-like main stem and branches ramifying out into the submerged river valleys. Second, reservoirs typically have a high catchment area to lake area ratio, again reflecting their riverine origins. For natural lakes, this ratio is relatively low […] These proportionately large catchments mean that reservoirs have short water residence times, and water quality is much better than might be the case in the absence of this rapid flushing. Nonetheless, noxious algal blooms can develop and accumulate in isolated bays and side-arms, and downstream next to the dam itself. Reservoirs typically experience water level fluctuations that are much larger and more rapid than in natural lakes, and this limits the development of littoral plants and animals. Another distinguishing feature of reservoirs is that they often show a longitudinal gradient of conditions. Upstream, the river section contains water that is flowing, turbulent, and well mixed; this then passes through a transition zone into the lake section up to the dam, which is often the deepest part of the lake and may be stratified and clearer due to decantation of land-derived particles. In some reservoirs, the water outflow is situated near the base of the dam within the hypolimnion, and this reduces the extent of oxygen depletion and nutrient build-up, while also providing cool water for fish and other animal communities below the dam. There is increasing attention being given to careful regulation of the timing and magnitude of dam outflows to maintain these downstream ecosystems. […] The downstream effects of dams continue out into the sea, with the retention of sediments and nutrients in the reservoir leaving less available for export to marine food webs. This reduction can also lead to changes in shorelines, with a retreat of the coastal delta and intrusion of seawater because natural erosion processes can no longer be offset by resupply of sediments from upstream.” “One of the most serious threats facing lakes throughout the world is the proliferation of algae and water plants caused by eutrophication, the overfertilization of waters with nutrients from human activities. […] Nutrient enrichment occurs both from ‘point sources’ of effluent discharged via pipes into the receiving waters, and ‘nonpoint sources’ such the runoff from roads and parking areas, agricultural lands, septic tank drainage fields, and terrain cleared of its nutrient- and water-absorbing vegetation. By the 1970s, even many of the world’s larger lakes had begun to show worrying signs of deterioration from these sources of increasing enrichment. […] A sharp drop in water clarity is often among the first signs of eutrophication, although in forested areas this effect may be masked for many years by the greater absorption of light by the coloured organic materials that are dissolved within the lake water. A drop in oxygen levels in the bottom waters during stratification is another telltale indicator of eutrophication, with the eventual fall to oxygen-free (anoxic) conditions in these lower strata of the lake. However, the most striking impact with greatest effect on ecosystem services is the production of harmful algal blooms (HABs), specifically by cyanobacteria. In eutrophic, temperate latitude waters, four genera of bloom-forming cyanobacteria are the usual offenders […]. These may occur alone or in combination, and although each has its own idiosyncratic size, shape, and lifestyle, they have a number of impressive biological features in common. First and foremost, their cells are typically full of hydrophobic protein cases that exclude water and trap gases. These honeycombs of gas-filled chambers, called ‘gas vesicles’, reduce the density of the cells, allowing them to float up to the surface where there is light available for growth. Put a drop of water from an algal bloom under a microscope and it will be immediately apparent that the individual cells are extremely small, and that the bloom itself is composed of billions of cells per litre of lake water.” “During the day, the [algal] cells capture sunlight and produce sugars by photosynthesis; this increases their density, eventually to the point where they are heavier than the surrounding water and sink to more nutrient-rich conditions at depth in the water column or at the sediment surface. These sugars are depleted by cellular respiration, and this loss of ballast eventually results in cells becoming less dense than water and floating again towards the surface. This alternation of sinking and floating can result in large fluctuations in surface blooms over the twenty-four-hour cycle. The accumulation of bloom-forming cyanobacteria at the surface gives rise to surface scums that then can be blown into bays and washed up onto beaches. These dense populations of colonies in the water column, and especially at the surface, can shade out bottom-dwelling water plants, as well as greatly reduce the amount of light for other phytoplankton species. The resultant ‘cyanobacterial dominance’ and loss of algal species diversity has negative implications for the aquatic food web […] This negative impact on the food web may be compounded by the final collapse of the bloom and its decomposition, resulting in a major drawdown of oxygen. […] Bloom-forming cyanobacteria are especially troublesome for the management of drinking water supplies. First, there is the overproduction of biomass, which results in a massive load of algal particles that can exceed the filtration capacity of a water treatment plant […]. Second, there is an impact on the taste of the water. […] The third and most serious impact of cyanobacteria is that some of their secondary compounds are highly toxic. […]\xa0phosphorus is the key nutrient limiting bloom development, and efforts to preserve and rehabilitate freshwaters should pay specific attention to controlling the input of phosphorus via point and nonpoint discharges to lakes.” “The aim of this book is to provide a condensed overview of scientific knowledge about lakes, their functioning as ecosystems that we are part of and depend upon, and their responses to environmental change. […] Each chapter briefly introduces concepts about the physical, chemical, and biological nature of lakes, with emphasis on how these aspects are connected, the relationships with human needs and impacts, and the implications of our changing global environment.” I’m currently reading this book and I really like it so far. I have added some observations from the first half of the book and some coverage-related links below. “High resolution satellites can readily detect lakes above 0.002 kilometres square (km2) in area; that’s equivalent to a circular waterbody some 50m across. Using this criterion, researchers estimate from satellite images that the world contains 117 million lakes, with a total surface area amounting to 5 million km2. […] continuous accumulation of materials on the lake floor, both from inflows and from the production of organic matter within the lake, means that lakes are ephemeral features of the landscape, and from the moment of their creation onwards, they begin to fill in and gradually disappear. The world’s deepest and most ancient freshwater ecosystem, Lake Baikal in Russia (Siberia), is a compelling example: it has a maximum depth of 1,642m, but its waters overlie a much deeper basin that over the twenty-five million years of its geological history has become filled with some 7,000m of sediments. Lakes are created in a great variety of ways: tectonic basins formed by movements in the Earth’s crust, the scouring and residual ice effects of glaciers, as well as fluvial, volcanic, riverine, meteorite impacts, and many other processes, including human construction of ponds and reservoirs. Tectonic basins may result from a single fault […] or from a series of intersecting fault lines. […] The oldest and deepest lakes in the world are generally of tectonic origin, and their persistence through time has allowed the evolution of endemic plants and animals; that is, species that are found only at those sites.” “In terms of total numbers, most of the world’s lakes […] owe their origins to glaciers that during the last ice age gouged out basins in the rock and deepened river valleys. […] As the glaciers retreated, their terminal moraines (accumulations of gravel and sediments) created dams in the landscape, raising water levels or producing new lakes. […] During glacial retreat in many areas of the world, large blocks of glacial ice broke off and were left behind in the moraines. These subsequently melted out to produce basins that filled with water, called ‘kettle’ or ‘pothole’ lakes. Such waterbodies are well known across the plains of North America and Eurasia. […] The most violent of lake births are the result of volcanoes. The craters left behind after a volcanic eruption can fill with water to form small, often circular-shaped and acidic lakes. […] Much larger lakes are formed by the collapse of a magma chamber after eruption to produce caldera lakes. […] Craters formed by meteorite impacts also provide basins for lakes, and have proved to be of great scientific as well as human interest. […] There was a time when limnologists paid little attention to small lakes and ponds, but, this has changed with the realization that although such waterbodies are modest in size, they are extremely abundant throughout the world and make up a large total surface area. Furthermore, these smaller waterbodies often have high rates of chemical activity such as greenhouse gas production and nutrient cycling, and they are major habitats for diverse plants and animals”. “For Forel, the science of lakes could be subdivided into different disciplines and subjects, all of which continue to occupy the attention of freshwater scientists today […]. First, the physical environment of a lake includes its geological origins and setting, the water balance and exchange of heat with the atmosphere, as well as the penetration of light, the changes in temperature with depth, and the waves, currents, and mixing processes that collectively determine the movement of water. Second, the chemical environment is important because lake waters contain a great variety of dissolved materials (‘solutes’) and particles that play essential roles in the functioning of the ecosystem. Third, the biological features of a lake include not only the individual species of plants, microbes, and animals, but also their organization into food webs, and the distribution and functioning of these communities across the bottom of the lake and in the overlying water.” “In the simplest hydrological terms, lakes can be thought of as tanks of water in the landscape that are continuously topped up by their inflowing rivers, while spilling excess water via their outflow […]. Based on this model, we can pose the interesting question: how long does the average water molecule stay in the lake before leaving at the outflow? This value is referred to as the water residence time, and it can be simply calculated as the total volume of the lake divided by the water discharge at the outlet. This lake parameter is also referred to as the ‘flushing time’ (or ‘flushing rate’, if expressed as a proportion of the lake volume discharged per unit of time) because it provides an estimate of how fast mineral salts and pollutants can be flushed out of the lake basin. In general, lakes with a short flushing time are more resilient to the impacts of human activities in their catchments […] Each lake has its own particular combination of catchment size, volume, and climate, and this translates into a water residence time that varies enormously among lakes [from perhaps a month to more than a thousand years, US] […] A more accurate approach towards calculating the water residence time is to consider the question: if the lake were to be pumped dry, how long would it take to fill it up again? For most lakes, this will give a similar value to the outflow calculation, but for lakes where evaporation is a major part of the water balance, the residence time will be much shorter.” “Each year, mineral and organic particles are deposited by wind on the lake surface and are washed in from the catchment, while organic matter is produced within the lake by aquatic plants and plankton. There is a continuous rain of this material downwards, ultimately accumulating as an annual layer of sediment on the lake floor. These lake sediments are storehouses of information about past changes in the surrounding catchment, and they provide a long-term memory of how the limnology of a lake has responded to those changes. The analysis of these natural archives is called ‘palaeolimnology’ (or ‘palaeoceanography’ for marine studies), and this branch of the aquatic sciences has yielded enormous insights into how lakes change through time, including the onset, effects, and abatement of pollution; changes in vegetation both within and outside the lake; and alterations in regional and global climate.” “Sampling for palaeolimnological analysis is typically undertaken in the deepest waters to provide a more integrated and complete picture of the lake basin history. This is also usually the part of the lake where sediment accumulation has been greatest, and where the disrupting activities of bottom-dwelling animals (‘bioturbation’ of the sediments) may be reduced or absent. […] Some of the most informative microfossils to be found in lake sediments are diatoms, an algal group that has cell walls (‘frustules’) made of silica glass that resist decomposition. Each lake typically contains dozens to hundreds of different diatom species, each with its own characteristic set of environmental preferences […]. A widely adopted approach is to sample many lakes and establish a statistical relationship or ‘transfer function’ between diatom species composition (often by analysis of surface sediments) and a lake water variable such as temperature, pH, phosphorus, or dissolved organic carbon. This quantitative species–environment relationship can then be applied to the fossilized diatom species assemblage in each stratum of a sediment core from a lake in the same region, and in this way the physical and chemical fluctuations that the lake has experienced in the past can be reconstructed or ‘hindcast’ year-by-year. Other fossil indicators of past environmental change include algal pigments, DNA of algae and bacteria including toxic bloom species, and the remains of aquatic animals such as ostracods, cladocerans, and larval insects.” “In lake and ocean studies, the penetration of sunlight into the water can be […] precisely measured with an underwater light meter (submersible radiometer), and such measurements always show that the decline with depth follows a sharp curve rather than a straight line […]. This is because the fate of sunlight streaming downwards in water is dictated by the probability of the photons being absorbed or deflected out of the light path; for example, a 50 per cent probability of photons being lost from the light beam by these processes per metre depth in a lake would result in sunlight values dropping from 100 per cent at the surface to 50 per cent at 1m, 25 per cent at 2m, 12.5 per cent at 3m, and so on. The resulting exponential curve means that for all but the clearest of lakes, there is only enough solar energy for plants, including photosynthetic cells in the plankton (phytoplankton), in the upper part of the water column. […] The depth limit for underwater photosynthesis or primary production is known as the ‘compensation depth‘. This is the depth at which carbon fixed by photosynthesis exactly balances the carbon lost by cellular respiration, so the overall production of new biomass (net primary production) is zero. This depth often corresponds to an underwater light level of 1 per cent of the sunlight just beneath the water surface […] The production of biomass by photosynthesis takes place at all depths above this level, and this zone is referred to as the ‘photic’ zone. […] biological processes in [the] ‘aphotic zone’ are mostly limited to feeding and decomposition. A Secchi disk measurement can be used as a rough guide to the extent of the photic zone: in general, the 1 per cent light level is about twice the Secchi depth.” “[W]ater colour is now used in […] many powerful ways to track changes in water quality and other properties of lakes, rivers, estuaries, and the ocean. […]\xa0Lakes have different colours, hues, and brightness levels as a result of the materials that are dissolved and suspended within them. The purest of lakes are deep blue because the water molecules themselves absorb light in the green and, to a greater extent, red end of the spectrum; they scatter the remaining blue photons in all directions, mostly downwards but also back towards our eyes. […] Algae in the water typically cause it to be green and turbid because their suspended cells and colonies contain chlorophyll and other light-capturing molecules that absorb strongly in the blue and red wavebands, but not green. However there are some notable exceptions. Noxious algal blooms dominated by cyanobacteria are blue-green (cyan) in colour caused by their blue-coloured protein phycocyanin, in addition to chlorophyll.” “[A]t the largest dimension, at the scale of the entire lake, there has to be a net flow from the inflowing rivers to the outflow, and […] from this landscape perspective, lakes might be thought of as enlarged rivers. Of course, this riverine flow is constantly disrupted by wind-induced movements of the water. When the wind blows across the surface, it drags the surface water with it to generate a downwind flow, and this has to be balanced by a return movement of water at depth. […] In large lakes, the rotation of the Earth has plenty of time to exert its weak effect as the water moves from one side of the lake to the other. As a result, the surface water no longer flows in a straight line, but rather is directed into two or more circular patterns or gyres that can move nearshore water masses rapidly into the centre of the lake and vice-versa. Gyres can therefore be of great consequence […] Unrelated to the Coriolis Effect, the interaction between wind-induced currents and the shoreline can also cause water to flow in circular, individual gyres, even in smaller lakes. […] At a much smaller scale, the blowing of wind across a lake can give rise to downward spiral motions in the water, called ‘Langmuir cells‘. […] These circulation features are commonly observed in lakes, where the spirals progressing in the general direction of the wind concentrate foam (on days of white-cap waves) or glossy, oily materials (on less windy days) into regularly spaced lines that are parallel to the direction of the wind. […] Density currents must also be included in this brief discussion of water movement […] Cold river water entering a warm lake will be denser than its surroundings and therefore sinks to the buttom, where it may continue to flow for considerable distances. […] Density currents contribute greatly to inshore-offshore exchanges of water, with potential effects on primary productivity, depp-water oxygenation, and the dispersion of pollutants.” Some more observations and links below. I may or may not add a third post about the book at a later point in time; there’s a lot of interesting stuff included in this book. “Because of the thickness of the lithosphere, its bending causes […] a stretching of its upper surface. This stretching of the upper portion of the lithosphere manifests itself as earthquakes and normal faulting, the style of faulting that occurs when a region extends horizontally […]. Such earthquakes commonly occur after great earthquakes […] Having been bent down at the trench, the lithosphere […] slides beneath the overriding lithospheric plate. Fault plane solutions of shallow focus earthquakes […] provide the most direct evidence for this underthrusting. […] In great earthquakes, […] the deformation of the surface of the Earth that occurs during such earthquakes corroborates the evidence for underthrusting of the oceanic lithosphere beneath the landward side of the trench. The 1964 Alaskan earthquake provided the first clear example. […] Because the lithosphere is much colder than the asthenosphere, when a plate of lithosphere plunges into the asthenosphere at rates of tens to more than a hundred millimetres per year, it remains colder than the asthenosphere for tens of millions of years. In the asthenosphere, temperatures approach those at which some minerals in the rock can melt. Because seismic waves travel more slowly and attenuate (lose energy) more rapidly in hot, and especially in partially molten, rock than they do in colder rock, the asthenosphere is not only a zone of weakness, but also characterized by low speeds and high attenuation of seismic waves. […] many seismologists use the waves sent by earthquakes to study the Earth’s interior, with little regard for earthquakes themselves. The speeds at which these waves propagate and the rate at which the waves die out, or attenuate, have provided much of the data used to infer the Earth’s internal structure.” “S waves especially, but also P waves, lose much of their energy while passing through the asthenosphere. The lithosphere, however, transmits P and S waves with only modest loss of energy. This difference is apparent in the extent to which small earthquakes can be felt. In regions like the western United States or in Greece and Italy, the lithosphere is thin, and the asthenosphere reaches up to shallow depths. As a result earthquakes, especially small ones, are felt over relatively small areas. By contrast, in the eastern United States or in Eastern Europe, small earthquakes can be felt at large distances. […] Deep earthquakes occur several hundred kilometres west of Japan, but they are felt with greater intensity and can be more destructive in eastern than western Japan […]. This observation, of course, puzzled Japanese seismologists when they first discovered deep focus earthquakes; usually people close to the epicentre (the point directly over the earthquake) feel stronger shaking than people farther from it. […] Tokuji Utsu […] explained this greater intensity of shaking along the more distant, eastern side of the islands than on the closer, western side by appealing to a window of low attenuation parallel to the earthquake zone and plunging through the asthenosphere beneath Japan and the Sea of Japan to its west. Paths to eastern Japan travelled efficiently through that window, the subducted slab of lithosphere, whereas those to western Japan passed through the asthenosphere and were attenuated strongly.” “Shallow earthquakes occur because stress on a fault surface exceeds the resistance to slip that friction imposes. When two objects are forced to slide past one another, and friction opposes the force that pushes one past the other, the frictional resistance can be increased by pressing the two objects together more forcefully. Many of us experience this when we put sandbags in the trunks […] of our cars in winter to give the tyres greater traction on slippery roads. The same applies to faults in the Earth’s crust. As the pressure increases with increasing depth in the Earth, frictional resistance to slip on faults should increase. For depths greater than a few tens of kilometres, the high pressure should press the two sides of a fault together so tightly that slip cannot occur. Thus, in theory, deep-focus earthquakes ought not to occur.” “In general, rock […] is brittle at low temperatures but becomes soft and flows at high temperature. The intermediate- and deep-focus earthquakes occur within the lithosphere, where at a given depth, the temperature is atypically low. […] the existence of intermediate- or deep-focus earthquakes is usually cited as evidence for atypically cold material at asthenospheric depths. Most such earthquakes, therefore, occur in oceanic lithosphere that has been subducted within the last 10–20 million years, sufficiently recently that it has not heated up enough to become soft and weak […]. The inference that the intermediate- and deep-focus earthquakes occur within the lithosphere and not along its top edge remains poorly appreciated among Earth scientists. […] the fault plane solutions suggest that the state of stress in the downgoing slab is what one would expect if the slab deformed like a board, or slab of wood. Accordingly, we infer that the earthquakes occurring within the downgoing slab of lithosphere result from stress within the slab, not from movement of the slab past the surrounding asthenosphere. Because the lithosphere is much stronger than the surrounding asthenosphere, it can support much higher stresses than the asthenosphere can. […]\xa0observations are consistent with a cold, heavy slab sinking into the asthenosphere and being pulled downward by gravity acting on it, but then encountering resistance at depths of 500–700 km despite the pull of gravity acting on the excess mass of the slab. Where both intermediate and deep-focus earthquakes occur, a gap, or a minimum, in earthquake activity near a depth of 300 km marks the transition between the upper part of the slab stretched by gravity pulling it down and the lower part where the weight of the slab above it compresses it. In the transition region between them, there would be negligible stress and, therefore, no or few earthquakes.” “Volcanoes occur where rock melts, and where that molten rock can rise to the surface. […] For essentially all minerals […] melting temperatures […] depend on the extent to which the minerals have been contaminated by impurities. […] hydrogen, when it enters most crystal lattices, lowers the melting temperature of the mineral. Hydrogen is most obviously present in water (H2O), but is hardly a major constituent of the oxygen-, silicon-, magnesium-, and iron-rich mantle. The top of the downgoing slab of lithosphere includes fractured crust and sediment deposited atop it. Oceanic crust has been stewing in seawater for tens of millions of years, so that its cracks have become full either of liquid water or of minerals to which water molecules have become loosely bound. […] the downgoing slab acts like a caravan of camels carrying water downward into an upper mantle desert. […] The downgoing slab of lithosphere carries water in cracks in oceanic crust and in the interstices among sediment grains, and when released to the mantle above it, hydrogen dissolved in crystal lattices lowers the melting temperature of that rock enough that some of it melts. Many of the world’s great volcanoes […] begin as small amounts of melt above the subducted slabs of lithosphere.” “… (in most regions) plates of lithosphere behave as rigid, and therefore undeformable, objects. The high strength of intact lithosphere, stronger than either the asthenosphere below it or the material along the boundaries of plates, allows the lithospheric plates to move with respect to one another without deforming (much). […] The essence of ‘plate tectonics’ is that vast regions move with respect to one another as (nearly) rigid objects. […] Dan McKenzie of Cambridge University, one of the scientists to present the idea of rigid plates, often argued that plate tectonics was easy to accept because the kinematics, the description of relative movements of plates, could be separated from the dynamics, the system of forces that causes plates to move with respect to one another in the directions and at the speeds that they do. Making such a separation is impossible for the flow of most fluids, […] whose movement cannot be predicted without an understanding of the forces acting on separate parcels of fluid. In part because of its simplicity, plate tectonics passed from being a hypothesis to an accepted theory in a short time.” “[F]or plates that move over the surface of a sphere, all relative motion can be described simply as a rotation about an axis that passes through the centre of the sphere. The Earth itself obviously rotates around an axis through the North and South Poles. Similarly, the relative displacement of two plates with respect to one another can be described as a rotation of one plate with respect to the other about an axis, or ‘pole’, of rotation […] if we know how two plates, for example Eurasia and Africa, move with respect to a third plate, like North America, we can calculate how those two plates (Eurasia and Africa) move with respect to each other. A rotation about an axis in the Arctic Ocean describes the movement of the Africa plate, with respect to the North America plate […]. Combining the relative motion of Africa with respect to North America with the relative motion of North America with respect to Eurasia allows us to calculate that the African continent moves toward Eurasia by a rotation about an axis that lies west of northern Africa. […] By combining the known relative motion of pairs of plates […] we can calculate how fast plates converge with respect to one another and in what direction.” “[W]e can measure how plates move with respect to one another using Global Positioning System (GPS) measurements of points on nearly all of the plates. Such measurements show that speeds of relative motion between some pairs of plates have changed a little bit since 2 million years ago, but in general, the GPS measurements corroborate the inferences drawn both from rates of seafloor spreading determined using magnetic anomalies and from directions of relative plate motion determined using orientations of transform faults and fault plane solutions of earthquakes. […] Among tests of plate tectonics, none is more convincing than the GPS measurements […] numerous predictions of rates or directions of present-day plate motions and of large displacements of huge terrains have been confirmed many times over. […] When, more than 45 years ago, plate tectonics was proposed to describe relative motions of vast terrains, most saw it as an approximation that worked well, but that surely was imperfect. […] plate tectonics is imperfect, but GPS measurements show that the plates are surprisingly rigid. […] Long histories of plate motion can be reduced to relatively few numbers, the latitudes and longitudes of the poles of rotation, and the rates or amounts of rotation about those axes.” “After evolving for nearly 150 years through the work of numerous individuals, the periodic table remains at the heart of the study of chemistry. This is mainly because it is of immense practical benefit for making predictions about all manner of chemical and physical properties of the elements and possibilities for bond formation. Instead of having to learn the properties of the 100 or more elements, the modern chemist, or the student of chemistry, can make effective predictions from knowing the properties of typical members of each of the eight main groups and those of the transition metals and rare earth elements.” I wasn’t very impressed with this book, but it wasn’t terrible. It didn’t include a lot of new stuff I didn’t already know and it focused in my opinion excessively on historical aspects; some of those things were interesting, for example the problems that confronted chemists trying to make sense of how best to categorize chemical elements in the late 19th century before the discovery of the neutron (the number of protons in the nucleus is not the same thing as the atomic weight of an atom – which was highly relevant because: “when it came to deciding upon the most important criterion for classifying the elements, Mendeleev insisted that atomic weight ordering would tolerate no exceptions”), but I’d have liked to learn a lot more about e.g. some of the chemical properties of the subgroups, instead of just revisiting stuff I’d learned earlier in other publications in the series. However I assume people who are new to chemistry – or who have forgot a lot, and would like to rectify this – might feel differently about the book and the way it covers the material included. However I don’t think this is one of the best publications in the physics/chemistry categories of this OUP series. Some quotes and links below. “Lavoisier held that an element should be defined as a material substance that has yet to be broken down into any more fundamental components. In 1789, Lavoisier published a list of 33 simple substances, or elements, according to this empirical criterion. […] the discovery of electricity enabled chemists to isolate many of the more reactive elements, which, unlike copper and iron, could not be obtained by heating their ores with charcoal (carbon). There have been a number of major episodes in the history of chemistry when half a dozen or so elements were discovered within a period of a few years. […] Following the discovery of radioactivity and nuclear fission, yet more elements were discovered. […] Today, we recognize about 90 naturally occurring elements. Moreover, an additional 25 or so elements have been artificially synthesized.” “Chemical analogies between elements in the same group are […] of great interest in the field of medicine. For example, the element beryllium sits at the top of group 2 of the periodic table and above magnesium. Because of the similarity between these two elements, beryllium can replace the element magnesium that is essential to human beings. This behaviour accounts for one of the many ways in which beryllium is toxic to humans. Similarly, the element cadmium lies directly below zinc in the periodic table, with the result that cadmium can replace zinc in many vital enzymes. Similarities can also occur between elements lying in adjacent positions in rows of the periodic table. For example, platinum lies next to gold. It has long been known that an inorganic compound of platinum called cis-platin can cure various forms of cancer. As a result, many drugs have been developed in which gold atoms are made to take the place of platinum, and this has produced some successful new drugs. […] [R]ubidium […] lies directly below potassium in group 1 of the table. […] atoms of rubidium can mimic those of potassium, and so like potassium can easily be absorbed into the human body. This behaviour is exploited in monitoring techniques, since rubidium is attracted to cancers, especially those occurring in the brain.” “Each horizontal row represents a single period of the table. On crossing a period, one passes from metals such as potassium and calcium on the left, through transition metals such as iron, cobalt, and nickel, then through some semi-metallic elements like germanium, and on to some non-metals such as arsenic, selenium, and bromine, on the right side of the table. In general, there is a smooth gradation in chemical and physical properties as a period is crossed, but exceptions to this general rule abound […] Metals themselves can vary from soft dull solids […] to hard shiny substances […]. Non-metals, on the other hand, tend to be solids or gases, such as carbon and oxygen respectively. In terms of their appearance, it is sometimes difficult to distinguish between solid metals and solid non-metals. […] The periodic trend from metals to non-metals is repeated with each period, so that when the rows are stacked, they form columns, or groups, of similar elements. Elements within a single group tend to share many important physical and chemical properties, although there are many exceptions.” “There have been quite literally over 1,000 periodic tables published in print […] One of the ways of classifying the periodic tables that have been published is to consider three basic formats. First of all, there are the originally produced short-form tables published by the pioneers of the periodic table like Newlands, Lothar Meyer, and Mendeleev […] These tables essentially crammed all the then known elements into eight vertical columns or groups. […] As more information was gathered on the properties of the elements, and as more elements were discovered, a new kind of arrangement called the medium-long-form table […] began to gain prominence. Today, this form is almost completely ubiquitous. One odd feature is that the main body of the table does not contain all the elements. […] The ‘missing’ elements are grouped together in what looks like a separate footnote that lies below the main table. This act of separating off the rare earth elements, as they have traditionally been called, is performed purely for convenience. If it were not carried out, the periodic table would appear much wider, 32 elements wide to be precise, instead of 18 elements wide. The 32-wide element format does not lend itself readily to being reproduced on the inside cover of chemistry textbooks or on large wall-charts […] if the elements are shown in this expanded form, as they sometimes are, one has the long-form periodic table, which may be said to be more correct than the familiar medium-long form, in the sense that the sequence of elements is unbroken […] there are many forms of the periodic table, some designed for different uses. Whereas a chemist might favour a form that highlights the reactivity of the elements, an electrical engineer might wish to focus on similarities and patterns in electrical conductivities.” “The periodic law states that after certain regular but varying intervals, the chemical elements show an approximate repetition in their properties. […] This periodic repetition of properties is the essential fact that underlies all aspects of the periodic system. […] The varying length of the periods of elements and the approximate nature of the repetition has caused some chemists to abandon the term ‘law’ in connection with chemical periodicity. Chemical periodicity may not seem as law-like as most laws of physics. […] A modern periodic table is much more than a collection of groups of elements showing similar chemical properties. In addition to what may be called ‘vertical relationships’, which embody triads of elements, a modern periodic table connects together groups of elements into an orderly sequence. A periodic table consists of a horizontal dimension, containing dissimilar elements, as well as a vertical dimension with similar elements.” “[I]n modern terms, metals form positive ions by the loss of electrons, while non-metals gain electrons to form negative ions. Such oppositely charged ions combine together to form neutrally charged salts like sodium chloride or calcium bromide. There are further complementary aspects of metals and non-metals. Metal oxides or hydroxides dissolve in water to form bases, while non-metal oxides or hydroxides dissolve in water to form acids. An acid and a base react together in a ‘neutralization’ reaction to form a salt and water. Bases and acids, just like metals and non-metals from which they are formed, are also opposite but complementary.” “[T]he law of constant proportion, [is] the fact that when two elements combine together, they do so in a constant ratio of their weights. […] The fact that macroscopic samples consist of a fixed ratio by weight of two elements reflects the fact that two particular atoms are combining many times over and, since they have particular masses, the product will also reflect that mass ratio. […] the law of multiple proportions [refers to the fact that] [w]hen one element A combines with another one, B, to form more than one compound, there is a simple ratio between the combining masses of B in the two compounds. For example, carbon and oxygen combine together to form carbon monoxide and carbon dioxide. The weight of combined oxygen in the dioxide is twice as much as the weight of combined oxygen in the monoxide.” “One of his greatest triumphs, and perhaps the one that he is best remembered for, is Mendeleev’s correct prediction of the existence of several new elements. In addition, he corrected the atomic weights of some elements as well as relocating other elements to new positions within the periodic table. […] But not all of Mendeleev’s predictions were so dramatically successful, a feature that seems to be omitted from most popular accounts of the history of the periodic table. […] he was unsuccessful in as many as nine out of his eighteen published predictions […] some of the elements involved the rare earths which resemble each other very closely and which posed a major challenge to the periodic table for many years to come. […] The discovery of the inert gases at the end of the 19th century [also] represented an interesting challenge to the periodic system […] in spite of Mendeleev’s dramatic predictions of many other elements, he completely failed to predict this entire group of elements (He, Ne, Ar, Kr, Xe, Rn). Moreover, nobody else predicted these elements or even suspected their existence. The first of them to be isolated was argon, in 1894 […] Mendeleev […] could not accept the notion that elements could be converted into different ones. In fact, after the Curies began to report experiments that suggested the breaking up of atoms, Mendeleev travelled to Paris to see the evidence for himself, close to the end of his life. It is not clear whether he accepted this radical new notion even after his visit to the Curie laboratory.” “While chemists had been using atomic weights to order the elements there had been a great deal of uncertainty about just how many elements remained to be discovered. This was due to the irregular gaps that occurred between the values of the atomic weights of successive elements in the periodic table. This complication disappeared when the switch was made to using atomic number. Now the gaps between successive elements became perfectly regular, namely one unit of atomic number. […] The discovery of isotopes […] came about partly as a matter of necessity. The new developments in atomic physics led to the discovery of a number of new elements such as Ra, Po, Rn, and Ac which easily assumed their rightful places in the periodic table. But in addition, 30 or so more apparent new elements were discovered over a short period of time. These new species were given provisional names like thorium emanation, radium emanation, actinium X, uranium X, thorium X, and so on, to indicate the elements which seemed to be producing them. […] To Soddy, the chemical inseparability [of such elements] meant only one thing, namely that these were two forms, or more, of the same chemical element. In 1913, he coined the term ‘isotopes’ to signify two or more atoms of the same element which were chemically completely inseparable, but which had different atomic weights.” “The popular view reinforced in most textbooks is that chemistry is nothing but physics ‘deep down’ and that all chemical phenomena, and especially the periodic system, can be developed on the basis of quantum mechanics. […] This is important because chemistry books, especially textbooks aimed at teaching, tend to give the impression that our current explanation of the periodic system is essentially complete. This is just not the case […]\xa0the energies of the quantum states for any many-electron atom can be approximately calculated from first principles although there is extremely good agreement with observed energy values. Nevertheless, some global aspects of the periodic table have still not been derived from first principles to this day. […] We know where the periods close because we know that the noble gases occur at elements 2, 10, 18, 36, 54, etc. Similarly, we have a knowledge of the order of orbital filling from observations but not from theory. The conclusion, seldom acknowledged in textbook accounts of the explanation of the periodic table, is that quantum physics only partly explains the periodic table. Nobody has yet deduced the order of orbital filling from the principles of quantum mechanics. […] The situation that exists today is that chemistry, and in particular the periodic table, is regarded as being fully explained by quantum mechanics. Even though this is not quite the case, the explanatory role that the theory continues to play is quite undeniable. But what seems to be forgotten […] is that the periodic table led to the development of many aspects of modern quantum mechanics, and so it is rather short-sighted to insist that only the latter explains the former.” “[N]uclei with an odd number of protons are invariably more unstable than those with an even number of protons. This difference in stability occurs because protons, like electrons, have a spin of one half and enter into energy orbitals, two by two, with opposite spins. It follows that even numbers of protons frequently produce total spins of zero and hence more stable nuclei than those with unpaired proton spins as occurs in nuclei with odd numbers of protons […] The larger the nuclear charge, the faster the motion of inner shell electrons. As a consequence of gaining relativistic speeds, such inner electrons are drawn closer to the nucleus, and this in turn has the effect of causing greater screening on the outermost electrons which determine the chemical properties of any particular element. It has been predicted that some atoms should behave chemically in a manner that is unexpected from their presumed positions in the periodic table. Relativistic effects thus pose the latest challenge to test the universality of the periodic table. […] The conclusion [however] seem to be that chemical periodicity is a remarkably robust phenomenon.” This is my second and last post about the book. Some more links and quotes below. “Many of the currently operating reactors were built in the late 1960s and 1970s. With a global hiatus on nuclear reactor construction following the Three Mile Island incident and the Chernobyl disaster, there is a dearth of nuclear power replacement capacity as the present fleet faces decommissioning. Nuclear power stations, like coal-, gas-, and oil-fired stations, produce heat to generate electricity and all require water for cooling. The US Geological Survey estimates that this use of water for cooling power stations accounts for over 3% of all water consumption. Most nuclear power plants are built close to the sea so that the ocean can be used as a heat dump. […] The need for such large quantities of water inhibits the use of nuclear power in arid regions of the world. […] The higher the operating temperature, the greater the water usage. […] [L]arge coal, gas and nuclear plants […] can consume millions of litres per hour”. “A nuclear reactor is utilizing the strength of the force between nucleons while hydrocarbon burning is relying on the chemical bonding between molecules. Since the nuclear bonding is of the order of a million times stronger than the chemical bonding, the mass of hydrocarbon fuel necessary to produce a given amount of energy is about a million times greater than the equivalent mass of nuclear fuel. Thus, while a coal station might burn millions of tonnes of coal per year, a nuclear station with the same power output might consume a few tonnes.” “There are a number of reasons why one might wish to reprocess the spent nuclear fuel. These include: to produce plutonium either for nuclear weapons or, increasingly, as a fuel-component for fast reactors; the recycling of all actinides for fast-breeder reactors, closing the nuclear fuel cycle, greatly increasing the energy extracted from natural uranium; the recycling of plutonium in order to produce mixed oxide fuels for thermal reactors; recovering enriched uranium from spent fuel to be recycled through thermal reactors; to extract expensive isotopes which are of value to medicine, agriculture, and industry. An integral part of this process is the management of the radioactive waste. Currently 40% of all nuclear fuel is obtained by reprocessing. […] The La Hague site is the largest reprocessing site in the world, with over half the global capacity at 1,700 tonnes of spent fuel per year. […] The world’s largest user of nuclear power, the USA, currently does not reprocess its fuel and hence produces [large] quantities of radioactive waste. […] The principal reprocessors of radioactive waste are France and the UK. Both countries receive material from other countries and after reprocessing return the raffinate to the country of origin for final disposition.” “Nearly 45,000 tonnes of uranium are mined annually. More than half comes from the three largest producers, Canada, Kazakhstan, and Australia.” “The designs of nuclear installations are required to be passed by national nuclear licensing agencies. These include strict safety and security features. The international standard for the integrity of a nuclear power plant is that it would withstand the crash of a Boeing 747 Jumbo Jet without the release of hazardous radiation beyond the site boundary. […] At Fukushima, the design was to current safety standards, taking into account the possibility of a severe earthquake; what had not been allowed for was the simultaneous tsunami strike.” “The costing of nuclear power is notoriously controversial. Opponents point to the past large investments made in nuclear research and would like to factor this into the cost. There are always arguments about whether or not decommissioning costs and waste-management costs have been properly accounted for. […] which electricity source is most economical will vary from country to country […]. As with all industrial processes, there can be economies of scale. In the USA, and particularly in the UK, these economies of scale were never fully realized. In the UK, while several Magnox and AGR reactors were built, no two were of exactly the same design, resulting in no economies in construction costs, component manufacture, or staff training programmes. The issue is compounded by the high cost of licensing new designs. […] in France, the Regulatory Commission agreed a standard design for all plants and used a safety engineering process similar to that used for licensing aircraft. Public debate was thereafter restricted to local site issues. Economies of scale were achieved.” “[C]onstruction costs […] are the largest single factor in the cost of nuclear electricity generation. […] Because the raw fuel is such a small fraction of the cost of nuclear power generation, the cost of electricity is not very sensitive to the cost of uranium, unlike the fossil fuels, for which fuel can represent up to 70% of the cost. Operating costs for nuclear plants have fallen dramatically as the French practice of standardization of design has spread. […] Generation III+ reactors are claimed to be half the size and capable of being built in much shorter times than the traditional PWRs. The 2008 contracted capital cost of building new plants containing two AP1000 reactors in the USA is around $10–$14billion, […] There is considerable experience of decommissioning of nuclear plants. In the USA, the cost of decommissioning a power plant is approximately $350 million. […] In France and Sweden, decommissioning costs are estimated to be 10–15% of construction costs and are included in the price charged for electricity. […] The UK has by far the highest estimates for decommissioning which are set at £1 billion per reactor. This exceptionally high figure is in part due to the much larger reactor core associated with graphite moderated piles. […] It is clear that in many countries nuclear-generated electricity is commercially competitive with fossil fuels despite the need to include the cost of capital and all waste disposal and decommissioning (factors that are not normally included for other fuels). […] At the present time, without the market of taxes and grants, electricity generated from renewable sources is generally more expensive than that from nuclear power or fossil fuels. This leaves the question: if nuclear power is so competitive, why is there not a global rush to build new nuclear power stations? The answer lies in the time taken to recoup investments. Investors in a new gas-fired power station can expect to recover their investment within 15 years. Because of the high capital start-up costs, nuclear power stations yield a slower rate of return, even though over the lifetime of the plant the return may be greater.” “Throughout the 20th century, the population and GDP growth combined to drive the [global] demand for energy to increase at a rate of 4% per annum […]. The most conservative estimate is that the demand for energy will see global energy requirements double between 2000 and 2050. […] The demand for electricity is growing at twice the rate of the demand for energy. […] More than two-thirds of all electricity is generated by burning fossil fuels. […] The most rapidly growing renewable source of electricity generation is wind power […] wind is an intermittent source of electricity. […] The intermittency of wind power leads to [a] problem. The grid management has to supply a steady flow of electricity. Intermittency requires a heavy overhead on grid management, and there are serious concerns about the ability of national grids to cope with more than a 20% contribution from wind power. […] As for the other renewables, solar and geothermal power, significant electricity generation will be restricted to latitudes 40°S to 40°N and regions of suitable geological structures, respectively. Solar power and geothermal power are expected to increase but will remain a small fraction of the total electricity supply. […] In most industrialized nations, the current electricity supply is via a regional, national, or international grid. The electricity is generated in large (~1GW) power stations. This is a highly efficient means of electricity generation and distribution. If the renewable sources of electricity generation are to become significant, then a major restructuring of the distribution infrastructure will be necessary. While local ‘microgeneration’ can have significant benefits for small communities, it is not practical for the large-scale needs of big industrial cities in which most of the world’s population live.” “Electricity cannot be stored in large quantities. If the installed generating capacity is designed to meet peak demand, there will be periods when the full capacity is not required. In most industrial countries, the average demand is only about one-third of peak consumption.” I originally gave the book 2 stars, but after I had finished this post I changed that rating to 3 stars (which was not that surprising; already when I wrote my goodreads review shortly after having read the book I was conflicted about whether or not the book deserved the third star). One thing that kept me from giving the book a higher rating was that I thought that the author did not spend enough time on ‘the basic concepts’, a problem I also highlighted in my goodreads review. I’d fortunately recently covered some of those concepts in other books in the series, so it wasn’t too hard for me to follow what was going on, but as sometimes happens for authors of books in this series, I think the author simply was trying to cover too much stuff. But even so this is a nice introductory text on this topic. I have added some links and quotes related to the first half or so of the book below. I prepared the link list before I started gathering quotes for my coverage, so there may be more overlap in terms of which topics are covered both in the quotes and the links than there usually is (I normally tend to reserve the links for topics and concepts which are covered in these books that I don’t find it necessary to cover in detail in the text – the links are meant to remind me/indicate which sort of topics are also covered in the book, aside from the topics included in the text coverage). “According to Einstein’s mass–energy equation, the mass of any composite stable object has to be less than the sum of the masses of the parts; the difference is the binding energy of the object. […] The general features of the binding energies are simply understood as follows. We have seen that the measured radii of nuclei [increase] with the cube root of the mass number A. This is consistent with a structure of close packed nucleons. If each nucleon could only interact with its closest neighbours, the total binding energy would then itself be proportional to the number of nucleons. However, this would be an overestimate because nucleons at the surface of the nucleus would not have a complete set of nearest neighbours with which to interact […]. The binding energy would be reduced by the number of surface nucleons and this would be proportional to the surface area, itself proportional to A2/3. So far we have considered only the attractive short-range nuclear binding. However, the protons carry an electric charge and hence experience an electrical repulsion between each other. The electrical force between two protons is much weaker than the nuclear force at short distances but dominates at larger distances. Furthermore, the total electrical contribution increases with the number of pairs of protons.” “The main characteristics of the empirical binding energy of nuclei […] can now be explained. For the very light nuclei, all the nucleons are in the surface, the electrical repulsion is negligible, and the binding energy increases as the volume and number of nucleons increases. Next, the surface effects start to slow the rate of growth of the binding energy yielding a region of most stable nuclei near charge number Z = 28 (iron). Finally, the electrical repulsion steadily increases until we reach the most massive stable nucleus (lead-208). Between iron and lead, not only does the binding energy decrease so also do the proton to neutron ratios since the neutrons do not experience the electrical repulsion. […] as the nuclei get heavier the Coulomb repulsion term requires an increasing number of neutrons for stability […] For an explanation of [the] peaks, we must turn to the quantum nature of the problem. […] Filled shells corresponded to particularly stable electronic structures […] In the nuclear case, a shell structure also exists separately for both the neutrons and the protons. […] Closed-shell nuclei are referred to as ‘magic number’ nuclei. […] there is a particular stability for nuclei with equal numbers of protons and neutrons.” “As we move off the line of stable nuclei, by adding or subtracting neutrons, the isotopes become increasingly less stable indicated by increasing levels of beta radioactivity. Nuclei with a surfeit of neutrons emit an electron, hence converting one of the neutrons into a proton, while isotopes with a neutron deficiency can emit a positron with the conversion of a proton into a neutron. For the heavier nuclei, the neutron to proton ratio can be reduced by emitting an alpha particle. All nuclei heavier than lead are unstable and hence radioactive alpha emitters. […] The fact that almost all the radioactive isotopes heavier than lead follow [a] kind of decay chain and end up as stable isotopes of lead explains this element’s anomalously high natural abundance.” “When two particles collide, they transfer energy and momentum between themselves. […] If the target is much lighter than the projectile, the projectile sweeps it aside with little loss of energy and momentum. If the target is much heavier than the projectile, the projectile simply bounces off the target with little loss of energy. The maximum transfer of energy occurs when the target and the projectile have the same mass. In trying to slow down the neutrons, we need to pass them through a moderator containing scattering centres of a similar mass. The obvious candidate is hydrogen, in which the single proton of the nucleus is the particle closest in mass to the neutron. At first glance, it would appear that water, with its low cost and high hydrogen content, would be the ideal moderator. There is a problem, however. Slow neutrons can combine with protons to form an isotope of hydrogen, deuterium. This removes neutrons from the chain reaction. To overcome this, the uranium fuel has to be enriched by increasing the proportion of uranium-235; this is expensive and technically difficult. An alternative is to use heavy water, that is, water in which the hydrogen is replaced by deuterium. It is not quite as effective as a moderator but it does not absorb neutrons. Heavy water is more expensive and its production more technically demanding than natural water. Finally, graphite (carbon) has a mass of 12 and hence is less efficient requiring a larger reactor core, but it is inexpensive and easily available.” “[During the Manhattan Project,] Oak Ridge, Tennessee, was chosen as the facility to develop techniques for uranium enrichment (increasing the relative abundance of uranium-235) […] a giant gaseous diffusion facility was developed. Gaseous uranium hexafluoride was forced through a semi permeable membrane. The lighter isotopes passed through faster and at each pass through the membrane the uranium hexafluoride became more and more enriched. The technology is very energy consuming […]. At its peak, Oak Ridge consumed more electricity than New York and Washington DC combined. Almost one-third of all enriched uranium is still produced by this now obsolete technology. The bulk of enriched uranium today is produced in high-speed centrifuges which require much less energy.” “In order to sustain a nuclear chain reaction, it is essential to have a critical mass of fissile material. This mass depends upon the fissile fuel being used and the topology of the structure containing it. […] The chain reaction is maintained by the neutrons and many of these leave the surface without contributing to the reaction chain. Surrounding the fissile material with a blanket of neutron reflecting material, such as beryllium metal, will keep the neutrons in play and reduce the critical mass. Partially enriched uranium will have an increased critical mass and natural uranium (0.7% uranium-235) will not go critical at any mass without a moderator to increase the number of slow neutrons which are the dominant fission triggers. The critical mass can also be decreased by compressing the fissile material.” “It is now more than 50 years since operations of the first civil nuclear reactor began. In the intervening years, several hundred reactors have been operating, in total amounting to nearly 50 million hours of experience. This cumulative experience has led to significant advances in reactor design. Different reactor types are defined by their choice of fuel, moderator, control rods, and coolant systems. The major advances leading to greater efficiency, increased economy, and improved safety are referred to as ‘generations’. […] [F]irst generation reactors […] had the dual purpose to make electricity for public consumption and plutonium for the Cold War stockpiles of nuclear weapons. Many of the features of the design were incorporated to meet the need for plutonium production. These impacted on the electricity-generating cost and efficiency. The most important of these was the use of unenriched uranium due to the lack of large-scale enrichment plants in the UK, and the high uranium-238 content was helpful in the plutonium production but made the electricity generation less efficient.” “PWRs, BWRs, and VVERs are known as LWRs (Light Water Reactors). LWRs dominate the world’s nuclear power programme, with the USA operating 69 PWRs and 35 BWRs; Japan operates 63 LWRs, the bulk of which are BWRs; and France has 59 PWRs. Between them, these three countries generate 56% of the world’s nuclear power. […] In the 1990s, a series of advanced versions of the Generation II and III reactors began to receive certification. These included the ACR (Advanced CANDU Reactor), the EPR (European Pressurized Reactor), and Westinghouse AP1000 and APR1400 reactors (all developments of the PWR) and ESBWR (a development of the BWR). […] The ACR uses slightly enriched uranium and a light water coolant, allowing the core to be halved in size for the same power output. […] It would appear that two of the Generation III+ reactors, the EPR […] and AP1000, are set to dominate the world market for the next 20 years. […]\xa0[…] the EPR is considerably safer than current reactor designs. […] A major advance is that the generation 3+ reactors produce only about 10 % of waste compared with earlier versions of LWRs. […] China has officially adopted the AP1000 design as a standard for future nuclear plants and has indicated a wish to see 100 nuclear plants under construction or in operation by 2020.” A few quotes from the book and some related links below. Here’s my very short goodreads review of the book. “The main naturally occurring radionuclides of primordial origin are uranium-235, uranium-238, thorium-232, their decay products, and potassium-40. The average abundance of uranium, thorium, and potassium in the terrestrial crust is 2.6 parts per million, 10 parts per million, and 1% respectively. Uranium and thorium produce other radionuclides via neutron- and alpha-induced reactions, particularly deeply underground, where uranium and thorium have a high concentration. […] A weak source of natural radioactivity derives from nuclear reactions of primary and secondary cosmic rays with the atmosphere and the lithosphere, respectively. […] Accretion of extraterrestrial material, intensively exposed to cosmic rays in space, represents a minute contribution to the total inventory of radionuclides in the terrestrial environment. […] Natural radioactivity is [thus] mainly produced by uranium, thorium, and potassium. The total heat content of the Earth, which derives from this radioactivity, is 12.6 × 1024 MJ (one megajoule = 1 million joules), with the crust’s heat content standing at 5.4 × 1021 MJ. For comparison, this is significantly more than the 6.4 × 1013 MJ globally consumed for electricity generation during 2011. This energy is dissipated, either gradually or abruptly, towards the external layers of the planet, but only a small fraction can be utilized. The amount of energy available depends on the Earth’s geological dynamics, which regulates the transfer of heat to the surface of our planet. The total power dissipated by the Earth is 42 TW (one TW = 1 trillion watts): 8 TW from the crust, 32.3 TW from the mantle, 1.7 TW from the core. This amount of power is small compared to the 174,000 TW arriving to the Earth from the Sun.” “Charged particles such as protons, beta and alpha particles, or heavier ions that bombard human tissue dissipate their energy locally, interacting with the atoms via the electromagnetic force. This interaction ejects electrons from the atoms, creating a track of electron–ion pairs, or ionization track. The energy that ions lose per unit path, as they move through matter, increases with the square of their charge and decreases linearly with their energy […] The energy deposited in the tissues and organs of your body by ionizing radiation is defined absorbed dose and is measured in gray. The dose of one gray corresponds to the energy of one joule deposited in one kilogram of tissue. The biological damage wrought by a given amount of energy deposited depends on the kind of ionizing radiation involved. The equivalent dose, measured in sievert, is the product of the dose and a factor w related to the effective damage induced into the living matter by the deposit of energy by specific rays or particles. For X-rays, gamma rays, and beta particles, a gray corresponds to a sievert; for neutrons, a dose of one gray corresponds to an equivalent dose of 5 to 20 sievert, and the factor w is equal to 5–20 (depending on the neutron energy). For protons and alpha particles, w is equal to 5 and 20, respectively. There is also another weighting factor taking into account the radiosensitivity of different organs and tissues of the body, to evaluate the so-called effective dose. Sometimes the dose is still quoted in rem, the old unit, with 100 rem corresponding to one sievert.” “Neutrons emitted during fission reactions have a relatively high velocity. When still in Rome, Fermi had discovered that fast neutrons needed to be slowed down to increase the probability of their reaction with uranium. The fission reaction occurs with uranium-235. Uranium-238, the most common isotope of the element, merely absorbs the slow neutrons. Neutrons slow down when they are scattered by nuclei with a similar mass. The process is analogous to the interaction between two billiard balls in a head-on collision, in which the incoming ball stops and transfers all its kinetic energy to the second one. ‘Moderators’, such as graphite and water, can be used to slow neutrons down. […] When Fermi calculated whether a chain reaction could be sustained in a homogeneous mixture of uranium and graphite, he got a negative answer. That was because most neutrons produced by the fission of uranium-235 were absorbed by uranium-238 before inducing further fissions. The right approach, as suggested by Szilárd, was to use separated blocks of uranium and graphite. Fast neutrons produced by the splitting of uranium-235 in the uranium block would slow down, in the graphite block, and then produce fission again in the next uranium block. […] A minimum mass – the critical mass – is required to sustain the chain reaction; furthermore, the material must have a certain geometry. The fissile nuclides, capable of sustaining a chain reaction of nuclear fission with low-energy neutrons, are uranium-235 […], uranium-233, and plutonium-239. The last two don’t occur in nature but can be produced artificially by irradiating with neutrons thorium-232 and uranium-238, respectively – via a reaction called neutron capture. Uranium-238 (99.27%) is fissionable, but not fissile. In a nuclear weapon, the chain reaction occurs very rapidly, releasing the energy in a burst.” “The basic components of nuclear power reactors, fuel, moderator, and control rods, are the same as in the first system built by Fermi, but the design of today’s reactors includes additional components such as a pressure vessel, containing the reactor core and the moderator, a containment vessel, and redundant and diverse safety systems. Recent technological advances in material developments, electronics, and information technology have further improved their reliability and performance. […] The moderator to slow down fast neutrons is sometimes still the graphite used by Fermi, but water, including ‘heavy water’ – in which the water molecule has a deuterium atom instead of a hydrogen atom – is more widely used. Control rods contain a neutron-absorbing material, such as boron or a combination of indium, silver, and cadmium. To remove the heat generated in the reactor core, a coolant – either a liquid or a gas – is circulating through the reactor core, transferring the heat to a heat exchanger or directly to a turbine. Water can be used as both coolant and moderator. In the case of boiling water reactors (BWRs), the steam is produced in the pressure vessel. In the case of pressurized water reactors (PWRs), the steam generator, which is the secondary side of the heat exchanger, uses the heat produced by the nuclear reactor to make steam for the turbines. The containment vessel is a one-metre-thick concrete and steel structure that shields the reactor.” “Nuclear energy contributed 2,518 TWh of the world’s electricity in 2011, about 14% of the global supply. As of February 2012, there are 435 nuclear power plants operating in 31 countries worldwide, corresponding to a total installed capacity of 368,267 MW (electrical). There are 63 power plants under construction in 13 countries, with a capacity of 61,032 MW (electrical).” “Since the first nuclear fusion, more than 60 years ago, many have argued that we need at least 30 years to develop a working fusion reactor, and this figure has stayed the same throughout those years.” “[I]onizing radiation is […] used to improve many properties of food and other agricultural products. For example, gamma rays and electron beams are used to sterilize seeds, flour, and spices. They can also inhibit sprouting and destroy pathogenic bacteria in meat and fish, increasing the shelf life of food. […] More than 60 countries allow the irradiation of more than 50 kinds of foodstuffs, with 500,000 tons of food irradiated every year. About 200 cobalt-60 sources and more than 10 electron accelerators are dedicated to food irradiation worldwide. […] With the help of radiation, breeders can increase genetic diversity to make the selection process faster. The spontaneous mutation rate (number of mutations per gene, for each generation) is in the range\xa010-8–10-5. Radiation can increase this mutation rate to 10-5–10-2. […] Long-lived cosmogenic radionuclides provide unique methods to evaluate the ‘age’ of groundwaters, defined as the mean subsurface residence time after the isolation of the water from the atmosphere. […] Scientists can date groundwater more than a million years old, through chlorine-36, produced in the atmosphere by cosmic-ray reactions with argon.” “Radionuclide imaging was developed in the 1950s using special systems to detect the emitted gamma rays. The gamma-ray detectors, called gamma cameras, use flat crystal planes, coupled to photomultiplier tubes, which send the digitized signals to a computer for image reconstruction. Images show the distribution of the radioactive tracer in the organs and tissues of interest. This method is based on the introduction of low-level radioactive chemicals into the body. […] More than 100 diagnostic tests based on radiopharmaceuticals are used to examine bones and organs such as lungs, intestines, thyroids, kidneys, the liver, and gallbladder. They exploit the fact that our organs preferentially absorb different chemical compounds. […] Many radiopharmaceuticals are based on technetium-99m (an excited state of technetium-99 – the ‘m’ stands for ‘metastable’ […]). This radionuclide is used for the imaging and functional examination of the heart, brain, thyroid, liver, and other organs. Technetium-99m is extracted from molybdenum-99, which has a much longer half-life and is therefore more transportable. It is used in 80% of the procedures, amounting to about 40,000 per day, carried out in nuclear medicine. Other radiopharmaceuticals include short-lived gamma-emitters such as cobalt-57, cobalt-58, gallium-67, indium-111, iodine-123, and thallium-201. […] Methods routinely used in medicine, such as X-ray radiography and CAT, are increasingly used in industrial applications, particularly in non-destructive testing of containers, pipes, and walls, to locate defects in welds and other critical parts of the structure.” “Today, cancer treatment with radiation is generally based on the use of external radiation beams that can target the tumour in the body. Cancer cells are particularly sensitive to damage by ionizing radiation and their growth can be controlled or, in some cases, stopped. High-energy X-rays produced by a linear accelerator […] are used in most cancer therapy centres, replacing the gamma rays produced from cobalt-60. The LINAC produces photons of variable energy bombarding a target with a beam of electrons accelerated by microwaves. The beam of photons can be modified to conform to the shape of the tumour, which is irradiated from different angles. The main problem with X-rays and gamma rays is that the dose they deposit in the human tissue decreases exponentially with depth. A considerable fraction of the dose is delivered to the surrounding tissues before the radiation hits the tumour, increasing the risk of secondary tumours. Hence, deep-seated tumours must be bombarded from many directions to receive the right dose, while minimizing the unwanted dose to the healthy tissues. […] The problem of delivering the needed dose to a deep tumour with high precision can be solved using collimated beams of high-energy ions, such as protons and carbon. […] Contrary to X-rays and gamma rays, all ions of a given energy have a certain range, delivering most of the dose after they have slowed down, just before stopping. The ion energy can be tuned to deliver most of the dose to the tumour, minimizing the impact on healthy tissues. The ion beam, which does not broaden during the penetration, can follow the shape of the tumour with millimetre precision. Ions with higher atomic number, such as carbon, have a stronger biological effect on the tumour cells, so the dose can be reduced. Ion therapy facilities are [however] still very expensive – in the range of hundreds of millions of pounds – and difficult to operate.” “About 50 million years ago, a global cooling trend took our planet from the tropical conditions at the beginning of the Tertiary to the ice ages of the Quaternary, when the Arctic ice cap developed. The temperature decrease was accompanied by a decrease in atmospheric CO2 from 2,000 to 300 parts per million. The cooling was probably caused by a reduced greenhouse effect and also by changes in ocean circulation due to plate tectonics. The drop in temperature was not constant as there were some brief periods of sudden warming. Ocean deep-water temperatures dropped from 12°C, 50 million years ago, to 6°C, 30 million years ago, according to archives in deep-sea sediments (today, deep-sea waters are about 2°C). […] During the last 2 million years, the mean duration of the glacial periods was about 26,000 years, while that of the warm periods – interglacials – was about 27,000 years. Between 2.6 and 1.1 million years ago, a full cycle of glacial advance and retreat lasted about 41,000 years. During the past 1.2 million years, this cycle has lasted 100,000 years. Stable and radioactive isotopes play a crucial role in the reconstruction of the climatic history of our planet”. A decent book. Below some quotes and links. “[A]ll mass spectrometers have three essential components — an ion source, a mass filter, and some sort of detector […] Mass spectrometers need to achieve high vacuum to allow the uninterrupted transmission of ions through the instrument. However, even high-vacuum systems contain residual gas molecules which can impede the passage of ions. Even at very high vacuum there will still be residual gas molecules in the vacuum system that present potential obstacles to the ion beam. Ions that collide with residual gas molecules lose energy and will appear at the detector at slightly lower mass than expected. This tailing to lower mass is minimized by improving the vacuum as much as possible, but it cannot be avoided entirely. The ability to resolve a small isotope peak adjacent to a large peak is called ‘abundance sensitivity’. A single magnetic sector TIMS has abundance sensitivity of about 1 ppm per mass unit at uranium masses. So, at mass 234, 1 ion in 1,000,000 will actually be 235U not 234U, and this will limit our ability to quantify the rare 234U isotope. […]\xa0AMS [accelerator mass spectrometry] instruments use very high voltages to achieve high abundance sensitivity. […]\xa0As I write this chapter, the human population of the world has recently exceeded seven billion. […] one carbon atom in 1012 is mass 14. So, detecting 14C is far more difficult than identifying a single person on Earth, and somewhat comparable to identifying an individual leaf in the Amazon rain forest. Such is the power of isotope ratio mass spectrometry.” “14C is produced in the Earth’s atmosphere by the interaction between nitrogen and cosmic ray neutrons that releases a free proton turning 147N into 146C in a process that we call an ‘n-p’ reaction […] Because the process is driven by cosmic ray bombardment, we call 14C a ‘cosmogenic’ isotope. The half-life of 14C is about 5,000 years, so we know that all the 14C on Earth is either cosmogenic or has been created by mankind through nuclear reactors and bombs — no ‘primordial’ 14C remains because any that originally existed has long since decayed.\xa014C is not the only cosmogenic isotope; 16O in the atmosphere interacts with cosmic radiation to produce the isotope 10Be (beryllium). […] The process by which a high energy cosmic ray particle removes several nucleons is called ‘spallation’. 10Be production from 16O is not restricted to the atmosphere but also occurs when cosmic rays impact rock surfaces. […] when cosmic rays hit a rock surface they don’t bounce off but penetrate the top 2 or 3 metres (m) — the actual ‘attenuation’ depth will vary for particles of different energy. Most of the Earth’s crust is made of silicate minerals based on bonds between oxygen and silicon. So, the same spallation process that produces 10Be in the atmosphere also occurs in rock surfaces. […] If we know the flux of cosmic rays impacting a surface, the rate of production of the cosmogenic isotopes with depth below the rock surface, and the rate of radioactive decay, it should be possible to convert the number of cosmogenic atoms into an exposure age. […] Rocks on Earth which are shielded from much of the cosmic radiation have much lower levels of isotopes like 10Be than have meteorites which, before they arrive on Earth, are exposed to the full force of cosmic radiation. […] polar scientists have used cores drilled through ice sheets in Antarctica and Greenland to compare 10Be at different depths and thereby reconstruct 10Be production through time. The 14C and 10Be records are closely correlated indicating the common response to changes in the cosmic ray flux.” “[O]nce we have credible cosmogenic isotope production rates, […] there are two classes of applications, which we can call ‘exposure’ and ‘burial’ methodologies. Exposure studies simply measure the accumulation of the cosmogenic nuclide. Such studies are simplest when the cosmogenic nuclide is a stable isotope like 3He and 21Ne. These will just accumulate continuously as the sample is exposed to cosmic radiation. Slightly more complicated are cosmogenic isotopes that are radioactive […]. These isotopes accumulate through exposure but will also be destroyed by radioactive decay. Eventually, the isotopes achieve the condition known as ‘secular equilibrium’ where production and decay are balanced and no chronological information can be extracted. Secular equilibrium is achieved after three to four half-lives […] Imagine a boulder that has been transported from its place of origin to another place within a glacier — what we call a glacial erratic. While the boulder was deeply covered in ice, it would not have been exposed to cosmic radiation. Its cosmogenic isotopes will only have accumulated since the ice melted. So a cosmogenic isotope exposure age tells us the date at which the glacier retreated, and, by examining multiple erratics from different locations along the course of the glacier, allows us to construct a retreat history for the de-glaciation. […] Burial methodologies using cosmogenic isotopes work in situations where a rock was previously exposed to cosmic rays but is now located in a situation where it is shielded.” “Cosmogenic isotopes are also being used extensively to recreate the seismic histories of tectonically active areas. Earthquakes occur when geological faults give way and rock masses move. A major earthquake is likely to expose new rock to the Earth’s surface. If the field geologist can identify rocks in a fault zone that (s)he is confident were brought to the surface in an earthquake, then a cosmogenic isotope exposure age would date the fault — providing, of course, that subsequent erosion can be ruled out or quantified. Precarious rocks are rock outcrops that could reasonably be expected to topple if subjected to a significant earthquake. Dating the exposed surface of precarious rocks with cosmogenic isotopes can reveal the amount of time that has elapsed since the last earthquake of a magnitude that would have toppled the rock. Constructing records of seismic history is not merely of academic interest; some of the world’s seismically active areas are also highly populated and developed.” “One aspect of the natural decay series that acts in favour of the preservation of accurate age information is the fact that most of the intermediate isotopes are short-lived. For example, in both the U series the radon (Rn) isotopes, which might be expected to diffuse readily out of a mineral, have half-lives of only seconds or days, too short to allow significant losses. Some decay series isotopes though do have significantly long half-lives which offer the potential to be geochronometers in their own right. […] These techniques depend on the tendency of natural decay series to evolve towards a state of ‘secular equilibrium’ in which the activity of all species in the decay series is equal. […] at secular equilibrium, isotopes with long half-lives (i.e. small decay constants) will have large numbers of atoms whereas short-lived isotopes (high decay constants) will only constitute a relatively small number of atoms. Since decay constants vary by several orders of magnitude, so will the numbers of atoms of each isotope in the equilibrium decay series. […] Geochronological applications of natural decay series depend upon some process disrupting the natural decay series to introduce either a deficiency or an excess of an isotope in the series. The decay series will then gradually return to secular equilibrium and the geochronometer relies on measuring the extent to which equilibrium has been approached.” “The ‘ring of fire’ volcanoes around the margin of the Pacific Ocean are a manifestation of subduction in which the oldest parts of the Pacific Ocean crust are being returned to the mantle below. The oldest parts of the Pacific Ocean crust are about 150 million years (Ma) old, with anything older having already disappeared into the mantle via subduction zones. The Atlantic Ocean doesn’t have a ring of fire because it is a relatively young ocean which started to form about 60 Ma ago, and its oldest rocks are not yet ready to form subduction zones. Thus, while continental crust persists for billions of years, oceanic crust is a relatively transient (in terms of geological time) phenomenon at the Earth’s surface.” “Mantle rocks typically contain minerals such as olivine, pyroxene, spinel, and garnet. Unlike say ice, which melts to form water, mixtures of minerals do not melt in the proportions in which they occur in the rock. Rather, they undergo partial melting in which some minerals […] melt preferentially leaving a solid residue enriched in refractory minerals […]. We know this from experimentally melting mantle-like rocks in the laboratory, but also because the basalts produced by melting of the mantle are closer in composition to Ca-rich (clino-) pyroxene than to the olivine-rich rocks that dominate the solid pieces (or xenoliths) of mantle that are sometimes transferred to the surface by certain types of volcanic eruptions. […] Thirty years ago geologists fiercely debated whether the mantle was homogeneous or heterogeneous; mantle isotope geochemistry hasn’t yet elucidated all the details but it has put to rest the initial conundrum; Earth’s mantle is compositionally heterogeneous.” I am no longer a student, but for multiple reasons I have decided to keep blogging here. I work in manufacturing intelligence. My work mainly revolves around developing and maintaining data pipelines and analytical solutions. This blog is a site where I used to keep close track of stuff I read and learnt. I rarely update the blog these days. Only a small subset of the posts on this blog deal with economics – the blog contains posts about all kinds of stuff: Mathematics, physics, statistics, geology, geography, health care and medicine, psychology, evolutionary biology, genetics, computer science, history, chemistry, anthropology, archaeology, chess, … Here’s a blog post with some more information about me and this blog. All of the above overview posts contain links to other blog posts covering many of those books, as well as reviews of the books which I have published on goodreads or elsewhere. Here’s a link to the profile I have created on TheStoryGraph to keep track of the books I read. Here’s a link to my former goodreads profile. It is no longer updated but it contains information linked to approximately 1400 books I have read over time. Aside from information about books I read the goodreads account also contains a large collection of quotes and aphorisms.', ""Get FREE ACCESS to every recipe and rating from this season of our TV show. Get FREE ACCESS to every recipe and rating from this season of our TV show. Get FREE ACCESS to every recipe and rating from this season of our TV show. Get FREE ACCESS to every recipe and rating from this season of our TV show. Years ago while on vacation in Maine I tried boiling down a pot of seawater until the salt crystallized on the bottom. It worked in the sense that I successfully boiled off the water, but the salt itself was a total failure—way too bitter a... Read More © 2023 America's Test Kitchen. All rights reserved."", ""One of my favorite movies, Enchanted April, came out in 1992.\xa0 I went to the theater at least seven or eight times and have watched it every April since that time.\xa0 My dream, influenced by the movie, was to return to Italy during the month of April and experience sunshine, wisteria, the deep blue sea and the passionate Italian way of life.\xa0 Returning to Italy eluded me for fifteen years for one reason or another.\xa0 Would this journey to Ischia in April bring my heart’s desire to fruition? On a brisk April morning I left Detroit, MI for New York’s Kennedy Airport for a connecting flight to Naples, Italy via Meridiana Air.\xa0 Arriving at JFK early left me time to contemplate the journey over a cappuccino.\xa0 As an Italian-American it was enjoyable watching other passengers arrive for the same flight.\xa0 I couldn’t help but wonder if any of the other passengers were from my ancestry since my family was from the Naples and the Mt. Vesuvius area.\xa0 Santa and Paulo, a couple I met while waiting to board, were returning home after visiting their family in New York.\xa0 Since my enthusiasm was evident they were receptive in speaking with me about my family surnames and the Naples area.\xa0 Soon after, we boarded Meridiana Air’s nonstop flight to Naples and it exceeded my expectations.\xa0 Their service to Naples was comfortable and delightful. Upon arriving in Naples and after a short van ride to the port we were on our way via a quick ferry ride to the island of Ischia.\xa0 With a glimpse of Mt. Vesuvius in the background I thought of my grandparents and felt a sense of admiration and connection to them. Ischia, the largest island in the Gulf of Naples, is a volcanic island with Mt. Epomeo as its highest peak (Mt. Vezzi is the other formation).\xa0 It is also known as the ‘Green Island’ due to its Mediterranean vegetation, mountains, rolling hills, and pine forests. \xa0Fascinating archeological finds show that Ischia was inhabited over 7000 years ago and discovered by the Greeks and the Romans.\xa0 Ischia is also known as the island of ‘Good Health’ due its mineral springs, which was one of the main interests for my journey as Ischia is world renowned for their many mineral springs and hidden underground sources. \xa0Summer brings in the highest number of tourists, however Ischia is a year-round destination. One of the most enchanting resorts in Ischia would also be my home for the next several days. A 5-star luxury resort located in the small village of Lacco Amena, L’Albergo della Regina Isabella immediately seduced me with her beauty and grandeur. Built in the 1950’s by Angelo Rizzoli, publisher and film producer, it soon became ‘the’ place for movie stars including Elizabeth Taylor, Richard Burton, and Clark Gable and continues to attract celebrities, music icons and many others. The Regina Isabella has 128 rooms, four swimming pools, two bars, three restaurants, 60 spa treatment rooms, a sauna and hammam, a gym, tennis and boats for private hire. From my balcony, I spent time gazing at the sea and colorful fishing boats.\xa0 Mesmerized by the various colors of the sky as the sun began to set, it was as if time stood still and perhaps it was because the dream I mentioned earlier was actually becoming a reality. All three of the dining venues at Regina Isabella were extraordinary.\xa0 Sporting offered a casual atmosphere and peaceful sea views while Regina Isabella offered an elegant atmosphere, both with stellar service. \xa0Michelin rated Indaco, led by Chef Pasquale Palamaro, offered an intimate setting and experience not to be missed. His artistic gourmet creations were exquisite and ranged from colorful appetizers to equally creative desserts.\xa0 This multi-course event was presented and appeared as artwork and each course was also paired with Italian wines.\xa0 A must-do culinary delight when in Ischia. Regina Isabella is also home to several annual events including the Global Film & Music Fest in mid-July and their food and wine event called Ischia Vintage held in late October. Ischia, as mentioned earlier, is best known for the regenerating thermal waters as the springs and muds have therapeutic properties. Prior to building the resort, Mr. Rizzoli rebuilt the thermae/bath complex on the site of the original Greek and Roman baths.\xa0 The resort’s water contains sodium, chloride, bicarbonate, sulphate, calcium magnesium, bromine, iodine ions and several other minerals.\xa0 The springs and the muds would soon offer me an opportunity to relieve some aches and pains.\xa0 By the way, it takes about six months in the thermal water for the muds to absorb mineral and medicinal qualities.\xa0 My experience with Regina Isabella’s mud pack was quite interesting, relaxing and helpful.\xa0 I don’t speak Italian and my therapist didn’t speak English, so it was an amusing experience, yet beneficial in the end.\xa0 I thought the mud packs were going on my knees, due to a bit of swelling. However I received the full mud pack from my upper thighs to ankles and while it was a bit messy, it was an experience I’d recommend to anyone interested in enhancing their well-being and one I would do again on my next visit.\xa0 One interesting note is that mud treatments with a prescription are covered in the Italian Health System. There are many other services offered at Regina Isabella and some require a mandatory medical exam prior to the service.\xa0 After my consultation with Costanza Popolano, Regina Isabella’s Spa Director, I set up an appointment with their osteopath, Dr. Leonardo Telese, as it was an opportunity to hear his perspective regarding my knee issue.\xa0 Fortunately, Costanza was available to be with me for translation.\xa0 His input was valuable and I was grateful to hear his natural recommendations that would ultimately help me further.\xa0 \xa0There’s a robust menu of services available for this Spa including inhalation therapy, laser therapy, massotherapy, endermologie, and dermatology offerings including microtherapy.\xa0 Relaxing massages, music and color therapy, Ayurvedic and Chinese Medicine services are also available. A queen, which is how I felt, must visit a castle and alas there was one rising above the deep blue sea called Aragonese Castle.\xa0 Built by Syracusan Hiero I, a Greek, it dates back to 474 B.C. and offers magnificent views.\xa0 There is a great deal of history surrounding the castle, which is connected to the main island via a stone bridge.\xa0 You can easily spend a full day exploring the different levels, gardens, convent and cellars. The next day included a visit to Giardini Poseidon Terme (Poseidon Gardens) and a healing opportunity to submerge my body in the various pools.\xa0 Volcanic springs feed the pools and different water temperatures create different benefits. It’s recommended that you go from coldest to hottest on the circuit with time limits for each pool depending on the mineral content. Rich in curative minerals bubbling up from the source, you emerge with a renewed sense of well-being…I know I did.\xa0 You’re surrounded by beauty as you meander through the gardens and take in the scent of jasmine, eucalyptus, hibiscus and oleander.\xa0 I would recommend that you plan a full day to immerse yourself in all that there is to do here.\xa0 Poseidon is along the beach and you can begin your day with a walk or plunge in the sea, followed by the mineral circuit and perhaps a yoga class or other service in the Wellness Centre.\xa0 Massage, Watsu, Shiatsu, Mud therapy and many other services are offered. There are several dining venues and you can end your day with a glass of wine at sunset. Shopping, of course, would be one more activity to engage in while in Ischia.\xa0 My interest was in items made in Italy and mainly scarves or wraps, however Ischia is known for their hand-made ceramics and specialty foods.\xa0 Via Roma offered a number of unique shops and street side cafés. There was nothing ordinary about staying at the Regina Isabella and exploring Ischia. \xa0It brought about feelings of truly living in the moment.\xa0 Calm breezes, sea views, sunshine and wisteria, amazing food and wine and the gracious people met along the way created a transforming experience.\xa0 I left there with a renewed sense of well-being and a knowing that I met one of my heart’s desires. Fall Colors! There’s no better artist than Nature when fall rolls around in rural VT. Few regions in America are more glorious in autumn than rural New England. Known for its colonial past, Atlantic coastline, forested mountains, and dazzling fall foliage, it's a realm of covered bridges, country inns, weathered barns, 18th-century farmhouses, mountain lakes,…"", 'Calcium is the chemical element with symbol\xa0Ca and atomic number\xa020. Calcium is a soft gray alkaline earth metal, and is the fifth-most-abundant element by mass in the Earth’s crust. Calcium is also the fifth-most-abundant dissolved ion in seawater by both molarity and mass, after sodium, chloride, magnesium, and sulfate. We all know what it’s like to watch our loved ones age. Let us help you find the best care your loved ones deserve. Subscribe now to get the latest tips, news, and advice.']","Seawater contains more dissolved ions than all types of freshwater. However, the ratios of solutes differ dramatically. For instance, although seawater contains about 2.8 times more bicarbonate than river water based on molarity, the percentage of bicarbonate in seawater as a ratio of all dissolved ions is far lower than in river water. Bicarbonate ions also constitute 48% of river water solutes but only 0.14% of all seawater ions. Differences like these are due to the varying residence times of seawater solutes; sodium and chloride have very long residence times, while calcium (vital for carbonate formation) tends to precipitate much more quickly. The most abundant dissolved ions in seawater are sodium, chloride, magnesium, sulfate and calcium. Its osmolarity is about 1000 mOsm / l."
which rosary mysteries on which days of the week,"['Abbess – the legal head and spiritual mother of a monastery. Abbot – the legal head and spiritual father of a monastery. Acolyte – anyone who performs ceremonial duties such as lighting altar candles, or serving at Mass. The term is also used for one who has been inducted into a particular liturgical ministry, even when not performing those duties. This is no longer gender specific to males only. Actual Grace – Spontaneous freely given act of divine love/mercy given to us because God desires us to have it because he sees we need it. Advent – c/f\xa0 Liturgical Seasons below. Ad Limina Visits — visit by diocesan bishops to the Holy See, usually every five years. The state of the Dioceses and the Church are discussed with the Holy Father. Altar –\xa0 a structure upon which offerings/sacrifices and worship are made for religious purposes. They are usually found at shrines, temples, churches, chapels, oratories and other places of worship. In the history of religious persecution they were also called Mass rocks. Ambo or Lectern – (from the Latin legere, “to read”), is a reading desk, with a slanted top, on which documents or books are placed as support for reading aloud, as in a scripture reading, lecture, or sermon. Let us pray. Pour forth, we beseech Thee, O Lord, Thy grace into our hearts; that we, to whom the Incarnation of Christ, Thy Son, was made known by the message of an angel, may by His Passion and Cross be brought to the glory of His resurrection. Through the same Christ, our Lord. Amen. Anointing of the sick – is a Sacramental ritual of healing appropriate not only for physical but also for mental and spiritual sickness. It is available to all seriously sick people. Annulment – a Declaration of Nullity is ‘Judgement’ of a church court, confirmed by an appellate court, that an ‘apparent marriage’ was not valid from the start because something was lacking: full knowledge and consent by both parties, freedom from force or grave fear, or some other factor needed for a valid marriage. “Putative” (meaning apparent or seeming) is a key word in the entire process: It refers to a marriage in which at least one party acted in good faith, believing it was valid at the time it took place. Children from a putative marriage are considered legitimate even if the marriage is later ruled to be invalid. This has been a source of one of the major popular misunderstandings of annulments; namely, that an annulment somehow makes the children of that union illegitimate. Church law explicitly rejects this interpretation, saying that children of a putative marriage are legitimate even if the marriage is later judged to be invalid. Apostolic administrator – a prelate appointed by the Pope to serve as the ordinary for an apostolic administration. Apostolic Blessing – a blessing that follows the anointing of a person who may be close to death.It takes the form of a diologue with the dying person and those present and offers the consolation of God’s constant love for humanity. It begins with asking God’s peace on the household. It affirms the tradition of passing from life through death to the promise of a fuller life with God. The person involved draws strength and grace for their journey.c/f Anointing Apostolic Chancery –\xa0 a dicastery or department of the Roman Curia. The chief official was the Cardinal Chancellor of Holy Roman Church. In 1973 ts functions were transferred to the Secretariat of State in Rome. Apostolic Nuncio to Ireland, Dr. Charles Brown –(officially known as an Apostolic nuncio also known as a papal nuncio) is the title for an ecclesiastical diplomat, being an envoy or permanent diplomatic representative of the Holy See to a state or international organization. Apostolic prefect or prefect apostolic –\xa0 is a priest who heads what is known as an apostolic prefecture, a missionary area where the Catholic Church is not yet sufficiently developed to have it made a diocese.The usual sequence of development is: mission, prefecture, vicariate, diocese. Apostolic succession: Apostolic succession is the method whereby the ministry of the Christian Church is held to be derived from the apostles by a continuous succession. Apostolic vicariate: a form of territorial jurisdiction of the Roman Catholic Church established in missionary regions and countries where a diocese has not yet been established. Apse – the apse (from Latin absis: “arch, vault”\xa0 is a semicircular recess covered with a hemispherical vault or semi-dome which stands at the liturgical east end of the church (where the altar is), regardless of the shape of the roof, which may be flat, sloping, domed, or hemispherical. (The image is that of San Clemente Basilica, Rome.\xa0The dome is the classic symbol of Heaven as its shape imitates the dome of the sky. It is fitting as the Sanctuary is often thought of as a little piece of Heaven). Archbishop — the bishop of an archdiocese, with limited jurisdiction over his suffragan sees; a titular and largely honorary designation granted to certain bishops, often Nuncios and other members of the Holy See diplomatic corps. Ascension of Jesus\xa0(anglicized from the Vulgate Latin Acts 1:9-11 section title: Ascensio Iesu) is the Christian teaching found in the New Testament that the resurrected\xa0Jesus\xa0was taken up to Heaven in his resurrected body, in the presence of eleven of his apostles, occurring 40 days after the resurrection. Auxiliary bishop – \xa0an additional bishop assigned to a diocese because of the size or complexity of said diocese. Baptism – The first and basic Christian sacrament (C/f Sacrament below) of initiation or admission and adoption, almost invariably with the use of water, into the Christian Church generally. Jesus himself was reported baptised by John the Baptist in the Jordan river in the early chapters gospels of Matthew, Mark and Luke. Baptism is also called christening a word often reserved for the baptism of infants. The usual form of baptism among the earliest Christians was for the candidate to be immersed, either totally (submerged completely under the water) or partially (standing or kneeling in water while water was poured on him or her). Other common forms of baptism now in use include pouring water three times on the forehead, a method called affusion. Martyrdom was accepted early in Church history as “baptism by/of blood”, enabling martyrs who had not been baptized by water to be saved. It is commonly referred to as: baptism of desire.’ Baptism of Jesus – This marks the beginning of Jesus’ public ministry and is described in the gospels of Matthew, Mark and Luke.\xa0 The Baptism of Jesus is one of the five major milestones in the gospel narrative of the life of Jesus, the others being the Transfiguration,\xa0 Crucifixion, ,Resurrection and Ascension. Baptismal Font – \xa0is an article of church furniture used in the administration of the sacrament of Baptism. The fonts are intended for baptisms using a non-immersion method, such as aspersion or affusion. They\xa0 are often placed at or near the entrance to the main body of the church to remind believers of their baptism as they enter the church to worship, since the rite of baptism served as their initiation into the Church. Beatification – (from Latin beatus, “blessed” and facere, “to make”) is a recognition accorded by the Catholic Church of a dead person’s entrance into Heaven and capacity to intercede on behalf of individuals who pray in his or her name. ‘Blesseds’ are celebrated regionally not universally. It is the second stage of a three part eccesiastical process. Stage one is to pronounce a deceased holy person, ‘venerable’. Stage two is to announce them ‘blessed’. The third, final stage is canonisation after which we call them ‘saint’. In the early church this was often done by acclamation of the faithful. Bible – also referred to as The Good Book, The Holy Book, Scriptures, Holy Writ, \xa0and The Word of God.\xa0The name bible comes from the Koine Greek τὰ βιβλία, tà biblía, a collection of texts sacred to Judaism and Christianity, written at different times by different authors in different locations. The basic division of the 73 book Bible is into the Old and New Testaments. The Christian Old Testament overlaps with the Hebrew Bible and the Greek Septuagint. The New Testament is a collection of writings by early Christians, consisting of narratives, (Gospels and Acts) letters, (e.g. Ss Peter and Paul, and some apocalyptic writings (e.g. St John). Jews and Christians consider the books of the Bible to be a product of divine inspiration or an authoritative record of the relationship between God and His people. With estimated total sales of over 5 billion copies, the Bible is widely considered to be the best-selling book of all time. It has estimated annual sales of 100 million copies, and has been a major influence on literature and history, especially in the western World. General Epistles : James, 1 Peter, 2 Peter, 1 John, 2 John, 3 John, Jude, Revelation. Bishop – an ordained minister who holds the fullness of the sacrament of Holy Orders and is responsible for teaching the Catholic faith and ruling the Church in his assigned jurisdiction. Catholics trace the origins of the office of \xa0bishop to the apostles,\xa0who it is believed were endowed with a special charism by the Holy Spirit at Pentecost. We believe this special charism has been transmitted through an unbroken succession from the Apostles by the laying-on of hands in the sacrament of Holy Orders.[ Bishop Emeritus – \xa0(or Archbishop emeritus or Pope emeritus) — an honorary title given to a retired bishop, archbishop or pope. Broadcast Mass on Internet/T.V. – c/f \xa0Mass on Internet/TV. below Brother— a lay member of a Catholic religious institute in which they promise public vows and lead a life in common. Cardinal – a senior ecclesiastical leader, an ecclesiastical prince, and usually (now always for those created when still within the voting age-range) an ordained bishop of the Church. The cardinals of the Church are collectively known as the College of Cardinals. A cardinal’s primary duty is electing the pope when the post becomes vacant. During the ‘sede vacante’ (the period between a pope’s death or resignation and the election of his successor), the day-to-day governance of the Holy See is in the hands of the College of Cardinals. c/f College of Cardinals below Cardinal Vicar – \xa0a title commonly given to the vicar general of the Diocese of Rome for the portion of the diocese within Italy. The official title, is “Vicar General of His Holiness”. The Pope is officially and fundamentally the Bishop of Rome and as such appoints the Cardinal Vicar with ordinary power to help with the spiritual administration of his diocese. Catholic Charismatic Renewal – a spiritual movement within the Catholic Church that incorporates aspects of both Catholic and charismatic practice. It places an emphasis on having a personal relationship with Jesus and expressing the gifts of the Spirit. Parishes that practice charismatic worship usually hold prayer meetings outside of Mass and feature such gifts as prophecy, faith healing, and glossolalia (speaking in tongues). Charismatic worship is sometimes described as praying with uplifted hands during spoken prayers and songs and audible praying in tongues. They go on to say that what distinguishes a charismatic Catholic church from a traditional one is their surrender to Jesus in all parts of life, obedience to both the Gospel and the Catholic teachings, and friendships centred on Jesus. Catechism of the Catholic Church – an official catechism promulgated for the Catholic Church summing up the beliefs of the Catholic faithful. Charity – the theological virtue by which we love God above all things for his own sake, and our neighbor as ourselves for the love of God. St Paul held it as “the greatest of the virtues.” c/f 1 Cor 13. Chaplain of His Holiness – a priest to whom the Pope has granted this title. They are addressed as Monsignor. Chalice – (from Latin calix, mug, borrowed from Greek kalyx, shell, husk) is a goblet or footed cup intended to hold a drink. In general religious terms, it is intended for drinking during a religious ceremony. In the Catholic Church it is a standing cup used to hold sacramental wine during the Eucharist (also called the Lord’s Supper or Holy Communion). Chalices are often made of precious metal, and they are sometimes richly enamelled and jewelled. Child of Prague – a 16th-century Roman Catholic wax-coated wooden statue of child Jesus holding a ‘globus cruciger’, located in the Discalced Carmelite Church of Our Lady Victorious in Malá Strana, Prague, Czech Republic.The globus cruciger (Latin, “cross-bearing orb”), an orb topped\xa0 by a cross (Latin, crux), has been a Christian symbol of authority since the Middle Ages. The cross represents Christ’s dominion over the orb of the world, and held in the hand of an earthly ruler. In the iconography of Western art, when Christ himself holds the globe, he is called Salvator Mundi, the Saviour of the World. The minature Infant Jesus of Prague statue is a domestic adaptation of this tradition. Many other traditions have developed around the domestic statue version. E.g. \xa0A small well- worn version of the statue is placed outside to plead for ‘good’ (suitable for my needs) weather on a particular day – please note, this is a tradition not a matter of faith!) Child Protection Policy – the Irish church child protection policy or the Catholic Church in Ireland: ‘Our Children, Our Church’, is published by the Irish Episcopal Conference, the Conference of Religious of Ireland and the Irish Missionary Union. It can be viewed online on the Irish Catholic Bishop’s conference website c/f www.safeguarding.ie and all religious orders’ websites or in all public church buildings that include services with/for children. c/f safeguarding( below) Christianity \xa0–\xa0an Abrahamic monotheistic religion based on the life and teachings of Jesus Christ as presented in the New Testament. Christianity is the world’s largest religion, with over 2.4 billion adherents, known as Christians. Christians believe that Jesus is the Son of God and the saviour of humanity whose coming as Christ or the Messiah was prophesied in the Old Testament. The name Christians was first given to the followers of Jesus in Antioch in St Paul’s time. Christian theology is expressed in ecumenical creeds. These professions of faith state that Jesus suffered, died, was buried, and was resurrected from the dead, in order to grant eternal life to those who believe in him and trust in him for the remission of their sins. The creeds further maintain that Jesus bodily ascended into heaven, where he reigns with God the Father, and that he will return to judge the living and dead and grant eternal life to his followers. His ministry, crucifixion and resurrection are often referred to as “the gospel”, meaning “good news”. The term gospel (Good News) also refers to written accounts of Jesus’s life and teaching, four of which by Ss Matthew, Mark, Luke, and John. Christian Community, Movement for Renewal, Ireland – brings together individuals in its communities who seek to become Christians in a form appropriate for our time. In the center of religious life in The Christian Community is the new service of worship, the Act of Consecration of Man. The Christian Community represents a worldview that sees the Deed of Christ as the decisive and most important event in human history. It is one of the most recent and fastest going religious groups in Ireland. Code of Canon Law 1917 – or CIC from its latin name ((Codex Iuris Canonici) The 1917 Code is also referred to as the Pio-Benedictine Code and was the first official comprehensive codification of Latin canon law. It was promulgated on 27 May 1917 and took legal effect on 19 May 1918. It was in force until the 1983 Code of Canon Law took legal effect and abrogated it on 27 November 1983. It has been described as “the greatest revolution in canon law since the time of Gratian” (1150s AD). c/f Canon Law (above) Code of Canon Law 1983 – is the “fundamental body of ecclesiastical laws for the Latin Church”. It is the second and current comprehensive codification of canonical legislation for the Latin Church sui juris of the Catholic Church. It was promulgated on 25 January 1983 by John Paul II and took legal effect on the First Sunday of Advent (27 November) 1983. It replaced the 1917 Code of Canon Law, promulgated by Benedict XV on 27 May 1917.\xa0 c/f Canon Law (above) College of Cardinals- is the body of all cardinals of the Catholic Church. A function of the college is to advise the pope about church matters when he summons them to an ordinary consistory or council. It convenes on the death or resignation of a pope as a papal conclave to elect a successor but is then restricted to eligible Cardinals under the age limit, which was set for the first time in 1970 by Pope Paul VI at 80.The college has no ruling power except during the ‘sede vacante’ (papal vacancy) period. Historically, cardinals were the clergy serving parishes of the city of Rome under its bishop, the Pope. Communion – comes from the latin communio at one or in one.\xa0 It is often used, in catholic circles, to indicate the consecrated species of bread and wine consecrated into the Body and Blood of the Lord. ( c/f: below for full communion, Mass , Eucharist and in communion). In other Christian denominations it often refers to a service of Divine worship. Communion Rite –or Communion Service consists of the priest/deacon introducing the communal recitation or singing of the “Lord’s Prayer” (“Pater noster” or “Our Father”). He follows this up with a prayer and the people respond with the doxology. The sign of peace is exchanged and then the “Lamb of God” (“Agnus Dei” in Latin), The priest/deacon then presents the previously consecrated bread to the congregation, saying: “Behold the Lamb of God, behold him who takes away the sins of the world. Blessed are those called to the supper of the Lamb.” Then all repeat: “Lord, I am not worthy that you should enter under my roof, but only say the word and my soul shall be healed.”\xa0 Communion is distributed to the people. After some time for silent prayer, A formal prayer after Communion is then said, hymn sung, and the congregation is dismissed. Communion of Saints –\xa0refers to the doctrine of the communion of saints is based on 1\xa0Cor. 12\xa0 and refer to Christians, who, whatever their personal sanctity as individuals, are called holy because they are consecrated to God and Christ. It refers to all persons, living and the dead, those on earth, in heaven, and, for those who are in that state of purification. They are all part of a single “mystical body”, with Christ as the head, in which each member contributes to the good of all and shares in the welfare of all. Confirmation is seen as a sacrament that seals the covenant created in Baptism. It renders the bond with the Church more perfect” because, while a baptized person is already a member, reception of the sacrament of Confirmation is necessary for the completion of baptismal grace”. In the Eastern churches it is conferred immediately after baptism. In the Western churches this practice is followed when adults are baptized, but in the case of infants not in danger of death it is administered, ordinarily by a bishop, only when the child reaches the age of reason or early adolescence. Among those Catholics who practice teen-aged confirmation, the practice may be perceived, secondarily, as a “coming of age” rite. Congregation – is used in four\xa0distinct senses, to mean a type of department in the Roman Curia, a type of religious institute, or some groups of Augustinian, Benedictine, and Cistercian houses, and a gathering of the faithful in church. In the Roman Curia it refers to the highest-ranking departments of the Roman Curia. Lower-ranking departments include pontifical councils, pontifical commissions, tribunals, and offices. The 1917 Code of Canon Law\xa0the name “religious order” is reserved for institutes in which the vows were solemn, and used the term “religious congregation” or simply “congregation” for those with simple vows. The current Code of Canon Law, which came into force in 1983, maintains the distinction between solemn and simple vows, but no longer makes any distinction between their juridical effects, including the distinction between “orders” and “congregations”. It has accordingly dropped the language of the 1917 code and uses the single term “religious institute to designate all such institutes of consecrated life alike. Consecrated life –\xa0\xa0 is a stable form of Christian living by those faithful who feel called to follow Jesus Christ in a more exacting way recognised by the Church. It is characterised by the public profession of the evangelical counsels of poverty, chastity, and obedience, in a stable state of life recognised by the Church. Consecrated life may be lived either in institutes or individually. While those living it are either clergy (if ordained) or lay people, the state of consecrated life is neither clerical nor lay by nature. Ciborium\xa0(plural\xa0ciboria; Latin from the Ancient Greek κιβώριον (kibōrion) is a container or vessel, a normally metal.large covered cup designed to hold hosts for, and after, the Eucharist, thus the equivalent for the bread of the chalice for the wine. Counter-Reformation – Catholic Reformation, Catholic Revival – the period of Catholic revival beginning with the Council of Trent and ending at the close of the Thirty Years’ War(1648) initiated in response to the Protestant Reformation. The Protestant Reformation, often referred to simply as ‘the Reformation’ (from Latin reformatio, lit. “restoration, renewal”). This was a schism from the Roman Catholic Church initiated by Martin Luther and continued by John Calvin and other early Protestant Reformers in 16th century Europe. c/f below) Credence table is a small side table in the sanctuary of a church which is used in the celebration of the Eucharist. (Latin credens, -entis, believer). Creed –a brief summary of the teachings of the faith. The most ancient is the Apostles Creed below and the Nicene Creed developed as the faith evolved. *The Apostles Creed – sets forth their doctrine “in sublime simplicity, in unsurpassable brevity, in beautiful order, and with liturgical solemnity.” In its present form it is dated no later than the fourth century. More than any other Christian creed, it may justly be called an ecumenical symbol of faith. It reads The Nicene Creed is a profession of faith widely used in Christian liturgy. It is called Nicene because it was originally adopted in the city of Nicaea (present day Iznik, Turkey) by the First Council of Nicaea in 325. The text can be found in the liturgy of the Word at Mass. It reads: Crosier\xa0(also known as a\xa0crozier,\xa0paterissa,\xa0pastoral staff, or\xa0bishop’s staff) is a stylized staff carried by high-ranking Roman Catholic, Eastern Orthodox, Anglican, and some Lutheran, United Methodist and Pentecostal prelates. Other typical insignia of many of these prelates are the mitre, the pectoral cross, and the episcopal ring. The crosier (known as the pastoral staff, from the Latin pastor, shepherd) is shaped like a shepherd’s crook. A bishop or church head bears this staff as “shepherd of the flock of God”, particularly the community under his canonical jurisdiction, but any bishop, whether or not assigned to a functional diocese, may also use a crosier when conferring sacraments and presiding at liturgies. A bishop usually holds his crosier with his left hand, leaving his right hand free to bestow blessings. Crucifix\xa0(from\xa0the Latin\xa0cruci fixus\xa0meaning one fixed to a cross. The crucifix is a principal symbol for many Christian groups. It is an image of Jesus\xa0on the\xa0cross, as distinct from a simple bare cross. The representation of\xa0Jesus himself on the cross is referred to as the\xa0corpus\xa0(Latin for “body”). Large crucifixes high across the central axis of a church are known by the\xa0Old English\xa0term\xa0rood. Curia\xa0consists of a group of officials who assist in the governance of a\xa0particular Church. These curias range from the relatively simple diocesan curia, to the larger patriarchal curias, to the\xa0Roman Curia, which is the central government of the\xa0Catholic Church. Deaconate/diaconate\xa0– Greek word \xa0diákonos\xa0(διάκονος), which is a standard\xa0ancient Greek\xa0word meaning “servant”, “waiting-man”, “minister”, or “messenger”. It is a ministry in the\xa0Christian Church\xa0that is generally associated with church service of some kind, but which varies among theological and denominational traditions. In many traditions the “deaconate”refers to the term for a deacon’s office. It is a\xa0clerical\xa0office to which to which one is ordained like priests and bishops. The Catholic Church has only male Deacons, who are ordained as a sacramental sign to the Church and to the world of Christ, who came to serve and not to be served. All ordained ministers in the Church are called to functions of Word, Sacrament, and Charity, but bishops, presbyters and deacons exercise these functions in various ways. As ministers of Word, deacons proclaim the Gospel, preach, and teach in the name of the Church. As ministers of Sacrament, deacons baptize, lead the faithful in prayer, witness marriages, and conduct Eucharistic services and funeral services. They are not ordained to say Mass. As ministers of Charity, deacons assist in identifying the needs of others and marshalling the Church’s resources to meet those needs. But no matter what specific functions a deacon performs, they flow from his sacramental identity. In other words, it is not only what a deacon does, but who a deacon is, that is important. A ‘lay’ deacon, so called by some people, is a person who may have no intention or desire to become a priest, or take on the promise o celibacy, thus may or may not marry or work full time \xa0with the church. Death, Christian – the end of a Christian person’s earthly life and the beginning of the eternal life in heaven, in the presence of God. According to our Christian faith, each person possesses a soul that leaves their body at the point of death and goes to an afterlife in heaven or hell. Catholics. We believe that we all will be called to judgement by God for our actions and as a consequence of our actions and God’s mercy we will be rewarded with a place in heaven, punished in hell or purified in purgatory. Declaration of Nullity — a canonical judicial declaration that a marriage or matrimonial covenant was invalid from the beginning due to some point of law or actions by the parties involed. Devil –\xa0(from Greek: διάβολος or diábolos slanderer or accuser is, according to Christianity and Islam, the primary opponent of God. Traditonally Christianity identifies the Devil (“Satan”) with the Serpent who tempted Adam and Eve to eat the forbidden fruit, and describes him as a “fallen angel” who terrorizes the world through evil, is the antithesis of Truth. In the New Testament, the name Satan occurs more than 30 times in passages alongside diábolos, referring to the same person or thing as Satan. Islam identifies the Devil (“Shaitan”) with all those who oppose Allah. The Modern English word devil descends from the Middle English devel, from Old English dēofol, that in turn represents an early Germanic borrowing of Latin diabolus. This in turn was borrowed from Ancient Greek Greek: διάβολος (diábolos), “slanderer”. Dicastery\xa0 — \xa0denotes the departments of the Roman Curia. c/f Curia above Diocesan administrator –\xa0a provisional ordinary of a Roman Catholic particular church. The college of consultors elects an administrator within eight days after the see is known to be vacant. The college must elect as administrator a priest or bishop at least 35 years old. Diocesan archbishop or bishop – an Archbishop or bishop in pastoral charge of an archdiocese as opposed to a titular Archbishop or bishop, whose see is only nominal, not pastoral. Diocesan chancery\xa0is the branch of administration which handles all written documents used in the official government of a Roman Catholic or Anglican diocese.or his representative, all documents which concern the diocese are drawn up, copied, forwarded, and a record kept of all official writings expedited or received. The official charged with the execution of these duties is known as the\xa0diocesan chancellor. Diocesan priest\xa0is a Roman Catholic or Eastern Orthodox priest who commits himself to a certain geographical area, and is ordained into the service of the citizens of a particular diocese or church administrative region. His duties include serving the everyday needs of the people in parishes but their activities are not limited to that of their parish. Discalceation\xa0means “removal of footwear”. St. Teresa of Ávila was one of a number of saints of the Roman Catholic Church who were “discalced,” or shoeless. She was one of the founders of the Discalced (barefoot) Carmelites religious order. Easter –\xa0 c/f\xa0 Liturgical Seasons below. East–West Schism – The Roman church divided medieval Christianity into Eastern (Greek) and Western (Latin) branches, which later became known as the Eastern Orthodox Church and the Roman Catholic Church, respectively. Eastern Catholic Churches – historically called Uniate Churches, are 23 self-governing particular churches in full communion with the Pope, which make up the Catholic Church together with the Latin Church. Liturgies of the 23 Eastern Catholic churches include the Byzantine, Alexandrian, Armenian, East Syrian, and West Syrian Rites, traditions that are shared with other Eastern Christian churches, the Eastern Orthodox and Oriental Orthodox churches. Although some theological issues divide them from other Eastern churches, they admit members of the latter churches to the Eucharist and the other sacraments, as governed by canon law. Eclesiastical judge (Latin: Judex -, or Judex Ecclesiasticus) is an ecclesiastical person who possesses ecclesiastical jurisdiction to deal with issues that come under his church jurisdiction. Episcopal Conference – Conference of Bishops, or\xa0National Conference of Bishops\xa0is an official assembly of all the bishops\xa0of a given territory. Episcopal vicar – is the principal deputy of the bishop of a diocese for the exercise of administrative authority and possesses the title of local ordinary. Epistle –\xa0 a writing directed or sent to a person or group of people, usually an elegant and formal\xa0didactic letter. The epistle genre of letter-writing was common in ancient Egypt as part of the scribal-school writing curriculum. The letters in the New Testament from Apostles to Christians are usually referred to as epistles. Those traditionally attributed to Paul are known as Pauline epistles, those attributed to Peter are known as Petrine or as catholic ( i.e., “general”) epistles. Eternity -an infinite or an indeterminately long period of time.It is often referred to as the afterlife, everlasting life, life after death, the life to come, the life hereafter, the hereafter, the world hereafter, the afterworld, the next world, the beyond\xa0In classical philosophy, however, eternity is defined as what exists outside time. A circle is commonly used as a symbol for eternity –no beginning or end. Eucharist – (pronunced: ˈyo͞okərist), a sacrament (Mass )containing the following elements: \xa0a commemoration of the Last Supper, the final meal that Jesus Christ shared with his disciples before his arrest, eventual crucifixion and resurrection. Eucharistic Congress –\xa0is a gathering of clergy, religious, and laity to bear witness to the Real Presence of Jesus in the Eucharist.\xa0Congresses bring together people from a wide area, and typically involve large open-air Masses, Eucharistic adoration (Blessed Sacrament), and other devotional ceremonies held over several days. Congresses may both refer to National (varies by country) and International Eucharistic Congresses. God willing, the next and 52nd International Eucharistic Congress, will take place in Budapest, Hungry in 2020 Eucharisic Service – The Church provides a rite for of Eucharistic service outside of Mass when priests are not available to celebrate same. This type of service is becoming more and more common across the worldwide church and here in Ireland.\xa0This rite was approved by Pope Paul in 1973 as there was need of it.\xa0There is, of course, no immediate consecration of the bread and wine but rather this has been done\xa0at a previous Mass. Excardination – Freeing a member of the clergy from one jurisdiction and being transferred to another. Incardination\xa0refers to a member of the clergy being placed under the jurisdiction of a particular bishop or other ecclesiastical superior. Excommunication\xa0 – an institutional act of religious\xa0censure used to deprive, suspend, or limit membership in a religious community or to restrict certain rights within it, in particular receiving of the sacraments. Exemption – the whole or partial release of an ecclesiastical person, corporation, or institution from the authority of the ecclesiastical superior. Exorcism –\xa0(from Greek ἐξορκισμός,\xa0exorkismos\xa0– binding by oath) is the religious or spiritual practice of purportedly evicting demons or other spiritual entities from a person or an area they are believed to have possessed. Faith – Trust, belief, confidence, conviction, credence, reliance or dependence in someone or something but it also allows for doubt. St Augustine prayed,’ O Lord , I believe, help my unbelief. It is numbered amongst the three theological virtues (faith, hope and love) meaning it is a free gift, infused into us through Divine grace. The theological virtues are so named because the object of these virtues is the divine being itself. Fall of Man— or fall of humankind, the transition of the first human parents from a state of innocent obedience to God, to a state of guilty disobedience to God. depicted in the early chapters of the Book of Genesis Family wage – a wage that is sufficient to raise a family. This contrasts with a living wage, (the minimum income necessary for a worker to meet their basic needs which is generally taken to mean a wage sufficient for a single individual to live on, but not necessarily sufficient to also support a family.) As a stronger form of living wage, a family wage is likewise advocated by proponents of social justice. Father (cleric) — a traditional religious title given to\xa0ordained priests in the church. In Christianity, God the Father is regarded as the first person of the Holy Trinity, father of all peoples. Jesus referred to God sometimed as Abba – an Aramaic word that would most closely be translated as “daddy.” signifying their close, intimate relationship of a father with his child, as well as the childlike trust that a young child places in his “daddy.” c/f God, names of, below Muslims believe that studying the various 99 names and attributes of Allah, (God) is one of the most effective ways of strengthening one’s relationship with God. Each Name and Attribute nourishes a kind of consciousness and humility in man and their study leads one to constantly better their actions. The Quran (Holy Book) says “The most beautiful names belong to Allah: so call on Him by them.” (Quran, 7:180). For\xa0example If one is asking for peace and tranquility in life while experiencing a period of tension, call on God by His name “As-Salaam,” meaning “The Ultimate Source of Peace.” Feastdays -The calendar of saints of ‘Saints of the Day’ (www.catholicireland.net) is a traditional Christian method of organizing a liturgical year by associating each day with one or more saints and referring to the day as the feast day or feast of said saint. (The word “feast” in this context does not mean “a large meal, typically a celebratory one”, but instead “an annual religious celebration, a day dedicated to a particular saint”.) The system arose from the early Christian custom of commemorating each martyr annually on the date of his or her death, or birth into heaven, a date therefore referred to in Latin as the martyr’s dies natalis (“day of birth”). c/f Roman Martyrology below. Font – A holy water font or stoup is a vessel containing holy water generally placed near the entrance of a church or home. It is used in Catholic Church, Anglican Church, and some Lutheran churches by\xa0making the Sign of the Cross using the holy water upon entrance or exiting the church or home. Holy water is blessed by a priest and acts as a reminder of one’s baptism and baptismal promises. Friars – \xa0members of one of the\xa0mendicant religious orders founded since the twelfth or thirteenth century that adopted a lifestyle of poverty, travelling, and living in urban areas for purposes of preaching, evangelization, and ministry, especially to the poor. These orders rejected the previously established monastic model of living in one stable, isolated community where members worked at a trade and owned property in common, including land, buildings and other wealth. By contrast, the mendicants avoided owning property, did not work at a trade, and embraced a poor, often itinerant lifestyle. They depended for their survival on the goodwill of the people to whom they preached. Some of the\xa0orders of friars are the\xa0Dominicans, Franciscans, Augustinians and Carmelites. Full communion – a relationship between church organizations or groups that mutually recognize their sharing the essential doctrines. As a practical matter for most Catholics, full communion means that a member of one Church may partake of the\xa0Eucharist celebrated in another and for priests, that they may concelebrate the Eucharist with priests of another Church. Protestants understand full communion a matter of practical relations among denominations that nonetheless fully retain their distinct identities. Funeral – a ceremony for honouring, respecting or sanctifying the life of a person who has died, and usually involves arrangements for the burial or cremation of their corpse. There are Funeral rite books available in www.Veritas.ie with appropriate prayers, hymns and scripture readings. Funeral, Rites, Music – Music is integral to the funeral rites.\xa0It allows the community to express convictions and feelings that words alone may fail to convey.\xa0 It has the power to console and uplift the bereaved and to strengthen the unity of the assembly in faith and love.\xa0 The music at funerals should support, console and uplift the participants and should help to create in them a spirit of hope in Christ’s victory over death and in the Christian’s share in that victory.The ideal is to have music which reflects the Paschal mystery, hope and consolation, families often do request\xa0favourite music which they like.\xa0 While the use of non-sacred music is not encouraged, it may be that the songs requested are not discordant with the Christian message. This should be discussed with the family and celebrant/minister. God – the Supreme Being and principal object of our faith. The concept of God as described by theologians commonly includes the attributes of omniscience (infinite knowledge), omnipotence (unlimited power), omnipresence (present everywhere), omnibenevolence (perfect goodness), divine simplicity, and eternal and necessary existence. God is also usually defined as a non-corporeal being without any human biological gender, but the concept of God actively creating the universe has caused some religions to give “Him” the metaphorical name of “Father” (which is also a metaphor for humans being God’s stewards,\xa0supreme above all creation). Because God is conceived as being invisible from direct sight and not being a corporeal being, God cannot (some say should not) be portrayed in a literal visual image. Most images reflect how God interacts with the cosmos, earth, nature, and us humans as is reflected in the Holy Scriptures. Christians believe God to be Triune, Father, Son and Holy Spirit. *The New Testament\xa0often\xa0 refer to God as Father/Abba, Ancient of Days,. “The Most High”.\xa0(θεός the Greek term for God),Kyrios (i.e. Lord in Greek), Pateras (πατέρας i.e. Father in Greek), the Aramaic word “Abba” meaning “Father.” Jesus and Emmanuel that refer to Jesus have salvific attributes. The name Jesus is given in Luke 1:31 and Matthew 1:21 and in both cases the name is not selected by humans but is received by angelic messages with theological significance, e.g. the statement in Matthew 1:21 “you shall call His name Jesus, for He will save his people from their sins” associates salvific attributes to the name Jesus. Emmanuel (Mt 1:23). The names of the Father, Son and the Holy Spirit are inherently related in the New Testament, e.g. with Jesus’ instruction ‘baptizing them in the name of the Father and of the Son and of the Holy Spirit”. The Greek word pneuma, generally translated spirit, is found around 385 times in the New Testament. The English terms Holy Spirit and Holy Ghost have identical meanings, Three separate terms, namely Holy Spirit, Spirit of Truth and Paraclete are used in John 14:17, 15:26 and 16:13. *Islamic faith , The Qur’an refers to – Allāh (Arabic term with no plural) meaning “the God”, or “the Deity”—is the most frequently used name of God in Islam. the Qur’an says ‘to Him Belong the Best Names’ (Lahu Al-Asmao Al-Husna), examples like Ar-Rahman (The Entirely Merciful), Ar-Rahim (The Especially Merciful). *Hinduism– God may also be given a proper name in monotheistic currents of Hinduism which emphasize the personal nature of God, with early references to his name as Krishna-Vasudeva in Bhagavata or later Vishnu and Hari. Grace – in theology grace has been defined as “a free gift of love and mercy given to us by God because He desires us to have it, and not because of anything we have done to earn it”, a spontaneous benevolence shown by God toward the human race”, generous, free and totally unexpected and undeserved” that takes the form of divine favor, love, clemency – a share in the divine life of God. Grace – a prayer. Grace and thanksgiving imparts a blessing which sanctifies or thankful praise. It can be said before or after eating meal. Reciting such a prayer is often referred to as “saying grace”. A prayer of ‘Grace’ is said by the head of the house although any family member or an honoured guest may be asked to offer it before/after a meal: Before: Bless us, O Lord, and these your gifts, which from your bounty we are about to receive, through Christ \xa0our Lord. (Response ): Amen. Heaven – this is the location of God’s abode, the throne of God and the beatific vision of the Lord, and the dwelling place of the angels The Scriptures tell us that the resurrected Jesus ascended to heaven where he now sits at the Right Hand of God the Father In traditional Christianity, heaven is also understood as the abode for the redeemed dead in the afterlife. According to Roman Catholic teaching, Mary, mother of Jesus, is also said to have been assumed into heaven. St Paul in 1 Corinthians 2:9 says “No eye has seen, no ear has heard, and no mind has imagined what God has prepared for those who love him.” Hell – The Roman Catholic Catechism n.1035 defines Hell as “a state of definitive self-exclusion from communion with God and the blessed.” One finds themselves in Hell as the result of dying in mortal sin without repenting and accepting God’s merciful love, becoming eternally separated from Him by one’s own free choice immediately after death. It is traditionally depicted as a place of torment and punishment in an afterlife,fiery and painful, inflicting guilt and suffering.\xa0It is said to be the permanent residence of the the fallen Angel Satan, the devil, the great deceiver, the evil one. Hierarchy –bishops, priests and deacons. In the ecclesiastical sense of the term, “hierarchy” commonly means the body of men who exercise authority within a Christian church. In the Catholic Church, authority rests chiefly with the bishop, while priests and deacons serve as their assistants, co-workers or helpers. It is also used to refer to bishops alone. His Eminence\xa0– \xa0a style of reference for high nobility, still in use in various religious contexts. The style remains in use as the official style or standard of address in reference to a cardinal of the Roman Catholic Church, reflecting his status as a Prince of the Church. A longer, and more formal, title is “His (or Your when addressing the cardinal directly) Most Reverend Eminence”. Patriarchs of Eastern Catholic Churches who are also cardinals may be addressed as “His Eminence” or by the style particular to Eastern Catholic patriarchs, His Beatitude. His Holiness – a style and form of address for supreme religious leaders, originally and most notably the Pope, Bishop of Rome and the leader of the worldwide Catholic Church. His Holiness (Latin: Sanctitas) is the official style used to address the Roman Catholic Pope and the Greek Orthodox Ecumenical Patriarch of Constantinople, as head of the Orthodox community. In February 2013, the Holy See announced that former Pope Benedict XVI would retain the style “His Holiness” after resigning and becoming Pope Emeritus. Holy Days of obligation – major feasts of the Church’s year on which catholics are obliged to go to Mass. In the medieval period, days off work for the workforce in Catholic countries, consisted of Sundays and single days off on major feasts of the Church. So for the workers holyday, was the same as holiday. The Church has retained a number of its feasts, the major ones are known as Solemnities. Some of these Solemnities are known as ‘Holy days of Obligation’, when those who are able are expected to attend Mass. Holy Days, Ireland – Immaculate Conception (8th December), Christmas Day (25th December), Epiphany (6th January ), St Patrick (17th March), Assumption of Our Lady (15th August), All Saints (1st November). In Ireland since October 1996, the Irish Bishops’ Conference removed the obligation on the feasts of Ascension and the Body and Blood of Christ (Corpus Christi), and the consequent transfer of these two feasts to the following Sundays in accordance with universal liturgical law. This decision has been confirmed by the Vatican Congregation for Divine Worship. Holy Door\xa0– Year of Mercy (Latin: Porta Sancta) traditionally refers to an entrance portal located within the one or all the Papal Major basilicas in Rome. The doors are normally sealed by mortar and cement from the inside so that they cannot be opened. They are ceremoniously opened during Jubilee years designated by the Pope, for pilgrims who enter through those doors may piously gain the plenary indulgences attached with the Jubilee year celebrations. Since the year 1300 when Pope Boniface VIII declared the first Holy Year, the Catholic Church has regularly celebrated “Holy Years,” usually every twenty-five years (at least since 1470), except for special circumstances, like in 1983 when a Holy Year was declared to mark the 1950th anniversary of the death and resurrection of our Lord.\xa0 A major aspect of the Holy Year has been that of pilgrimage to Rome to make reparation for sin and to renew the conversion of one’s life. In October 2015, Pope Francis broke with tradition in having each Roman Catholic diocese throughout the world designate one or more local Holy Doors during the Extraordinary Jubilee of Mercy, so that Catholics could gain the plenary indulgences granted during the Jubilee year without having to travel to Rome. These ‘doors’ may take different forms. The year came to an end in November 201 Holy Hour –\xa0an hour set aside for prayer and reflection either privately in a quiet \xa0or holy place. It can also refer to a hour of public prayer in a church or shrine with or without the blessed Sacrament exposed. Holy Orders – in the church there are three degrees of sacramental orders: bishop, priest, and deacon. . In the phrase “holy orders”, the word “holy” \xa0means “set apart for some purpose.” “Orders” is simply a group within a hierarchical structure that is set apart for ministry in the Church. Ordination to the Diaconate typically happens in the last year of seminary training that a man will be ordained to the “transitional diaconate.” After six months or more as a transitional deacon, a man will be ordained to the priesthood. Priests are able to preach, perform baptisms, witness marriages, hear confessions and give absolution, anoint the sick, and celebrate the Eucharist or the Mass. Some priests go on to be chosen to be bishops.This distinguishes men bound for priesthood from those who have entered the “permanent diaconate” and do not intend to seek ordination as a priest. Deacons, whether transitional or permanent, receive faculties to preach, to perform baptisms, and to witness marriages. They may assist at the Eucharist or the Mass, but are not the ministers of the Eucharist. Holy See – the Episcopal jurisdiction of the Bishop of Rome (the Pope), and is the preeminent episcopal see of the world wide Catholic Church, forming the central government of the Church. It is a very small \xa0independent sovereign entity. It serves as the central point of reference for the church everywhere and the focal point of communion due to its position as the pre-eminent episcopal see of the universal church. It traces its origin to the 1st century during the apostolic era, when Saint Peter arrived in Rome to evangelise and form a significant early Christian community of believers there. Today, it is responsible for the governance of all Catholics, organised in their particular Churches, Patriarchates and religious institutes. As an independent sovereign entity, holding the Vatican City enclave in Rome as sovereign territory, it maintains diplomatic relations with an immense number of other states. It is viewed as analogous to a state while administered by the Roman Curia (Latin for Roman Court), similar to a centralised government with the Cardinal Secretary of State as its chief administrator, and various dicasteries, comparable to ministries and executive departments. Holy Water – Holy water is water blessed by a pope, bishop, priest or deacon, and is used to bless oneself, others or other objects. It is also used as a reminder of our baptism. Hope -(latin spes) is one of the three theological virtues (Faith, Hope and Charity) in the Christian tradition. Hope being a combination of the desire for something and expectation of receiving it, it is ultimately the virtue is hoping for Divine union and eternal happiness. Like all virtues, it arises from the will, not the passions and is infused in us\xa0from/by God. The Christian who hopes seeks God for himself or herself. In technical language, the formal object of theological hope is God-as-possessed. Hypostasis —refers to the union of two natures divine and human, in the one divine person of the Son of God, Jesus Christ. Immaculate Conception — the dogma of the conception of the Blessed Virgin Mary (in the womb of her mother, St Anne), but free from original sin by God in virtue of the foreseen merits of her son Jesus Christ. – (not to be confused with the Incarnation of the Word of God) Incarnation\xa0of Christ— Latin ‘in carne’ enfleshment of The Word of God taking on a human nature and remaining God -becoming a true man named Jesus, Son of God and Mary, daughter of St Anne. This divine/human action is a\xa0central mystery of our faith Institute of consecrated life – institutes or groupings in the Catholic Church whose members profess the evangelical counsels of chastity, poverty, and obedience as vows or other sacred bonds. Institute, Religious — institutes, which are characterized by the public profession of vows, life in common as brothers or sisters, and separation from the world. Intercession/intercessory prayer – the act of praying to God on behalf of others. In Western Christianity, intercession forms a distinct form of prayer, alongside Adoration, Confession and Thanksgiving. Jesus – (/ˈdʒiːzəs/; Greek: Ἰησοῦς Iesous; c. 4 BC to AD 30–33), was also referred to as: Jesus of Nazareth or Jesus Christ, the long awaited Messiah (or the Christ, the Anointed One) promised in the Old Testament. Jesus – Names of –There are over 200 of names of Jesus in the New Testament. Many of the names of Jesus come from the Gospels directly, others arose from his parables or sayings, others again came later on reflection. Jubilee Year of Mercy – (Latin:\xa0Iubilaeum Extraordinarium Misericordiae) is\xa0a Roman Catholic period of prayer held from the Feast of the Immaculate Conception (December 8), 2015 to the Feast of Christ the King (November 20), 2016. Like previous jubilees, it is seen by the Church as a period for remission of sins and universal pardon focusing particularly on God’s forgiveness and mercy. It is an extraordinary Jubilee because it had not been predetermined long before; usually ordinary jubilees take place every 25 years. The 2016 Jubilee was first announced by Pope Francis on March 13, 2015. It was declared in the Pope’s April 2015 papal bull of indiction,’ Misericordiae Vultus’ (Latin: “The Face of Mercy”). It is the 27th holy year in history, following the ordinary 2000 Jubilee during John Paul II papacy. The opening day was also the fiftieth anniversary of the closing of the Second Vatican Council. In prior months it was stressed that the Pontiff wishes the Jubilee to be celebrated not only in Rome but all around the world; for the first time holy doors are going to be opened in many dioceses across the world, either in the main cathedral or in local historical churches. The first holy door was opened by Pope Francis in Bangui on November 29, 2015 during a tour of East Africa (c/f Holy Doors above). Other doors have been opened since across the globe. Judicial Vicar –\xa0(Latin:officialis) is an officer of the\xa0diocese who has ordinary power to judge cases in the diocesan ecclesiastical court. Justification by faith – is God’s act of removing the guilt and penalty of sin while at the same time declaring a sinner righteous i.e.being made righteous, just, holy, and acceptable before God through Christ’s atoning sacrifice.\xa0 Protestantism protest that righteousness from God is viewed as being credited to the sinner’s account through faith alone, without works and they lean heavily on S Paul’s writing for support. The Catholic Church maintains that St. James says we are justified by works as well as by faith. Is this not a contradiction? Not if we recognize that St. James is using the word “Justification” in a slightly different sense to that in which St. Paul uses it. Put very simply, Paul uses “justification” to mean to change from being “bad” in God’s sight (state of sin) to being “good” (state of grace). James, however, uses the same word to mean being kept good—and becoming even better—in God’s sight. Just war theory\xa0(jus bellum iustum) is a\xa0doctrine, also referred to as a tradition, of military ethics studied by theologians, ethicists, policy makers, and military leaders. The purpose of the doctrine is to ensure war is morally justifiable through a series of criteria, all of which must be met for a war to be considered just. Keys of the Kingdom – c/f Matthew 16:19. Jesus had asked His disciples who people thought He was. After responding with several of the more popular opinions, Jesus aimed His question directly at His disciples. Peter, responding for the twelve, acknowledged Jesus as the Christ, the Son of the Living God. After this great confession, Jesus replied, “Blessed are you, Simon Bar-Jonah! For flesh and blood has not revealed this to you, but my Father who is in heaven. And I tell you, you are Peter, and on this rock I will build my church, and the gates of hell shall not prevail against it. I will give you the keys of the kingdom of heaven, and whatever you bind on earth shall be bound in heaven, and whatever you loose on earth shall be loosed in heaven” (Matt 16:17-19). Keys are used to lock or unlock doors. In this text, Jesus is laying the foundation of His church (Ephesians 2:20). The disciples will be the leaders of this new institution, and Jesus is giving them the authority to, as it were, open the doors to heaven and invite the world to enter. Kiss of peace – an ancient traditional Christian greeting. Also called “Holy kiss”, “Brother kiss” among men, or “Sister kiss” among women. Some congregations do not perform inter-gender holy-kissing. The practice remains a part of the worship in traditional churches where it is often called the kiss of peace, sign of peace, Holy kiss or simply peace or pax. Laity – There are estimated to be over one billion Roman Catholics in the world. The majority of these are lay Catholics, also known as the laity, which includes all Roman Catholics, except those who are part of the clergy. These faithful are by baptism made one body with Christ and are constituted among the People of God; they are in their own way made sharers in the priestly, prophetical, and kingly functions of Christ; and they carry out for their own part the mission of the whole Christian people in the Church and in the world Lapsed Catholic\xa0— a Catholic who has ceased believing the teaching or practicing the Catholic faith.\xa0 Such a person is said to have lapsed from all or some of the faith. (‘a la carte Catholic’) Such a person may still identify as a Catholic and remains a Catholic. Last Rites- The Sacrament of the Anointing of the sick is no longer referred to as the last rites or Extreme Unction as its use has been extended to all those who are seriously sick and not just the dying. It is a ritual of healing appropriate not only for physical but also for mental and spiritual sickness. c/f Anointing of the Sick above. Latin Church –\xa0 a group of Christian faithful united by a hierarchy according to the norm of law which the supreme authority of the Church expressly or tacitly recognizes as\xa0‘sui iuris’. There are several such\xa0‘sui iuris’\xa0particular churches within the Catholic Church. Sui iuris,\xa0is a\xa0Latin phrase which literally means “of one’s own right” Latin Rites –\xa0 liturgical rites\xa0 used within that area of the Catholic Church where the Latin language once dominated. Their number is now much reduced. In the aftermath of the Council of Trent, in 1568 and 1570 Pope Pius V suppressed the Breviaries and Missals that could not be shown to have an antiquity of at least two centuries. Many local rites that remained legitimate even after this decree were abandoned voluntarily, especially in the 19th century. In the second half of the 20th century. A few such liturgical rites persist today for the celebration of Mass, since 1965-1970 in revised forms, but the distinct liturgical rites for celebrating the other sacraments have been almost completely abandoned. The\xa0Roman Rite is by far the most widely used. Like other liturgical rites, it developed over time, with newer forms replacing the older. c/f Tridentine Mass Rite Laws of the Church – Canon Law of the Catholic Church (Ecclesiastical Latin: Jus Canonicum) is the system of laws and legal principles made and enforced by the hierarchical authorities of the Church to regulate its external organization and government and to order and direct the activities of Catholics toward the mission of the Church. c/f Canon law above Lay Ecclesial Ministry\xa0is the term adopted by the United States Conference of Catholic Bishops to identify the relatively new category of pastoral ministers in the Catholic Church who serve the Church but are not ordained. Lay ecclesial ministers are co-workers with the bishop alongside priests and deacons.\xa0He/she\xa0is an individual who wishes to serve the Church while remaining in secular employment. He/ she is required to attend a programme of training to enhance his/her biblical knowledge, theology and worship and, of course, how to conduct a Service for which there are strict guidelines. Upon successful completion of the programme, he/she is commissioned as a lay Minister. A Mass has the important aspect of the Consecration of bread and wine to the body and blood of Christ. Neither a Lay Minister nor a\xa0Deacon is authorized to consecrate Lectio Divina – (Latin for “Divine Reading”) is a traditional Benedictine practice of scriptural reading, meditation and prayer intended to promote communion with God and to increase the knowledge of God’s Word. It does not treat Scripture as texts to be studied, but as the Living Word. Traditionally,\xa0Lectio Divina\xa0has four separate steps: read; meditate; pray; contemplate. First a passage of Scripture is read, then its meaning is reflected upon. This is followed by prayer and contemplation on the Word of God. The focus of\xa0Lectio Divina\xa0is not a theological analysis of biblical passages but viewing them with\xa0Christ\xa0as the key to their meaning. Lectionary is a book or listing that contains a collection of scripture readings appointed for worship on a given day or occasion. Lector – a\xa0 reader is responsible for reading aloud excerpts of the scripture at a liturgy. He reads from a lecturn c/f (below) Lecturn – the place or stand from which a lector reads his assigned scripture text. Legion of Mary -(Latin: Legio Mariae) is an international association of the faithful of the Catholic Church who serve the Church on a voluntary basis. It was founded in Dublin, Ireland, as a Roman Catholic Marian Movement by layman Frank Duff. Today between active and auxiliary (praying) members there are over 10 million members worldwide making it the largest apostolic organization of lay people in the Catholic Church. Membership is highest in South Korea, Philippines, Brazil, Argentina and the Democratic Republic of Congo. These countries have between 250,000 and 500,000 members each. To be in the Legion of Mary, one must be a practicing Catholic. Active members serve God under the banner of Mary by practicing the Spiritual Works of Mercy. The main apostolate of the Legion consists in activities directed towards all men and women, young and old, rich and poor as well as people from the margins of society (homeless, prostitutes, prisoners etc.) and towards non-Catholics. The members of the Legion are primarily engaged in the performance of the Spiritual Works of Mercy rather than works of material aid. Lent –\xa0 c/f\xa0 Liturgical Seasons below. Limbo — from the Latin limbus, edge or boundary, referring to the “edge” of Hell.\xa0 It is a speculative idea about the afterlife condition of those who die in original sin. Medieval theologians of western Europe described the afterworld/underworld\xa0 as divided into four distinct parts: Hell of the Damned, Purgatory, Limbo of the Fathers or Patriarchs, and Limbo of the Infants. Limbo is not an official doctrine of the Roman Catholic Church nor is it mentioned in the1994 or 1997 Cathechism of the Catholic Church. It is important to stress that all children are children of God. We canconfidently entrust all such clildren, born, unborn, baptised and unbaptisd to God’s loving kindness and endless mercy Liturgical Colours –\xa0 refer to the colour of church vestments and altar appendages that appear in connection with different seasons of the liturgical year. i.e. Ordinary time: green, Advent and Lent\xa0 purple c/f Liturgial Seasons (below) Liturgical Seasons – The liturgical, Church or Christian year, consists of the cycle of liturgical seasons that determine when feast days, including celebrations of saints, are to be observed, and which portions of Scripture are to be read either in an annual cycle or in the Sunday cycle of three years. The Catholic Church sets aside certain days and seasons of each year to recall and celebrate various events in the life of Christ. In its Roman Rite the liturgical year begins with Advent, the time of preparation for both the celebration of Jesus’ birth, and his expected second coming at the end of time. This season lasts from four Sundays before Dec 24(Christmas Eve). Christmastide follows, beginning with First Vespers of Christmas on the evening of 24 December and ending with the Feast of the Baptism of the Lord. Lent is the period of purification and penance that begins on Ash Wednesday and ends on Holy Thursday. The Holy Thursday evening Mass of the Lord’s Supper marks the beginning of the Easter Triduum, which includes Good Friday, Holy Saturday, and Easter Sunday. The days of the Easter Triduum recall Jesus’ Last Supper with his disciples, death on the cross, burial, and resurrection. The seven-week liturgical season of Eastertime immediately follows the Triduum, climaxing at Pentecost. This last feast recalls the descent of the Holy Spirit upon Jesus’ disciples after the Ascension of Jesus. The rest of the liturgical year is commonly known as Ordinary Time when we reflect on the words and actions of Jesus while he preached to his followers and trained the Twelve apostles. Latria — worship, adoration, reverence or prayer owed/directed\xa0 to God alone. It carries an emphasis on the internal form of worship. A most common use of latria in the Church is adoration of the Lord in/at the Eucharist. Liturgy – (Greek: λειτουργία) is the customary public worship – a communal response to the sacred through activity reflecting praise, thanksgiving, supplication, or repentance. Local ordinary – local hierarchy or local church authority is the bishop of the area. Priests and deacons are his assistants. Mass on Internet/TV – \xa0The first thing to remember is that a televised Mass is not a substitute for assisting at Mass within a parish faith community and does not fulfill the Sunday precept. If you truly cannot go to a physical Mass, then the obligation is suspended. If you are sick, you don’t have to fulfill the obligation. If you are old and afraid to go out alone, or that you might slip on the ice, you don’t have to fulfill the obligation. If you are far from a church while travelling and don’t know where to go or can’t get to a church, you don’t have to fulfill the obligation.\xa0 If you are taking care of a sick person and cannot leave, you are not obliged to go to Mass. The 1983 Code of Canon Law, in can. 1245 gives to pastors or \xa0“the parish priest” the ability to grant a dispensation from the obligation in individual cases or else to commute the obligation to other pious works. You can debate whether or not watching Mass on TV or the internet counts as a “pious work”. The limitation of the medium of Internet/television “with its inherent lack of physical interaction with others can lead people to more passive roles as spectators.” But the benefits for those who make use of it outweigh the dangers involved. Many regard televised liturgies as a means of evangelization, of sharing the Good News of Jesus Christ and promoting the Church’s worship via modern means of communication (cf. Church Document “Inter Mirifica,” No. 14).” Live transmission is practically the only form contemplated in the Italian norms due to the particular Italian situation in which Mass is transmitted live every Sunday by one of the national public television stations, either from the Vatican or from a different church or cathedral every week. A next-best solution is the delayed telecast, which is the taping of a Sunday Mass and its transmission on the same day. The least satisfactory solution, to be avoided if possible, is the pre-recorded telecast. \xa0Viewers must be informed that it is pre-recorded and has certain limitations such as having been celebrated outside the liturgical day or season. The guidelines give as an example the “taping of ‘Christmas morning Mass’ on Monday of the fourth week of Advent.” Mariology— the theology concerned with the Virgin Mary, the mother of Jesus Christ. Mary, Names of – According to the New Testament, Mary (Aramaic: Mariam; Hebrew: Miriam; also known as Saint Mary, the Virgin Mary, Our Lady, and the Madonna woman of Nazareth and the mother of Jesus. To distinguish her from the many other Marys appearing in the gospels, she is a often referred to as “Mary, mother of Jesus”. Mediatrix — the role of the Blessed Virgin Mary as a (female human) mediator in the salvation process, “This intercessory role is to be so understood that it neither takes away from nor adds anything to the dignity and efficaciousness of Christ the one Mediator. Metropolitan bishop – A Latin Church Metropolitan is the bishop of the principal (the “metropolitan”) see of an ecclesiastical province composed of several dioceses. He receives a pallium from the pope as a symbol of his office. The metropolitan bishop has limited oversight authority over the suffragan dioceses in their province, including ensuring that the faith and ecclesiastical discipline are properly observed. Military ordinariate – an ecclesiastical jurisdiction responsible for the pastoral care of Catholics serving in the armed forces of a nation. Miracles – an event not explicable by natural or scientific laws – a phenomenon not explained by known laws of nature. Such an event may be attributed to a supernatural being (a deity), magic, a miracle worker, a saint or a religious leader. The gospels record three sorts of miracles performed by Jesus: exorcisms, cures, and nature wonders. In the Gospel of John the miracles are referred to as “signs” and the emphasis is on God demonstrating his underlying normal activity in remarkable ways. In the New Testament, the greatest miracle is the resurrection of Jesus, the event central to Christian faith. Missal – a liturgical book containing all instructions and texts necessary for the celebration of Mass or Eucharist throughout the year. Missal, Roman – Roman Missal (Latin: Missale Romanum) is the liturgical book that contains the texts and rubrics for the celebration of the Mass in the Roman Rite of the Catholic Church. Mitre – Greek: μίτρα, “headband” or “turban”), is part of ceremonial head-dress of bishops and certain abbots in traditional Christianity; continuing the priestly practice of Temple Judaism. They are worn in the Orthodox Church, Roman Catholic Church, as well as in the Anglican Communion, some Lutheran churches, and also bishops and certain other clergy in the Eastern Catholic Churches and the Oriental Orthodox Churches. Monk (from Latin monachus) is a person who practices religious asceticism, living either alone or with any number of other monks. A monk may be a person who decided to dedicate his life to serving all other living beings, or to be an ascetic who voluntarily chooses to leave mainstream society and live his life in prayer and contemplation. The concept is ancient and can be seen in many religions and in philosophy. In modern English the term monk is mainly in use for men. The word nun is typically used for female monastics. Monsignor –\xa0 (english pronunciation: ‘mon-see-knor’) is an honorific form of address for those members of the clergy of the Catholic Church including bishops, honorary prelates and canons. In some cases, these ecclesiastical honorific titles derive from the pope, but in other cases it is simply a customary or honorary style belonging to a prelate or honorary prelate. These are granted to individuals who have rendered valuable service to the Church, or who provide some special function in Church governance, or who are members of bodies such as certain chapters. It is abbreviated Mgr, Msgr, or Mons.Mortal Sin –c/f\xa0 Sin mortal (below) Nave – the main body of the church. It provides the central approach to the high altar. The term nave is from medieval Latin navis (ship). A ship was an early Christian symbol. Narthex\xa0is an architectural element of a church building consisting of the entrance or lobby area, located at the west end of the nave, opposite the church’s main altar. Novice – is a prospective member of a religious institute who is being tried and being proven for suitability of admission to a religious order of brothers, sisters or monks. They are not admitted to vows until they have successfully completed the prescribed period of training and proving. The legislated length and conditions by which anyone aspiring to become a monk or religious\xa0 is obliged to be a novice is normally at least one year. Nun – a member of a religious community of women, typically one living under vows of poverty, chastity, and obedience. She may have decided to dedicate her life to serving all other living beings, or she might be an ascetic who voluntarily chose to leave mainstream society and live her life in prayer and contemplation in a monastery or convent. While in common usage the terms “nun” and “sister” are often used interchangeably (the same title of “Sister” for an individual member of both forms), they are considered different ways of life, with a “nun” being a religious woman who lives a contemplative and cloistered life of meditation and prayer for the salvation of others, while a “religious sister”, in religious institutes like Mother Teresa’s Missionaries of Charity, lives an active vocation of both prayer and service, often to the needy, ill, poor, and uneducated. Nuncio (officially known as an Apostolic nuncio and also known as a papal nuncio) is the title for an ecclesiastical diplomat, being an envoy or permanent diplomatic representative of the Holy See to a state or international organization. A nuncio is appointed by and represents the Holy See, and is the head of the diplomatic mission, called an Apostolic Nunciature, which is the equivalent of an embassy. A nuncio is usually an archbishop. He performs the same functions as an ambassador and has the same diplomatic privileges. Ordinary time – c/f\xa0 Liturgical Seasons below. Papal or (Pontifical) Family or Household – (Latin: Domus Pontificalis), called until 1968 the Papal Court (Pontificalis Aula).\xa0 consists of ecclesiastics at the Holy See who participate in religious ceremonies (Cappella Pontificia) . Historically, they chanted divine service daily in the papal palace, with the Pope in person celebrating or assisting at Pontifical Mass on certain days. The Familia Pontificia), which assists the pope as a juridical body with civil functions. Parish – (Latin: parochus) is a stable community of the faithful within a diocese headed by a bishop, whose pastoral care has been entrusted to a parish priest (Latin: pastor), under the authority of the bishop. It is the primary constituent unit of a diocese.Most parishes are territorial parishes, which comprise all Catholics living within a defined geographic area. A parish may be joined with others in a deanery or vicariate forane and overseen by a vicar forane, also known as a dean or archpriest. As per canon 518, a bishop may also erect non-territorial parishes, or personal parishes, within his diocese. Parish priest – (Latin: pastor), is under the authority of the bishop. It is the primary constituent unit of a diocese. They are also created to better serve Catholics of a particular rite, language, nationality, or other commonality which make them a distinct community. Pastor – The word “pastor” derives from the Latin noun pastor which means “shepherd” and relates to the Latin verb pascere – “to lead to pasture, set to grazing, cause to eat”. The term “pastor” also relates to the role of elder within the New Testament, but is not synonymous with the biblical understanding of minister. Many Protestant churches call their ministers “pastors”. Bishops in Western Christianity often bear a formal crosier in the form of a stylised shepherd’s crook as a symbol of their pastoral/shepherding functions. Patron Saint – a saint who in Roman Catholicism and Eastern Orthodoxy is regarded as the heavenly advocate, protector or guardian of a nation, place, craft, activity, class, clan, family, person or any area of our lives.\xa0 They are sometimes nominated by popes but not necessarily. Anyone can select any saint as a patron. e.g St Joseph, when one is moving house. It is connected to the idea of the communion of saints. Personal Ordinariate – often called a “personal ordinariate for former Anglicans or more informally an “Anglican ordinariate”, is a canonical structure within the Catholic Church established in accordance with the apostolic constitution, Anglicanorum Coetibus of 4 November 2009and its complementary norms.The ordinariates were established in order to enable “groups of Anglicans” to join the Catholic Church while preserving elements of their liturgical and spiritual patrimony. They are juridically equivalent to diocese, “a particular church in which and from which exists the one and unique Catholic Church, but may be erected in the same territory as other dioceses “by reason of the rite of the faithful or some similar reason.” Personal prelature – a canonical structure which comprises a prelate, clergy and laity who undertake specific pastoral activities. The first, and thus far the onlypersonal prelature is Opus Dei. Personal prelatures, similar to dioceses and military ordinariates, are under the governance of the Vatican’s Congregation for Bishops. Pentecost –\xa0 c/f\xa0 Liturgical Seasons below. Pew –\xa0 a long bench seat or enclosed box, used for seating members of a congregation or choir in a church or sometimes a courtroom. Pontiff – from Latin pontifex, a word commonly held to come from the Latin root words pons (bridge) + facere (to do, to make), and so to have the literal meaning of “bridge-builder”. Most commonly it refers to the Bishop of Rome, the Pope- the Supreme Pontiff. Prayer – (Latin precari “to ask earnestly, beg, entreat”) is an invocation or act that seeks to connect with God or some holy person\xa0 Prayer may be directed towards a deity, spirit, holy or deceased person, for the purpose of worshipping, requesting guidance, requesting assistance, confessing transgressions (sins) or to express one’s thoughts and emotions. Thus, people pray for many reasons such as personal benefit, asking for divine grace, spiritual connection, or for the sake of others. Prayer may be either individual or communal and take place in public or in private. It may involve the use of words, song or complete silence. When language is used, prayer may take the form of a hymn, incantation, formal creedal statement, or a spontaneous utterance in the praying person. Prayer online – An online invitation to make a ‘Sacred Space’ in your day, praying here and now, as you visit this website, with the help of scripture chosen every day and on-screen\xa0c/f www.sacredspace.ie/ Predestination and Free will – predestination is, “God’s act of decreeing or foreordaining events from eternity or, from eternity, whatever comes to pass. It is used particularly in theology to denote the preordination of people to everlasting happiness or misery. Free will is our ability to make choices according to our desire. God’s predestination does not mean that we cannot make free will choices. God predestines in and through our choices because God is all-knowing and all-powerful. He knows what we will do because He knows all things. He cannot not know all things. So, whatever you choose to do out of your own free volition is known. But His knowing doesn’t mean you don’t freely choose. An illustration would be that I could arrange for my child to choose ice cream over something else and not violate his free will. For instance, I could put a bowl of chocolate ice cream and a bowl of dirt and rocks in front of my child, and I know exactly which one the child will choose to eat. But my knowing does not violate my child’s free will. Prelate is a high-ranking member of the clergy who is an ordinary or who ranks in precedence with ordinaries. The word derives from the Latin prælatus, “be set above or over” or “prefer”; hence, a prelate is one set over others. The archetypal prelate is a bishop, whose prelature is his particular church. All other prelates, including the regular prelates such as abbots and major superiors, are based upon this original model of prelacy. Presbytery – (residence), a clergy house, especially for the home of one or more Roman Catholic priests. Presbyterium – a body of ordained, active priests in the Roman Catholic or Anglican churches or\xa0 a body of Church elders and ministers, especially (in Presbyterian Churches) an administrative body (court) representing all the local congregations of a district. Priest – The ministerial orders of the Church are those of bishop, presbyter (priest in English), and deacon. All the baptized faithful share the common priesthood with Jesus Christ himself. All who, through the Sacrament of Holy Orders, share in the person of Christ, the Head of His Body, the Church. Their priesthood is thus different in function and essence. “The Latin word ‘sacerdos’ is used to refer in general to the ministerial priesthood shared by bishops and presbyters. An ordained priest is commonly addressed with the title “Father”. Prior –derived from the Latin for “earlier, first”, (or prioress for nuns) is an ecclesiastical title for a superior, usually lower in rank than an abbot or abbess. Its earlier generic usage referred to any monastic superior. c/f Abbot above Prophet – an individual who has claimed to have been contacted by the supernatural or the divine, and to speak for them, serving as an intermediary with humanity, delivering this newfound knowledge from the supernatural entity to other people. The message that the prophet conveys is called a prophecy, which transports —at least in Judaism— a message beyond mere pagan soothsaying, augury, divination, or forecasting, and, often comprises issues of social justice. Claims of prophet-hood have existed in many cultures through history, including Judaism, Christianity, Islam, in Ancient Greece, Zoroastrianism, Manichaeism and many others. Traditionally, prophets are regarded as having a role in society that promotes change due to their messages and actions which can convey the displeasure of God for the behaviour of people. Providence, Divine – the foreseeing care and guidance of God over nature all the creatures of the earth and us with wise loving benevolence. Psalms, Book of – (Hebrew: תְּהִלִּים\u200e or תהילים, Tehillim, “praises”), c The Book of Psalms commonly referred to simply as Psalms or “the Psalms”, is the first book of the “Writings”, the third section of the Hebrew Bible, and a book of the Christian Old Testament. The title is derived from the Greek translation, ψαλμοί psalmoi, meaning “instrumental music” and, by extension, “the words accompanying the music.” The book is an anthology of individual psalms, with 150 in the Jewish and Western Christian tradition and more in the Eastern Christian churches. Many of the psalms are linked to the name of King David, although his authorship is not accepted by some modern Bible scholars. They are a great source of support and consolation e.g. Ps 24 the Good Shepherd Psalm ‘Ratum sed non consummatum’ – (Latin phrase: ratified but not consummated) refers to a specific type of marriage in Catholic matrimonial canon law. If a matrimonial celebration takes place (ratification) but the spouses have not yet engaged in intercourse (consummation), then the marriage is said to be a marriage ‘ratum sed non consummatum.’ The Tribunal of the Roman Rota has exclusive competence to dispense from marriages ‘ratum sed non consummatum’, which can only be granted for a ‘just reason.’ Reader – \xa0an \xa0appointed person who is responsible for reading aloud excerpts of the scripture at a liturgy. In early Christian times, the reader was of particular value due to the rarity of literacy. Rector – an ecclesiastical sense, a cleric who functions as an administrative leader in some Christian denominations. Relics of saints –\xa0 the Bible condones the veneration of relics – parts of the bodies of holy people. In the Old Testament, the Second Book of Kings records that a dead man was brought back to life when his corpse came into contact with the bones of the great prophet Elisha (cf. II Kings 13:20-21). The Acts of the Apostles describe how pieces of cloth that had touched St. Paul’s skin were used to heal the sick and cast out evil spirits (cf. Acts 19:11-12). By the second century, the veneration of relics was already a widespread Christian practice. After St. Polycarp of Smyrna had been burnt at the stake, for example, his faithful disciples carried off his remains. “We took up his bones,” they later recorded, “which are more valuable than precious stones and finer than refined gold, and laid them in a suitable place, where the Lord will permit us to gather ourselves together, as we are able, in gladness and joy, and to celebrate the birthday of his martyrdom.” But even if modern secularism considers relics as leftovers from an uncivilized, superstitious past, the Catholic Church doesn’t. Relics are of three classes: 1. First-class relics are parts of the saint’s body (these are often placed in altars at their consecration); 2. Second-class relics are part of the clothing or anything used during the saint’s life; and 3. Third-class relics are any other object, such as a piece of cloth, that has been touched to a first-class relic. Canon law strictly forbids the buying and selling of relics, a practice which bred abuses in past centuries. Religious (using the word as a noun i.e ‘a religious’ ) what in common language one would call a “monk” or “nun”, as opposed to an ordained “priest”. A religious may also be a priest if he has undergone ordination, but in general he is not. Religious Institute – a society in which members pronounce or make public vows and lead a life of brothers or sisters in common”. Religious Orders –\xa0 a category of Catholic religious institutes. Subcategories are canons regular (canons and canonesses regular who recite the divine office and serve a church and perhaps a parish); monastics (monks or nuns living and working in a monastery and reciting the divine office); mendicants (friars or religious sisters who live from alms, recite the divine office, and, in the case of the men, participate in apostolic activities); and clerks regular (priests who take religious vows and have a very active apostolic life). Resurrection, of Jesus\xa0is the Christian religious belief that, after being put to death, Jesus rose again from the dead. It is the central tenet of Christian theology and part of the Nicene Creed: “On the third day he rose again in accordance with the Scriptures.” In the New Testament, after the Romans crucified Jesus, he was anointed and buried in a new tomb by Joseph of Arimathea but God raised him from the dead and he appeared to many people over a span of forty days before he ascended into heaven, to sit at the right hand of God. The Resurrection of Jesus is the basis of our hope for our own resurrection. Roman Catholic Church – a term which appeared in the English language at the beginning of the 17th century to differentiate members of the Catholic Church (in communion with the Pope) from other Christians who use the term “Catholic”; comparable terms in other languages already existed. Being “catholic” is one of the Four Marks of the Church set out in the Nicene Creed, a statement of belief accepted by many churches even if not in communion with the Pope. The church known as the “Catholic Church” consists of 24 autonomous churches (all of which are subject to the Pope)— one “Western” and 23 “Eastern” — governed by the same two sets of codes of canon law. “Roman Catholic” is used by some governments and scholars to refer to members of the majority Latin Church within the Catholic Church. In compound forms such as “Roman Catholic worship” the term is sometimes used to differentiate Western (Latin Church) practices from Eastern. Roman Martyrology (Latin: Martyrologium Romanum) is the official martyrology of the Catholic Church. Its use is obligatory in matters regarding the Roman Rite liturgy, but dioceses, countries and religious institutes may add to it duly approved appendices. It provides an extensive but not exhaustive list of the saints recognized by the Church. Rosary or Chaplet – (Latin: rosarium, in the sense of “crown of roses” or “garland of roses”), is a form of prayer used especially in the Catholic Church named for the string of prayer beads used to count the component prayers. The prayers that essentially compose the Rosary are arranged in sets of ten Hail Marys with each set preceded by one Lord’s Prayer and followed by one Glory Be. During recitation of each set, known as a decade, thought is given to one of the Mysteries of the Rosary, which recall events in the lives of Jesus and Mary. Normally, five decades are recited in a session. Other prayers are sometimes decade) and before each recitation e.g, the Apostles’ Creed, and after i.e, the Hail, Holy Queen. A standard fifteen Mysteries of the Rosary, based on the long-standing custom, was established by Pope Pius V in the 16th century, grouping the mysteries in three sets: the Joyful Mysteries, the Sorrowful Mysteries, and the Glorious Mysteries. In 2002 Pope John Paul II suggested a new set of five, called the Luminous Mysteries, bringing the total number of mysteries to twenty. Sacraments – ceremonies that point to what is sacred, significant and important for Christians. They are special occasions for experiencing God’s saving presence. They are at the same time signs and instruments of God’s grace. Sacraments, seven – Baptism, Confirmation, Eucharist, Penance, Anointing of the Sick, Holy Orders and Matrimony. They touch all the stages and all the important moments of Christian life. The Church affirms that for believers the sacraments are necessary for salvation”, although not all are necessary for every individual. c/f them the sacraments individually above. Sacrament of Penance – (commonly called Confession, Reconciliation or Penance) is one of seven sacraments of the Catholic Church and sacred mysteries of Eastern Christianity, in which the faithful obtain divine mercy for the sins committed against God and neighbour and are reconciled with the community of the Church. By this sacrament Christians are freed from sins committed after Baptism. The sacrament of Penance is considered the normal way to be absolved from mortal sins which would otherwise seperate a person fron union with God. As biblical basis for this sacrament, the Catholic Church refers to James 5:16, “confess your sins to one another” and to Jesus’ breathing the Holy Spirit to the Apostles, saying “Whose sins you forgive are forgiven them, and whose sins you retain are retained” (John 20:23). Sacred Heart Devotion – This devotion (also known as the Most Sacred Heart of Jesus, Sacratissimi Cordis Iesu in Latin) is one of the most widely practiced and well-known Roman Catholic devotions, taking Jesus Christ’s physical heart as the representation of His divine love for humanity.It is also popular among some high-church Anglicans and Lutherans. The devotion is especially concerned with what the Church deems to be the love and compassion of the heart of Christ towards humanity, and its long suffering. The origin of this devotion in its modern form is derived from a Roman Catholic nun from France, Saint Margaret Mary Alacoque, who said she learned the devotion from Jesus during a series of apparitions to her between 1673 and 1675. The Sacred Heart is often depicted in Christian art as a flaming heart shining with divine light, pierced by the lance-wound, encircled by the crown of thorns, surmounted by a cross, and bleeding. Sometimes the image is shown shining within the bosom of Christ with his wounded hands pointing at the heart. The wounds and crown of thorns allude to the manner of Jesus’ death, while the fire represents the transformative power of divine love. Safeguarding\xa0– the Irish church child protection policy or the Catholic Church in Ireland: ‘Our Children, Our Church’, is published by the Irish Episcopal Conference, the Conference of Religious of Ireland and the Irish Missionary Union. It can be viewed online on the Irish Catholic Bishop’s conference website c/f www.safeguarding.ie and all religious orders’ websites or in all public church buildings that include services with/for children. c/f\xa0Child Protection Policy (above) Sede Vacante – a latin expression that refers to the vacancy of the episcopal see of a particular church. It is Latin for “the seat being vacant” (the ablative absolute of sedes vacans “vacant seat”, or the Italian for the same term), the seat in question being the cathedra of the particular church. After the death or resignation of a pope, the Holy See enters a period of sede vacante. In this case the particular church is the Diocese of Rome and the “vacant seat” is the cathedra of Saint John Lateran, the cathedral church of the Bishop of Rome. During this period, the Holy See is administered by a regency of the College of Cardinals. Shrine – a holy or sacred place of religious devotion, dedicated to a specific deity, ancestor, hero, martyr, saint, or similar figure of awe and respect, at which they are venerated or worshipped.\xa0 Shrines often contain relics, statues or other such objects associated with the figure being venerated. Shrines, Irish – Knock, Clonmacnoise, Glendalough, Mellifontabbey, Christchuch, St Patrick’s Cathedral, Monasterboice, Croagh Patrick, Rock of Cashel, Skellg Michael, St Peter’s, Drogheda, Lough Derg. Shrines, International – International – Divine Mercy Sanctuary, Kraków, Basilica of Saint Anthony of Padua, Sanctuary of Fátima,, Lourdes, Rome, Jerusalem, too many to list\xa0 here. Sin – an offence, wrong-doing, misdeed, any act of violating God’s will or any action that violates the ideal relationship between an individual and God; or an individual and any other person. Ill treating any other creature can also be viewed a sin. Sin, Original – entered the human world through Adam and Eve’s sin in the Garden of Eden \xa0and that human beings have since lived with the consequences of this first sin. Sin, Mortal – seriously wrong actions, omissions performed with full knowledge and consent that cause one to break one’s relationship with God and lose salvation unless the sinner repents and receives forgiveness. Sin, Venial – wrong actions against God or other people that rupture our relationship with God and require some sort of penance either on Earth or in the afterlife e.g Purgatory. Slavery and the Church – The following Popes all condemned slavery. Pope Eugene IV in 1435, Pius II in 1482, Paul III in 1537 He imposed excommunication on those who took part in it), Urban VIII in 1689, Benedict the XIV in 1741 and Gregory XVI in 1838. The Catechism of 1992 continued this long tradition saying the 7th Commandment fibids acts that lead to theesavement f human beings, to their being bought, sold,or exchanged like merchandise, in disregard of their human dignity. Synod – (pronounced sɪned),\xa0 comes from the Greek “σύνοδος” (synodos) meaning “assembly” or “meeting”, and it is synonymous with the Latin word “concilium” meaning “council”.a council of a church, usually convened to decide an issue of doctrine, administration or application. Originally, synods were meetings of bishops, In modern usage, the word often refers to the governing body of a particular church or diocese, e.g Limerick Diocesan Synod 2016 involving laity as well as clergy. Sometimes the phrase “general synod” or “general council” refers to an ecumenical council. The word “synod” also refers to the standing council of high-ranking bishops governing. Tabernacle, Old Testament – means “tent,” “place of dwelling” or “sanctuary.” It was a sacred place where God chose to meet His people, according to the Hebrew Bible, was the portable earthly dwelling place for the divine presence, from the\xa0 time of the Exodus. The image to the left is as Moses designed it – a tent of meeting Tabernacle, Church – A tabernacle is a fixed locked box in the sanctuary in which the Eucharist is reserved after Mass. When Mass is over the consecrated hosts now the containing the sacramental presence of Jesus are placed in the tabernacle for veneration purposes and for the benefit of the sick. Trinity, The Holy – The Christian doctrine of the Trinity (from Latin trinitas “triad”, from trinus “threefold”) defines God as three consubstantial persons, expressions, or hypostases: the Father, the Son (Jesus Christ), and the Holy Spirit; “one God in three persons”. The three persons are distinct, yet are one “substance, essence or nature”, co-equal, co-eternal and consubstantial, and “each is God, whole and entire” while distinct from one another in their relations of origin: The Father generates, the Son who is begotten, and the Holy Spirit who proceeds from the Father. Accordingly, the whole work of creation and grace is seen as a single operation common to all three divine persons, in which each shows forth what is proper to him in the Trinity, so that all things are “from the Father”, “through the Son” and “in the Holy Spirit”. Tridentine Mass Rite –\xa0the Roman Rite Mass which appears in typical editions of the Roman Missal published from 1570 to 1962. The most widely used Mass liturgy in the world until the introduction of the Mass of Paul VI in 1969, it is celebrated in Liturgical Latin. “Tridentine” is derived from the Latin Tridentinus, “related to the city of Tridentum” (modern-day Trent, Italy). In response to a decision of the Council of Trent Pope Pius V promulgated the 1570 Roman Missal, making it mandatory throughout the Western Church, except in places and religious orders with missals from before 1370. Other names used include Traditional Mass and Latin Mass, although the revised form of the Mass that replaced it has its official text in Latin and is sometimes celebrated in that language. In 2007, Pope Benedict XVI issued the motu proprio Summorum Pontificum, accompanied by a letter to the world’s bishops authorizing use of the Tridentine Mass and Ritual for competent priests. The Pope stated that the 1962 edition of the Roman Missal is to be considered an “extraordinary form” (forma extraordinaria) of the Roman Rite, of which the Missal as revised by Pope Paul VI in 1970 is the ordinary, normal or standard form. Since that is the only authorized extraordinary form, some refer to the 1962 Tridentine Mass as “the extraordinary form” of the Mass The 1962 Tridentine Mass is sometimes referred to as the “usus antiquior” (older use) or “forma antiquior” (older form), to differentiate it from the newer form of the Roman Rite in use since 1970, again in the sense of being the only one of the older forms for which authorization has been granted. Vatican, the – refers to: The Holy See, the central governing body of the Catholic Church and sovereign entity recognized by international law, consisting of the Pope and the Roman Curia. (c/f Vatican City below, Holy See above) Vatican Apostolic Library – (Latin: Bibliotheca Apostolica Vaticana), is located in Vatican City. Formally established in 1475, although it is much older, it is one of the oldest libraries in the world and contains one of the most significant collections of historical texts. It currently has 75,000 codices from throughout history, as well as 1.1 million printed books. The Vatican Library is also a research library \xa0for history, law, philosophy, science and theology. The Vatican Library is open to anyone who can document their qualifications and research needs. Photocopies for private study of pages from books published between 1801 and 1990 can be requested in person or by mail. In March 2014, the Vatican Library began an initial four-year project of digitalising a collection of manuscripts, to be made available online. Vatican Secret Archives – were separated from the library at the beginning of the 17th century; they contain about 150,000 items. Some believe they house evidence of extraterrestrial life forms, or ancient texts disproving the existence of Jesus or dark truths that would discredit or destroy the church but alas nothing so dramatic.They contain records chronicling intriguing historical local, national and international events. The ‘secrecy’ is more acurately translated as ‘personal’ or\xa0‘private’ rather than ‘public’ letters. The library has not been secret since 1881 when Pope Leo XIII opened them to scholars of history projects. Vatican Publishing House, the publisher of official documents of the Holy See, separated from the Vatican Library in 1926. Vatican City – the city-state ruled by the Pope, in existence since 1929, on the Vatican Hill in Rome, and which includes St. Peter’s Basilica, the Sistine Chapel and the Vatican Museums. Vatican Hill – One of the hills in Rome, after which the Vatican is named, on the opposite side of the Tiber from the traditional seven hills of Rome. Vatican Basilica – St. Peter’s Basilica, also known as the principal church on the Vatican Hill Vatican Museums –\xa0 (Italian: Musei Vaticani) are the museums of the Vatican City and are located within the city’s boundaries. They contain cultural wealth of the Vatican and display works from the immense collection built up by the Popes throughout the centuries including some of the most renowned classical sculptures and most important masterpieces of Renaissance art in the world e.g. The Sistine Chapel with its ceiling decorated by Michelangelo and the Stanze di Raffaello decorated by Raphael are on the visitor route through the 54 galeries of the Vatican Museums. In 2013, they were visited by 6 million people, which combined makes it is one of the largest museums in the world and the 6th most visited art museum in the world. Venerable – In the Latin Church of the Catholic Church, after a deceased Catholic has been declared a Servant of God by a bishop and proposed for beatification by the Pope, such a servant of God may next be declared venerable (“heroic in virtue”) during the investigation and process leading to possible canonization as a saint. Before a person is considered to be venerable, that person must be declared as such by a proclamation, approved by the Pope, of having lived a life that was “heroic in virtue”, the virtues being the theological virtues of faith, hope, and charity and the cardinal virtues of prudence, justice, fortitude, and temperance. The next steps are beatification, from which point the person is referred to as The Blessed, and finally canonization, from which point he is referred to as Saint. For example, Popes Pius XII and John Paul II were both declared venerable by Pope Benedict XVI in December 2009 and John Paul II was declared saint in 2014 Vestments, Church – liturgical garments and articles associated primarily with the Christian religion, especially among the Eastern Orthodox, Catholics (Latin Church and others), Anglicans, and Lutherans. e.g copes, albs, cotas, humeral veils, stoles, cinctures, amices, chasubles, dalmatics, epicopal gloves, mitres, palliums, zucchettos. Vicar of Christ – (from Latin Vicarius Christi) is the term used in different ways. As the original notion a vicar is of “earthly representative of God or Christ” but also used in sense of “person acting as parish priest in place of ordinary one.” The title is regularly used \xa0to refer to the bishops and more specifically to the Bishop of Rome (the pope. The first record of the concept of the Vicar of Christ is mentioned in the Epistle to the Magnesians of St. Ignatius, Bishop of Antioch, a disciple of John the Apostle, probably commanded by Saint Peter, with a pastoral sense, written between the years 88 and 107 AD “your bishop presides in the place of God (…)”. Vices – Vice is a practice, behaviour, or habit generally considered immoral, sinful, criminal, rude, taboo, depraved, or degrading. They are pride, greed, lust, envy, gluttony, wrath and sloth. There is a parallel tradition of seven virtues. Virtues- the seven Christian virtues or heavenly virtues refers to the union of two sets of virtues: the four cardinal virtues, from ancient Greek philosophy, prudence, justice, temperance (restraint), and courage and the three theological virtues, are faith, hope, and charity (or love). Wisdom, gift of – the ability to judge rightly in matters relating to life and conduct; it involves soundness of judgement in the choice of means and ends; thinking and acting using knowledge, experience, understanding, common sense, and insight.\xa0 Wisdom As a virtue, it is a habit or disposition to perform the action with the highest degree of adequacy under any given circumstance, and to avoid wrongdoing. This implies a possession of knowledge, an understanding of people, objects, events, situations, and the willingness as well as the ability to apply perception, judgement, and action in keeping with the understanding of what is the optimal course of action. It often requires control of one’s emotional reactions (the “passions”)\xa0 so that the universal principle of reason prevails to determine one’s action. In short, wisdom is a disposition to find the truth coupled with an optimum judgement as to what actions should be taken. World Meeting of Families \xa0– takes place every three years, and is coordinated by the Vatican’s Dicastery for the Laity, Family and Life.\xa0 Established by Pope Saint John Paul II in 1992 as a pastoral initiative, its aim is to strengthen the sacred bonds of the family unit across the globe.\xa0 The first World Meeting of Families took place in Rome in 1994, the International Year of the Family.\xa0 Every three years since 1994, families from all over the world are invited by the Holy Father to attend this global gathering.\xa0 During a World Meeting, families come together to share experiences, to dialogue, to pray and work together to grow as individuals and as family units.\xa0 Delegates participate in discussion groups on the role of the Christian family in the Church and society, and are addressed by distinguished speakers.\xa0 The eighth and most recent World Meeting took place in Philadelphia in September 2015. Jesus, Mary and Joseph,\xa0in you we contemplate\xa0the splendour of true love;\xa0to you we turn with trust. Holy Family of Nazareth,\xa0grant that our families too\xa0may be places of communion and prayer,\xa0authentic schools of the Gospel\xa0and small domestic churches. Holy Family of Nazareth,\xa0may families never again experience\xa0violence, rejection and division;\xa0may all who have been hurt or scandalized\xa0find ready comfort and healing. Holy Family of Nazareth,\xa0make us once more mindful\xa0of the sacredness and inviolability of the family,\xa0and its beauty in God’s plan. Jesus, Mary and Joseph,\xa0graciously hear our prayer. Amen.', 'The Rosary ( Latin : rosarium , in the sense of ""crown of roses"" or ""garland of roses"", usually in the form of the Dominican Rosary , is a form of prayer used especially in the Catholic Church named for the string of prayer beads used to count the component prayers. When used of the form of prayer, the word is usually capitalized (""the Rosary""), as is customary for other names of prayers, such as ""the Lord\'s Prayer "", ""the Hail Mary "", ""the Magnificat "". When referring to the beads, it is normally written with a lower-case initial (""a rosary""). The prayers that essentially compose the Rosary are arranged in sets of ten Hail Marys with each set preceded by one Lord\'s Prayer and followed by one Glory Be . During recitation of each set, known as a decade, thought is given to one of the Mysteries of the Rosary , which recall events in the lives of Jesus and Mary . Normally, five decades are recited in a session. Other prayers are sometimes added after each decade (in particular, the Fátima Prayer ) and before (in particular, the Apostles\' Creed ), and after (in particular, the Hail, Holy Queen ) the five decades taken as a whole. The rosary as a material object is an aid towards saying these prayers in the proper sequence. A standard fifteen Mysteries of the Rosary, based on the long-standing custom, was established by Pope Pius V in the 16th century, grouping the mysteries in three sets: the Joyful Mysteries, the Sorrowful Mysteries, and the Glorious Mysteries. In 2002 Pope John Paul II suggested a new optional set of five, called the Luminous Mysteries, bringing the total number of mysteries to twenty. For over four centuries, the rosary has been promoted by several popes as part of the veneration of Mary in Roman Catholicism . The rosary also represents the Roman Catholic emphasis on ""participation in the life of Mary, whose focus was Christ"", and the Mariological theme ""to Christ through Mary"", taught by Saint Louis de Montfort . https://en.wikipedia.org/wiki/Rosary Whoever shall faithfully serve me by the recitation of the Rosary, shall receive signal graces. I promise my special protection and the greatest graces to all those who shall recite the Rosary. The Rosary shall be a powerful armor against hell, it will destroy vice, decrease sin, and defeat heresies. It will cause virtue and good works to flourish; it will obtain for souls the abundant mercy of God; it will withdraw the hearts of people from the love of the world and its vanities, and will lift them to the desire of eternal things. Oh, that souls would sanctify themselves by this means. The soul which recommends itself to me by the recitation of the Rosary, shall not perish. Whoever shall recite the Rosary devoutly, applying themselves to the consideration of its Sacred Mysteries shall never be conquered by misfortune. God will not chastise them in His justice, they shall not perish by an unprovided death; if they be just, they shall remain in the grace of God, and become worthy of eternal life. Whoever shall have a true devotion for the Rosary shall not die without the Sacraments of the Church. Those who are faithful to recite the Rosary shall have during their life and at their death the light of God and the plentitude of His graces; at the moment of death they shall participate in the merits of the Saints in Paradise. I shall deliver from purgatory those who have been devoted to the Rosary. The faithful children of the Rosary shall merit a high degree of glory in Heaven. You shall obtain all you ask of me by the recitation of the Rosary. All those who propagate the Holy Rosary shall be aided by me in their necessities. I have obtained from my Divine Son that all the advocates of the Rosary shall have for intercessors the entire celestial court during their life and at the hour of death. All who recite the Rosary are my children, and brothers and sisters of my only Son, Jesus Christ. Devotion to my Rosary is a great sign of predestination. Saint Louis-Marie Grignion de Montfort (31 January 1673 – 28 April 1716) was a French Roman Catholic priest and Confessor. He was known in his time as a preacher and was made a missionary apostolic by Pope Clement XI.[1] ""If you say the Rosary faithfully until death, I assure you that in spite of the gravity of your sins, you shall receive a never-fading crown of glory. Even if you are on the brink of damnation, even if you have one foot in Hell, even if you have sold your soul to the devil as sorcerers do who practice black magic, and even if you are a heretic as obstinate as a devil, sooner or later you will be converted and will amend your life and save your soul, if and mark well what I say -- if you say the Holy Rosary devoutly every day until death for the purpose of knowing the truth and obtaining contrition and pardon of your sins."" Pray the Rosary every day, in order to obtain peace for the world, and the end of the war. ...May 13, 1917 I wish you to come here on the 13th of next month, to pray the Rosary each day. ...June 13, 1917 I want you to come here on the 13th of next month, and to continue praying the Rosary every day in honor of Our Lady of the Rosary, in order to obtain peace for the world and the end of the war, because only She can help you. ...July 13, 1917 I want you to continue praying the Rosary every day. ...August 19, 1917 Continue to say the Rosary to obtain the end of the war. ...September 13, 1917 I am Our Lady of the Rosary. Continue to say the Rosary every day. ...October 13, 1917 You at least try to console Me and announce in My name that I promise to assist at the moment of death, with all the graces necessary for salvation, all those who, on the First Saturday of five consecutive months shall confess, receive Holy Communion, recite ftve decades of the Rosary, and keep Me Company for fifteen minutes while meditating on the fifteen mysteries of the Rosary, with the intention of making Reparation to Me. ... December 10, 1925 to Sister Lucy at Pontevedra ""There is no surer means of calling down God\'s blessing upon the family than the daily recitation of the Rosary."" ""Those who say the Rosary frequently and fervently will gradually grow in grace and holiness and will enjoy the special protection of Our Lady and the abiding friendship of God."" 1. Have Masses offered for them. 2. Pray the Rosary and and the Chaplet for the Holy Souls. 3. Pray the Stations of the Cross. 4. Offer up little sacrifices and fast. 5. Spread devotion to them. 6. Attend Eucharistic Adoration and pray for them. 7. Gain all the indulgences you can, and apply them to the Holy Souls. mentally, for the departed.  The indulgence is plenary each day from the 1st to the 8th of November;  on other days of the year it is partial. A plenary indulgence, applicable only to the Souls in Purgatory, is granted to the faithful, who on the day dedicated to the Commemoration of all the faithful departed piously visit a church, a public oratory or ----- for those entitled to use it ----- a semipublic oratory. The above indulgence can be acquired either on the day designated above or, with the consent of the Ordinary, on the preceding or following Sunday or the Feast of All Saints [November 1]. The above indulgence is contained in the Apostolic Constitution The Doctrine of Indulgences, Norm 15, with account being taken of proposals made to the Sacred Penitentiary in the meantime. In visiting the church or oratory, it is required, according to Norm 16 of the same Apostolic Constitution, that ""one Our Father and the Creed be recited."" circumstances]. pious meditation on a particular mystery of our Redemption."" Eternal rest grant to them, O Lord, and let perpetual light shine upon them.  May they rest in peace. Partial indulgence, applicable only to the Souls in Purgatory. May it please Thee, O Lord, to reward with eternal life all those who do good to us for Thy Name\'s sake.  Amen. Partial indulgence. Merciful Lord Jesus, grant them everlasting rest.  (Roman Missal) Partial indulgence. on us to help them.  If we release a soul from there, it will be while we yet live on earth and if, we should go there. When praying the Rosary, reserve, if possible, one decade to pray for these Poor Souls. If you are able, say an entire Rosary exclusively for their release, at least in November. and the Church suffering in Purgatory. Eternal rest grant unto them, O Lord; and let perpetual light shine upon them. May they rest in peace. Amen. Requiem aeternam dona eis Domine; et lux perpetua luceat eis. Requiescant in pace. Amen . All before the throne it bringeth. To its Judge an answer making. Thence shall judgment be awarded. Nothing unavenged remaineth. Leave me not to reprobation. Ere that day of retribution. Thou to me a hope hast given. Rescue me from fires undying. To Thy right hand do thou guide me. Call me, with Thy Saints surrounded. Grant them Thine eternal rest. Amen. MOST loving Jesus, I humbly beseech Thee, that Thou Thyself wouldst offer to Thine eternal Father in behalf of the Holy Souls in Purgatory, the Most Precious Blood which poured forth from the sacred Wounds of Thine adorable Body, together with Thine agony and death. And do thou likewise, O sorrowful Virgin Mary, present unto Him, together with the dolorous Passion of thy dear Son, thine own sighs and tears, and all the sorrows thou didst suffer in His suffering, in order that, through the merits of the same, refreshment may be granted to the Souls now suffering in the fiery torments of Purgatory, so that, being delivered from that painful prison, they may be clothed with glory in Heaven, there to sing the mercies of God for ever and ever. Amen . Absolve, O Lord, the Souls of all the faithful departed from every bond of sin, that with Thy gracious assistance they may deserve to escape the judgment of vengeance and enjoy the blessedness of everlasting light. O God, Who hast commanded us to honor our father and our mother, in Thy mercy have pity on the souls of my father and mother, and forgive them their trespasses, and make me to see them again in the joy of everlasting brightness. Through Christ our Lord. Amen. O Most compassionate Jesus, have mercy on the Souls detained in Purgatory, for whose redemption Thou didst take upon Thyself our nature and endure a bitter death. Mercifully hear their sighs, look with pity upon the tears which they now shed before Thee, and by virtue of Thy Passion, release them from the pains due to their sins. O most merciful Jesus, let Thy Precious Blood reach down into Purgatory and refresh and revive the captive souls who suffer there. Stretch out to them Thy strong right hand, and bring them forth into the place of refreshment, light and peace. Amen.', 'Rosary on the Coast locations in Ireland yesterday. The head of the Catholic Church in Ireland has added his voice to Pope Francis’s call to the faithful to pray the Holy Rosary every day during the month of October. Archbishop Eamon Martin of Armagh said that Ireland has a long tradition and devotion to praying the Rosary within the family. The Archbishop was speaking from speaking from Rome, where he is attending the Synod on Young People, Faith and Vocational Discernment. “It is a beautiful prayer but there are often misconceptions about the Rosary because it is quite repetitive,” he said. “In every decade of the Rosary we contemplate a different aspect of the life, death and Resurrection of Jesus. I always encourage people to place themselves into the scene of the particular decade as you pray, imagining the feeling and emotions that Jesus, Mary, Joseph, and others experienced during the actual events highlighting Our Lord’s ministry.” Archbishop Martin pointed out that in Ireland and in more than 40 other countries across the globe, people were gathering at coastal and border locations to recite the Rosary together for Life and for Faith. Organisers of the international Rosary on the Coast initiative described it as an attempt to form “a Holy League of Nations”. As reported last week by CatholicIreland.Net, as well as calling for daily recitation of the Rosary this month, Pope Francis is asking that the faithful conclude their recitations with two special prayers. The first is to Our Lady, Sub tuum praesidium:\xa0“We fly to thy protection, O Holy Mother of God. Do not despise our petitions in our necessities, but deliver us always from all dangers, O Glorious and Blessed Virgin.” The second is a prayer to St Michael the Archangel: “Saint Michael Archangel, defend us in battle, be our protection against the wickedness and snares of the devil; may God rebuke him, we humbly pray; and do thou, O Prince of the heavenly host, by the power of God, cast into hell Satan and all the evil spirits who prowl through the world seeking the ruin of souls. Amen.” During the recitation of each decade of the Rosary – comprising the Lord’s Prayer, ten Hail Marys and a Glory Be – Catholics focus on Mysteries, or elements of the life of Our Lord and Our Lady. Since the time of Pope Pius V in the 16th century, there were 15 Mysteries grouped into three sets – the Joyful Mysteries, the Sorrowful Mysteries and the Glorious Mysteries. However, in 2002 Pope John Paul II added a new set of five mysteries, the Luminous Mysteries. Often, when people recite the Rosary, they offer particular intentions before each decade to ask Our Lady to grant a favour, said Archbishop Martin. These intentions may be to heal a sick person or convert a sinner, to help and guide in times of trouble, illness, financial difficulties, seeking employment or to ask for her help when studying for exams. The Archbishop said intentions are as varied as the people who pray. “Our Lady loves the prayer of the Rosary. She wants to hear and grant our petitions and requests. “Especially in this month of the Holy Rosary, we can join in communion and in penitence, as the people of God, in asking Our Lady and Saint Michael the\xa0Archangel to protect the Church from the devil and in the struggle against evil. I encourage members of the faithful to visit their local grotto or shrine to Our Lady during the month of the Rosary.” Sunday, 7 October was the Feast of Our Lady of the Rosary.', 'October is the month devoted to the Holy Rosary. This is the perfect time for us to reflect upon the meaning of the Rosary and its significance in our walk of faith. The Rosary is taken from the Latin word “rosarium” which means “crown of roses” or “garland of roses.” To us members of the Catholic Faith, the Rosary is a form of prayer that we use along with its namesake prayer beads. When referring to the prayer, the word Rosary is usually capitalized and when talking about the beads, the lower-case form is used. According to pious tradition, the idea of the Rosary was given to Saint Dominic when the Virgin Mary appeared to him in an apparition in the year 1214. This Marian apparition is given the title of Our Lady of the Rosary. The Dominican priest and theologian Alanus de Rupe promoted the practice of the Rosary by establishing the “fifteen rosary promises” and founding several rosary confraternities. Devotion to the Rosary is one of the most distinguishable features of popular Catholic spirituality. The Rosary inspires us to meditate on the mysteries of the lives of Jesus and Mary. Meditation is an important of our lives as Catholics. According to the Catechism of the Catholic Church, meditation “engages thought, imagination, emotion and desire. This mobilization of faculties is necessary in order to deepen our convictions of faith, prompt the conversion of our heart and strengthen our will to follow Christ.” The Rosary is a devotion in honor of the Virgin Mary. It is made up of a set number of prayers. At the start of the Rosary are the introductory prayers which are composed of one Apostle’s Creed, one Our Father, three Hail Mary’s and one Glory Be. In the 16th century, Pope Pius V established the standard fifteen Mysteries of the Rosaries which are grouped into three, the Joyful Mysteries, the Sorrowful Mysteries and the Glorious Mysteries. In 2002, Pope John Paul II added a set of five to the existing fifteen mysteries and these became known as the Luminous Mysteries. Today, the total number of mysteries is twenty. The Joyful Mysteries include the Annunciation (Luke 1:26-38), the Visitation (Luke 1:40-56), the Nativity (Luke 2:6-20), the Presentation of Jesus in the Temple (Luke 2:21-39), and the Finding of the child Jesus in the Temple (Luke 2:41-51). Then comes the Sorrowful Mysteries include the Agony in the Garden (Matthew 26:36-46), the Scourging (Matt. 27:26), the Crowning with Thorns (Matt. 27:29), the Carrying of the Cross (John 19:17), and the Crucifixion (Luke 23:33-46). The third mystery is Glorious Mysteries which are the Resurrection (Luke 24:1-12), the Ascension (Luke 24:50-51), the Descent of the Holy Spirit (Acts 2:1-4), the Assumption of Mary into heaven (Rev. 12), and her Coronation (Rev. 12:1). The Luminous Mysteries include the Baptism of Jesus in the Jordan, the Wedding at Cana, Jesus’ Proclamation of the Kingdom of God, the Transfiguration and the Institution of the Eucharist. All throughout the history of the Catholic Church, many popes and saints have encouraged praying the Rosary. As we begin to understand and appreciate the Rosary and pray it more frequently, we come to see the true meaning of its meditations. We begin to appreciate how its prayers are reminders not only of Mary the Mother of God but of Christ himself. Through Mary, we are led to a closer relationship with her son, Jesus. The Rosary is an invitation for us to present our needs to God and to love Him more. When we recite the twelve prayers that form the decade of the rosary, we need to deeply reflect on the mystery associated with that decade. Simple recitation, whether vocally or in silence, is not enough because we miss the true essence of the prayers. Praying the Rosary therefore is not just simply about reciting prayers. It involves reflecting on the grace of God. Praying is a powerful act that lets us develop and strengthen our relationship with God and the Rosary offers the same beautiful reward. By praying the Rosary, we meditate on the events in the life of Jesus Christ and this lets us know God more. When we are unaware of the meditation aspect of the Rosary, we reduce the prayer to an empty, repetitive and meaningless gesture. In Matthew 6:7, Jesus Christ forbids us to practice prayer in meaningless and repetitive babbles. It is precisely the reflective nature of the Rosary that distinguishes it as a powerful and profound way of praying. Rosaries are not just beads or a prayer that we recite during the month of October. Many spiritual battles have been won because of this symbolic act. Many hearts have been touched and many discouraged people have been uplifted because of the Rosary. How do you plan to celebrate the month of Rosary? What is the significance of the Rosary in your personal life? How did it strengthen you in your walk of faith? Hi Henry, thank you for your comment. We have sent you an email. – Admin Copyright 2023 The Catholic Faith Store.', 'The system has encountered an unexpected error in accessing the page that you requested. The page you are looking for may no longer exist.  Please refresh or reload this page to try again.', 'how-to-pray-the-rosary-everyday.com St. Michael Cemetery Software Mapping of our St. Michael Cemetery is a work in progress.\xa0 Please be patient as it may take me up to a couple of years to enter all the data related to our cemetery.\xa0 As I learn more and enter more information I will be able to let the parish see how to best utilize this program. For the Christian death is not an end, but a beginning. In death, the faithful follower truly lives with our Lord in eternal and blessed union. At the time of mourning, it can be a great comfort to your family and friends to know that the readings, songs and other arrangements that are made for the celebration of Holy Mass and Christian Burial were specifically chosen by you. The link above will let you print off the Funeral Mass Pre-Arrangement Book that you can use to help you plan your funeral Mass. File in pages 20-21 of this document and keep them in a place that is known to your immediate family. Remember, it is the grace of being baptized Christian that upon death the Sacred Rite of Christian Burial should be celebrated. This is the desire of the Church. St. Michael School Website St. Michael School Classroom Web page', 'The Rosary (from Latin rosarium, meaning ""rose garden""[1] or ""garland of roses""[2]) is a popular traditional Roman Catholic devotional practice, which denotes both a set of prayer beads and the devotional prayer itself. The prayers consist of repeated sequences of the Lord\'s Prayer followed by ten recitations of the Hail Mary and a single recitation of ""Glory Be to the Father""; each of these sequences is known as a decade. The recitation of each decade is accompanied by meditation on one of the Mysteries of the Rosary, which are events in the lives of Jesus Christ and his mother, the Blessed Virgin Mary. The traditional 15 Mysteries of the Rosary were finalized by the sixteenth century. The mysteries were grouped into three sets: the joyful mysteries, the glorious mysteries, and the sorrowful mysteries. In 2002, Pope John Paul II announced five new optional mysteries, the luminous mysteries, bringing the total number of mysteries to 20. Emphasis on the rosary is part of the Roman Catholic focus on Mariology, as exemplified by Pope John Paul II\'s Apostolic Letter Rosarium Virginis Mariae[3] which builds on the ""total Marian devotion"" pioneered by Saint Louis de Montfort. On the Roman Catholic liturgical calendar the Feast of Our Lady of the Rosary is celebrated on October 7. The rosary is sometimes used by other Christians, especially in the Anglican Communion and the Old Catholic Church, and also by some Lutherans. Evangelical Protestants, however, such as Baptists and Presbyterians do not use it and actively discourage their members from using this method of prayer. Many similar prayer practices exist in popular Roman Catholicism, each with its own set of prescribed prayers and its own form of prayer beads, such as the prayer rope in Eastern Orthodox Christianity. These other devotions and their associated beads are usually referred to as ""chaplets."" There are differing views on the history of the rosary. According to Roman Catholic tradition, the rosary was given to Saint Dominic in an apparition by the Blessed Virgin Mary in the year 1214 in the church of Prouille. This Marian apparition received the title of Our Lady of the Rosary.[4] However, most scholarly research suggests a more gradual and organic development of the rosary.[5] Prayers with beads like the rosary may have begun as a practice by the laity to imitate the monastic Liturgy of the Hours, during the course of which the monks prayed the 150 Psalms daily. As many of the laity and even lay monastics could not read, they substituted 150 repetitions of the Our Father (Pater noster in Latin) for the Psalms, sometimes using a cord with knots on it to keep an accurate count.[5] During the middle ages, evidence suggests that both the Our Father and the Hail Mary were recited with prayer beads. In the seventh century, Saint Eligius wrote of using a counting device to keep track of the 150 Hail Marys of the Psalter of Mary.[6] In thirteenth century Paris, four trade guilds existed of prayer bead makers, who were referred to as paternosterers, and the beads were referred to as paternosters, suggesting a continued link between the Our Father (Pater noster in Latin) and the prayer beads.[5] In the twelfth century, the rule of the English anchorites, the Ancrene Wisse, specified how groups of fifty Hail Marys were to be broken into five decades of ten Hail Marys each.[5] Gradually, the Hail Mary came to replace the Our Father as the prayer most associated with beads. Eventually, each decade came to be preceded by an Our Father, which further mirrored the structure of the monastic Liturgy of the Hours. The practice of meditation during the recitation of the Hail Marys can be attributed to Dominic of Prussia (1382-1461), a Carthusian monk.[5] Regardless of the origin of the rosary, it was greatly promoted by the preaching of the Dominican priest Alan de Rupe, who helped to spread the devotion in France, Flanders, and the Netherlands between 1460 and his death in 1475.[7] From the sixteenth to the early twentieth century, the structure of the rosary remained essentially unchanged. There were 15 mysteries, one for each of the 15 decades. In the twentieth century the addition of the ""Fatima Prayer"" to the end of each decade became popular. There were no other changes until 2002 when John Paul II instituted five optional new Luminous Mysteries. A rosary provides a physical method of keeping track of the number of Hail Marys said. The fingers are moved along the beads as the prayers are recited. By not having to keep track of the count mentally, the mind is more able to meditate on the mysteries. A five decade rosary contains five groups of ten beads (a decade), with additional large beads before each decade. The Hail Mary is said on the ten beads within a decade, while the Our Father is said on the large bead before each decade. A new mystery is meditated upon at each of the large beads. Some rosaries, particularly those used by religious orders, contain 15 decades, corresponding to the traditional 15 mysteries of the rosary. Both five and fifteen decade rosaries are attached to a shorter strand, which starts with a crucifix followed by one large, three small, and one large beads before connecting to the rest of the rosary. The recitation of the rosary is started on the short strand, reciting the Apostle\'s Creed at the crucifix, an Our Father at the first large bead, three Hail Marys on the next three beads, then a Glory be to the Father on the next large bead. The recitation of the decades then follows. Although counting the prayers on a string of beads is customary, the prayers of the rosary do not actually require a set of beads, but can be said using any type of counting device, by counting on one\'s fingers, or by counting by oneself without any device at all. The beads can be made from wood, bone, glass, crushed flowers, semi-precious stones such as agate, jet, amber, or jasper, or precious materials including coral, crystal, silver, and gold. Rosaries are sometimes made from the seeds of the ""rosary pea"" or ""bead tree."" Today, the vast majority of rosary beads are made of glass, plastic, or wood. Early rosaries were strung on strong thread, often silk, but modern ones are more often made as a series of chain-linked beads. Our Lady\'s Rosary Makers produce some seven million rosaries annually that are distributed to those in economic and spiritual need.[22] It is especially common for beads to be made of material with some special significance, such as jet from the shrine of Saint James at Santiago de Compostela, or olive seeds from the Garden of Gethsemane. Beads are sometimes made to enclose sacred relics, or drops of holy water. A set of blessed Rosary Beads is a sacramental. In addition to a string of beads the rosary comes in other forms for ease of use. A ring rosary is a finger ring with eleven knobs on it, ten round ones and one crucifix. A rosary bracelet is one with ten beads and often a cross or medal as well. The most modern form is the rosary card. A rosary card is either one with a ""handle"" that moves like a slide rule to count the decade, or it has a whole rosary with bumps similar to Braille. Rosary beads are at times used to say Roman Catholic rosary based prayers which do not involve the Hail Mary and the mysteries of the rosary. Examples include the Chaplet of Divine Mercy introduced by Saint Faustina Kowalska and the Rosary of the Holy Wounds introduced by the Venerable Sister Mary Martha Chambon.[23] These prayers often use rosary beads, but their words and format do not correspond to the usual mysteries. Both Saint Faustina Kowalska and the Venerable Sister Mary Martha Chambon attributed these prayers to Jesus as part of their Visions of Jesus and Mary|visions of Jesus Christ.[24] The recitation of the Rosary is traditionally dedicated to one of three sets of ""Mysteries"" to be said in sequence, one per a day: the Joyful (sometimes Joyous) Mysteries; the Sorrowful Mysteries; and the Glorious Mysteries. Each of these three sets of Mysteries has within it five different themes to be meditated on, one for each decade of ten Hail Marys. Pope John Paul II, in his apostolic letter Rosarium Virginis Mariae (October 2002), recommended an additional set called the Luminous Mysteries (or the ""Mysteries of Light"").[21]Catholic faithful who prefer the original fifteen mysteries point to the belief that the Rosary is Mary\'s Psalter, containing 150 Hail Marys in its body for the 150 Psalms.[25] The Luminous Mysteries make the total 200, but incorporate Christ\'s ministry. Many people add a recitation of the Fatima Decade Prayer at the end of each Decade. In the practice of the Brothers of the Christian Schools, they have an additional decade for the intentions of the students or the Blessed Virgin Mary. Rosary is usually prayed in Church during afternoon or evening hours. Many Catholics pray the rosary on their own, when alone. But the rosary is also an old family prayer. This specific family devotion has been supported be several popes including Pope Pius XII in his encyclical Ingruentium Malorum: The custom of the family recitation of the Holy Rosary is a most efficacious means. What a sweet sight - most pleasing to God - when, at eventide, the Christian home resounds with the frequent repetition of praises in honor of the High Queen of Heaven! Then the Rosary, recited in the family, assembled before the image of the Virgin, in an admirable union of hearts, the parents and their children, who come back from their daily work. It unites them piously with those absent and those dead. It links all more tightly in a sweet bond of love, with the most Holy Virgin, who, like a loving mother, in the circle of her children, will be there bestowing upon them an abundance of the gifts of concord and family peace.[30] In Monastic Houses, monks were expected to pray the Divine Office daily in Latin, the liturgical language of the Roman Catholic Church. In some Houses, lay brothers who did not understand Latin or who were illiterate were required to say the Lord\'s Prayer a certain number of times per day while meditating on the Mysteries of the Incarnation of Christ. Since there were 150 Psalms, this could number up to 150 times per day. To count these repetitions, they used beads strung upon a cord and this set of prayer beads became commonly known as a Pater noster, which is the Latin for ""Our Father."" Lay people adopted this practice as a form of popular worship. The Paternoster could be of various lengths, but was often made up of five “decades” of ten beads, which when performed three times made up 150 prayers. Other Paternosters, most notably those used by lay persons, may have had only had 10 beads, and may have also been highly ornamented. As the Rosary (ring of flowers) incorporating the Hail Mary prayer became more common, it was often still referred to as a Paternoster. In 1233, seven of the members of a Florentine Confraternity devoted to the Holy Mother of God were gathered in prayer under the presidency of Alessio Falconieri. According to tradition, Mary appeared and exhorted them to devote themselves to her service, in retirement from the world. They retired to the deserted slopes of Monte Senario near Florence, where they experienced another vision of Mary. There they formed a new Order called the Servants of Mary, or Servites, in recognition of their special manner of venerating Our Lady of Sorrows. The seven-""week"" Servite Rosary is variously called the Servite Chaplet; Rosary of the Seven Dolors of the Blessed Virgin Mary; and the Seven Swords Rosary. A set of introductory prayers for the Servite Rosary was written by Saint Alphonsus Liguori in his book The Glories of Mary.[31] The Irish (specifically the Gaelic-speaking) and their descendants have a tradition of saying 13 Aves rather than ten, in honor of Saint Anthony of Padua, whose feast day is June 13. Also called the St. Anthony Chaplet, its prayers are accompanied by a poem called the Miraculous Responsory or si quideris, written by Saint Bonaventure. In 1263, Saint Bonaventure encouraged liturgical devotion honoring the mystery of The Visitation. The Franciscan Crown, officially established in 1422, consists of seven decades of Hail Marys, each preceded by an Our Father and followed by a Glory Be, and completed by two more Hail Marys after the 7th decade to complete the number 72 which is thought to be the age of Mary at the time of her Assumption. The Crown recalls the seven joys of Mary and how she responded to the grace of God in her life. Franciscans are credited with adding the final words to the Hail Mary: Jesus. Holy Mary, Mother of God, pray for us sinners (from the writings of St. Bernardino of Siena) now and at the hour of our death (from the writings of the Servite Fathers and the Roman Breviary). The rosary as prayed by the Birgittine order comprises 7 Our Fathers (to honor the joys and sorrows of the Blessed Virgin), and 63 Hail Marys, one for each (presumed) year of her life before the Assumption. The layout of the beads is a loop containing six decades, together with a short string of beads leading to the crucifix.[32] An example of the Birgittine rosary may be seen depicted on the Statue of the Crowned Virgin in the Sanctuary of Our Lady of Lourdes. Religious persecution of Catholics began in England and Ireland under Henry VIII in 1540 and continued until about 1731. During what has been called the Penal Times, death became the common penalty for attending a Mass or harboring a priest. Small, easily hidden Rosaries were used to avoid detection. Sometimes rather than a cross, other symbols of specific meanings were used: These rosaries, especially the smaller ring-type, have since become known as soldiers\' rosaries, because they were often taken into battle by soldiers, most notably during World War I. These single-decade Rosary variations can be worn as a ring or carried easily and are still popular. A rosary ring is a ring worn around the finger with 10 indentations and a cross on the surface, representing one decade of a rosary. This is often worn as jewelry, and used through the day. Some ring Rosaries use a small bearing on the inside of the ring to permit easy turning. A finger Rosary is similar to a ring, but is a bit larger. Rosaries like these are used by either rotating or just holding them between a finger and thumb while praying. A hand Rosary is a decade in a complete loop, with one bead separated from ten other beads, this is meant to be carried while walking or running, so as not to entangle the larger type. Credit card-sized Rosaries have also appeared, especially among members of militaries, where holes or bumps represent the prayers and the persons praying move their fingers along the bumps to count prayers. While use of the Roman Catholic rosary has gradually been adopted by many Eastern Catholics, many Eastern Catholic churches have undertaken a campaign of liturgical de-Latinization, removing imported devotions and practices (such as the rosary) that have obscured and replaced traditional and authentic devotions and practices of the Eastern Catholic Churches. Subsequently, the most common prayer used in the Eastern Christian Churches (Eastern Orthodox and Eastern Catholic) is the Jesus Prayer, which makes use of the more ancient prayer rope (chotki), a knotted rope (rather than beads) joined together with a knotted cross. The prayer rope is not as fixed in form as the Western rosary (it may have 10, 33, 50, 100, or 500 knots on it), and it normally makes use of beads only as dividers between sections. The Eastern prayer rope is often divided into decades, but it may also be divided into sections of 25 or some other number, or not divided at all. Among High Church Anglicans, Anglican prayer beads are sometimes used. This set is also known as the ""Anglican Rosary"" or as ""Christian prayer beads,"" the latter term arising from the popularity this set has gained among Christians of various other traditions. Anglican bead sets contain 28 beads in groups of seven called ""weeks,"" with an additional large bead before each. In total, there are 33 beads representing the years of Jesus\' life on Earth. A number of Anglicans use the Jesus Prayer, just like the Eastern Christians, but there are no Church-appointed prayers or meditations in the Anglican practice. Some Anglo-Catholics use the traditional Roman Catholic rosary. A recent creation known as the Ecumenical Miracle Rosary uses the same beads as the Roman Catholic rosary but with different prayers and with mysteries which focus on Christ\'s miracles. Wearing of a Rosary that one actually uses to pray is neither uncommon nor sacrilegious in various Roman Catholic-adherent cultures and was a common practice in the Medieval and Renaissance periods, particularly among religious (monks, nuns, and friars). Rosaries are also worn hanging from or looped over a belt, particularly with some religious habits, pinned to and hanging from a shoulder or neckline, or wrapped around a wrist or arm as a bracelet. Some Christians feel that it is sacrilegious for a non-believer to wear a rosary around the neck. This is especially true in Roman Catholic cultures that have histories of persecution, particularly among the Irish and English Catholics. Because Irish Catholic tradition is often seen as normative in the United States and Canada, this has been the source of some conflict in the past. The Roman Catholic Church states: ""Sacred objects, set aside for divine worship by dedication or blessing, are to be treated with reverence. They are not to be made over to secular or inappropriate use, even though they may belong to private persons""[33]. Thus it is acceptable to wear a rosary if one is doing so to show veneration, however it is not acceptable if one is wearing the rosary irreverently, such as wearing it as a piece of jewelry. Many saints have worn their Rosary around the neck, and in the Secret of the Rosary, it is mentioned that a person put his rosary round his neck to keep devils away from him. Rosaries or rosary-like necklaces are often worn for non-religious purposes as a fashion or jewelry item, and are sold in different variations in popular jewelry and clothing stores. Such ornamental use, especially the wearing of a rosary around the neck, was heavily popularized by singer Madonna in the early 1980s and has experienced a come-back in recent years. Wearing a rosary around the neck can be considered disrespectful if the person wearing it does not affiliate with the Christian religion. Ornate or medieval-style rosary sets are occasionally featured in ""goth"" fashion. The rosary has been featured in the writings of Roman Catholic figures from saints to popes and continues to be mentioned in reported Marian apparitions, with a number of promises attributed to the power of the rosary. In the eighteenth century, the French priest Louis de Montfort elaborated on the importance of the rosary and its power in his widely read book the Secret of the Rosary.[36] He emphasized the power of the rosary and provided specific instructions on how it should be prayed, e.g. with attention, devotion and modesty (reverence), with reflective pauses [37] between the beads and smaller pauses between phrases of the prayers. All links retrieved December 16, 2022. Note: Some restrictions may apply to use of individual images which are separately licensed.']","A standard 15 Mysteries of the Rosary, based on the long-standing custom, was established by Pope Pius V during the 16th century, grouping the mysteries in three sets: the Joyful Mysteries, the Sorrowful Mysteries, and the Glorious Mysteries. During 2002 Pope John Paul II said that it is fitting that a new set of five be added, termed the Luminous Mysteries, bringing the total number of mysteries to 20. The Glorious mysteries are said on Sunday and Wednesday, the Joyful on Monday and Saturday, the Sorrowful on Tuesday and Friday, and the Luminous Mysteries are said on Thursday. Usually five decades are recited in a session."
is limited slip differential the same as traction control,"[""You have not viewed any items recently. Your shopping cart is currently empty.  If you would like to make a purchase today, add items to your shopping cart. C180, C200, C220, C230 & C250 Sedan & Wagon (not C240 or C280).   1797, 1799, 1998, 2199 & 2295cc petrol (not Kompressor or 6-cylinder   models). 2155 & 2497cc diesel & turbo-diesel. NOTE: Only maintenance, adjustment, minor repair procedures plus removal and installation are described for the transmissions. Does NOT cover supercharged (Kompressor) or 6 Cylinder petrol, C200 or CDI 220 Diesel, or AMG versions. Does NOT cover new C-Class range introduced September 2000. Inside   this manual you will find: Routine Maintenance, tune-up procedures,   engine repair, cooling and heating, air-conditioning, fuel and exhaust,   emissions control, ignition, brakes, suspension and steering, electrical   systems and wiring diagrams. Find great deals on eBay for w202 w202 amg. Shop with confidence. Mercedes Benz W202 C36 AMG. 9,876 likes · 611 talking about this. The W202 is one of the best classes put out into the production after the w201 called... The Mercedes-Benz C-Class is a line of compact executive cars produced by Daimler AG. Introduced in 1993 as a replacement for the 190 (W201) range, the C-Class was ... Sign in now to see your channels and recommendations! Sign in. YouTube Red Mercedes-Benz C-Class (W202) - Wikipedia, the free ... In October 1986, 3 years into Mercedes-Benz W201 (190)'s production run, work began on a successor. In May 1993, the first generation W202 Mercedes-Benz C-Class was ... Find great deals on eBay for mercedes benz w202 mercedes w202. Shop with confidence. Mercedes Benz EPC Type W202 202 C-Class Information ... Online index to lookup and find Mercedes Benz Electronic Parts Catalog (EPC) part number information and diagrams. This is an english language index with links to EPC ... Pelican Parts - Mercedes-Benz C-Class (1994-2000) W202 ... Mercedes-Benz C-Class (1994-2000) W202: Basic Maintenance: Air Filters, Oil Filters, Fuel Filters, Wiper Blades, Valve Cover Gaskets, Fluids..."", ""You have not viewed any items recently. Your shopping cart is currently empty.  If you would like to make a purchase today, add items to your shopping cart. Mercedes Benz 190 1984 - 1988 Haynes Owners Service & Repair Manual covers: All models, 4 Cylinder Petrol engines 1984 - 1988 (W201 series). Haynes   repair manuals can save you money on maintenance and repair bills.   Step-by-step procedures and illustrations guide you through every job,   from basic maintenance and troubleshooting, to complete teardown &   rebuild. The Mercedes-Benz E-Class is a range of executive cars manufactured by German automaker Mercedes-Benz in various engine and body configurations produced since 1993 ... Mercedes-Benz E-Class (W210) - Wikipedia, the free ... The Mercedes-Benz W210 is an executive car which was produced by the German automaker Mercedes-Benz from 1995 through 2002 (production of the wagon variant (codenamed ... The Mercedes-Benz W210 is a Mid-size car Luxury car–Executive car which was produced by the Germany Automaker Mercedes-Benz from 1995 through 2002 (production of ... Mercedes Benz W210 E-Class - facebook.com Mercedes Benz W210 E-Class. 10,484 likes · 33 talking about this. Author 630 results found: 1996-2002 Mercedes-Benz W210 E320 E300 E420 E430 E55 AMG WINDSHIELD TRIM SCREEN · (1998-2002) Mercedes-Benz W210 E320 E430 E55 E300 DIESEL VACCUM ... Find great deals on eBay for benz w210 benz w 210 headlight trim. Shop with confidence. Pelican Parts - Mercedes-Benz E-Class (1996-2003) W210 ... Welcome to our Mercedes-Benz W210 E-Class Technical Articles section. We've gathered a vast collection of useful articles to ..."", '', 'The term axle is loosely used to describe the shaft or two half shaft connected to transverse wheels. It can be a load bearing shaft or a shaft that drives the wheels. On a rear wheel drive vehicles the drive to the wheels comes from the propeller shaft which runs under the center of the vehicle, front to back, from the gearbox to the differential drive which is located centrally between the two rear wheels.The differential is a set of cogs which turns the drive rotation ninety degrees to each back wheel.The Differential, through the clever design and setup of the cogs, also allows the rear wheels to turn at different speeds necessary when the vehicle is turning. The term rear axle can refer to the complete set of two half shafts or half axles and the differential. On front wheel drive vehicles there are two half shaft/axles connected from a differential that is usually combined in the gearbox\xa0 via\xa0 constant velocity joints which allows the front wheels to turn for steering the vehicle while under torque from the rotating shaft/axle. These CV joints are usually encased in a rubber sleeve containing lubricant grease. The rear wheels of the front wheel drive vehicle have stub axles which are usually short and part of an independent suspension system on each rear wheel. Although usually very resilient, problems can occur in rear wheel drive vehicles in the differential with the wear of cogs, which maybe caused by lack of lubrication due to leaks. In front wheel drive vehicles the most common problem is the breakdown of the rubber sleeve\xa0on the CV joints connecting the drive shaft from the gearbox to the half shaft axle and to the driving wheels. The CV joints can suffer damage if the damaged rubber sleeves are not replaced, this is caused by wear with the ingression of dust and grit and loss of lubricant. Another cause of damage can be the collision with obstructions in the road or running up high kerbs etc. Calls cost 13p per minute plus your phone company’s access charge. Copyright © 2000 - 2023 www.Breakeryard.com ® All Rights Reserved. Registered Office: Breaker Yard Limited, Wilkerson House, Uphall Road, Ilford, Essex, IG1 2JJ', 'Please register or login to enable Dark Mode. I agree to receive emails from the site. I can unsubscribe anytime to withdraw my consent. Read our Privacy Policy for more info. When you click on links to various merchants on this site and make a purchase, this can result in this site earning a commission. Affiliate programs and affiliations include, but are not limited to, the eBay Partner Network.', '', 'the best replica watches in the world craftsmen entrepreneurs focused.']","The main advantage of a limited-slip differential is demonstrated by considering the case of a standard (or ""open"") differential in off-roading or snow situations where one wheel begins to slip. In such a case with a standard differential, the slipping or non-contacting wheel will receive the majority of the power (in the form of low-torque, high rpm rotation), while the contacting wheel will remain stationary with respect to the ground. The torque transmitted by an open differential will always be equal at both wheels; if one tire is on a slippery surface, the supplied torque will easily overcome the available traction at a very low number. For example, the right tire might begin to spin as soon as 70 N ⋅ m (50 lb ⋅ ft) of torque is placed on it, since it is on an icy surface. Since the same amount of torque is always felt at both wheels, regardless of the speed which they are turning, this means that the wheel with traction cannot receive more than 70 Nm of torque either, which is far less than is required to move the vehicle. Meanwhile, the tire on the slippery surface will simply spin, absorbing all of the actual power output (which is a function of torque provided over time), even though both wheels are provided the same (very low) amount of torque. In this situation, a limited-slip differential prevents excessive power from being allocated to one wheel, and so keeps both wheels in powered rotation, ensuring that the traction will not be limited to the wheel which can handle the minimum amount of power. The advantages of LSD in high-power, rear wheel drive automobiles were demonstrated during the United States ""Muscle-Car"" era from the mid 1960s through the early 1970s. Cars of this era normally were rear wheel drive and did not feature independent suspension for the rear tires (but instead used a live axle). With a live axle, when high torque is applied through the differential, the traction on the right rear tire is lower as the axle naturally wants to turn with the torsion of the drive shaft (but is held stationary by being mounted to the vehicle frame). This coined the term ""one wheel peel"". As such, ""Muscle-Cars"" with LSD or ""posi"" (positraction) were at a distinct advantage to their wheel-spinning counterparts."
how to identify the isotope of an element,"['', '', 'Meteorites formed during the birth of the Solar System have helped scientists pinpoint the origin of organic materials necessary for the formation of life on Earth. The finding could also help astronomers explore the possible habitability of planets in other solar systems. Carbonaceous chondrites are meteorites created from chondritic asteroids that are as old as the Solar System. Organic-rich carbonaceous chondrites are especially rare, encompassing only a few percent of all known meteorites. They consist of the first solid materials – rocks, organics, water ice and fine grain dust – formed in the early Solar System 4.5 billion years ago. When discovered on Earth and analyzed, such meteorites can act much like a time capsule; storing essential clues and revealing information to help scientists understand how planets formed and changed over billions of years. Researchers from the School of Earth and Environmental Sciences at the University of Manchester have spent the past two years studying the isotopic composition of oxygen in organic materials found in chondritic meteorite samples from a collection at the Muséum National d’Histoire Naturelle in Paris, France. Chondrites are a snapshot of the early Solar System, providing key insights on how protoplanets and planets formed and were processed. Earth is a dynamic planet – processes such as plate tectonics and erosion have erased most of the early Earth records. Dr. Romain Tartèse, Research Fellow in the School of Earth and Environmental Sciences This means inclusive studies on chondrites are even more important to help scientists understand how our planet formed and evolved. Dr. Tartèse and his colleagues precisely measured and interpreted the oxygen isotope composition of organic materials in these early chondritic meteorites. Isotopes are atoms of the same element that have the same number of protons but a different number of neutrons. Because they have the same electronic configuration, isotopes have the same chemical properties but different physical properties. The analysis provided the scientists with an isotopic signature of compounds within the organic material, which acts as a fingerprint of processes involved in its creation. Their results confirmed that organic materials in such asteroids – carbon, hydrogen, oxygen, nitrogen, and sulfur - were probably formed via basic chemical reactions during the early stages of the Solar System. The findings, published in Proceedings of the National Academy of Sciences of the United States of America (PNAS), suggests that if organic materials can form by basic chemical procedures functioning in our Solar System, then it is conceivable that they are prevalent in other planetary systems too. The study is the first to provide high-precision triple oxygen isotope analysis of carbonaceous chondrite organics. Whereas most previous studies have focussed on hydrogen and nitrogen, two other building blocks of life that are abundant in organics, Tartèse and his colleagues fixated on oxygen. Oxygen is more prevalent in these meteorites, comprising approximately 10-20% of chondrite organics. It also has three different stable isotopes - hydrogen and nitrogen only have two stable varieties of isotopes – which provides an extra level of information and critical clues to limit the origin or chondritic organics even further. The oxygen isotope pattern was similar to the relationship linking the composition of the Sun, asteroids and terrestrial planets. Therefore, this likely implies that carbonaceous chondrite organics were formed through chemical reactions in the early Solar System, rather than having been inherited from the interstellar medium. Dr. Romain Tartèse, Research Fellow in the School of Earth and Environmental Sciences Disclaimer: The views expressed here are those of the author expressed in their private capacity and do not necessarily represent the views of AZoM.com Limited T/A AZoNetwork the owner and operator of this website. This disclaimer forms part of the Terms and conditions of use of this website. Kerry has been a freelance writer, editor, and proofreader since 2016, specializing in science and health-related subjects. She has a degree in Natural Sciences at the University of Bath and is based in the UK. Taylor-Smith, Kerry. (2018, August 29). Early Meteorites Reveal Makeup of Solar System 4.5 Billion Years Ago. AZoQuantum. Retrieved on May 08, 2023 from https://www.azoquantum.com/News.aspx?newsID=6154. Taylor-Smith, Kerry. ""Early Meteorites Reveal Makeup of Solar System 4.5 Billion Years Ago"". AZoQuantum. 08 May 2023. <https://www.azoquantum.com/News.aspx?newsID=6154>. Taylor-Smith, Kerry. ""Early Meteorites Reveal Makeup of Solar System 4.5 Billion Years Ago"". AZoQuantum. https://www.azoquantum.com/News.aspx?newsID=6154. (accessed May 08, 2023). Taylor-Smith, Kerry. 2018. Early Meteorites Reveal Makeup of Solar System 4.5 Billion Years Ago. AZoQuantum, viewed 08 May 2023, https://www.azoquantum.com/News.aspx?newsID=6154. Dr. Foni Raphaël Lebrun-Gallagher AZoQuantum had the pleasure of speaking with Dr.\xa0Foni Raphaël Lebrun-Gallagher about his team\'s breakthrough research at the University of Sussex. Their latest research proves the viability of\xa0connecting independent ion-trap quantum computer modules via electric fields. In our latest interview, Assistant Professor Shuolong Yang from the Pritzker School of Molecular Engineering discusses a\xa0new\xa0topological superconductor to carry quantum information, and how its production method was inspired by paper block printing. Ahead of the International Day of Women and Girls in Science, AZoQuantum spoke with Jennifer Choy, an assistant professor at the University of Wisconsin-Madison, about the field of quantum physics and her impressive research career in this sector. LabOne Q is a new software framework that accelerates quantum computing progress on Zurich Instruments’ hardware. With LabOne Q, users can design complex quantum experiments with an intuitive, high-level programming language. The ORCA-Quest qCMOS camera provides high-quality and low-noise imaging for a variety of needs and uses. This makes it the perfect choice for imaging needs in the wider quantum industry. AZoQuantum.com - An AZoNetwork Site', 'The origin of organic matter found in meteorites that formed during the birth of the Solar System 4.5\u2009billion years ago may provide key clues to understanding the birth of life here on Earth. According to a study led by the University of Manchester, it could also help astronomers investigate the potential habitability of other solar systems. Manchester/UK — The new research, published in ‘Proceedings of the National Academy of Sciences of the United States of America (Pnas)’, confirms that organic materials accreted in chondritic asteroids probably formed via basic chemical reactions during the infant stage of our Solar System. Carbonaceous chondrites are meteorites that originated from chondritic asteroids that are as old as our Solar System. Researchers, led by Dr\u2009Romain Tartèse of Manchester’s School of Earth and Environmental Sciences, have been analysing the isotopic makeup of oxygen in the organic materials found in these specific meteorites. Isotopes are atoms of the same element that share the same numbers of protons, but have a different numbers of neutrons. Isotopic analysis provides scientists with the isotopic signature of a compound, which acts as a fingerprint of processes involved in its formation. By doing this, the team has helped pinpoint the origins of the organic materials contained within the meteorites, which are made up of key elements necessary for life, such as carbon, hydrogen, oxygen, nitrogen, and sulphur. The findings suggest that if organic materials can form by basic chemical processes operating in our Solar System, there is a possibility that they are widespread in other planetary systems. Carbonaceous chondrites are made of the first solid materials — such as rocks, organics, water ice, and fine grain dust — formed in the Solar System. When found on Earth and analysed in detail, they act as time capsules for understanding how planets formed and evolved over billions of years. Organic-rich carbonaceous chondrites are particularly rare, comprising only a few per cent of all known meteorites. Earth is a dynamic planet — processes such as plate tectonics and erosion have erased most of the early Earth records. This makes comprehensive studies on chondrites all the more important to understand how our planet formed and evolved. Using samples from the Muséum National d’Histoire Naturelle in Paris, the research team spent two years precisely measuring and interpreting the oxygen isotope composition of organics in some of these early-formed meteorites. The study provides the first “high-precision triple oxygen isotope analysis” of carbonaceous chondrite organics. Past studies mostly focused on two other building blocks of life abundant in organics – hydrogen and nitrogen. Oxygen has a crucial advantage over other elements, such as hydrogen and nitrogen, as it is fairly abundant in these meteorites, comprising 10-20\u2009% of chondrite organics. But most importantly, it is made of three different stable isotopes, while hydrogen and nitrogen only have two stable isotope varieties. Having three stable isotopes, oxygen offers an extra level of information compared to elements with two stable isotopes such as hydrogen and nitrogen, providing critical clues to further constrain the origin of chondritic organics. Dr\u2009Tartèse added that the oxygen isotope pattern had been similar to the relationship linking the composition of the Sun, asteroids and terrestrial planets. Therefore, this likely implied that carbonaceous chondrite organics were formed through chemical reactions in the early Solar System, rather than having been inherited from the interstellar medium. This portal is a brand of Vogel Communications Group. You will find our complete range of products and services on\t\t\t\t www.vogel.com', '', 'The origin of organic matter found in meteorites that formed during the birth of the Solar System 4.5 billion years ago may provide key clues to understanding the birth of life here on Earth. It could also help astronomers investigate the potential habitability of other solar systems. That’s according to a new study led by The University of Manchester. The new research, published in ‘Proceedings of the National Academy of Sciences of the United States of America (PNAS)’, confirms that organic materials accreted in chondritic asteroids probably formed via basic chemical reactions during the infant stage of our Solar System. Carbonaceous chondrites are meteorites that originated from chondritic asteroids that are as old as our Solar System. Researchers, led by Dr Romain Tartèse of Manchester’s School of Earth and Environmental Sciences, have been analysing the isotopic makeup of oxygen in the organic materials found in these specific meteorites. Isotopes are atoms of the same element that share the same numbers of protons, but have a different numbers of neutrons. Isotopic analysis provides scientists with the isotopic signature of a compound, which acts as a fingerprint of processes involved in its formation. By doing this, the team has helped pinpoint the origins of the organic materials contained within the meteorites, which are made up of key elements necessary for life, such as carbon, hydrogen, oxygen, nitrogen, and sulphur. The findings suggest that if organic materials can form by basic chemical processes operating in our Solar System, there is a possibility that they are widespread in other planetary systems. Carbonaceous chondrites are made of the first solid materials – such as rocks, organics, water ice, and fine grain dust – formed in the Solar System. When found on Earth and analysed in detail, they act as time capsules for understanding how planets formed and evolved over billions of years. “Chondrites are a snapshot of the early Solar System, providing key insights on how protoplanets and planets formed and were processed,” says Dr Tartèse. Organic-rich carbonaceous chondrites are particularly rare, comprising only a few per cent of all known meteorites. “Earth is a dynamic planet – processes such as plate tectonics and erosion have erased most of the early Earth records,” Dr Tartèse says. This makes comprehensive studies on chondrites all the more important to understand how our planet formed and evolved. Using samples from the Muséum National d’Histoire Naturelle in Paris, the research team spent two years precisely measuring and interpreting the oxygen isotope composition of organics in some of these early-formed meteorites. The study provides the first “high-precision triple oxygen isotope analysis” of carbonaceous chondrite organics. Past studies mostly focused on two other building blocks of life abundant in organics – hydrogen and nitrogen. Oxygen has a crucial advantage over other elements, such as hydrogen and nitrogen, as it is fairly abundant in these meteorites, comprising 10-20% of chondrite organics. But most importantly, it is made of three different stable isotopes, while hydrogen and nitrogen only have two stable isotope varieties. Having three stable isotopes, oxygen offers an extra level of information compared to elements with two stable isotopes such as hydrogen and nitrogen, providing critical clues to further constrain the origin of chondritic organics. Dr Tartèse added: “The oxygen isotope pattern was similar to the relationship linking the composition of the Sun, asteroids and terrestrial planets. Therefore, this likely implies that carbonaceous chondrite organics were formed through chemical reactions in the early Solar System, rather than having been inherited from the interstellar medium.” If you would like to contribute to About Manchester, contact us here.', '']","Isotopes are atoms of the same element having the same numbers of protons (atomic number), but different numbers of neutrons. They have same chemical properties due to the same electron configuration, but different physical properties."
what happened to the painting woman in gold,"['Paul Karl Ludwig Drude shows that moving electrons conduct electricity in metals. Paul Ulrich Villard is the first to observe a radiation that is more penetrating than X-rays, now called gamma rays. On December 14, Max Planck announces the first step toward quantum theory. He states that substances can emit light only at certain energies, which implies that some physical processes are not continuous, but occur only in specified amounts called quanta. Photograph by Alfred Stieglitz: Spring Showers, The Street Cleaner. Eugène Atget: Marchand d\'Abat-Jours, an albumen silver print, now in the J. Paul Getty Museum. Painting by Gustav Klimt: Judith and the Head of Holofernes (also known as Judith I) depicts the biblical character of Judith holding the severed head of Holofernes.  Judith I reveals a curious symbolic and compositional consonance with The Sin by Franz Stuck: the temptation illustrated by the German painter becomes the model for Klimt\'s femme fatale by suggesting the posture of the disrobed and evanescent body as focal piece of the canvas, as well as the facial set. Judith\'s force originates from the close-up and the solidity of posture, rendered by the orthogonal projection of lines: to the body\'s verticality (and that of Holofernes\') corresponds to the horizontal parallels in the lower margin: those of the arm, the shoulders joined by the collier, and finally the hair base. Physicist Ernest Rutherford lectures the British Association that radioactivity could  power the sun and maintain its heat, meaning the sun and Earth could be much older than Lord Kelvin\'s estimate. Painting by Pablo Picasso: The Old Guitarist depicts an old, blind, haggard man with threadbare clothing weakly hunched over his guitar, playing in the streets of Barcelona, Spain. It is currently on display in the Art Institute of Chicago as part of the Helen Birch Bartlett Memorial Collection.  At the time of The Old Guitarist\'s creation, Modernism, Impressionism, Post-Impressionism, and Symbolism had merged and created an overall movement called Expressionism which greatly influenced Picasso\'s style. Furthermore, El Greco, Picasso\'s poor standard of living, and the suicide of a dear friend influenced Picasso\'s style at the time which came to be known as his Blue Period.  In the early 1960s, nearly forty percent of all college dorm rooms had a poster of this painting on the wall. Photograph by Edward Steichen: The Flatiron Building. Painting by Henri Matisse: Luxe, Calme et Volupté is an oil painting by the French artist Henri Matisse. Both foundational in the oeuvre of Matisse and a pivotal work in the history of art, Luxe, Calme et Volupté is considered the starting point of Fauvism.  Luxe, Calme et Volupté was painted by artist called Matisse in 1904, after a summer spent working in St. Tropez on the French Riviera alongside the neo-Impressionist painters Paul Signac and Henri-Edmond Cross. The painting is Matisse\'s most important work in which he used the Divisionist technique advocated by Signac. Painting by Maxfield Parrish: The Dinky Bird, an illustration from Poems of Childhood exemplifies Parrish\'s characteristic use of androgynous figures.  To a modern eye, Parrish\'s early work — characterized by himself as ""girls on rocks"" — may bring to mind the words kitsch or schlock or schmaltz or maudlin, but to many who were enduring the Great Depression or World War II, his images, like  Busby Berkeley musicals, inspired a bit of hope — an imagining that things did not always have to be this bad. During those hard times, many a lower middle class American living room had one or more cheap Parrish prints, sometimes just a page from a magazine, adorning the wall. Albert Einstein proposes the special theory of relativity (E=mc2). Painting by Gustav Klimt: Margaret ""Gretl"" Stonborough-Wittgenstein. Stonborough-Wittgenstein, a member of the prominent and wealthy Viennese Wittgenstein family, was a sister of the philosopher Ludwig Wittgenstein and the pianist Paul Wittgenstein. She was the subject of a portrait painted for her wedding by the artist Gustav Klimt (Stonborough-Wittgenstein and other members of the Wittgenstein family were among Klimt\'s most important patrons), which was sold in 1960 by her son Thomas and may now be seen in the Neue Pinakothek gallery in Munich.  Aside: The painting  appears briefly behind Ava, an AI robot, in the film Ex Machina  (a film that is an excellent exploration of artificial intelligence, the nature of consciousness, and passing a Turing Test). Painting by Henri Matisse: Woman with a Hat (La femme au chapeau) depicts Matisse\'s wife, Amelie. It was painted in 1905 and exhibited at the Salon d\'Automne during the fall of the same year, along with works by André Derain, Maurice de Vlaminck and several other artists known as ""Fauves"".  Woman with a Hat was at the center of the controversy that led to the term Fauvism. It was also a painting that marked a stylistic shift in the work of Matisse from the Divisionist brushstrokes of his earlier work to a more expressive style. Its loose brushwork and ""unfinished"" quality shocking viewers as much as its vivid, non-naturalistic colors.  Although the Fauve works on display were condemned by many — ""A pot of paint has been flung in the face of the public"", declared the critic Camille Mauclair — they also gained some favorable attention. The painting that was singled out for attacks was Matisse\'s Woman with a Hat. painting by Henri Matisse: Le bonheur de vivre (The Joy of Life) is (along with Picasso\'s Les Demoiselles d\'Avignon) regarded as one of the pillars of early modernism. The monumental canvas was first exhibited at the Salon des Indépendants of 1906, where its cadmium colors and spatial distortions caused a public expression of protest and outrage.  ""The work is known to have invigorated fellow artists, especially Pablo Picasso, who, in an effort to outdo Matisse in terms of shock value, immediately began work on his watershed Les Demoiselles D\'Avignon,"" writes Martha Lucy, associate curator at the Barnes Foundation. Painting by Gustav Klimt : The Kiss (Lovers) was painted by the Austrian Symbolist painter Gustav Klimt between 1907 and 1908, the highpoint of his ""Golden Period"", when he painted a number of works in a similar gilded style. A perfect square, the canvas depicts a couple embracing, their bodies entwined in elaborate robes decorated in a style influenced by both linear constructs of the contemporary Art Nouveau style and the organic forms of the earlier Arts and Crafts movement. The work is composed of oil paint with applied layers of gold leaf, an aspect that gives it its strikingly modern, yet evocative appearance. The painting is now in the Österreichische Galerie Belvedere museum in the Belvedere palace, Vienna, and is widely considered a masterpiece of the early modern period. It is a symbol of Vienna Jugendstil—Viennese Art Nouveau—and is considered Klimt\'s most popular work Painting by Gustav Klimt:  Portrait of Adele Bloch-Bauer I (also called The Lady in Gold or The Woman in Gold) was completed between 1903 and 1907. The portrait was commissioned by the sitter\'s husband, Ferdinand Bloch-Bauer, a Jewish banker and sugar producer. It is the final and most fully representative work of Klimt\'s golden phase. The portrait was the first of two depictions of Adele by Klimt — the second was completed in 1912; these were two of several works by the artist that the family owned. Adele died in 1925; her will asked that the artworks by Klimt were to be left to the Österreichische Galerie Belvedere, although these belonged to Ferdinand, not her. Painting by Ivan Grohar: The Sower (Slovene: Sejalec), is an image of a peasant sowing seeds on a ploughed field in an early and foggy morning. A hayrack, typical of the Slovene landscape, stands in the back, and even farther, the rocks of the small hill Kamnitnik near Škofja Loka. It has been a metaphor for the 19th-century myth of Slovenes as a vigorous nation in front of an unclear destiny, a symbol for the Slovene nation that sows in order that it could harvest, and a depiction of human interrelatedness with the nature. It is also a reflection of the context of Slovene transition from a rural to an urban culture. It has become one of the most characteristic and established Slovene creations in visual arts. Painting by Pablo Picasso: Les Demoiselles d\'Avignon (The Young Ladies of Avignon, and originally titled The Brothel of Avignon)  portrays five nude female prostitutes from a brothel on Carrer d\'Avinyó (Avinyó Street) in Barcelona. Each figure is depicted in a disconcerting confrontational manner and none are conventionally feminine.  In this adaptation of Primitivism and abandonment of perspective in favor of a flat, two-dimensional picture plane, Picasso makes a radical departure from traditional European painting. This proto-Cubist work is widely considered to be seminal in the early development of both Cubism and Modern art. Les Demoiselles was revolutionary and controversial, and led to widespread anger and disagreement, even amongst the painter\'s closest associates and friends. Matisse considered the work something of a bad joke, yet indirectly reacted to it in his 1908 Bathers with a Turtle. Braque too initially disliked the painting, yet perhaps more than anyone else, studied the work in great detail. And effectively, his subsequent friendship and collaboration with Picasso led to the Cubist revolution Henri Matisse coins the term ""Cubism"" — the first Cubist exhibition opens in Paris. Sculpture by Constantin Brâncusi: The Kissis an early example of his proto-cubist style of non-literal representation.  This plaster was exhibited at the 1913 Armory Show and published in the Chicago Tribune, 25 March 1913. This early plaster sculpture is one of six casts that Brancusi made of the 1907–08 The Kiss.  The original stone carving is in the Muzeul de Arta at Craiova, Romania.  Brâncusi created many versions of The Kiss, further simplifying geometric forms and sparse objects in each version, tending each time further toward abstraction. His abstract style emphasizes simple geometrical lines that balance forms inherent in his materials with the symbolic allusions of representational art. Here, the shape of the original block of material is maintained. Painting by Georges Braque: Houses at l\'Estaque (French: Maisons à l\'Estaque) is considered either an important Proto-Cubist landscape or the first Cubist landscape. The painting prompted art critic Louis Vauxcelles to mock it as being composed of cubes which led to the name of the movement.  This painting by Braque was refused at the Salon d\'Automne in 1908. Louis Vauxcelles recounted how Matisse told him at the time, ""Braque has just sent in [to the 1908 Salon d\'Automne] a painting made of little cubes"". The critic Charles Morice relayed Matisse\'s words and spoke of Braque\'s little cubes.  The motif of the viaduct at l\'Estaque had inspired Braque to produce three paintings marked by the simplification of form and deconstruction of perspective. Six landscapes painted at L\'Estaque signed Georges Braque were presented to the Jury of the Salon d\'Automne: Guérin, Marquet, Rouault and Matisse rejected Braque\'s entire submission. Guérin and Marquet elected to keep two in play. Braque withdrew the two in protest, placing the blame on Matisse. Painting by Henri Matisse: Dance (La Danse). The title refers to either of two related paintings made between 1909 and 1910. The first, preliminary version is Matisse\'s study for the second version. The composition or arrangement of dancing figures is reminiscent of Blake\'s watercolour  ""Oberon, Titania and Puck with fairies dancing"" from 1786. CRISPR-Cas: Bringing precise editing to DNA manipulation. Using DNA as a mass-storage device for digital data. Dinosaur tail, complete with feathers, found preserved in amber. Mysterious fast radio burst (FRB) detected in the distant universe. Gravitational waves, ripples in space-time, detected. Hacking the genome: Identifying anonymized human subjects using publicly available data. Using DNA as a mass-storage device for digital data.', ""I am so excited about today’s post. If you know me at all, you know I LOVE art! So when I walked into my daughter’s school and saw dozens of HUGE recreations of famous pieces of art painted by the students, I was so giddy. I only took photos of a few of the pieces of art, but there were literally dozens and dozens lining the walls. They were huge too – like, floor to ceiling huge. I should have taken a picture with my daughter next to one. I think they projected the images onto the paper and then each group got to paint theirs. Without further adieu, today is art appreciation day at House of Hepworths. Enjoy! We’ll start with my favorite piece of art – The Starry Night by Vincent Van Gough. I have loved this painting since I was a kid. I remember once, when I was about 14, we took a vacation and ended up at an Observatory… McDonald Observatory maybe? Anyway, I bought a poster of The Starry Night and it hung in my room until I grew up and moved out. “The Starry Night was created by Dutch painter Vincent van Gogh. Painted in June 1889, it depicts the view from the east-facing window of his asylum room at Saint-Rémy-de-Provence, just before sunrise, with the addition of an idealized village. It has been in the permanent collection of the Museum of Modern Art in New York City since 1941, acquired through the Lillie P. Bliss Bequest. It is regarded as among Van Gogh’s finest works, and is one of the most recognized paintings in the history of Western culture. “In the aftermath of the December 23, 1888 breakdown that resulted in the self-mutilation of his left ear, Van Gogh voluntarily admitted himself to the asylum on May 8, 1889. During his time in the asylum, he produced some of the best-known works of his career, including the Irises, the blue self-portrait, and The Starry Night.” Source An American Classic, American Gothic by Grant Wood is one of the most recognized, copied, and  widely parodied paintings in American pop culture. “American Gothic is a painting by Grant Wood in the collection of the Art Institute of Chicago. Wood’s inspiration came from the American Gothic House, and his decision to paint the house along with “the kind of people I fancied should live in that house.” Created in 1930, it depicts a farmer standing beside a woman that has been interpreted to be either his wife or his daughter. The figures were modeled by Wood’s sister, Nan Wood Graham, and Wood and Graham’s dentist, Dr. Byron McKeeby. The woman is dressed in a colonial print apron evoking 19th-century Americana, and the man is holding a pitchfork. The plants on the porch of the house are mother-in-law’s tongue and beefsteak begonia, which are the same plants as in Wood’s 1929 portrait of his mother, Woman with Plants. “In August 1930, Grant Wood drove around Eldon, Iowa and noticed a small white house built in the Carpenter Gothic architectural style. Wood “thought it a form of borrowed pretentiousness, a structural absurdity, to put a Gothic-style window in such a flimsy frame house.” At the time, Wood classified it as one of the “cardboardy frame houses on Iowa farms” and considered it “very paintable”. Source Here’s another piece you might recognize… The Son of Man by René Magritte is another classic. “Mr. Magritte painted it as a self-portrait. About the painting, Magritte said: “At least it hides the face partly well, so you have the apparent face, the apple, hiding the visible but hidden, the face of the person. It’s something that happens constantly. Everything we see hides another thing, we always want to see what is hidden by what we see. There is an interest in that which is hidden and which the visible does not show us. This interest can take the form of a quite intense feeling, a sort of conflict, one might say, between the visible that is hidden and the visible that is present.” Source The Marilyn Diptych by American pop artist Andy Warhol is another favorite. I’ve loved Andy Warhol for as long as I can remember. I even made my own Warhol inspired art several years ago. “The Marilyn Diptych was painted in 1962 and is a silkscreen painting. The piece is one of the artist’s most noted works, and it has been praised by several cultural critics. “The work was completed during the weeks after Marilyn Monroe’s death in August 1962. It contains fifty images of the actress, which are all based on a single publicity photograph. The diptych is actually fifty pictures; the left half are brightly colored, while the right half are in black and white. It has been suggested that the relation between the left side of the canvas and the right side of the canvas is evocative of the relation between the celebrity’s life and death. “In a December 2, 2004 article in The Guardian, the painting was named the third most influential piece of modern art. The piece is currently on display at the Tate Modern, as part of the exhibition: Witty, Sexy, Gimmicky: Pop 1957-67.” Source When you think of Andy Warhol, you probably immediately think of the Campbell’s Soup Cans. “Campbell’s Soup Cans, sometimes referred to as 32 Campbell’s Soup Cans, is a work of art produced in 1962 by Andy Warhol. It consists of thirty-two canvases, each measuring 20″ × 16”, and each consisting of a painting of a Campbell’s Soup can; one of each of the canned soup varieties the company offered at the time. Campbell’s Soup Cans’ reliance on themes from popular culture helped to usher in pop art as a major art movement in the United States. “Because of the eventual popularity of the entire series of similarly themed works, Warhol’s reputation grew to the point where he was not only the most-renowned American pop art artist but also the highest-priced living American artist.” Source When I think of my teen years, I had exactly two artists who were my absolute favorite; Van Gogh and M.C. Escher. I was obsessed with M.C. Escher. I had a coffee table book of his work, a t-shirt, and also I would draw hands frequently. I felt so inspired by his mind-altering work. “Drawing Hands is a lithograph by the Dutch artist M. C. Escher first printed in January 1948. It depicts a sheet of paper out of which, from wrists that remain flat on the page, two hands rise, facing each other and in the paradoxical act of drawing one another into existence. Although Escher used paradoxes in his works often, this is one of the most obvious examples. “Drawing Hands has been referenced and copied many times by artists in different ways. One common tribute in tech culture is to draw robot hands drawing or building each other or human hands and robot hands drawing each other.” Source When I saw two different M.C. Escher pieces of art depicted on the walls of the middle school, I think I let out an audible squeal. “Sky and Water I is a woodcut print first printed in June 1938. In this central layer of this piece, the elements are equal: birds and fish are alternately foreground or background, depending on whether the eye concentrates on light or dark elements. “According to Escher: “In the horizontal center strip there are birds and fish equivalent to each other. We associate flying with sky, and so for each of the black birds the sky in which it is flying is formed by the four white fish which encircle it. Similarly swimming makes us think of water, and therefore the four black birds that surround a fish become the water in which it swims.” “This print has been used in physics, geology, chemistry, and in psychology for the study of visual perception.” Source If you’ve been in any type of chachki art store, you’ve probably seen some variation of The Scream by Edvard Munch. The Scream is by Norwegian Expressionist artist Edvard Munch. The work shows a figure with an agonized expression against a landscape with a tumultuous orange sky. It has been described as “an icon of modern art, a Mona Lisa for our time.” “There are four versions of The Scream; two painted and pastel versions. One of the four was sold for $119,922,600 at Sotheby’s Impressionist and Modern Art auction on May 2, 2012 to financier Leon Black, the fourth highest nominal price paid for a painting at auction. “The Scream has been the target of several high-profile art thefts. In 1994, the version in the National Gallery was stolen. It was recovered several months later. In 2004, both The Scream and Madonna were stolen from the Munch Museum, and both were recovered two years later.” Source You might recognize Gustav Klimt by his even more popular piece, The Kiss, although The Lady in Gold is also quite famous. “Portrait of Adele Bloch-Bauer I (also called The Lady in Gold or The Woman in Gold) is a painting by Gustav Klimt, completed between 1903 and 1907. The portrait was commissioned by the sitter’s husband, Ferdinand Bloch-Bauer (de), a Jewish banker and sugar producer. The painting was stolen by the Nazis in 1941 and displayed at the Österreichische Galerie Belvedere. In 2006, following eight years of effort by the Bloch-Bauer heirs, the painting was returned to the family; it was sold the same year for $135 million, at the time a record price for a painting. “In 1998 Hubertus Czernin, the Austrian investigative journalist, established that the Galerie Belvedere contained several works stolen from Jewish owners in the war, and that the gallery had refused to return the art to their original owners, or to acknowledge a theft had taken place. One of Ferdinand’s nieces, Maria Altmann, hired the lawyer E. Randol Schoenberg to make a claim against the gallery for the return of five works by Klimt. After a seven year legal claim, which included a hearing in front of the Supreme Court of the United States, an arbitration committee in Vienna agreed that the painting, and others, had been stolen from the family and that it should be returned to Altmann. It was sold to the businessman and art collector Ronald Lauder, who placed the work in the Neue Galerie, the New York-based gallery he co-founded.” Source Last on our artwork tour, The Book of the Dead is an ancient Egyptian funerary text, based on the Papyrus of Ani. It was created c. 1250 BCE, in the 19th dynasty of the New Kingdom of ancient Egypt. “The original Egyptian name for the text is translated as Book of Coming Forth by Day. The book consists of a number of magic spells intended to assist a dead person’s journey through the underworld and into the afterlife. It was written by many priests over a period of about 1000 years. The Book of the Dead was most commonly written in hieroglyphics on a papyrus scroll, and often illustrated with vignettes depicting the deceased and their journey into the afterlife.” Source I hope you enjoyed your Art Appreciation Tour today! I wish I could have taken one of these huge paintings done by these kids home with me. They were so so so cool! Do you have any specific favorite pieces of art? What piece, and why? Filed Under: Crafting, Crafts, kid crafts Tagged With: American Gothic, Andy Warhol, art, art appreciation, Book of the Dead, Campbells Soup, Drawing Hands, Grant Wood, Klimt, M.C. Escher, Magritte, Marilyn Diptych, Munch, Sky and Water, Son of Man, The Lady in Gold, The Scream, The Starry Night, Van Gogh What a great post today. I so enjoyed all the art information. Thank you. <3 I'm glad you liked it! I loved writing it. So interesting to hear some history about each piece. Have you seen the movie Woman in Gold about the Klimt painting?  It stars Helen Mirren and Ryan Reynolds.  It was amazing to watch all they had to go through to get the painting back. The elementary school does an art show every year and among featuring the student’s artwork, there are reproductions of some of these famous paintings.  Some like The Scream and The Mona Lisa, have the faces cut out so you can insert your own face and take a picture.  Love that they are learning about all different types of art. That is so fun! I love that the schools are teaching art appreciation to children. I hope they never cut those programs. Your email address will not be published. Required fields are marked *"", 'Join our art enthusiasts’ community, and take home a piece of museum! By signing up, you are agreeing to our Privacy Policy. The Musart boutique is a brand new concept which brings art and culture together at accessible prices. Our vision is to perpetuate the legacy of iconic artists and share our passion for cultural heritage. Our partnerships with first class museums allow us to bring not only the best and authentic items; but also to share our enthusiasm for worldwide renowned artists. You are browsing the Musart site from .', '', '“Portrait of Adele Bloch-Bauer I”\xa0by Gustav Klimt is\xa0also called “The Lady in Gold” or “The Woman in Gold” is a portrait commissioned by Adele’s husband. This picture is the most significant representative work of Klimt’s golden phase. It was the first of two depictions of Adele by Klimt. Klimt drew over a hundred preparatory sketches for the portrait starting\xa0is 1903. During\xa0that year, Klimt visited the Basilica of San Vitale in Ravenna where he studied the early-Christian Byzantine gold mosaics of Justinian I and his wife, Empress Theodora. The mosaics made a deep impression on Klimt. Klimt later said that the: “mosaics of unbelievable splendor” were a “revelation.” Klimt undertook more preparatory work for this portrait than any other piece he created. This painting was completed using an\xa0elaborate technique of gold and silver leaf and then adding decorative motifs in bas-relief using gesso. Klimt finished the work in1907, almost five years after his initial preparatory sketches. Adel died in 1925 and then following the annexation of Austria into Nazi Germany in 1938, Adele’s husband fled to Switzerland, leaving behind his extensive art collection. The painting was stolen by the Nazis in 1941, along with the remainder of Ferdinand’s assets. The lawyer acting on behalf of the German state gave the portrait to the Galerie Belvedere, claiming he was following the wishes Adele had made in her will. When Ferdinand, her husband, died in 1946, he left a will that stated that his estate should go to his nephew and two nieces. In 2006, following eight years of legal efforts by the Bloch-Bauer heirs, the painting was returned to the family. In 2015 the story of how this painting returned to the family was dramatized in the famous film “Woman in Gold” starring Helen Mirren. Gustav Klimt was a symbolist painter and one of the most prominent members of the Vienna Secession movement. Klimt’s primary subject was the female body, and his works are marked by eroticism. Klimt was influenced by Japanese art and Byzantine gold mosaics which led to his success with the paintings of his “golden phase,” many of which include gold leaf. “The Kiss” is Klimt’s most famous painting.', 'Elaine Mokhtefi and her husband had lived on the Upper West Side in New York City for twenty years. When he died in 2015, she brought him a bench in the park on Riverside Drive, where he liked to sit, gazing at the river through a mass of trees. George W. Bush read The Stranger during his second term in office, at the urging of historian Alexander Horne, whose Algerian war classic, A Savage War of Peace, Bush had also read, we were told. Algeria as a key to understanding Iraq? As if Arabs or “Arabs” were interchangeable? Oh dear. In 1914, my husband’s uncle Gustav Kirstein bought a lovely painting from the German impressionist master, Max Liebermann – a cheerful summer scene, clearly influenced by Renoir, of rowboats on Hamburg’s Alster River. In 1943 the Nazis stole the painting, along with the rest of Kirstein’s estate. by Suzanne Ruta Picturing Algeria, by Pierre Bourdieu, forward by Craig Calhoun. Edited by Franz Schultheis and Christine Frisinghelli, Columbia University Press, 230 pp. Algeria, by Dirk Alvermann, Facsimile edition of a work first published in 1960. Steidl, Germany 2011 In 2004, just around the time the Abu Ghraib scandal broke, an exhibition of photographs… Photograph by Omar D by Suzanne Ruta In My Time A Personal and Political Memoir, by Dick Cheney, Threshold Editions: New York, 565 pp. Abduction, by Anouar Benmalek, Arabia Books, Haus Publishing Co: London, 299 pp Dick Cheney’s memoir, In My Time, is self serving, stonewalling and riddled with glaring omissions. But it does contain… John Perivolaris \xa0\xa0 To Algeria, with Love sketches the portrait of an Algerian everyman through the eyes of his ditsy American girlfriend (who hears his hopes and dreams) and his grieving daughter (who knows his bitter disappointments). The novel is set in France 1961, in Algeria, 1988 and in New York, 2003. From Part I,… Yves Jeanmougin Translation and\xa0introduction by Suzanne Ruta Le Quotidien d’Oran is one of Algeria’s most widely read French language dailies. People say they buy it just to read Kamel Daoud’s page three chronique or column, Raina raikoum, (my opinion, your opinion). In a country where the lone TV station is state controlled and investigative reporting… To understand the alchemy of Far From Men, it helps to recall the story that inspired it. “The Guest” is not as well known as Camus’s classic The Stranger, but it is a favorite text for teaching the history of decolonization. The Sea Battle of Navarino, Louis Ambroise Garneray, 1831 From Eurozine: A supranational construct of Europe that imposes boundaries but also makes them negotiable has contradiction built into its genetic code. Looking at maps of Europe at various times since antiquity, this hardly seems new – Europe’s external borders as well as its internal ones… From The Hunger Games, Lionsgate, 2012 by James Warner Battle Royale and The Hunger Games are young adult novels in which governments force teenagers to kill each other. Comparing these books to classic works by William Golding and Robert Sheckley suggests that, while becoming more skeptical about governments, we’ve become more trusting about our own…', '(Burial mask of Egyptian Pharaoh\xa0Tutankhamun; images courtesy of Huffpost and Deposit Photos.) The ancient Egyptians were of the belief that the bodies of the dead were to be preserved in order for the soul to have a place to dwell after death. The mummified corpses had masks that covered their faces; plaster for the common folk and masks made of precious metals like gold for royalty. One of the most famous burial masks belonged to Tutankhamun who was an Egyptian Pharaoh of the 18th dynasty. The mask is carved such that it has a nemes headcloth, bearing the royal insignia of a cobra and vulture. \xa0There are inlays of gemstones and coloured glass, quartz for the eyes, obsidian for the pupils, lapis lazuli around the eyes and eyebrows, turquoise, amazonite, faience carnelian, feldspar and other stones make up the inlays for the collar. This mask is now on public display in a museum in Cairo. (Illuminated manuscripts, Islamic and Christian; images courtesy of\xa0 Pinterest and Wikimedia.) An illuminated manuscript referred to manuscripts decorated with gold or silver in the form of borders or miniature illustrations. This practice of creating illuminated manuscripts prevailed in Islamic as well as European texts. (Kintsugi pottery; image courtesy of Ceramic School.) Gold dust and lacquer, that is what the Japanese use to fix what’s broken. Pottery in particular. Cracks are filled in with this combination which ultimately results in beautiful scars. It is called Kintsugi pottery, the basis of which lies in wabi-sabi, which in turn refers to acknowledging the beauty in imperfection. Gold; durable malleable gold has always been of immense value, for good reason, since time immemorial. (Visitors of the Belvedere Museum watch Gustav Klimt´s painting ‘Der Kuss’; image courtesy of Getty Images.) Gold in art; it would be remiss of us to leave out Gustav Klimt, especially with regard to the subject of gold leaf. Klimt was an Austrian artist, a Symbolist painter who lived and worked during the 19th century. Symbolism; as Symbolist poet Stéphane Mallarmé puts it is, “to depict not the thing but the effect it produces”.\xa0 The protagonists in his work were largely women, the female body played a consistent role and there was a degree of eroticism in his compositions that often made his work the subject of controversy. Klimt’s golden phase is what brought him a lot of critical acclaims and those artworks created during the said phase remain the most regaled of his body of work. He used a lot of gold in his paintings and is especially well known for his use of gold leaf. The Kiss is a painting by Klimt which consists of a perfect square that encloses a couple mid-embrace in elaborately embellished robes; Art Nouveau style. This famous painting is now housed by the Österreichische Galerie Belvedere museum in the Belvedere Palace, Vienna. (Judith and the Head of Holofernes Gustav Klimt Artist Gustav Klimt Year 1901; image courtesy of Pinterest.) Judith and the Head of Holofernes also known as Judith I is yet another famed golden painting by Klimt. The subject matter is biblical in nature and it represents Judith with the head of Holofernes (whom she decapitated herself). The composition is such that Judith is front and centre, the focus of the piece with the head of Holofernes in the corner, conveniently cropped out of the frame. Österreichische Galerie Belvedere museum in the Belvedere Palace, Vienna houses this work of art. (Gustav Klimt (1862-1918), Adele Bloch-Bauer I, 1907. Oil, silver, and gold on canvas; image courtesy of Christie’s.) Portrait of Adele Bloch-Bauer I, also known as The Woman in Gold is yet another famous painting in gold leaf by Gustav Klimt. It was a painting of a Jewish banker’s wife; Adele Bloch-Bauer, commissioned by the banker, it was embroiled in intriguing events of history wherein it was stolen by the Nazis but recovered years later in order to be returned to the family before being sold yet again. It is the last painting depicting his golden phase in its entirety. It is now displayed in the Neue Galerie, New York. If we’re going to talk about gold leaf, it’s best to begin with Gold beating. (The last artisan battiloro goldbeater in Europe; image courtesy of L’Italo-Americano Newsletter.) Gold beating is a process that has been in use since the time of the Egyptians. Gold is a metal that has always been known for its ductile quality and the fact that it is long-lasting in nature. Hence the process of hammering this precious metal became a technique frequently practised by craftsmen and artisans. Gold was hammered into the thinnest possible sheets, as thin as a leaf, which is where it got its name. The gold with an alloy such as silver or copper is melted then cast into bars which are run through rolling mills several times until they are close to an inch thick. These sheets are then cut into smaller sized pieces, wrapped in goldbeater’s skin (ox intestine membrane) or in modern times – polyester film about 150 in number and this wrapping is called a cutch. This is wrapped further in parchment to hold it all together; placed upon larger surfaces like marble or granite slabs that can withstand heavy blows. Then these are hammered again, for hours together, into thinner sheets as the packages are rotated and turned until the gold within expands somewhat equally in every direction. (Gold leaf tissue book; image courtesy of Pinterest.) They are then removed from the cutch, cut up equally and put into a packet called a shoder which is 100 times the number of skins used in the cutch. The packet is hammered for hours again until the gold expands to about 5-inch square. The pieces are then removed, cut further, coated with gypsum so that it doesn’t stick to the skin after which it is put into a mold for the final beating which again lasts a couple of hours and the gold is about 6 inches in diameter after which it is finally cut and placed in a book of tissue pages for safe keeping. (Athena Varvakeion, a\xa0small Roman replica of the Athena Parthenos by Phidias; image courtesy of Pinterest.) Mighty Athena and formidable Zeus; both with a core of wood and covered in carved ivory, embellished with gold, all at the hands of Phidias – sculptor of the Classical Greek era. Athena stands tall in the Parthenon at Athens at 40 ft.; Zeus is seated in the temple at Olympia, 36 ft. tall. These towering structures were known as Chryselephantine sculptures, the word chryselephantine itself suggests ivory covered in gold (chryso- is used in combination with another word to indicate the use of gold). The face, the arms and the legs of these figures were carved in ivory and the embellishments which consisted of armour, robes, jewellery/ accessories and locks (literally golden locks) were distinguishable from the ivory body parts because they were covered in gold leaf. (Statue of Zeus, The State Hermitage Museum, St. Petersburg; image courtesy of Pinterest.) However, nothing of the original art remains to this day with the exception of miniatures (replicas) from the archaic era and remnants of certain sculptures which lead to knowledge of these towering structures. Quite unfortunately and yet understandably, it is the expensive nature of the materials used that led the statues to be destroyed during the periods of warfare. More about the fascinating Gold leaf technique in the next post. (Tanjore painting of Lord Krishna; image courtesy of Pinterest.) 1600 AD is as far back as Tanjore paintings go. What are those, you ask? Thanjavur is a south Indian town, which is where this style of painting originated, hence the name. Tanjore paintings are famed for the gold coating that graces the surfaces of their artwork. Especially since most of the compositions were dedicated to portrayals of Gods and Goddesses wherein the application of gold gave the work a bit of life and seemed to inspire a sense of devotion in the worshippers who came across the work of art. Artwork depicting deities were often embellished with gemstones and glass beads and other ornaments in order to give it a royal look and a 3 dimensional one at that. The ornaments that adorned the deities, along with the clothing were made of pure gold as well. (Tanjore painting of Sri Lakshmi Devi; image courtesy of Pinterest.) Gold foil or gold dust is what was used most often in the application on the artwork/ paintings which gave the work a sheen that could last decades since gold isn’t as susceptible to corrosion and tarnishing as is the case with other metals. Gold can outlast most other metals which is what benefitted the artwork it was upon which it was used. This is strictly to Tanjore paintings and the manner in which they originated the trend that picked up in Indian painting traditions. Blog at WordPress.com.']","Portrait of Adele Bloch-Bauer I (also called The Lady in Gold or The Woman in Gold) is a painting by Gustav Klimt, completed between 1903 and 1907. The portrait was commissioned by the sitter's husband, Ferdinand Bloch-Bauer (de), a Jewish banker and sugar producer. The painting was stolen by the Nazis in 1941 and displayed at the Österreichische Galerie Belvedere. In 2006, following eight years of effort by the Bloch-Bauer heirs, the painting was returned to the family; it was sold the same year for $135 million, at the time a record price for a painting."
how chapters and verses are in the bible,"['The Bible is a compilation of many shorter books written at different times by a variety of authors, and later assembled into the biblical canon. All but the shortest of these books have been divided into chapters, generally a page or so in length, since the early 13th century. Since the mid-16th century, each chapter has been further divided into ""verses"" of a few short lines or sentences. Sometimes a sentence spans more than one verse, as in the case of Ephesians 2:8–9, and sometimes there is more than one sentence in a single verse, as in the case of Genesis 1:2. As the chapter and verse divisions were not part of the original texts, they form part of the paratext of the Bible. The Jewish divisions of the Hebrew text differ at various points from those used by Christians.  For instance, in Jewish tradition, the ascriptions to many Psalms are regarded as independent verses or parts of the subsequent verses, making 116 more verses, whereas the established Christian practice is to treat each Psalm ascription as independent and unnumbered.  Some chapter divisions also occur in different places, e.g. 1\xa0Chronicles 5:27–41 in Hebrew Bibles is numbered as 1\xa0Chronicles 6:1–15 in Christian translations. Bible verse across the street from the United Nations Building. Bible verse from Isaiah writen on a wall across the street from the United Nations Building in New York City The original manuscripts did not contain the chapter and verse divisions in the numbered form familiar to modern readers.  In antiquity Hebrew texts were divided into paragraphs (parashot) that were identified by two letters of the Hebrew alphabet.  Peh פ indicated an ""open"" paragraph that began on a new line, while Samekh ס indicated a ""closed"" paragraph that began on the same line after a small space.[1] These two letters begin the Hebrew words open (patuach) and closed (sagoor), and are, themselves, open פ and closed ס. The earliest known copies of the Book of Isaiah from the Dead Sea Scrolls used parashot divisions, although they differ slightly from the Masoretic divisions.[2] (This is different from the use of consecutive letters of the Hebrew alphabet to structure  certain poetic compositions, known as acrostics, such as several of the Psalms and most of the Book of Lamentations.) The Hebrew Bible was also divided into some larger sections.  In Israel the Torah (its first five books) were divided into 154 sections so that they could be read through aloud in weekly worship over the course of three years. In Babylonia it was divided into 53 or 54 sections (Parashat ha-Shavua) so it could be read through in one year.[2]  The New Testament was divided into topical sections known as kephalaia by the fourth century.  Eusebius of Caesarea divided the gospels into parts that he listed in tables or canons. Neither of these systems corresponds with modern chapter divisions.[3]  (See fuller discussions below.) Chapter divisions, with titles, are also found in the 9th century Tours manuscript, Paris Bibliothèque Nationale MS Lat. 3, the so-called Bible of Rorigo.[4] Archbishop Stephen Langton and Cardinal Hugo de Sancto Caro developed different schemas for systematic division of the Bible in the early 13th century. It is the system of Archbishop Langton on which the modern chapter divisions are based.[5][6][7] While chapter divisions have become nearly universal, editions of the Bible have sometimes been published without them.  Such editions, which typically use thematic or literary criteria to divide the biblical books instead, include John Locke\'s Paraphrase and Notes on the Epistles of St. Paul (1707),[8] Alexander Campbell\'s The Sacred Writings (1826),[9] Richard Moulton\'s The Modern Reader\'s Bible (1907),[10] Ernest Sutherland Bates\' The Bible Designed to Be Read as Living Literature (1936),[11] and The Books of the Bible (2007) from the International Bible Society (Biblica). Since at least 916 the Tanakh has contained an extensive system of multiple levels of section, paragraph, and phrasal divisions that were indicated in Masoretic vocalization and cantillation markings. One of the most frequent of these was a special type of punctuation, the sof passuq, symbol for a full stop or sentence break, resembling the colon (:) of English and Latin orthography. With the advent of the printing press and the translation of the Bible into English, Old Testament versifications were made that correspond predominantly with the existing Hebrew full stops, with a few isolated exceptions. Most attribute these to Rabbi Isaac Nathan ben Kalonymus\'s work for the first Hebrew Bible concordance around 1440.[6] The first person to divide New Testament chapters into verses was Italian Dominican biblical scholar Santi Pagnini (1470–1541), but his system was never widely adopted.[12] His verse divisions in the New Testament were far longer than those known today.[13] Robert Estienne created an alternate numbering in his 1551 edition of the Greek New Testament [14] which was also used in his 1553 publication of the Bible in French. Estienne\'s system of division was widely adopted, and it is this system which is found in almost all modern Bibles. Estienne produced a 1555 Vulgate that is the first Bible to include the verse numbers integrated into the text. Before this work, they were printed in the margins.[13] The first English New Testament to use the verse divisions was a 1557 translation by William Whittingham (c. 1524–1579). The first Bible in English to use both chapters and verses was the Geneva Bible published shortly afterwards in 1560. These verse divisions soon gained acceptance as a standard way to notate verses, and have since been used in nearly all English Bibles and the vast majority of those in other languages.  (Nevertheless, some Bibles have removed the verse numbering, including the ones noted above that also removed chapter numbers; a recent example of an edition that removed only verses, not chapters, is The Message: The Bible in Contemporary Language by Eugene H. Peterson.)[15] Most important are the verse endings. According to the Talmudic tradition, the division of the text into verses is of ancient origin. In Masoretic versions of the Bible, the end of a verse is indicated by a small mark in its final word called a silluq (which means ""stop""). Less formally, verse endings are usually also indicated by two horizontal dots following the word with a silluq. The Masoretic textual tradition also contains section endings called parashot, which are usually indicated by a space within a line (a ""closed"" section) or a new line beginning (an ""open"" section). The division of the text reflected in the parashot is usually thematic. Unlike chapters, the parashot are not numbered, but some of them have special titles. In early manuscripts (most importantly in Tiberian Masoretic manuscripts, such as the Aleppo codex), an ""open"" section may also be represented by a blank line, and a ""closed"" section by a new line that is slightly indented (the preceding line may also not be full). These latter conventions are no longer used in Torah scrolls and printed Hebrew Bibles. In this system, the one rule differentiating ""open"" and ""closed"" sections is that ""open"" sections must always start at the beginning of a new line, while ""closed"" sections never start at the beginning of a new line. Another division of the biblical books found in the Masoretic text is the division of the sedarim. This division is not thematic, but is almost entirely based upon the quantity of text. For the Torah, this division reflects the triennial cycle of reading that was practiced by the Jews of the Land of Israel. The Byzantines also introduced a concept roughly similar to chapter divisions, called kephalaia (singular kephalaion, literally meaning heading). This system, which was in place no later than the 5th century, is not identical to the present chapters. Unlike the modern chapters, which tend to be of roughly similar length, the distance from one kephalaion mark to the next varied greatly in length both within a book and from one book to the next.  For example, the Sermon on the Mount, comprising three chapters in the modern system, has but one kephalaion mark, while the single modern chapter 8 of the Gospel of Matthew has several, one per miracle.  Moreover, there were far fewer kephalaia in the Gospel of John than in the Gospel of Mark, even though the latter is the shorter text. In the manuscripts, the kephalaia with their numbers, their standard titles (titloi) and their page numbers would be listed at the beginning of each biblical book; in the book\'s main body, they would be marked only with arrow-shaped or asterisk-like symbols in the margin, not in the text itself. The titles usually referred to the first event or the first theological point of the section only, and some kephalaia are manifestly incomplete if one stops reading at the point where the next kephalaion begins (for example, the combined accounts of the miracles of the Daughter of Jairus and of the healing of the woman with a haemorrhage  gets two marked kephalaia, one titled of the daughter of the synagogue ruler at the beginning when the ruler approaches Jesus and one titled of the woman with the flow of blood where the woman enters the picture – well before the ruler\'s daughter is healed and the storyline of the previous kephalaion is thus properly concluded). Thus the kephalaia marks are rather more like a system of bookmarks or links into a continuous text, helping a reader to quickly find one of several well-known episodes, than like a true system of chapter divisions. Cardinal Hugo de Sancto Caro is often given credit for first dividing the Latin Vulgate into chapters in the real sense, but it is the arrangement of his contemporary and fellow cardinal Stephen Langton who in 1205 created the chapter divisions which are used today. They were then inserted into Greek manuscripts of the New Testament in the 16th century. Robert Estienne (Robert Stephanus) was the first to number the verses within each chapter, his verse numbers entering printed editions in 1551 (New Testament) and 1571 (Hebrew Bible).[16] The division of the Bible into chapters and verses has received criticism from some traditionalists and modern scholars. Critics state that the text is often divided in an incoherent way, or at inappropriate rhetorical points, and that it encourages citing passages out of context. Nevertheless, the chapter and verse numbers have become indispensable as technical references for Bible study. Several modern publications of the Bible have eliminated numbering of chapters and verses. Biblica published such a version of the NIV in 2007 and 2011. In 2014, Crossway published the ESV Reader\'s Bible and Bibliotheca published a modified ASV.[17] Projects such as Icthus[18] also exist which strip chapter and verse numbers from existing translations.', 'With lots of New Year Resolutions floating around, I wonder if any have resolved to dig deeper into the bible this year.\xa0 Do you set out with good intentions to read the Bible but get bogged down in the language, such as “he begot this person and that person begot that person” for an example?\xa0 I know I have really tried to set my mind to exploring and understanding the bible, but the verbiage gets me at times.\xa0 But there’s more to the Bible, and that is where this book comes in! I was actually surprised how this book broke things down.\xa0 For example, we all know that the Bible consists of the Old Testament and the New Testament.\xa0 We probably all were taught in Sunday School that there are 66 total books of the Bible.\xa0 Maybe you even had to recite the books of the Bible like I had to growing up.\xa0 Well, this book takes it further in exploring the Old Testament, which goes from creation, through the life of Jewish people, and right on up to the time of Christ.\xa0 There are 39 books of the Bible in the Old Testament, with 28 authors writing over a span of two thousand years.\xa0 Did you know that?\xa0 I didn’t!\xa0 Further, the New Testament tells of the birth of Jesus, His life and ministry, and the ministry of His disciples that was carried on after His crucifixion.\xa0 There are 27 books of the Bible in the New Testament, with nine authors writing over a span of less than one hundred years. This book goes a step further in explaining the Old Testament, with 17 historical, five poetical, and 17 prophetical books of the Bible.\xa0 Likewise, the New Testament is broken down into five historical, 13 Pauline Epistles to the churches, and nine General Epistles. You don’t have to try to absorb ALL of the bible in one sitting.\xa0 That’s virtually impossible.\xa0 Even if you could read it all in a day, you wouldn’t be able to comprehend it all.\xa0 With the aid of this book, however, you will gain more insight and understanding with just taking 15 minutes a day to devote to this cause.\xa0 Further, they have fill in the blank areas within the book so you can jog your memory on what you just learned as you go along.\xa0 This is done in an effort for you to retain the material later. As I held this book in my hands, the first person I thought of was my father.\xa0 Through the years, his faith has really been tested and tried.\xa0 He’s gone from being a firm believer, to being on shaky ground after losing his oldest daughter so tragically.\xa0 Finally, after years of us praying over him, my dad was able to come to terms with his anger over the loss of his precious daughter and turn back to God.\xa0 In doing so, he tried to dive into the Bible to gain further understanding and comfort with the Word of God.\xa0 He began praying heartfelt, almost preacher-worthy prayers, which surprised us but comforted us at the same time.\xa0 This was the Godly man my heart knew, loved, and remembered from my childhood.\xa0 He has returned! Knowing my father’s desire to learn more about the Bible, I presented him with a copy of this book as one of his Christmas gifts this past year.\xa0 He held it in his hands looking down at the cover, then slowly started thumbing through the pages.\xa0 I could tell it definitely stirred something within his soul, and then he spoke, “I have been wanting to learn more about the Bible, so this is going to really come in handy in the new year.” And my heart smiled. Many thanks to Propeller Consulting, LLC for providing this book for my review. Maybe you have heard of Anne Wilson or even heard her beautiful song “My Jesus.”\xa0 Or maybe this is the first time you are hearing of her.\xa0 Whatever the case, Anne is a Jesus-loving lady that is on fire for Him. Anne and her brother, Jacob, and sister, Elizabeth, grew up with beautiful, loving parents […] Just recently, someone dear to me endured the “wrath” of several individuals who tried to “put her in her place” because she didn’t act or react the way they wanted her to.\xa0 ~insert the biggest eye roll ever here~ News Flash:\xa0 We are individuals that have free will, a mind of our own, with morals, […] This week I had a lot of time on my hands as I stayed two nights in the hospital with my loved one after surgery. \xa0While the patient was sleeping, I began reading The Flirtation Experiment co-written by Lisa Jacobson and Phylicia Masonheimer. The book allowed me to pass the time instead of watching the […] Your email address will not be published. Required fields are marked * Save my name, email, and website in this browser for the next time I comment. Notify me of follow-up comments by email. Notify me of new posts by email. This site uses Akismet to reduce spam. Learn how your comment data is processed. Shirley is the proud mother of two beautiful young ladies.  She enjoys spending time with them on their ranch in the deep South with their three paint horses.  Always looking for an adventure, she looks forward to hikes in the mountains chasing waterfalls, or scouring the coast for beautiful lighthouses!  Shirley writes to encourage others and often times shares things that motivate and inspire her.  She believes in living life to the fullest because no one is promised the gift of another day.  Join her as we honor our bodies, minds, hearts, souls, and our Almighty Creator, God above!', 'The Bible is a compilation of many shorter books written at different times by a variety of authors, and later assembled into the biblical canon. Since the early 13th century, most copies and editions of the Bible present all but the shortest of these books with divisions into chapters, generally a page or so in length. Since the mid-16th century editors have further subdivided each chapter into verses – each consisting of a few short lines or sentences. Early manuscripts of the biblical texts did not contain the chapter and verse divisions in the numbered form familiar to what we have today, rather, they form part of the paratext of the Bible. The Jewish divisions of the Hebrew text differ at various points from those used by Christians. For instance, in Jewish tradition, the ascriptions to many Psalms are regarded as independent verses or parts of the subsequent verses, making 116 more verses, whereas established Christian practice treats each Psalm ascription as independent and unnumbered. Some chapter divisions also occur in different places, e.g. Hebrew Bibles have 1 Chronicles 5:27–41 where Christian translations have 1 Chronicles 6:1–15 The Bible was divided into chapters and verses to help us find Scriptures more quickly and easily. It is much easier to find “John chapter 3, verse 16” than it is to find “for God so loved the world…” In a few places, chapter breaks are poorly placed and as a result divide content that should flow together. Overall, though, the chapter and verse divisions are very helpful. The chapter divisions commonly used today were developed by Stephen Langton, an Archbishop of Canterbury. Langton put the modern chapter divisions into place in around A.D. 1227. The Wycliffe English Bible of 1382 was the first Bible to use this chapter pattern. Since the Wycliffe Bible, nearly all Bible translations have followed Langton’s chapter divisions. The Hebrew Old Testament was divided into verses by a Jewish rabbi by the name of Nathan in A.D. 1448. Robert Estienne, who was also known as Stephanus, was the first to divide the New Testament into standard numbered verses, in 1555. Stephanus essentially used Nathan’s verse divisions for the Old Testament. Since that time, beginning with the Geneva Bible, the chapter and verse divisions employed by Stephanus have been accepted into nearly all the Bible versions. Save my name, email, and website in this browser for the next time I comment. Notify me of follow-up comments by email. Notify me of new posts by email.', '', 'Sorry the page you’re looking for doesn’t exist. Go back to the homepage © 2023 C3SYD. All rights reserved.\xa0 \xa0 \xa0Privacy Policy\xa0 \xa0 \xa0 Terms of Service.\xa0 \xa0 \xa0 (02) 9972 8688', 'Jesus said, “I came into this world for judgment so that those who do not see may see, and those who do see may become blind.” John 9:39 I can’t read anymore. For most of my life, I have had excellent vision. For more than ten years now, I have worn glasses. For most things, especially things that are not too close, I can see fine without my glasses. But now, without glasses, I cannot see to read anything in normal print. Reading is an important part of Christian faith. You do not have to be able to read to know Jesus as your Savior or to live a life of faith. Many have done so. But our faith depends on the revelation God has given us through the Bible. We believe that the Bible is essential to our understanding of all that we know about God. But the Bible is a big book. There is a lot of material there. Most of us have our favorite parts, the books and verses that we return to over and over for comfort and strength. The Bible is comprised of 66 books, written by many authors and compiled over 1000 years or so. How do we understand how all of these words apply to our life of faith? This has been the subject of many long discussions among pastors and Christian teachers ever since the idea of sacred scripture began. I don’t have space here to say all that needs to be said about this important idea. But there is one focus of Bible interpretation that I think Christians should always remember as the foundation of how we read the Bible. “The church’s one foundation is Jesus Christ her Lord.” That’s how the old hymn puts it. This is the foundation of our understanding of all of the Bible. The words and actions of Jesus as described in the gospels should be central to how we understand all that the Bible has to say. The life and teachings of Jesus in the gospels are the lens through which we see more clearly what the rest of the Bible teaches us about faith. Through our faith in Jesus, through His words and life, we can also say, “I was blind, but now I see.” Notify me of new comments via email. Notify me of new posts via email.', '']","The Bible is a compilation of many shorter books written at different times by a variety of authors, and later assembled into the biblical canon. Since the early 13th century, most copies and editions of the Bible present all but the shortest of these books with divisions into chapters, generally a page or so in length. Since the mid-16th century editors have further subdivided each chapter into verses-each consisting of a few short lines or sentences. Sometimes a sentence spans more than one verse, as in the case of Ephesians 2: 8 -- 9, and sometimes there is more than one sentence in a single verse, as in the case of Genesis 1: 2."
where did the dove peace symbol come from,"['A very unusual 15ct62.5% pure gold (or 625 parts pure gold and 375 parts other metals). Popular during the Victorian, Edwardian and Art Deco eras but was discontinued in the mid-1930s. gold locket that opens to reveal seven compartments that can hold twelve photographs in total. On the front is a dove of peace. The dove has a small cabochonA polished, not faceted, dome shaped stone - either round or oval with a flat polished base, primarily used as a cut for phenomenal stones such as cat\'s eyes and stars. rubyOne of the most valuable gemstones on earth. From the corundum family, the red variety being ruby and the blue, sapphire. With the exception of the diamond, corundum is the hardest of the gemstones on the Mohs scale scoring a 9. in it’s eye and the olive branch is set with three naturalA natural stone is called such because it has not been subjected to any treatments.\xa0 pearls. The use of a dove and olive branch as a symbol of peace originated with the early Christians, who portrayed the act of baptism accompanied by a dove holding an olive branch in its beak. So what a wonderful meaning and this locket would be ideal for holding photographs of your children. Secretive, sentimental and sweet, lockets are a guaranteed hit with any girl. Here are some ideas for making yours uniquely personal. Buying antique jewellery is both ethical and eco-friendly as harmful and destructive mining processes are not needed to make an item yours. So give yourself a pat on the back! Purchased 5 or 6 items already from this shop and every time I am happy with the results. Quick shipment to Germany. Really satisfied, returning customer."" ""The Interest Free Finance which is now available is also super easy to set up and use. Couldn\'t recommend AJC more highly! (She said yes!)"" ""The place to find unusual and beautiful jewellery.  Service is friendly and helpful and delivery extremely prompt."" ""I love my ring so much. I\'ve worn it everyday, even when I\'m sleeping. Your collection and service are excellent. I woukd like to get my next one at your shop."" ""Great website, great selection, London based, excellent & quick customer service. 10/10"" ""Always wonderful to work with. Piece was even beyond expectation! I will be back for more wonderful items!!"" ""I live in Canada and was initially quite concerned at the prospect of buying jewellery online. However I could not be happier with my purchase and the speed in which I received my item. Could not say enough good things about the ring I purchased. Thank you."" ""Buying an engagement ring isn\'t an easy experience but the team not only made the process pain free, they also helped me pick the perfect ring. Friendly, knowledgeable and with a great selection of antique rings. Would highly recommend."" ""Stellar team, great customer experience, knowledgeable and friendly. Will definitely be back"" ""Amazing company, friendly and helpful staff, they’ve helped me choose the most beautiful gifts. I cannot recommend them enough."" ""Great customer service. Very helpful. Beautifully packaged. Could not have asked for more! Highly recommended."" ""I bought my gorgeous Georgian ring from this company and they have fulfilled all my expectations. It had to be resized and they did a beautiful job considering the design of the ring and the postage was insanely quick! The packaging of my new ring was absolutely gorgeous. Finished with a bow!"" ""This is my favorite antique store to visit in London. I\'ve been there my last two trips to London and each time I\'ve gotten amazing pieces. Olly has a great eye and a wonderful collection to select from. I definitely plan on going the next time I\'m in London! ""I could not be happier with the customer service. Beautifully sourced antique jewellery, in a great central and traditional location. One very happy groom to be (fingers crossed)!"" ""Excellent service with personal attention to detail and the item fully matching the description and photograph. This is the first place I will go to for future purchases of fine antique jewellery."" ""Thank you for the whole experience. The website, your help and efficiency could hardly be bettered. Looking forward to seeing my new purchase."" ""I live in the United States, and working with AJC was easier than going into a store here! They were easily accessible and we even did a video Skype session for additional looks. They had the ring sized and out and shipped to the USA by the next day. Simply an amazing customer experience!"" ""Fabulous service and customer care. I was very happy with the ring I purchased, it was just as beautiful in real life as displayed on the website. I would highly recommend The Antique Jewellery Company."" ""Can\'t say enough about the amazing service we received. They have the most exquisite selection of jewellery and really take the time to help you decide. I would strongly recommend a visit."" ""Olly was so lovely and helpful, which is exactly what you need when you\'re buying an engagement ring."" ""Service was unbeatable - worked to an extremely tight time scale and delivered without a hitch. The ring is perfect and I\'m proud to see it on the hand of my fiancé. You guys have made us both very happy!"" ""Excellent service - very personal, engaged and attentive. From advice on the provenance and suitability of the rings I had chosen, from a very well presented website, to ensuring that they arrived on time  - faultless!"" Monday – Friday, 11.00am – 6.30pm (GMT) Any item may be reserved for up to 72 hours. For longer you can pay a 20% non-refundable deposit to secure your item and pay the remainder off over up to 3 months. Reserving an item does not occur automatically so there may be a short delay while we recieve your request. To purchase this item click Add to Basket. When you are happy, click Shopping Bag in the top right of the screen and follow our simple and secure checkout. Alternatively you can call us directly on +44 (0)20 7206 2477 to process the payment manually. While every piece of antique jewellery is unique, we are happy to notify you if we find something similar to this item. We are constantly buying, so your dream piece may be just around the corner. To get the ball rolling please fill in the form below, remembering to provide us with as much information as possible. When a customer asks us to put an item on hold, we set it aside for 72 hours. If this item is released from hold we will contact you immediately. Please use the form below to be placed on our waiting list. Sign up and we\'ll give you 200 points to get you started. So what are you waiting for? To request more images of this item, please fill in the form below. Why not book an appointment at our Central London Showroom to see this item in the flesh. To reserve your appointment, please fill in this form. Alternatively you can call us directly on +44 (0)20 7206 2477 or email us at enquiries@antiquejewellerycompany.com. We’re pleased to offer our customers in the UK the chance to spread the cost of their purchase with up to 12 months Interest Free Finance. On orders of £262.50 and above, you can apply for Interest Free Finance  and choose between 3, 6, 9 or 12 month periods to pay off the cost, with a minimum deposit of 5%. If you would like to pay using Finance, please contact us and let us know what arrangement would work for you. Applying for finance is similar to applying for a new credit card. The details you provide are checked against public registers, such as credit rating agencies. To increase the chances of acceptance, ideally, you will have a good credit history (no late payments, CCJs, etc) and meet the following minimum criteria: Applying for finance is similar to applying for a new credit card. The details you provide are checked against public registers, such as credit rating agencies. To increase the chances of acceptance, ideally, you will have a good credit history (no late payments, CCJs, etc) and meet the following minimum criteria: To apply for online finance, you must be over the age of 18, work at least 16 hours a week, or be retired with an income. You must also be a resident of the United Kingdom and have lived in the UK for the last 3 years or more. Your monthly repayments will begin one month after your purchase has been delivered. Yes, All repayments will be taken by direct debit from the finance company. No. There are no arrangement fees or hidden extras. Within minutes of your application being approved, you will be presented with the option to sign your credit agreement. You should read the credit agreement carefully before clicking all the relevant sections agreeing to its terms. Once you have agreed to the terms of the credit agreement The Antique Jewellery Company will be notified and you need do nothing more. Please note that products will not be allocated to your order until your completed and signed agreement is returned and received by etika Finance UK Ltd. Shipment of your goods will follow soon after your agreement has been returned and received. In order to safeguard against fraudulent applications, we regret that we\'re able only to deliver goods to the home address of the applicant. Credit scoring is the process used by financial services companies to evaluate the credit risk of new applicants. \xa0This technique will be applied to your application for online finance. Credit scoring works by awarding points for each answer given on the application form such as age, income and occupation, together with information obtained from credit reference agencies. \xa0This information allows us to produce consistent decisions, ensuring all our applicants are treated fairly. The credit scoring process does not discriminate on the grounds of sex, race, religion or disability. In addition to credit scoring, we also take into account confirmation of your identity, validation of certain application details, existing commitments and information held at the credit reference agencies. Though we are unable to provide you with a main reason for decline of your application, it is usually based on one, or a combination of the following: Yes. We acknowledge that your circumstances change and just because we have refused a previous application, it does not mean that we\'ll automatically turn down a further request. We do suggest however, that you leave at least 6 months between applications. Some of the information is public information, for example electoral roll, County Court Judgements and bankruptcies. Other lenders may also file information about accounts you hold with them for instance this could include your payment history and outstanding balance on these accounts. Any requests for credit, where a credit reference search has been undertaken, will also be filed, although the result of the request is not recorded. etika (a trading name of etika Finance UK Ltd) is a company registered in England and Wales (07440512) and authorised and regulated by the Financial Conduct Authority (registration number: 697658, company address: WeWork, No.1 Spinningfields, Quay Street, Manchester, M3 3JE). For more information please visit www.etika.com/uk. All our items will arrive in our complimentary blue AJC boxes, which we think are very smart. They will be wrapped in tissue and accompanied by a handwritten note confirming the piece\'s authenticity. If you would like to include a personal note to the recipient, then you can add this during checkout. In many countries, import tax/duty does not apply when purchasing antiques aged over 100 years old. We will therefore declare these items as ‘antique’, providing a signed and dated Antique Declaration. Please be aware that you may be liable to pay local tax/duty or handling fees on imported goods. Usually your country will have a website or customs office providing you with the relevant rates. Please let us know if you are contacted by customs requesting supporting documents. Further partial restrictions on importation of items such as ours exist in specific countries. Please contact us to make sure your country does not fit into this bracket. We have no authority over a local country\'s customs department. Our jewellery is Conflict Free and Eco-Friendly and when purchasing an item from us you can be sure you are not contributing to any unethical procedures. When buying new jewellery you can never be 100% sure that they are not conflict free. At The AJC we stand behind every item we sell with a 100% Satisfaction Guarantee and are confident that your jewellery purchase will exceed your expectations. However, if you are not entirely satisfied with your purchase, we offer a 30 Day, Full Money-Back Guarantee on all purchases. Contact us within 30 days of receipt of the item to let us know of your intention to return the item/s. Return the item/s to us within the original packaging (including padded envelope). Attach the two DHL return labels provided to the outside of the parcel. Drop off the parcel at your nearest DHL Service Point. The buyer pays return postage and any taxes and duties applied. Contact us within 30 days of receipt of the item to let us know of your intention to return the item/s. We strongly recommend that you return the item/s via DHL Express International as we are not responsible for items that do not reach us. Import tax/duty may also be applied by UK customs if the item/s are not shipped correctly. Return the item/s to us within the original packaging (including padded envelope). Attach the DHL return label supplied with your order to the outside of the parcel. If you are only returning part of your order, we will need to send you a new DHL return label. Drop off the parcel at your nearest DHL Service Point, and hand the shipper the Antique Declaration that was attached to the outside of the original DHL envelope. Please request a copy from us if this has been misplaced. Please be aware that international customs duties and sales taxes are NOT refunded for shipments outside the UK. We value our customers\' peace of mind over everything.We therefore created our 5 point promise. We take great pride in our collection of antique jewellery, one that embodies only the very best from across the ages. Under no circumstances will you find any reproductions and, unless stated clearly, all our items are in good condition and 100% original, free from enhancements. All our items are one-offs, quite often commissions, meticulously handmade by skilled craftsmen of old. With the steady increase in international, mass-produced jewellery, our antique jewellery has a timeless beauty and charm that simply cannot be replicated. With over 35 years of experience in the London trade, Olly Gerrish has a reputation as one of London\'s leading antique jewellery authorities; only the best examples from her stock are selected for the site. Investing in a piece of antique jewellery can be a daunting process. We value our customers\' confidence and peace of mind above all and strive to uphold a culture of trust and decency at all times. Our reputation for providing expert advice and support for our customers should reassure prospective customers. Should a customer for any reason be unhappy with their online purchase we will not hesitate to offer them a 30 day full money back guarantee. Finding the perfect piece should be a fun and enlightening experience. To help achieve this we are here to lend our customers a helping hand and provide impartial expert advice. Building lasting relationships is far more important to us than a quick sale. We are pleased to offer Complimentary Sizings on all ring purchases, undertaken by one of the best jewellers in the business. We offer our customers in the UK the chance to spread the cost of their purchase with up to 12 months Interest Free Finance. To discuss what works for you please contact us. We can hold items for up to 72 hours. Please contact us to let us know if you wish to put an item on hold. Alternatively, items may be reserved for up to 3 months, with a 20% non-refundable deposit. Please note that this is offered on a case-by-case basis depending on the item in question. All transactions are processed by Stripe, our third-party payment partner. Stripe is highly secure, using industry-leading technology to keep your information safe. Visit the Stripe website for more information. The Antique Jewellery Company does not store any financial information.', '']","The use of a dove and olive branch as a symbol of peace originated with the early Christians, who portrayed the act of baptism accompanied by a dove holding an olive branch in its beak and also used the image on their sepulchres."
